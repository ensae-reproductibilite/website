::: {.application}

## Application 16a: Dissocier entraînement et évaluation

[^skops]: [`skops`](https://skops.readthedocs.io/en/stable/index.html) est une nouvelle librairie développée par _Probabl_, la startup derrière `Scikit`. Elle vise à sécuriser la réutilisation de modèles de _machine learning_ afin d'éviter que du code malicieux soit exécuté lors de l'ouverture d'un modèle entraîné par quelqu'un d'autre. Elle est progressivement amenée à se substituer à `joblib`, la librairie qui permettait jusqu'à présent d'enregistrer sous forme persistente et réutiliser un modèle de machine learning.  

- Installer `fastAPI`, `uvicorn` et `skops`[^skops]. N'oubliez pas que nous n'utilisons plus `pip install` pour cela.  
- Renommer le fichier `main.py` en `train.py`. 
- Dans ce script, ajouter une sauvegarde du modèle après l'avoir entraîné, en suivant la [documentation de Scikit](https://scikit-learn.org/stable/model_persistence.html#skops-io).
- Faire tourner `train.py` pour enregistrer en local votre modèle de production. Optionnel: tester la lecture du modèle depuis un _notebook_ et une inférence sur un exemple inventé. 

- Ajouter `model.skops` au `.gitignore` car `Git` n'est pas fait pour ce type de fichiers.

- Modifier les appels à `main.py` dans votre `Dockerfile` et vos actions `Github` sous peine d'essuyer des échecs lors de vos actions `Github` après le prochain _push_.

Nous allons maintenant passer au développement de l'API. Comme découvrir `FastAPI` n'est pas l'objet de cet enseignement, nous donnons directement le modèle pour créer l'API. Si vous désirez tester de vous-mêmes, vous pouvez créer votre fichier sans vous référer à l'exemple.
:::


::: {.application}
## Application 16b: Utiliser une API pour l'inférence

- Créer le fichier `app/api.py` permettant d'initialiser l'API:


<details>
<summary>
Fichier `app/api.py`
</summary>

```{.python include="./applications/code/appli17_api_main.py" filename="app/api.py"}
```

</details>

- Déployer l'API en local avec la commande suivante.

```{.bash filename="terminal"}
uv run uvicorn app.api:app
```

- Observer l'*output* dans la console. Notre API est désormais déployée en local, plus précisément sur le *localhost*, un serveur web local déployé à l'adresse `http://127.0.0.1`. L'API est déployée sur le port par défaut utilisé par `uvicorn`, soit le port `8000`. 
- **Sans fermer le terminal précédent**, ouvrir un nouveau terminal. Tester le bon déploiement de l'API en requêtant son *endpoint*. Pour cela, on envoie une simple requête `GET` sur le *endpoint* via l'utilitaire `curl`.

```{.bash filename="terminal"}
curl "http://127.0.0.1:8000"
```

- Si tout s'est bien passé, on devrait avoir récupéré une réponse (au format `JSON`) affichant le message d'accueil de notre API. Dans ce cas, on va pouvoir requêter notre modèle via l'API.

- En vous inspirant du code qui définit le *endpoint* `/predict` dans le code de l'API (`app/api.py`), effectuer sur le même modèle que la requête précédente une requête qui calcule la survie d'une femme de `32` ans qui aurait payé son billet `16` dollars et aurait embarqué au port `S`.

<details>
<summary>
Solution
</summary>

```{.bash filename="terminal"}
curl "http://127.0.0.1:8000/predict?sex=female&age=32&fare=16&embarked=S"
```

</details>

- **Toujours sans fermer le terminal qui déploie l'API**, ouvrir une session `Python` et tester une requête avec des paramètres différents, avec la librairie `requests` :

<details>
<summary>
Solution
</summary>

```{.python}
import requests

URL = "http://127.0.0.1:8000/predict?sex=male&age=25&fare=80&embarked=S"
requests.get(URL).json()
```

</details>

- Une fois que l'API a été testée, vous pouvez fermer l'application en effectuant <kbd>CTRL</kbd>+<kbd>C</kbd> depuis le terminal où elle est lancée.

:::

{{< checkpoint appli16 >}}

