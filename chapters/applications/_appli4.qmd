Pour commencer, cet exercice fait un petit pas de côté pour faire comprendre la manière dont les _pipelines_ scikit sont un outil au service des bonnes pratiques.

::: {.application}
## Application 4 (optionnelle): pourquoi utiliser un _pipeline_ `Scikit` ?

* Le _pipeline_ `Scikit` d'estimation et d'évaluation vous a été donné tel quel. Regardez, ci-dessous, le code équivalent sans utiliser de _pipeline_ `Scikit`:

<details>

<summary>

Le code équivalent sans _pipeline_

</summary>

```{.python include="./applications/code/_appli4_no_pipeline.py"}
```

</details>

* Voyez-vous l'intérêt de l'approche par _pipeline_ en termes de lisibilité, évolutivité et fiabilité ?

* Créer un _notebook_ qui servira de brouillon. Y introduire le code suivant:

<details>

<summary>

Le code à copier-coller dans un _notebook_

</summary>

```{.python include="./applications/code/_appli4_pipeline.py"}
```

</details>

* Afficher ce pipeline dans une cellule de votre _notebook_. Cela vous aide-t-il mieux à comprendre les différentes étapes du _pipeline_ de modélisation ?

* Comment pouvez-vous accéder aux étapes de _preprocessing_ ?

<!-------
pipe['preprocessor'] ou pipe[:-1]
--------->

* Comment pouvez-vous faire pour appliquer le _pipeline_ de _preprocessing_ des variables numériques (et uniquement celui-ci) à ce _DataFrame_ ?

<details>

<summary>

Le _DataFrame_ à créer pour appliquer un bout de notre _pipeline_

</summary>

```python
import numpy as np

new_data = {
    "Age": [22, np.nan, 35, 28, np.nan],
    "Fare": [7.25, 8.05, np.nan, 13.00, 15.50]
}

new_data = pd.DataFrame(new_data)
```

</details>

<!-------
preprocessor_numeric = pipe['preprocessor']['Preprocessing numerical']
new_data_preprocessed = preprocessor_numeric.transform(new_data)

pd.DataFrame(
    new_data_preprocessed,
    columns=preprocessor_numeric[:-1].get_feature_names_out()
)
--------->

* Normalement ce code ne devrait pas prendre plus d'une demie-douzaine de lignes. Sans _pipeline_ le code équivalent, beaucoup plus verbeux et moins fiable, ressemble à celui-ci

```{.python include="./applications/code/_appli4_no_pipeline_numerical_feature.py"}
```

* Imaginons que vous ayez déjà des données préprocessées:

<details>

<summary>

Créer des données _préprocessées_

</summary>

```python
import numpy as np
import pandas as pd

new_data = pd.DataFrame({
    "Age": [25, np.nan, 40, 33, np.nan],
    "Fare": [10.50, 7.85, np.nan, 22.00, 12.75],
    "Embarked": ["S", "C", np.nan, "Q", "S"],
    "Sex": ["male", "female", "male", np.nan, "female"]
})
new_y = np.random.randint(0, 2, size=len(new_data))

preprocessed_data = pd.DataFrame(
    pipe[:-1].transform(new_data),
    columns = preprocessor_numeric.get_feature_names_out()
)
preprocessed_data
```

</details>

* Déterminer le score en prédiction sur ces données

<!------
pipe[-1].score(preprocessed_data, new_y)
------->

:::

Maintenant, revenons à notre chaine de production et appliquons des fonctions pour la rendre plus lisible, plus fiable et plus modulaire.

::: {.application}
## Application 4: adoption des standards de programmation fonctionnelle

Cette application peut être chronophage, vous pouvez aller plus ou moins
loin dans la fonctionalisation de votre script en fonction du temps dont vous
disposez.


* Créer une fonction générique pour réduire la redondance de code
 dans l'étape d'exploration des données où on utilise `split` ;
* Créer une fonction qui réalise le *split train/test* en fonction d'un paramètre représentant la proportion de l'échantillon de test
et d'arguments optionnels sur les chemins d'écriture des deux échantillons en csv.
* Créer une fonction qui intègre les différentes étapes du _pipeline_ (preprocessing et définition du modèle). Cette fonction prend
en paramètre le nombre d'arbres (argument obligatoire) et des arguments optionnels supplémentaires (les colonnes sur lesquelles s'appliquent les différentes étapes du _pipeline_, `max_depth` et `max_features`).
* Créer une fonction d'évaluation renvoyant le score obtenu et la matrice de confusion, à l'issue d'une estimation (mais cette estimation est faite en amont de la fonction, pas au sein de celle-ci)
- Déplacer toutes les fonctions ensemble, en début de script. Si besoin, ajouter des paramètres à votre fichier d'environnement pour créer de nouvelles variables comme les chemins des données.
:::

[^notepandas]: Au passage vous pouvez noter que mauvaises pratiques discutables,
    peuvent
    être corrigées, notamment l'utilisation excessive de `apply` là où
    il serait possible d'utiliser des méthodes embarquées par `Pandas`.
    Cela est plutôt de l'ordre du bon style de programmation que de la
    qualité formelle du script. Ce n'est donc pas obligatoire mais c'est mieux.


::: {.callout-important}
Le fait d'appliquer des fonctions a déjà amélioré la fiabilité du processus
en réduisant le nombre d'erreurs de copier-coller. Néanmoins, pour vraiment
fiabiliser le processus, il faudrait utiliser un _pipeline_ de transformations
de données.

Ceci n'est pas encore au programme du cours mais le sera dans une prochaine
version.
:::


{{< checkpoint appli4 >}}
