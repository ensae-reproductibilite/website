---
title: "Rendre son projet de data science portable et reproductible"
date: 2022-03-03
author: "Romain Avouac et Lino Galiana"
draft: false
# layout options: single, single-sidebar
layout: single
---


# La notion de portabilit√©

Dans les chapitres pr√©c√©dents, nous avons vu un ensemble de bonnes pratiques qui permettent de consid√©rablement am√©liorer la qualit√© d'un projet : rendre le code plus lisible, adopter une structure du projet normalis√©e et √©volutive, et versionner proprement son code sur un d√©p√¥t `GitHub`.

Une fois ces bonnes pratiques appliqu√©es √† notre projet, ce dernier appara√Æt largement partageable. Du moins en th√©orie, car la pratique est souvent plus compliqu√©e : il y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement d'ex√©cution (un autre ordinateur, un serveur, etc.), les choses ne se passent pas du tout comme attendu. Cela signifie que qu'**en l'√©tat, le projet n'est pas portable : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.

La principale raison est qu'un code ne vit pas dans une bulle isol√©e, il contient en g√©n√©ral de nombreuses adh√©rences, plus ou moins visibles, au langage et √† l'environnement dans lesquels il a √©t√© d√©velopp√© :

- des d√©pendances dans le langage du projet  ;
- des d√©pendances dans d'autres langages (ex : `NumPy` est √©crit en `C` et n√©cessite donc un compilateur `C`) ;
- des librairies syst√®mes n√©cessaires pour installer certains _packages_
(par exemple, les librairies de cartographie dynamique comme `Leaflet` ou `Folium`
n√©cessitent la librairie syst√®me `GDAL`),
qui ne seront pas les m√™mes selon le syst√®me d'exploitation utilis√©.

Si le premier probl√®me peut √™tre g√©r√© relativement facilement en adoptant une [structure de projet](XXXXXX) et en sp√©cifiant bien les diff√©rentes d√©pendances utilis√©es, par exemple avec un fichier
`requirements.txt`, les deux autres n√©cessitent en g√©n√©ral des outils plus avanc√©s.

Ces outils vont nous permettre de **normaliser l'environnement afin de produire un projet portable**, i.e. ex√©cutable sur une large vari√©t√© d'environnements d'ex√©cution. Cette √©tape est primordiale lorsque l'on se pr√©occupe de la mise en production d'un projet, car elle assure une transition relativement indolore entre l'environnement de d√©veloppement et celui de production.

![](https://img.devrant.com/devrant/rant/r_174386_yx6zV.jpg){fig-align="center"}

_Image emprunt√©e √† [devrant.com}(https://devrant.com/rants/174386/when-i-say-but-it-works-on-my-machine)_



# Les environnements virtuels üêç

## Introduction

Pour illustrer l'importance de travailler avec des environnements virtuels, mettons-nous √† la place d'un.e aspirant.e *data scientist* qui commencerait ses premiers projets.

Selon toute vraisemblance, on va commencer par installer une distribution de `Python` ‚Äî souvent, via `Anaconda` ‚Äî sur son poste et commencer √† d√©velopper, projet apr√®s projet. Dans cette approche, les diff√©rents *packages* qu'on va √™tre amen√© √† utiliser vont √™tre install√©s au m√™me endroit. Cela pose plusieurs probl√®mes :

- **conflits de version** : une application A peut d√©pendre de la version 1 d'un package l√† o√π une application B peut d√©pendre de la version 2 de ce m√™me package. Une seule application peut donc fonctionner dans cette configuration ;
- **version de `Python` fixe** ‚Äî on ne peut avoir qu'une seule installation par syst√®me ‚Äî l√† o√π on voudrait pouvoir avoir des versions diff√©rentes selon le projet ;
- **reproductiblit√© limit√©e** : difficile de dire quel projet repose sur tel package, dans la mesure o√π ceux-ci s'accumulent en un m√™me endroit au fil des projets ;
- **portabilit√© limit√©e** : cons√©quence du point pr√©c√©dent, il est difficile de fixer dans un fichier les d√©pendances sp√©cifiques √† un projet.

Les environnements virtuels constituent une solution √† ces diff√©rents probl√®mes.

## Fonctionnement

Le concept d'environnement virtuel est techniquement tr√®s simple.
On peut lui donner la d√©finition suivante pour `Python` :

> _"dossier auto-suffisant qui contient une installation de `Python`
pour une version particuli√®re de `Python` ainsi que des *packages* additionnels
et qui est isol√© des autres environnements existants."_

On peut donc simplement voir les environnements virtuels comme un moyen de faire cohabiter sur un m√™me syst√®me diff√©rentes installations de `Python` avec chacune leur propre liste de packages install√©s et leurs versions. D√©velopper dans des environnements virtuels vierges √† chaque d√©but de projet est une tr√®s bonne pratique pour accro√Ætre la reproductibilit√© des analyses.

## Impl√©mentations

Il existe diff√©rentes impl√©mentations des environnements virtuels en `Python`, dont chacune ont leurs sp√©cificit√©s et leur communaut√© d'utilisateurs : 

* L'impl√©mentation standard en `Python` est `venv`.
* Dans le domaine de la *data science*, l'impl√©mentation la plus courante est sans doute `conda`.

En pratique, ces impl√©mentations sont relativement proches. La diff√©rence majeure est que `conda` est √† la fois un *package manager* (comme `pip`) et un gestionnaire d'environnements virtuels (comme `venv`).

Pendant longtemps, `conda` en tant que *package manager* s'est av√©r√© tr√®s pratique en *data science*, dans la mesure o√π il g√©rait non seulement les d√©pendances `Python` mais aussi dans d'autres langages ‚Äî comme des d√©pendances `C`. L'autre diff√©rence majeure avec `pip` est que Conda utilise une m√©thode plus avanc√©e ‚Äî et donc √©galement plus co√ªteuse en temps ‚Äî de r√©solution des d√©pendances[^2]. En effet, diff√©rents packages peuvent sp√©cifier diff√©rentes versions d'un m√™me package dont ils d√©pendent tous les deux, ce qui provoque un conflit de version. Conda va par d√©faut appliquer un algorithme qui vise √† g√©rer au mieux ces conflits, l√† o√π `pip` va choisir une approche plus minimaliste. Enfin, la *distribution* `Anaconda`, qui contient √† la fois `Python`, `conda` et beaucoup de *packages* utiles pour la *data science*, explique √©galement cette popularit√© aupr√®s des *data scientists*. 

[^2]: La lenteur de l'installation des packages dans les environnements `conda` par rapport √† `pip` et l'acc√®s de plus en plus fr√©quent √† des [_wheels_](https://pythonwheels.com/) a permis un retour en gr√¢ce des environnements virtuels impl√©ment√©s par `venv`. Une autre alternative populaire est [`mamba`](https://mamba.readthedocs.io/en/latest/), une r√©impl√©mentation de `Conda` en `C++` qui utilise un _solver_ bien plus efficace. En proposant celui-ci, le projet `mamba` vise √† pallier l'un des irritants principaux de `conda`, √† savoir la lenteur du _solver_.

Pour toutes ces raisons, nous allons pr√©senter l'utilisation de `conda` comme gestionnaire d'environnements virtuels. Les principes pr√©sent√©s restent n√©anmoins valides pour les autres impl√©mentations.

## Conda

### Installation

Les instructions √† suivre pour installer `conda` sont d√©taill√©es dans la [documentation officielle](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html). `conda` seul √©tant peu utile en pratique, il est g√©n√©ralement install√© dans le cadre de distributions. Les deux plus populaires sont :

- `Miniconda` : une distribution minimaliste contenant `conda`, `Python` ainsi qu'un petit nombre de packages techniques tr√®s utiles ;
- `Anaconda` : une distribution assez volumineuse contenant `conda`, `Python`, d'autres logiciels (`R`, `Spyder`, etc.) ainsi qu'un ensemble de packages utiles pour la *data science* (`SciPy`, `NumPy`, etc.).

Le choix de la distribution importe assez peu en pratique, dans la mesure o√π nous allons de toute mani√®re utiliser des environnements virtuels vierges pour d√©velopper nos projets.

**L'√©cosyst√®me Conda**

![](/conda-eco.png)

### En pratique

#### Cr√©er un environnement

Pour commencer √† utiliser `conda`, commen√ßons par cr√©er un environnement vierge, nomm√© `dev`, en sp√©cifiant la version de Python que l'on souhaite installer pour notre projet.

```bash
$ conda create -n dev python=3.9.7
Collecting package metadata (current_repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /home/coder/local/bin/conda/envs/dev

  added / updated specs:
    - python=3.9.7


The following packages will be downloaded:
...
The following NEW packages will be INSTALLED:
...
Proceed ([y]/n)? y
Downloading and Extracting Packages
...
```

Comme indiqu√© dans les logs,
`Conda` a cr√©√© notre environnement et nous indique son emplacement sur le *filesystem*.
En r√©alit√©, l'environnement n'est jamais vraiment vierge :
`Conda` nous demande ‚Äî et il faut r√©pondre oui en tapant _"y"_ ‚Äî 
d'installer un certain nombre de packages,
qui sont ceux qui viennent avec la distribution `Miniconda`.

On peut v√©rifier que l'environnement a bien √©t√© cr√©√© en listant les environnements install√©s sur le syst√®me.

```bash
conda info --envs
# conda environments:
#
base                    * /home/coder/local/bin/conda
basesspcloud              /home/coder/local/bin/conda/envs/basesspcloud
dev                       /home/coder/local/bin/conda/envs/dev
```

#### Activer un environnement

Comme plusieurs environnements peuvent coexister sur un m√™me syst√®me,
il faut sp√©cifier √† `Conda`
que l'on souhaite utiliser cet environnement pour la session courante du terminal.

```bash
$ conda activate dev
```

`Conda` nous indique que l'on travaille √† partir de maintenant dans l'environnement `dev` en indiquant son nom entre parenth√®ses au d√©but de la ligne de commandes. Autrement dit, `dev` devient pour un temps notre 
environnement par d√©faut. 
Pour s'en assurer,
v√©rifions avec la commande `which` l'emplacement de l'interpr√©teur Python qui sera utilis√© si on lance une commande du type `python mon-script.py`.

```bash
(dev) $ which python 
/home/coder/local/bin/conda/envs/dev/bin/python
```

On travaille bien dans l'environnement attendu : l'interpr√©teur qui se lance n'est pas celui du syst√®me global, mais bien celui sp√©cifique √† notre environnement virtuel.

#### Lister les packages install√©s

Une fois l'environnement activ√©, on peut lister les packages install√©s et leur version. Cela confirme qu'un certain nombre de packages sont install√©s par d√©faut lors de la cr√©ation d'un environnement virtuel.

```bash
(dev) $ conda list
# packages in environment at /home/coder/local/bin/conda/envs/dev:
#
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_openmp_mutex             4.5                       1_gnu  
ca-certificates           2022.3.29            h06a4308_0  
...
```

#### Installer un package

La syntaxe pour installer un package avec Conda est tr√®s similaire √† celle de `pip` : 

```shell
conda install nom_du_package
```

La diff√©rence est que l√† o√π `pip install` va installer un package √† partir du r√©pertoire [PyPI](https://pypi.org/), `conda install` va chercher le package sur les r√©pertoires maintenus par les d√©veloppeurs de Conda[^1]. Installons par exemple le package phare de *machine learning* `scikit-learn`.

[^1]: Ces r√©pertoires sont, dans le langage `conda` les _canaux_.
Le canal par d√©faut est maintenu par les d√©veloppeurs d`Anaconda`. 
Cependant, pour en assurer la stabilit√©, ce canal a une forte inertie. 
La `conda-forge` a √©merg√© pour offrir plus de flexibilit√© aux d√©veloppeurs
de _package_ qui peuvent ainsi mettre √† disposition des versions plus
r√©centes de leurs packages, comme sur  [PyPI](https://pypi.org/).


```bash
(dev) $ conda install scikit-learn
Collecting package metadata (current_repodata.json): done
Solving environment: done

## Package Plan ##

  environment location: /home/coder/local/bin/conda/envs/dev

  added / updated specs:
    - scikit-learn
...
```

L√† encore, Conda nous demande d'installer d'autres packages, qui sont des d√©pendances de `scikit-learn`. Par exemple, la librairie de calcul scientifique `NumPy`.

Il arrive que des packages disponibles sur le r√©pertoire `PyPI`
ne soient pas disponible sur les canaux g√©r√©s par Conda.
Dans ce cas, il est possible d'installer un package dans l'environnement via la commande `pip install`.
Il est n√©anmonins toujours pr√©f√©rable de privil√©gier une installation via Conda si disponible.

#### Exporter les sp√©cifications de l'environnement

D√©velopper √† partir d'un environnement vierge est une bonne pratique de reproductibilit√© :
en partant d'une base minimale, on s'assure que seuls les packages effectivement n√©cessaires
au bon fonctionnement de notre application ont √©t√© install√©s au fur et √† mesure du projet. 

Cela rend √©galement notre projet plus portable : on peut exporter les sp√©cifications de l'environnement (version de Python, canaux de t√©l√©chargement des packages, packages install√©s et leurs versions) dans un fichier, appel√© par convention `environment.yml`.

```bash
(dev) $ conda env export > environment.yml
```

Ce fichier est mis par convention √† la racine du d√©p√¥t `Git` du projet.
Ainsi, les personnes souhaitant tester l'application peuvent recr√©er le m√™me environnement Conda que celui qui a servi au d√©veloppement via la commande suivante.

```bash
$ conda env create -f environment.yml
```

#### Changer d'environnement

Pour changer d'environnement, il suffit d'en activer un autre.

```bash
(dev) $ conda base
(base) $ 
```

Pour sortir de tout environnement Conda, on utilise la commande `conda deactivate` :

```bash
(base) $ conda deactivate
$ 
```

#### Supprimer un environnement

Pour supprimer l'environnement `dev`, on utilise la commande `conda env remove -n dev`.

### Aide-m√©moire

| Commande | Principe |
|----------|----------|
| `conda create -n <env_name> python=<python_version>` | Cr√©ation d'un environnement nomm√© `<env_name>` dont la version de Python est `<python_version>` |
| `conda info --envs` | Lister les environnements |
| `conda activate <env_name>` | Utiliser l'environnement `<env_name>` pour la session du terminal |
| `conda list` | Lister les _packages_ dans l'environnement actif |
| `conda install <pkg>` | Installer le _package_ `<pkg>` dans l'environnement actif |
| `conda env export > environment.yml` | Exporter les sp√©cifications de l‚Äôenvironnement dans un fichier `environment.yml` |

## Limites

D√©velopper dans des environnements virtuels est une bonne pratique, car cela accro√Æt la portabilit√© d'une application. N√©anmoins, il y a plusieurs limites √† leur utilisation :

- les librairies syst√®me n√©cessaires √† l'installation des packages ne sont pas g√©r√©es ;
- les environnements virtuels ne permettent pas toujours de g√©rer des projets faisant intervenir diff√©rents langages de programmation ;
- devoir installer `conda`, `Python`, et les packages n√©cessaires √† chaque changement d'environnement peut √™tre assez long et p√©nible en pratique ;
- dans un environnement de production, g√©rer des environnements virtuels diff√©rents pour chaque projet peut s'av√©rer rapidement complexe pour les administrateurs syst√®me.

La technologie des conteneurs permet de r√©pondre √† ces diff√©rents probl√®mes.

# Les conteneurs üêã

## Introduction

Avec les environnements virtuels, l'id√©e √©tait de permettre √† chaque utilisateur potentiel de notre projet d'installer sur son environnement d'ex√©cution les packages n√©cessaires √† la bonne ex√©cution du projet.
N√©anmoins, comme on l'a vu, cette approche ne garantit pas une reproductibilit√© parfaite et a l'inconv√©nient de n√©cessiter beaucoup de gestion manuelle.

Changeons de perspective : _au lieu de distribuer une recette permettant √† l'utilisateur de recr√©er l'environnement n√©cessaire sur sa machine, ne pourrait-on pas directement distribuer √† l'utilisateur une machine contenant l'environnement pr√©-configur√© ?_

Bien entendu, on ve pas configurer et envoyer des ordinateurs portables √† tous les utilisateurs potentiels d'un projet.
Une autre solution serait de distribuer des machines virtuelles, qui tournent sur un serveur et simulent un v√©ritable ordinateur.
Ces machines ont cependant l'inconv√©nient d'√™tre assez lourdes, et complexes √† r√©pliquer et distribuer. Pour pallier ces diff√©rentes limites, on va utiliser la technologie des conteneurs.

![](https://external-preview.redd.it/aR6WdUcsrEgld5xUlglgKX_0sC_NlryCPTXIHk5qdu8.jpg?auto=webp&s=5fe64dd318eec71711d87805d43def2765dd83cd){fig-align="center"}

_Image trouv√©e sur [reddit](https://www.reddit.com/r/ProgrammerHumor/comments/cw58z7/it_works_on_my_machine/)_

## Fonctionnement

Comme les machines virtuelles, les conteneurs permettent d'empaqueter compl√®tement l'environnement (librairies syst√®mes, application, configuration) qui permet de faire tourner l'application.
Mais √† l'inverse d'une machine virtuelle, le conteneur n'inclut pas de syst√®me d'exploitation propre, il utilise celui de la machine h√¥te qui l'ex√©cute. La technologie des conteneurs permet ainsi de garantir une tr√®s forte reproductibilit√© tout en restant suffisamment l√©g√®re pour permettre une distribution et un d√©ploiement simple aux utilisateurs.

**Diff√©rences entre l'approche conteneurs (gauche) et l'approche machines virtuelles (droite)**

![](/docker-vm.png)

Source : [docker.com](https://www.docker.com/resources/what-container/)

## Impl√©mentations

Comme pour les environnements virtuels, il existe diff√©rentes impl√©mentations de la technologie des conteneurs. En pratique, l'impl√©mentation offerte par `Docker` est devenue largement pr√©dominante, au point qu'il est devenu courant d'utiliser de mani√®re interchangeable les termes _"conteneuriser"_ et _"Dockeriser"_ une application. C'est donc cette impl√©mentation que nous allons √©tudier et utiliser dans ce cours.

## Docker <i class="fab fa-docker"></i>

### Installation

Les instructions √† suivre pour installer `Docker` <i class="fab fa-docker"></i>
selon son syst√®me d'exploiration sont d√©taill√©es dans la [documentation officielle](https://docs.docker.com/get-docker/).
Il existe √©galement des environnements bacs √† sable en ligne comme
[Play with Docker](https://labs.play-with-docker.com).


### Principes

Un conteneur Docker est mis √† disposition sous la forme d'une **image**, c'est √† dire d'un fichier binaire qui contient l'environnement n√©cessaire √† l'ex√©cution de l'application.

Pour construire (*build*) l'image, on utilise un `Dockerfile`, un fichier texte qui contient la recette ‚Äî sous forme de commandes Linux ‚Äî de construction de l'environnement. L'image va √™tre upload√©e (*push*) sur un d√©p√¥t (*registry*), public ou priv√©, depuis lequel les utilisateurs vont pouvoir t√©l√©charger l'image (*pull*). Le moteur Docker permet ensuite de lancer (*run*) un **conteneur**, c'est √† dire une instance vivante de l'image.

::: {.callout-note}
Le r√©pertoire d'images publiques le plus connu est [`DockerHub`](https://hub.docker.com/). Il s'agit d'un r√©pertoire o√π n'importe qui peut proposer une image `Docker`, associ√©e ou non √† un projet disponible sur `Github` ou `Gitlab`. Il est possible de mettre √† disposition de mani√®re manuelle des images mais, comme nous le montrerons dans le chapitre sur la [mise en production](/chapters/deployment.html), il est beaucoup plus pratique d'utiliser des fonctionalit√©s d'interaction automatique entre `DockerHub` et un d√©p√¥t `GitHub`.
:::



### En pratique

#### Application

Afin de pr√©senter l'utilisation de `Docker` en pratique, nous allons pr√©senter les diff√©rentes √©tapes permettant de _"dockeriser"_ une application web minimaliste construite avec le _framework_ `Python` [`Flask`](https://flask.palletsprojects.com/en/2.1.x/)[^3].

[^3]: [`Flask`](https://flask.palletsprojects.com/en/2.1.x/) est un 
_framework_ permettant de d√©ployer, de mani√®re l√©g√®re,
des applications reposant sur 
`Python`. 

La structure de notre projet est la suivante.

```bash
‚îú‚îÄ‚îÄ myflaskapp
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îú‚îÄ‚îÄ hello-world.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
```

Le script `hello-world.py` contient le code d'une application minimaliste, qui affiche simplement _"Hello, World!"_ sur une page web.

```python
from flask import Flask

app = Flask(__name__)


@app.route("/")
def hello_world():
    return "<p>Hello, World!</p>"
```

Pour faire tourner l'application, il nous faut donc √† la fois `Python` et le package `Flask`. Ces installations doivent √™tre sp√©cifi√©es dans le `Dockerfile` (cf. [section suivante](#dockerfile)). L'installation de `Flask`
se fait via un fichier `requirements.txt`, qui contient juste la ligne suivante :

```bash
Flask==2.1.1
```

#### Le `Dockerfile` {#dockerfile}

A l√† base de chaque image `Docker` se trouve un `Dockerfile`. C'est un fichier texte qui contient une s√©rie de commandes qui permettent de construire l'image. Ces fichiers peuvent √™tre plus ou moins complexes selon l'application que l'on cherche √† conteneuriser, mais leur structure est assez normalis√©e. Pour s'en rendre compte, analysons ligne √† ligne le `Dockerfile` n√©cessaire pour construire une image `Docker` de notre application `Flask.`

```bash
FROM ubuntu:20.04

RUN apt-get update -y && \
    apt-get install -y python3-pip python3-dev
    
WORKDIR /app

COPY requirements.txt /app/requirements.txt
RUN pip install -r requirements.txt

COPY . /app

ENV FLASK_APP="hello-world.py"
EXPOSE 5000

CMD ["flask", "run", "--host=0.0.0.0"]
```

- `FROM` : sp√©cifie l'image de base. Une image Docker h√©rite toujours d'une image de base. Ici, on choisit l'image `Ubuntu` version `20.04`, tout va donc se passer comme si l'on d√©veloppait sur une machine virtuelle vierge ayant pour syst√®me d'exploitation `Ubuntu 20.04`[^4] ;
- `RUN` : lance une commande Linux. Ici, on met d'abord √† jour la liste des packages t√©l√©chargeables via `apt`, puis on installe `Python` ainsi que des librairies syst√®me n√©cessaires au bon fonctionnement de notre application ;
- `WORKDIR` : sp√©cifie le r√©pertoire de travail de l'image. Ainsi, toutes les commandes suivantes seront ex√©cut√©es depuis ce r√©pertoire ;
- `COPY` : copie un fichier local sur l'image `Docker`. Ici, on copie d'abord le fichier `requirements.txt` du projet, qui sp√©cifie les d√©pendances `Python` de notre application, puis on les installe avec une commande `RUN`. La seconde instruction `COPY` copie le r√©pertoire du projet sur l'image ;
- `ENV` : cr√©e une variable d'environnement qui sera accessible √† l'application dans le conteneur. Ici, on d√©finit une variable d'environnement attendue par `Flask`, qui sp√©cifie le nom du script permettant de lancer l'application ;
- `EXPOSE` : informe `Docker` que le conteneur "√©coute" sur le port 5000, qui est le port par d√©faut utilis√© par le serveur web de `Flask` ;
- `CMD` : sp√©cifie la commande que doit ex√©cuter le conteneur lors de son lancement. Il s'agit d'une liste, qui contient les diff√©rentes parties de la commande sous forme de cha√Ænes de caract√®res. Ici, on lance `Flask`, qui sait automatiquement quelle application lancer du fait de la commande `ENV` sp√©cifi√©e pr√©c√©demment.

[^4]: Dans l'id√©al, on essaie de partir d'une couche la plus petite possible
pour limiter la taille de l'image finalement obtenue. Il n'est en effet
pas n√©cessaire d'utiliser une image disposant de `R` si on n'utilise que
du `Python`. En g√©n√©ral, les diff√©rents langages proposent des images de petite taille dans lequel un interpr√©teur est d√©j√† install√© et proprement configur√©. Dans cette application, on aurait par exemple pu utiliser l'image [python:3.9-slim-buster](https://hub.docker.com/layers/python/library/python/3.9-slim-buster/images/sha256-e07b35c0c81c21995a43cefd64730ac0e57a5164cc440b6a5c94c118cfacd0ca?context=explore).


::: {.callout-tip}
Avec la premi√®re commande `RUN` du `Dockerfile`, nous installons `Python` mais aussi des librairies syst√®me n√©cessaires au bon fonctionnement de l'application. Mais comment les avons-nous trouv√©es ?

Par essai et erreur. Lors de l'√©tape de [build](#build) que l'on verra juste apr√®s, le moteur `Docker` va essayer de construire l'image selon les sp√©cifications du `Dockerfile`, comme s'il partait d'un ordinateur vide contenant simplement `Ubuntu 20.04`. Si des librairies manquent, le processus de *build* devrait renvoyer une erreur, qui s'affichera dans les *logs* de l'application, affich√©s par d√©faut dans la console. Quand on a de la chance, les logs d√©crivent explicitement les librairies syst√®me manquantes. Mais souvent, les messages d'erreur ne sont pas tr√®s explicites, et il faut alors les copier dans un moteur de recherche bien connu pour trouver la r√©ponse, souvent sur [Stackoverflow](https://stackoverflow.com/).
:::


::: {.callout-tip}
La recette pr√©sente dans le `Dockerfile` peut n√©cessiter l'utilisation de
fichiers appartenant au dossier de travail. Pour que `Docker` les trouve
dans son contexte, il est n√©cessaire d'introduire une
commande `COPY`. C'est un petit peu comme pour la cuisine: pour utiliser
un produit dans une recette, il faut le sortir du frigo (fichier local)
et le mettre sur la table. 
:::

::: {.callout-note}
Nous n'avons vu que les commandes `Docker` les plus fr√©quentes, il en existe beaucoup d'autres en pratique. N'h√©sitez pas √† consulter la [documentation officielle](https://docs.docker.com/engine/reference/builder/) pour comprendre leur utilisation.
:::


#### Construction d'une image Docker {#build}

Pour construire une image √† partir d'un `Dockerfile`, il suffit d'utiliser la commande `docker build`. Il faut ensuite sp√©cifier deux √©l√©ments importnats :
- le *build context*. Il faut indiquer √† `Docker` le chemin de notre projet, qui doit contenir le `Dockerfile`. En pratique, il est plus simple de se mettre dans le dossier du projet via la commande `cd`, puis de passer `.` comme *build context* pour indiquer √† `Docker` de *build* "d'ici" ;
- le *tag*, c'est √† dire le nom de l'image. Tant que l'on utilisee `Docker` en local, le *tag* importe peu. On verra par la suite que la structure du *tag* a de l'importance lorsque l'on souhaite [exporter](#imp-docker) ou [importer](#exp-docker) une image `Docker` √† partir d'un d√©p√¥t distant.

Regardons ce qui se passe en pratique lorsque l'on essaie de construire notre image.

```bash
$ docker build -t myflaskapp .
Sending build context to Docker daemon     47MB
Step 1/8 : FROM ubuntu:20.04
 ---> 825d55fb6340
Step 2/8 : RUN apt-get update && apt-get install -y python3-pip python3-dev
 ---> Running in 92b42d579cfa
...
done.
Removing intermediate container 92b42d579cfa
 ---> 8826d53e3c01
Step 3/8 : WORKDIR /app
 ---> Running in 153b32893c23
Removing intermediate container 153b32893c23
 ---> 7b4d22021986
Step 4/8 : COPY requirements.txt /app/requirements.txt
...
Successfully built 125bd8da70ff
Successfully tagged myflaskapp:latest
```

Le moteur `Docker` essaie de construire notre image s√©quentiellement √† partir des commandes sp√©cifi√©es dans le `Dockerfile`. S'il rencontre une erreur, la proc√©dure s'arr√™te, et il faut alors trouver la source du probl√®me dans les *logs* et adapter le `Dockerfile` en cons√©quence. Si tout se passe bien, `Docker` nous indique que le *build* a r√©ussi et l'image est pr√™te √† √™tre utilis√©e. On peut v√©rifier que l'image est bien disponible √† l'aide de la commande `docker images`.

```bash
$ docker images
REPOSITORY                               TAG       IMAGE ID       CREATED          SIZE
myflaskapp                               latest    57d2f410a631   2 hours ago      433MB
```

Int√©ressons nous un peu plus en d√©tail aux *logs* de l'√©tape de *build*. Entre les √©tapes, `Docker` affiche des suites de lettres et de chiffres un peu √©sot√©riques, et nous parle de conteneurs interm√©diaires. En fait, il faut voir une image `Docker` comme un empilement de couches (*layers*), qui sont elles-m√™mes des images `Docker`. Quand on h√©rite d'une image avec l'instruction `FROM`, on sp√©cifie donc √† `Docker` la couche initiale, sur laquelle il va construire le reste de notre environnement. A chaque √©tape sa nouvelle couche, et √† chaque couche son *hash*, un identifiant unique fait de lettres et de chiffres.

Cela peut ressembler √† des d√©tails techniques, mais c'est en fait extr√™mement utile en pratique car cela permet √† `Docker` de faire du *caching*. Lorsque l'on d√©veloppe un `Dockerfile`, il est fr√©quent de devoir modifier ce dernier de nombreuses fois avant de trouver la bonne recette, et on aimerait bien ne pas avoir √† *rebuild* l'environnement complet √† chaque fois. `Docker` g√®re cela tr√®s bien : il *cache* chacune des couches interm√©diaires. Par exemple, si l'on modifie la 5√®me commande du `Dockerfile`, `Docker` va utiliser le cache pour ne pas avoir √† recalculer les √©tapes pr√©c√©dentes, qui n'ont pas chang√©. Cela s'appelle l'_"invalidation du cache"_ :
d√®s lors qu'une √©tape du `Dockerfile` est modifi√©e, `Docker` va recalculer toutes les √©tapes suivantes, mais seulement celles-ci. Cons√©quence directe de cette observation : il faut toujours ordonner les √©tapes d'un `Dockerfile` de sorte √† ce qui est le plus susceptible d'√™tre souvent modifi√© soit √† la fin du fichier, et inversement.

Pour illustrer cela, regardons ce qui se passe si l'on modifie le nom du script qui lance l'application, et donc la valeur de la variable d'environnement `FLASK_APP` dans le `Dockerfile`.

```bash
$ docker build . -t myflaskapp
Sending build context to Docker daemon  4.096kB
Step 1/10 : FROM ubuntu:20.04
 ---> 825d55fb6340
Step 2/10 : ENV DEBIAN_FRONTEND=noninteractive
 ---> Using cache
 ---> ea1c7c083ac9
Step 3/10 : RUN apt-get update -y &&     apt-get install -y python3-pip python3-dev
 ---> Using cache
 ---> 078b8ac0e1cb
Step 4/10 : WORKDIR /app
 ---> Using cache
 ---> cd19632825b3
Step 5/10 : COPY requirements.txt /app/requirements.txt
 ---> Using cache
 ---> 271cd1686899
Step 6/10 : RUN pip install -r requirements.txt
 ---> Using cache
 ---> 3ea406fdf383
Step 7/10 : COPY . /app
 ---> 3ce5bd3a9572
Step 8/10 : ENV FLASK_APP="new.py"
 ---> Running in b378d16bb605
Removing intermediate container b378d16bb605
 ---> e1f50490287b
Step 9/10 : EXPOSE 5000
 ---> Running in ab53c461d3de
Removing intermediate container ab53c461d3de
 ---> 0b86eca40a80
Step 10/10 : CMD ["flask", "run", "--host=0.0.0.0"]
 ---> Running in 340eec151a51
Removing intermediate container 340eec151a51
 ---> 16d7a5b8db28
Successfully built 16d7a5b8db28
Successfully tagged myflaskapp:latest
```

L'√©tape de *build* a pris quelques secondes au lieu de plusieurs minutes, et les *logs* montrent bien l'utilisation du cache faite par `Docker` : les √©tapes pr√©c√©dant le changement r√©utilisent les couches cach√©es, mais celle d'apr√®s sont recalcul√©es.

#### Ex√©cuter une image `Docker` {#execution}

L'√©tape de *build* a permis de cr√©er une *image* `Docker`. Une image doit √™tre vue comme un *template* : elle permet d'ex√©cuter l'application sur n'importe quel environnement d'ex√©cution sur lequel un moteur `Docker` est install√©. En l'√©tat, on a donc juste *construit*, mais rien *lanc√©* : notre application ne tourne pas encore. Pour cela, il faut cr√©er un *conteneur*, i.e. une instance vivante de l'image qui permet d'acc√©der √† l'application. Cela se fait via la commande `docker run`.

```bash
$ docker run -d -p 8000:5000 myflaskapp:latest
6a2ab0d82d051a3829b182ede7b9152f7b692117d63fa013e7dfe6232f1b9e81
```

D√©taillons la syntaxe de cette commande :

- `docker run tag` : lance l'image dont on fournit le *tag*. Le *tag* est de la forme `repository/projet:version`. Ici, il n'y a pas de *repository* puisque tout est fait en local ;
- `-d` : "d√©tache" le conteneur du terminal qui le lance ;
- `-p` : effectue un *mapping* entre un port de la machine qui ex√©cute le conteneur, et le conteneur lui-m√™me. Notre conteneur √©coute sur le port 5000, et l'on veut que notre application soit expos√©e sur le port 8000 de notre machine.

Lorsque l'on ex√©cute `docker run`, `Docker` nous r√©pond simplement un *hash* qui identifie le conteneur que l'on a lanc√©. On peut v√©rifier qu'il tourne bien avec la commande `docker ps`, qui renvoie toutes les informations associ√©es au conteneur.

```bash
$ docker ps
CONTAINER ID   IMAGE        COMMAND                  CREATED         STATUS         PORTS                                   NAMES
6a2ab0d82d05   myflaskapp   "flask run --host=0.‚Ä¶"   7 seconds ago   Up 6 seconds   0.0.0.0:8000->5000/tcp, :::8000->5000/tcp   vigorous_kalam
```

Les conteneurs peuvent √™tre utilis√©s pour r√©aliser des t√¢ches tr√®s diff√©rentes. Grossi√®rement, on peut distinguer deux situations :

- le conteneur effectue une t√¢che "one-shot", c'est √† dire une op√©ration qui a vocation √† s'effectuer en un certain temps, suite √† quoi le conteneur peut s'arr√™ter ;
- le conteneur ex√©cute une application. Dans ce cas, on souhaite que le conteneur reste en vie aussi longtemps que l'on souhaite utiliser l'application en question.

Dans notre cas d'application, on se situe dans la seconde configuration puisque l'on veut ex√©cuter une application web. Lorsque l'application tourne, elle expose sur le *localhost*, accessible depuis un navigateur web ‚Äî en l'occurence, √† l'adresse [localhost:8000/](localhost:8000/). Les calculs sont effectu√©s sur un serveur local, et le navigateur sert d'interface avec l'utilisateur ‚Äî comme lorsque vous utilisez un notebook `Jupyter` par exemple. 

Finalement, on a pu d√©velopper et ex√©cuter une application compl√®te sur notre environnement local, sans avoir eu √† installer quoi que ce soit sur notre machine personnelle, √† part `Docker.`

#### Exporter une image `Docker` {#exp-docker}

Jusqu'√† maintenant, toutes les commandes `Docker` que nous avons ex√©cut√©es se sont pass√©es en local. Ce mode de fonctionnement peut √™tre int√©ressant pour la phase de d√©veloppement. Mais comme on l'a vu, un des gros avantages de `Docker` est la facilit√© de redistribution des images construites, qui peuvent ensuite √™tre utilis√©es par de nombreux utilisateurs pour faire tourner notre application. Pour cela, il nous faut uploader notre image sur un d√©p√¥t distant, √† partir duquel les utilisateurs pourront la t√©l√©charger.

Plusieurs possibilit√©s existent selon le contexte de travail : une entreprise peut avoir un d√©p√¥t interne par exemple. Si le projet est open-source, on peut utiliser le [DockerHub](https://hub.docker.com/). Le *workflow* pour uploader une image est le suivant :
- cr√©er un compte sur le DockerHub ;
- cr√©er un projet (public) sur le DockerHub, qui va h√©berger les images `Docker` du projet ;
- sur un terminal, utiliser `docker login` pour s'authentifier au `DockerHub` ;
- on va modifier le *tag* que l'on fournit lors du *build* pour sp√©cifier le chemin attendu. Dans notre cas : `docker build -t compte/projet:version .` ;
- uploader l'image avec `docker push compte/projet:version`

```bash
$ docker push avouacr/myflaskapp:1.0.0
The push refers to repository [docker.io/avouacr/myflaskapp]
71db96687fe6: Pushed 
624877ac887b: Pushed 
ea4ab6b86e70: Pushed 
b5120a5bc48d: Pushed 
5fa484a3c9d8: Pushed 
c5ec52c98b31: Pushed 
1.0.0: digest: sha256:b75fe53fd1990c3092ec41ab0966a9fbbb762f3047957d99327cc16e27c68cc9 size: 1574
```

#### Importer une image `Docker` {#imp-docker}

En supposant que le d√©p√¥t utilis√© pour uploader l'image est public, la proc√©dure que doit suivre un utilisateur pour la t√©l√©charger se r√©sume √† utiliser la commande `docker pull compte/projet:version`

```bash
$ docker pull avouacr/myflaskapp:1.0.0
1.0.0: Pulling from avouacr/myflaskapp
e0b25ef51634: Pull complete 
c0445e4b247e: Pull complete 
48ba4e71d1c2: Pull complete 
ffd728caa80a: Pull complete 
906a95f00510: Pull complete 
d7d49b6e17ab: Pull complete 
Digest: sha256:b75fe53fd1990c3092ec41ab0966a9fbbb762f3047957d99327cc16e27c68cc9
Status: Downloaded newer image for avouacr/myflaskapp:1.0.0
docker.io/avouacr/myflaskapp:1.0.0
```

`Docker` t√©l√©charge et extrait chacune des couches qui constituent l'image (ce qui peut parfois √™tre long). L'utilisateur peut alors cr√©er un conteneur √† partir de l'image, en utilisant `docker run` comme illustr√© pr√©c√©demment.

### Aide-m√©moire

Voici une premi√®re aide-m√©moire sur les principales commandes √† int√©grer dans 
un `Dockerfile`:

| Commande | Principe |
|----------|----------|
| `FROM <image>:<tag>` | Utiliser comme point de d√©part l'image `<image>` ayant le tag `<tag>` |
| `RUN <instructions>` | Utiliser la suite d'instructions `<instructions>` dans un terminal `Linux`. Pour passer plusieurs commandes dans un `RUN`, utiliser `&&`. Cette suite de commande peut avoir plusieurs lignes, dans ce cas, mettre `\` en fin de ligne |
| `COPY <source> <dest>` | R√©cup√©rer le fichier pr√©sent dans le syst√®me de fichier local √† l'emplacement `<source>` pour que les instructions ult√©rieures puissent le trouver √† l'emplacement `<source>`   |
| `ADD <source> <dest>` | Globalement, m√™me r√¥le que `COPY` |
| `ENV MY_NAME="John Doe"` | Cr√©ation d'une variable d'environnement (qui devient disponible sous l'alias `$MY_NAME`)   |
| `WORKDIR <path>` | D√©finir le _working directory_ du conteuneur Docker dans le dossier `<path>`  |
| `USER <username>` | Cr√©ation d'un utilisateur non _root_ nomm√© `<username>`  |
| `EXPOSE <PORT_ID>` | Lorsqu'elle tournera, l'application sera disponible depuis le port `<PORT_ID>`
| `CMD ["executable","param1","param2"]` | Au lancement de l'instance Docker la commande `executable` (par exemple `python3`) sera lanc√©e avec les param√®tres additionnels fournis  |

Une seconde aide-m√©moire pour les principales commandes `Linux` est disponible ci-dessous:

| Commande | Principe |
|----------|----------|
| `docker build . -t <tag>` | Construire l'image `Docker` √† partir des fichiers dans le r√©pertoire courant (`.`) en l'identifiant avec le tag `<tag>`  |
| `docker run -it <tag>` | Lancer l'instance docker identifi√©e par `<tag>`  |
| `docker images` | Lister les images disponibles sur la machine et quelques unes de leurs propri√©t√©s (tags, volume, etc.) |
| `docker system prune` | Faire un peu de m√©nage dans ses images `Docker` (bien r√©fl√©chir avant de faire tourner cette commande) |

