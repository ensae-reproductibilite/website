<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Introduction aux principes du MLOps pour le passage en production des applications de machine learning.">

<title>Introduction aux enjeux du MLOps ‚Äì Mise en production</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-bd706bf7cc79ec682822fd2bf903aab3.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
div.callout-application.callout {
  border-left-color: #9c5bd9;
}
div.callout-application.callout-style-default > .callout-header {
  background-color: rgba(156, 91, 217, 0.13);
}
div.callout-application .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-application.callout-style-default .callout-icon::before, div.callout-application.callout-titled .callout-icon::before {
  content: 'üß†';
  background-image: none;
}
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://ensae-reproductibilite.github.io/"> 
<span class="menu-text">Mise en production</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../chapters/introduction.html"> 
<span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-les-bases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Les bases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-les-bases">    
        <li>
    <a class="dropdown-item" href="../chapters/linux101.html">
 <span class="dropdown-text">Linux 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/git.html">
 <span class="dropdown-text">Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bonnes-pratiques-de-d√©veloppement" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Bonnes pratiques de d√©veloppement</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bonnes-pratiques-de-d√©veloppement">    
        <li>
    <a class="dropdown-item" href="../chapters/code-quality.html">
 <span class="dropdown-text">Qualit√© du code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/projects-architecture.html">
 <span class="dropdown-text">Structure des projets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/big-data.html">
 <span class="dropdown-text">Traitement des donn√©es volumineuses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/portability.html">
 <span class="dropdown-text">Portabilit√©</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-mise-en-production" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Mise en production</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-mise-en-production">    
        <li>
    <a class="dropdown-item" href="../chapters/yaml101.html">
 <span class="dropdown-text">YAML 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/deployment.html">
 <span class="dropdown-text">D√©ploiement</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/mlops.html">
 <span class="dropdown-text">MLOps</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../chapters/application.html"> 
<span class="menu-text">Application</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projets</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projets">    
        <li>
    <a class="dropdown-item" href="../chapters/evaluation.html">
 <span class="dropdown-text">Modalit√©s d‚Äô√©valuation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/galerie.html">
 <span class="dropdown-text">Galerie des projets pass√©s</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/website">
 <span class="dropdown-text">Site web</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/slides">
 <span class="dropdown-text">Slides</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/application">
 <span class="dropdown-text">Application fil rouge</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#fondements-du-mlops" id="toc-fondements-du-mlops" class="nav-link active" data-scroll-target="#fondements-du-mlops">Fondements du MLOps</a>
  <ul class="collapse">
  <li><a href="#du-devops-au-mlops" id="toc-du-devops-au-mlops" class="nav-link" data-scroll-target="#du-devops-au-mlops">Du DevOps au MLOps</a></li>
  <li><a href="#principes-du-mlops" id="toc-principes-du-mlops" class="nav-link" data-scroll-target="#principes-du-mlops">Principes du MLOps</a></li>
  </ul></li>
  <li><a href="#sp√©cificit√©s-li√©es-√†-la-mise-en-production-de-mod√®les-de-ml" id="toc-sp√©cificit√©s-li√©es-√†-la-mise-en-production-de-mod√®les-de-ml" class="nav-link" data-scroll-target="#sp√©cificit√©s-li√©es-√†-la-mise-en-production-de-mod√®les-de-ml">Sp√©cificit√©s li√©es √† la mise en production de mod√®les de ML</a>
  <ul class="collapse">
  <li><a href="#entra√Ænements-des-mod√®les" id="toc-entra√Ænements-des-mod√®les" class="nav-link" data-scroll-target="#entra√Ænements-des-mod√®les">1Ô∏è‚É£ Entra√Ænements des mod√®les</a>
  <ul class="collapse">
  <li><a href="#batch-training" id="toc-batch-training" class="nav-link" data-scroll-target="#batch-training">Batch training</a></li>
  <li><a href="#online-training" id="toc-online-training" class="nav-link" data-scroll-target="#online-training">Online training</a></li>
  <li><a href="#distribuer-loptimisation-des-hyperparam√®tres" id="toc-distribuer-loptimisation-des-hyperparam√®tres" class="nav-link" data-scroll-target="#distribuer-loptimisation-des-hyperparam√®tres">Distribuer l‚Äôoptimisation des hyperparam√®tres</a></li>
  </ul></li>
  <li><a href="#servir-un-mod√®le-ml-√†-des-utilisateurs" id="toc-servir-un-mod√®le-ml-√†-des-utilisateurs" class="nav-link" data-scroll-target="#servir-un-mod√®le-ml-√†-des-utilisateurs">2Ô∏è‚É£ Servir un mod√®le ML √† des utilisateurs</a></li>
  <li><a href="#observabilit√©-en-temps-r√©el-dun-mod√®le-de-ml" id="toc-observabilit√©-en-temps-r√©el-dun-mod√®le-de-ml" class="nav-link" data-scroll-target="#observabilit√©-en-temps-r√©el-dun-mod√®le-de-ml">3Ô∏è‚É£ Observabilit√© en temps r√©el d‚Äôun mod√®le de ML</a>
  <ul class="collapse">
  <li><a href="#data-drift" id="toc-data-drift" class="nav-link" data-scroll-target="#data-drift">Data drift</a></li>
  <li><a href="#concept-drift" id="toc-concept-drift" class="nav-link" data-scroll-target="#concept-drift">Concept drift</a></li>
  </ul></li>
  <li><a href="#r√©-entra√Ænement-dun-mod√®le-ml" id="toc-r√©-entra√Ænement-dun-mod√®le-ml" class="nav-link" data-scroll-target="#r√©-entra√Ænement-dun-mod√®le-ml">4Ô∏è‚É£ R√©-entra√Ænement d‚Äôun mod√®le ML</a></li>
  <li><a href="#d√©fis-organisationnels-du-mlops" id="toc-d√©fis-organisationnels-du-mlops" class="nav-link" data-scroll-target="#d√©fis-organisationnels-du-mlops">5Ô∏è‚É£ D√©fis organisationnels du MLOps</a></li>
  </ul></li>
  <li><a href="#impl√©mentation-de-lapproche-mlops-avec-mlflow" id="toc-impl√©mentation-de-lapproche-mlops-avec-mlflow" class="nav-link" data-scroll-target="#impl√©mentation-de-lapproche-mlops-avec-mlflow">Impl√©mentation de l‚Äôapproche MLOps avec MLflow</a>
  <ul class="collapse">
  <li><a href="#pourquoi-mlflow" id="toc-pourquoi-mlflow" class="nav-link" data-scroll-target="#pourquoi-mlflow">Pourquoi MLflow ?</a></li>
  <li><a href="#les-projets-mlflow" id="toc-les-projets-mlflow" class="nav-link" data-scroll-target="#les-projets-mlflow">Les projets MLflow</a></li>
  <li><a href="#le-serveur-de-suivi-tracking-server" id="toc-le-serveur-de-suivi-tracking-server" class="nav-link" data-scroll-target="#le-serveur-de-suivi-tracking-server">Le serveur de suivi (<em>tracking server</em>)</a></li>
  <li><a href="#lentrep√¥t-de-mod√®les-model-registry" id="toc-lentrep√¥t-de-mod√®les-model-registry" class="nav-link" data-scroll-target="#lentrep√¥t-de-mod√®les-model-registry">L‚Äôentrep√¥t de mod√®les (<em>model registry</em>)</a></li>
  <li><a href="#mlflow-en-r√©sum√©" id="toc-mlflow-en-r√©sum√©" class="nav-link" data-scroll-target="#mlflow-en-r√©sum√©">MLflow en r√©sum√©</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction aux enjeux du MLOps</h1>
</div>

<div>
  <div class="description">
    <p>Introduction aux principes du MLOps pour le passage en production des applications de machine learning.</p>
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<details>
<summary>
D√©rouler les <em>slides</em> ci-dessous ou <a href="https://ensae-reproductibilite.github.io/slides/#/mlops">cliquer ici</a> pour afficher les slides en plein √©cran.
</summary>
<div id="cb1" class="sourceCode">
<pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<iframe class="sourceCode yaml code-with-copy" src="https://ensae-reproductibilite.github.io/slides/#/mlops">
</iframe>
</div>
</details>
<p>Dans les chapitres pr√©c√©dents, nous avons vu qu‚Äôune majorit√© des projets <em>data-driven</em> restaient au stade de l‚Äôexp√©rimentation, et qu‚Äôune des raisons pour expliquer ce ph√©nom√®ne √©tait l‚Äôexistence de <strong>frictions</strong> emp√™chant l‚Äô<strong>am√©lioration continue</strong> des projets. Dans le cadre des projets bas√©s sur des mod√®les de <em>machine learning</em>, cette probl√©matique devient encore plus cruciale : en suppl√©ment des enjeux sur le cycle de vie de la donn√©e intervient la dimension suppl√©mentaire du cycle de vie des mod√®les. Parmi les principaux enjeux, une question souvent √©lud√©e dans les enseignements ou les nombreuses ressources en ligne sur le <em>machine learning</em> est la probl√©matique des <strong>r√©-entra√Ænements p√©riodiques</strong>, guid√©s par l‚Äôutilisation faite des mod√®les et les retours des utilisateurs, afin de maintenir √† jour la base de connaissance des mod√®les et ainsi garantir leur pouvoir pr√©dictif. Ce sujet du r√©-entra√Ænement des mod√®les rend les <strong>aller-retours entre les phases d‚Äôexp√©rimentation et de production</strong> n√©cessairement fr√©quents. Pour faciliter la mise en place de <em>pipelines</em> favorisant ces boucles de r√©troaction, une nouvelle approche a √©merg√© : le <strong>MLOps</strong>, qui vise l√† encore √† mobiliser les concepts et outils issus de l‚Äôapproche <strong><em>DevOps</em></strong> tout en les adaptant au contexte et aux sp√©cificit√©s des projets de machine learning.</p>
<section id="fondements-du-mlops" class="level1">
<h1>Fondements du MLOps</h1>
<section id="du-devops-au-mlops" class="level2">
<h2 class="anchored" data-anchor-id="du-devops-au-mlops">Du DevOps au MLOps</h2>
<p>L‚Äôapproche <em>MLOps</em> s‚Äôest construite sur les bases de l‚Äôapproche <em>DevOps</em>. En cela, on peut consid√©rer qu‚Äôil s‚Äôagit simplement d‚Äôune extension de l‚Äôapproche <em>DevOps</em>, d√©velopp√©e pour r√©pondre aux d√©fis sp√©cifiques li√©s √† la gestion du cycle de vie des mod√®les de machine learning. Le MLOps int√®gre les principes de collaboration et d‚Äôautomatisation propres au <em>DevOps</em>, mais prend √©galement en compte tous les aspects li√©s aux donn√©es et aux mod√®les de machine learning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlops.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<details>
<summary>
A mettre en regard √† la boucle du <em>DevOps</em>
</summary>
<img src="https://ensae-reproductibilite.github.io/slides/img/exploration-production.png" class="img-fluid">
</details>
<p>Le <em>MLOps</em> implique l‚Äô<strong>automatisation des t√¢ches</strong> telles que la gestion des donn√©es, le suivi des <strong>versions des mod√®les</strong>, leurs <strong>d√©ploiements</strong>, ainsi que l‚Äô<strong>√©valuation continue</strong> de la performance des mod√®les en production. De la m√™me mani√®re que le <em>DevOps</em>, le <em>MLOps</em> met l‚Äôaccent sur la collaboration √©troite entre les √©quipes de d√©veloppement et d‚Äôadministration syst√®me d‚Äôune part, ainsi que les √©quipes de data science d‚Äôautre part. Cette collaboration est cl√© pour garantir une communication efficace tout au long du cycle de vie du mod√®le de <em>machine learning</em> et fludifier le passage entre les √©tapes d‚Äôexp√©rimentation et de passage en production.</p>
</section>
<section id="principes-du-mlops" class="level2">
<h2 class="anchored" data-anchor-id="principes-du-mlops">Principes du MLOps</h2>
<p>Puisque le <em>MLOps</em> est ainsi une extension des principes du <em>DevOps</em> aux enjeux du <em>machine learning</em>, les principes g√©n√©raux sont les m√™mes que ceux √©voqu√©s pr√©c√©demment mais ceux-ci s‚Äôadaptent √† la probl√©matique de la gestion du cycle de vie d‚Äôun mod√®le:</p>
<ul>
<li><p>la <strong>reproductibilit√©</strong> : les r√©sultats de chaque exp√©rimentation, fructueuse comme infructueuse, doivent pouvoir √™tre <strong>reproduits</strong> sans co√ªt. Cela implique d‚Äôabord une certaine rigueur dans la gestion des packages, la gestion des environnements, la gestion des librairies syst√®me, le contr√¥le de version du code, etc.</p></li>
<li><p>le <strong>contr√¥le de version</strong>: au-del√† du simple suivi des versions du code, pour reproduire de mani√®re identique les r√©sultats d‚Äôun code c‚Äôest l‚Äôensemble des <em>inputs</em> et param√®tres influen√ßant l‚Äôentra√Ænement d‚Äôun mod√®le (donn√©es d‚Äôentra√Ænement, hyper-param√®tres, etc.) qui doivent √™tre <strong>versionn√©es</strong> avec le mod√®le ;</p></li>
<li><p>l‚Äô<strong>automatisation</strong> : afin de favoriser les boucles r√©troactives d‚Äôam√©lioration continue, le cycle de vie du mod√®le (tests, <em>build</em>, validation, d√©ploiement) doit √™tre automatis√© au maximum. Les outils issus de l‚Äôapproche <em>DevOps</em>, en particulier l‚Äô<strong>int√©gration et d√©ploiement continus (CI/CD)</strong>, doivent √™tre mobilis√©s ;</p></li>
<li><p>la <strong>collaboration</strong> : valoriser une culture de travail collaborative autour des projets de ML, dans laquelle la communication au sein des √©quipes doit permettre de r√©duire le travail en silos et b√©n√©ficier des expertises des diff√©rents m√©tiers parti prenantes d‚Äôun mod√®le (analystes, <em>data engineers</em>, devs..). Sur le plan technique, les outils MLOps utilis√©s doivent favoriser le travail collaboratif sur les donn√©es, le mod√®le et le code utilis√©s par le projet ;</p></li>
<li><p>l‚Äô<strong>am√©lioration continue</strong> : une fois d√©ploy√©, il est essentiel de s‚Äôassurer que le mod√®le fonctionne bien comme attendu en √©valuant ses performances sur des donn√©es r√©elles √† l‚Äôaide d‚Äôoutils de <strong>monitoring en continu</strong>. Dans le cas d‚Äôune d√©gradation des performances dans le temps, un <strong>r√©-entra√Ænement p√©riodique</strong> ou un <strong>entra√Ænement en continu</strong> du mod√®le doivent √™tre envisag√©s.</p></li>
</ul>
<p>Pour plus de d√©tails, voir <span class="citation" data-cites="kreuzberger2023machine">Kreuzberger, K√ºhl, and Hirschl (<a href="#ref-kreuzberger2023machine" role="doc-biblioref">2023</a>)</span>.</p>
</section>
</section>
<section id="sp√©cificit√©s-li√©es-√†-la-mise-en-production-de-mod√®les-de-ml" class="level1">
<h1>Sp√©cificit√©s li√©es √† la mise en production de mod√®les de ML</h1>
<section id="entra√Ænements-des-mod√®les" class="level2">
<h2 class="anchored" data-anchor-id="entra√Ænements-des-mod√®les">1Ô∏è‚É£ Entra√Ænements des mod√®les</h2>
<p>La premi√®re √©tape d‚Äôun projet de <em>machine learning</em> correspond √† tout ce que l‚Äôon effectue jusqu‚Äô√† l‚Äôentra√Ænement des premiers mod√®les. Cette √©tape est un processus it√©ratif et fastidieux qui ne suit pas un d√©veloppement lin√©aire : les m√©thodes de r√©cup√©ration des donn√©es peuvent √™tre changeantes, le <em>preprocessing</em> peut varier, de m√™me que la s√©lection des <em>features</em> pour le mod√®le (<em>feature engineering</em>), et les algorithmes test√©s peuvent √™tre nombreux‚Ä¶ On est donc aux antipodes des hypoth√®ses habituelles de stabilit√© n√©cessaires √† l‚Äôentra√Ænement et la validit√© externe dans les enseignements de <em>machine learning</em>.</p>
<p>Garder une trace de tous les essais effectu√©s appara√Æt indispensable afin de savoir ce qui a fonctionn√© ou non. Le besoin d‚Äôarchiver ne concerne pas que les m√©triques de performances associ√©es √† un jeu de param√®tres. Ceux-ci ne sont qu‚Äôune partie des ingr√©dients n√©cessaires pour aboutir √† une estimation. L‚Äôensemble des <em>inputs</em> d‚Äôun processus de production (code, donn√©es, configuration logicielle, etc.) est √©galement √† conserver pour √™tre en mesure de r√©pliquer une exp√©rimentation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Le <em>tracking server</em> de <code>MLFlow</code>, un environnement id√©al pour archiver des exp√©rimentations
</div>
</div>
<div class="callout-body-container callout-body">
<p>La phase exploratoire est rendue tr√®s simple gr√¢ce au <em>Tracking Server</em> de <code>MLFlow</code>. Comme cela sera expliqu√© ult√©rieurement, lors de l‚Äôex√©cution d‚Äôun <em>run</em>, MLflow enregistre tout un tas de m√©tadonn√©es qui permettent de retrouver toutes les informations relatives √† ce <em>run</em> : la date, le hash du commit, les param√®tres du mod√®le, le dataset utilis√©, les m√©triques sp√©cifi√©es, etc. Cela permet non seulement de comparer les diff√©rents essais r√©alis√©s, mais aussi d‚Äô√™tre capable de reproduire un <em>run</em> pass√©.</p>
</div>
</div>
<p>De mani√®re g√©n√©rale, cette phase exploratoire est r√©alis√©e par le <em>data scientist</em> ou le <em>ML engineer</em> dans des <em>notebooks</em>. Ces <em>notebooks</em> sont en effet parfaitement adapt√©s pour cette √©tape puisqu‚Äôils permettent une grande flexibilit√© et sont particuli√®rement commodes pour effectuer des tests. En revanche, lorsque l‚Äôon souhaite aller plus loin et que l‚Äôon vise une mise en production de son projet, les notebooks ne sont plus adapt√©s, et cela pour diverses raisons :</p>
<ul>
<li>la collaboration est grandement limit√©e √† cause d‚Äôune compatibilit√© tr√®s faible avec les outils de contr√¥le de version standard (notamment <code>Git</code>).</li>
<li>l‚Äôautomatisation de <em>pipeline</em> est beaucoup plus compliqu√©e et peu lisible. Il existe certes des packages qui permettent d‚Äôautomatiser des <em>pipelines</em> de notebooks comme <a href="https://github.com/elyra-ai/elyra">Elyra</a> par exemple, mais ce n‚Äôest clairement pas l‚Äôapproche que nous vous recommandons car les scripts sont beaucoup moins usine √† gaz.</li>
<li>Les <em>workflows</em> sont souvent moins clairs, mal organis√©s (toutes les fonctions d√©finies dans le m√™me fichier affectant la lisibilit√© du code par exemple) voire peu reproductibles car les cellules sont rarement ordonn√©es de sorte √† ex√©cuter le code de mani√®re lin√©aire.</li>
<li>Les notebooks offrent g√©n√©ralement une modularit√© insuffisante lorsque l‚Äôon veut travailler avec des composants de <em>machine learning</em> complexes.</li>
</ul>
<p>Toutes ces raisons nous am√®nent √† vous conseiller de r√©duire au maximum votre utilisation de notebooks et de restreindre leur utilisation √† la phase exploratoire ou √† la diffusion de r√©sultats/rapports. Passer le plus t√¥t possible √† des scripts <code>.py</code> vous permettra de r√©duire le co√ªt de la mise en production. Pour reprendre ce qui a d√©j√† √©t√© √©voqu√© dans le chapitre <a href="../chapters/projects-architecture.html">Architecture des projets</a>, nous vous invitons √† favoriser une structure modulaire de sorte √† pouvoir industrialiser votre projet.</p>
<p>Une autre sp√©cificit√© pouvant impacter la mise en production concerne la mani√®re dont l‚Äôentra√Ænement est r√©alis√©. Il existe pour cela 2 √©coles qui ont chacune leurs avantages et d√©savantages : le <em>batch training</em> et l‚Äô<em>online training</em>.</p>
<section id="batch-training" class="level3">
<h3 class="anchored" data-anchor-id="batch-training">Batch training</h3>
<p>Le <em>batch training</em> est la mani√®re usuelle d‚Äôentra√Æner un mod√®le de machine learning. Cette m√©thode consiste √† entra√Æner son mod√®le sur un jeu de donn√©es fixe d‚Äôune seule traite. Le mod√®le est entra√Æn√© sur l‚Äôint√©gralit√© des donn√©es disponibles et les pr√©dictions sont r√©alis√©es sur de nouvelles donn√©es. Cela signifie que le mod√®le n‚Äôest pas mis √† jour une fois qu‚Äôil est entra√Æn√©, et qu‚Äôil est n√©cessaire de le r√©-entra√Æner si l‚Äôon souhaite ajuster ses poids. Cette m√©thode est relativement simple √† mettre en ≈ìuvre : il suffit d‚Äôentra√Æner le mod√®le une seule fois, de le d√©ployer, puis de le r√©-entra√Æner ult√©rieurement en cas de besoin. Cependant, cette simplicit√© comporte des inconv√©nients : le mod√®le reste statique, n√©cessitant un r√©-entra√Ænement fr√©quent pour int√©grer de nouvelles donn√©es. Par exemple, dans le cas de la d√©tection de spams, si un nouveau type de spam appara√Æt, le mod√®le entra√Æn√© en batch ne sera pas capable de le d√©tecter sans un r√©-entra√Ænement complet. De plus, cette m√©thode peut rapidement exiger une grande quantit√© de m√©moire en fonction de la taille du jeu de donn√©es, ce qui peut poser des contraintes sur l‚Äôinfrastructure et prolonger consid√©rablement le temps d‚Äôentra√Ænement.</p>
</section>
<section id="online-training" class="level3">
<h3 class="anchored" data-anchor-id="online-training">Online training</h3>
<p>L‚Äô<em>online training</em> se pr√©sente comme l‚Äôantith√®se du <em>batch training</em>, car il se d√©roule de mani√®re incr√©mentale. Dans ce mode d‚Äôentra√Ænement, de petits lots de donn√©es sont envoy√©s s√©quentiellement √† l‚Äôalgorithme, ce qui permet √† celui-ci de mettre √† jour ses poids √† chaque nouvelle donn√©e re√ßue. Cette approche permet au mod√®le de d√©tecter efficacement les variations dans les donn√©es en temps r√©el. Il est toutefois crucial de bien ajuster le learning rate afin d‚Äô√©viter que le mod√®le oublie les informations apprises sur les donn√©es pr√©c√©dentes. L‚Äôun des principaux avantages de cette m√©thode est sa capacit√© √† permettre un entra√Ænement continu m√™me lorsque le mod√®le est en production, ce qui se traduit par une r√©duction des co√ªts computationnels. De plus, l‚Äô<em>online training</em> est particuli√®rement adapt√© aux situations o√π les donn√©es d‚Äôentr√©e √©voluent fr√©quemment, comme dans le cas des pr√©dictions de cours de bourse. Cependant, sa mise en ≈ìuvre dans un contexte de production est bien plus complexe que celle du <em>batch training</em>, et les <em>frameworks</em> traditionnels de machine learning tels que Scikit-learn, PyTorch, TensorFlow et Keras ne sont pas compatibles avec cette approche.</p>
</section>
<section id="distribuer-loptimisation-des-hyperparam√®tres" class="level3">
<h3 class="anchored" data-anchor-id="distribuer-loptimisation-des-hyperparam√®tres">Distribuer l‚Äôoptimisation des hyperparam√®tres</h3>
<p>Une autre sp√©cificit√© des mod√®les de machine learning r√©side dans le nombre important d‚Äôhyperparam√®tres √† optimiser, lesquels peuvent sensiblement impacter les performances du mod√®le. L‚Äôapproche standard pour r√©aliser cette optimisation est ce qu‚Äôon appelle un <em>Grid Search</em>. Il s‚Äôagit simplement de lister toutes les combinaisons d‚Äôhyperparam√®tres √† tester et d‚Äôentra√Æner successivement des mod√®les avec ces combinaisons pr√©d√©finies. Il n‚Äôest pas difficile de comprendre que cette technique est tr√®s co√ªteuse en temps de calcul lorsque le nombre d‚Äôhyperparam√®tres √† optimiser et leurs modalit√©s √† tester sont √©lev√©s. Cependant, cette optimisation est indispensable pour entra√Æner le meilleur mod√®le pour notre t√¢che, et si s‚Äôinspirer de la litt√©rature est crucial pour limiter le domaine d‚Äôoptimisation de nos hyperparam√®tres, r√©aliser un <em>Grid Search</em> est une √©tape incontournable.</p>
<p>Ainsi, pour s‚Äôinscrire dans l‚Äôapproche du MLOps, une bonne m√©thode est d‚Äôautomatiser cette optimisation des hyperparam√®tres en la distribuant sur un <em>cluster</em> lorsqu‚Äôon dispose de l‚Äôinfrastructure ad√©quate. L‚Äôid√©e est de cr√©er des processus ind√©pendants, chacun li√©s √† une combinaison de nos hyperparam√®tres, et d‚Äôentra√Æner notre mod√®le sur ceux-ci puis d‚Äôenregister les informations √† archiver dans un environnement ad√©quat, par exemple dans <code>MLFlow</code>.</p>
<p>Il existe un moteur de workflow populaire pour orchestrer des t√¢ches parall√®les sur un cluster Kubernetes : <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a>. Le principe est de d√©finir un <em>workflow</em> dans lequel chaque √©tape correspond √† un conteneur contenant uniquement ce qui est strictement n√©cessaire √† l‚Äôex√©cution de cette √©tape. Ainsi, on s‚Äôapproche de la perfection en ce qui concerne la reproductibilit√©, car on ma√Ætrise totalement les installations n√©cessaires √† l‚Äôex√©cution de notre entra√Ænement. Un <em>workflow</em> √† plusieurs √©tapes peut ainsi √™tre mod√©lis√© comme un graphe acyclique orient√©, et l‚Äôexemple ci-dessous repr√©sente un cas d‚Äôoptimisation d‚Äôhyperparam√®tres :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../dag-argo-workflow.png" class="img-fluid figure-img"></p>
<figcaption>Workflow d‚Äôoptimisation d‚Äôhyperparam√®tres en parall√®le</figcaption>
</figure>
</div>
<p>Cette approche permet d‚Äôex√©cuter facilement en parall√®le des t√¢ches intensives en calcul de mani√®re totalement reproductible. √âvidemment, l‚Äôutilisation de tels workflows ne se limite pas √† l‚Äôoptimisation d‚Äôhyperparam√®tres mais peut √©galement √™tre utilis√©e pour le preprocessing de donn√©es, la cr√©ation de pipelines d‚ÄôETL, etc. D‚Äôailleurs, √† l‚Äôorigine, ces outils ont √©t√© pens√© pour ces t√¢ches et permettent ainsi de d√©finir un processus de donn√©es comme un ensemble de transformations sous la forme de diagramme acyclique dirig√© (DAG).</p>
</section>
</section>
<section id="servir-un-mod√®le-ml-√†-des-utilisateurs" class="level2">
<h2 class="anchored" data-anchor-id="servir-un-mod√®le-ml-√†-des-utilisateurs">2Ô∏è‚É£ Servir un mod√®le ML √† des utilisateurs</h2>
<p>Une partie tr√®s importante, parfois n√©glig√©e, des projets de <em>machine learning</em> est la mise √† disposition des mod√®les entra√Æn√©s √† d‚Äôautres utilisateurs. Puisque vous avez parfaitement suivi les diff√©rents chapitres de ce cours, votre projet est en th√©orie totalement reproductible. Une mani√®re triviale de transmettre le mod√®le que vous avez s√©lectionn√© serait de partager votre code et toutes les informations n√©cessaires pour qu‚Äôune personne tierce r√©-entra√Æne votre mod√®le de son c√¥t√©. √âvidemment, ce proc√©d√© n‚Äôest pas optimal, car il suppose que tous les utilisateurs disposent des ressources/infrastructures/connaissances n√©cessaires pour r√©aliser l‚Äôentra√Ænement.</p>
<p>L‚Äôobjectif est donc de mettre √† disposition votre mod√®le de mani√®re simple et efficace. Pour cela, plusieurs possibilit√©s s‚Äôoffrent √† vous en fonction de votre projet, et il est important de se poser quelques questions pr√©alables :</p>
<ul>
<li>Quel format est le plus pertinent pour mettre √† disposition des utilisateurs ?</li>
<li>Les pr√©dictions du mod√®le doivent-elles √™tre r√©alis√©es par lots (<em>batch</em>) ou en temps r√©el (<em>online</em>) ?</li>
<li>Quelle infrastructure utiliser pour d√©ployer notre mod√®le de machine learning ?</li>
</ul>
<p>Dans le cadre de ce cours, nous avons choisi d‚Äôutiliser une API REST pour mettre √† disposition un mod√®le de machine learning. Cela nous semble √™tre la m√©thode la plus adapt√©e dans une grande majorit√© des cas, car elle r√©pond √† plusieurs crit√®res :</p>
<ul>
<li><strong>Simplicit√©</strong> : les API REST permettent de cr√©er une porte d‚Äôentr√©e qui peut cacher la complexit√© sous-jacente du mod√®le, facilitant ainsi sa mise √† disposition.</li>
<li><strong>Standardisation</strong> : l‚Äôun des principaux avantages des API REST est qu‚Äôelles reposent sur le standard HTTP. Cela signifie qu‚Äôelles sont agnostiques au langage de programmation utilis√© et que les requ√™tes peuvent √™tre r√©alis√©es en XML, JSON, HTML, etc.</li>
<li><strong>Modularit√©</strong> : le client et le serveur sont ind√©pendants. En d‚Äôautres termes, le stockage des donn√©es, l‚Äôinterface utilisateur ou encore la gestion du mod√®le sont compl√®tement s√©par√©s de la mise √† disposition (le serveur).</li>
<li><strong>Passage √† l‚Äô√©chelle</strong> : la s√©paration entre le serveur et le client permet aux API REST d‚Äô√™tre tr√®s flexibles et facilite le passage √† l‚Äô√©chelle (<em>scalability</em>). Elles peuvent ainsi s‚Äôadapter √† la charge de requ√™tes concurrentes.</li>
</ul>
<p>L‚Äôexposition d‚Äôun mod√®le de machine learning peut √™tre r√©sum√©e par le sch√©ma suivant :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../API-diag.png" class="img-fluid figure-img"></p>
<figcaption>Exposer un mod√®le de ML via une API</figcaption>
</figure>
</div>
<p>Comme le montre le sch√©ma, l‚ÄôAPI est ex√©cut√©e dans un conteneur afin de garantir un environnement totalement autonome et isol√©. Seules les d√©pendances n√©cessaires √† l‚Äôex√©cution du mod√®le et au fonctionnement de l‚ÄôAPI ne sont int√©gr√©es √† ce conteneur. Travailler avec des <em>images docker</em> l√©g√®res pr√©sente plusieurs avantages. Tout d‚Äôabord, cr√©er une image ne contenant que le strict n√©cessaire au fonctionnement de votre application permet justement de savoir ce qui est absolument indispensable et ce qui est superflu. De plus, plus votre image est l√©g√®re, plus son temps de t√©l√©chargement depuis votre Hub d‚Äôimages (e.g.&nbsp;<em>Dockerhub</em>) sera rapide √† chaque cr√©ation de conteneur de votre application. Les conteneurs ont l‚Äôavantage d‚Äô√™tre totalement portables et offrent la possibilit√© de mettre √† l‚Äô√©chelle votre application de mani√®re simple et efficace. Par exemple, si l‚Äôon imagine que vous avez d√©ploy√© votre mod√®le et que vous souhaitez le requ√™ter un grand nombre de fois dans un laps de temps court, il est alors pr√©f√©rable de cr√©er plusieurs instances de votre application pour que les calculs puissent √™tre effectu√©s en parall√®le. L‚Äôavantage de proc√©der de cette mani√®re est qu‚Äôune fois qu‚Äôon a cr√©√© l‚Äôimage sous-jacente √† notre application, il est ensuite tr√®s simple de cr√©er une multitude de conteneurs (<em>replicas</em>) toutes bas√©es sur l‚Äôimage en question.</p>
<p>Pour tout ce qui concerne le d√©ploiement de votre application, vous pouvez vous r√©f√©rer au chapitre <a href="../chapters/deployment.html">Mise en production</a>. Techniquement, il n‚Äôy a aucune difficult√© suppl√©mentaire lorsque l‚Äôon veut avoir une approche MLOps lors de cette √©tape. L‚Äôunique subtilit√© √† avoir en t√™te est que l‚Äôon souhaite maintenant faire communiquer notre application avec MLflow. En effet, chaque d√©ploiement est bas√© sur une version particuli√®re du mod√®le et il est n√©cessaire de renseigner quelques informations afin de r√©cup√©rer le bon mod√®le au sein de notre entrep√¥t de mod√®le. Comme pour tout d√©ploiement sous Kubernetes, il faut tout d‚Äôabord cr√©er les 3 fichiers YAML : <code>deployment.yaml</code>, <code>service.yaml</code>, <code>ingress.yaml</code>. Ensuite, comme vous pouvez le voir sur le sch√©ma, notre API doit pouvoir √™tre reli√©e √† MLflow qui lui-m√™me a besoin d‚Äô√™tre connect√© √† un espace de stockage (ici s3/MinIO) qui contient l‚Äôentrep√¥t des mod√®les. Pour cela, dans le fichier <code>deployment.yaml</code>, on rajoute simplement quelques variables d‚Äôenvironnement qui nous permettent de cr√©er de lien √† savoir :</p>
<ul>
<li><strong>MLFLOW_S3_ENDPOINT_URL</strong> : L‚ÄôURL de l‚Äôendpoint S3 utilis√© par MLflow pour stocker les donn√©es (et mod√®les)</li>
<li><strong>MLFLOW_TRACKING_URI</strong> : L‚ÄôURI du serveur de suivi MLflow, qui sp√©cifie o√π les informations concernant les mod√®les sont stock√©es.</li>
<li><strong>AWS_ACCESS_KEY_ID</strong> : L‚Äôidentifiant d‚Äôacc√®s utilis√© pour authentifier l‚Äôacc√®s aux services de stockage s3.</li>
<li><strong>AWS_SECRET_ACCESS_KEY</strong> : La cl√© secr√®te utilis√©e pour authentifier l‚Äôacc√®s aux services de stockage s3.</li>
<li><strong>AWS_DEFAULT_REGION</strong> : Identifie la r√©gion S3 pour laquelle vous souhaitez envoyer les demandes aux serveurs. <!--Trouv√© dans la doc AWS pas sur du tout de vouloir mettre ca --></li>
</ul>
<p>Pour faciliter le d√©ploiement continu (voir <a href="../chapters/deployment.html">chapitre Mise en production</a>), il est conseill√© de rajouter des variables d‚Äôenvironnement sp√©cifiant la version du mod√®le √† d√©ployer ainsi que le nom du mod√®le √† d√©ployer. En effet, en sp√©cifiant ces valeurs dans le fichier <code>deployment.yaml</code>, cela va permettre de d√©clencher un nouveau d√©ploiement d√®s lors que l‚Äôon modifiera ces valeurs.</p>
<p>Il est bon de noter que MLflow permet √©galement de d√©ployer directement un mod√®le MLflow. Vous pouvez aller regarder la <a href="https://mlflow.org/docs/latest/deployment/index.html">documentation</a> si cela vous int√©resse. Cette option est relativement r√©cente et pas encore tout √† fait mature mais se base sur les m√™mes technologies que celles pr√©sent√©es dans ce cours (Kubernetes, S3, etc.). C‚Äôest pour cela que nous avons pr√©f√©r√© d√©tailler le d√©veloppement de notre propre API en utilisant le <em>framework</em> <a href="https://fastapi.tiangolo.com/">FastAPI</a>, qui est devenu le standard pour le d√©veloppement d‚ÄôAPI en Python.</p>
<ul>
<li><p>D√©ployer sur Kubernetes (plutot dans chap mise en prod ?) <!-- j'ai vu que dans les slides vous parlez de kubernetes vous pensez faut mettre un paragraphe dessus ? j'y connais R moi --></p></li>
<li><p>Batch vs real-time prediction</p></li>
</ul>
</section>
<section id="observabilit√©-en-temps-r√©el-dun-mod√®le-de-ml" class="level2">
<h2 class="anchored" data-anchor-id="observabilit√©-en-temps-r√©el-dun-mod√®le-de-ml">3Ô∏è‚É£ Observabilit√© en temps r√©el d‚Äôun mod√®le de ML</h2>
<p>Une fois la mod√©lisation r√©alis√©e, le mod√®le entra√Æn√©, optimis√© et mis √† disposition des utilisateurs gr√¢ce √† un d√©ploiement sur un serveur, on peut consid√©rer que le travail est fini. Du point de vue du <em>data-scientist</em> stricto sensu, cela peut √™tre le cas, puisque l‚Äôon consid√®re souvent que le domaine du <em>data-scientist</em> s‚Äôarr√™te √† la s√©lection du mod√®le √† d√©ployer, le d√©ploiement √©tant r√©alis√© par ce qu‚Äôon appelle les <em>data-engineers</em>. Pourtant, une fois d√©ploy√© dans un environnement de production, le mod√®le n‚Äôa pas r√©alis√© l‚Äôint√©gralit√© de son cycle de vie. En production, le cycle de vie d‚Äôun mod√®le de machine learning suivant l‚Äôapproche MLOps peut √™tre sch√©matis√© de la mani√®re suivante :</p>
<div id="fig-model-lifecycle" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../ML-model-lifecycle.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Source : <a href="https://martinfowler.com">martinfowler.com</a>
</figcaption>
</figure>
</div>
<p>On retrouve les diff√©rentes composantes du MLOps avec les donn√©es (DataOps), les mod√®les (ModelOps) et le code (DevOps). Ces composantes rendent le cycle de vie d‚Äôun mod√®le de machine learning complexe impliquant plusieurs parties prenantes autour du projet. En r√®gle g√©n√©rale, on observe trois parties prenantes principales :</p>
<ul>
<li><em>Data-scientists</em>/<em>Data-engineers</em></li>
<li>IT/DevOps</li>
<li>√âquipes m√©tiers</li>
</ul>
<p>Quelques fois, les <em>data-scientists</em> peuvent √™tre int√©gr√©s aux √©quipes m√©tiers et les <em>data-engineers</em> aux √©quipes IT. Cela peut simplifier les √©changes entre les deux √©quipes, mais cela peut √©galement entra√Æner un travail en silos et cloisonner les deux √©quipes aux expertises, attentes et vocabulaires tr√®s diff√©rents. Or, la communication est primordiale pour permettre une bonne gestion du cycle de vie du mod√®le de machine learning et notamment pour surveiller le mod√®le dans son environnement de production.</p>
<p>Il est extr√™mement important de surveiller comment le mod√®le se comporte une fois d√©ploy√© pour s‚Äôassurer que les r√©sultats renvoy√©s sont conformes aux attentes. Cela permet d‚Äôanticiper des changements dans les donn√©es, une baisse des performances ou encore d‚Äôam√©liorer le mod√®le de mani√®re continue. Il est √©galement n√©cessaire que notre mod√®le soit toujours accessible, que notre application soit bien dimensionn√©e, etc. C‚Äôest pour cela que la surveillance (<em>monitoring</em>) d‚Äôun mod√®le de machine learning est un enjeu capital dans l‚Äôapproche MLOps.</p>
<p>Le terme surveillance peut renvoyer √† plusieurs d√©finitions en fonction de l‚Äô√©quipe dans laquelle l‚Äôon se situe. Pour une personne travaillant dans l‚Äô√©quipe informatique, surveiller une application signifie v√©rifier sa validit√© <strong>technique</strong>. Elle va donc s‚Äôassurer que la latence n‚Äôest pas trop √©lev√©e, que la m√©moire est suffisante ou encore que le stockage sur le disque est bien proportionn√©. Pour un <em>data-scientist</em> ou une personne travaillant dans l‚Äô√©quipe m√©tier, ce qui va l‚Äôint√©resser est la surveillance du mod√®le d‚Äôun point de vue <strong>m√©thodologique</strong>. Malheureusement, il n‚Äôest pas souvent √©vident que contr√¥ler la performance en temps r√©el d‚Äôun mod√®le de machine learning. Il est rare que l‚Äôon connaisse la vraie valeur au moment de la pr√©diction du mod√®le (sinon on ne s‚Äôemb√™terait pas √† construire un mod√®le !) et on ne peut pas vraiment savoir s‚Äôil s‚Äôest tromp√© ou non. Il est donc commun d‚Äôutiliser des proxies pour anticiper une potentielle d√©gradation de la performance de notre mod√®le. On distingue g√©n√©ralement 2 principaux types de d√©gradation d‚Äôun mod√®le de machine learning : le <em>data drift</em> et le <em>concept drift</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../data-concept-drift.png" class="img-fluid figure-img"></p>
<figcaption>Source : <a href="https://whylabs.ai/">whylabs.ai</a></figcaption>
</figure>
</div>
<section id="data-drift" class="level3">
<h3 class="anchored" data-anchor-id="data-drift">Data drift</h3>
<p>On parle de <em>data drift</em> lorsque l‚Äôon observe un changement de distribution dans les donn√©es utilis√©es en entr√©e du mod√®le. En d‚Äôautres termes, il y a <em>data drift</em> lorsque les donn√©es utilis√©es lors de l‚Äôentra√Ænement sont sensiblement diff√©rentes des donn√©es utilis√©es lors de l‚Äôinf√©rence en production. Imaginons que vous souhaitez rep√©rer des habitations √† partir d‚Äôimages satellites. Vous entra√Ænez votre mod√®le sur des donn√©es datant par exemple de f√©vrier 2022, et une fois en production vous essayer de rep√©rer les habitations tous les mois suivants. Vous constatez finalement durant l‚Äô√©t√© que votre mod√®le n‚Äôest plus du tout aussi performant puisque les images satellites de juillet diff√®rent fortement de celle de f√©vrier. La distribution des donn√©es d‚Äôentra√Ænement n‚Äôest plus proche de celle d‚Äôinf√©rence, <span class="math inline">\(P_{train}(X) \neq P_{inference}(X)\)</span>. Les <em>data drifts</em> apparaissent d√®s lors que les propri√©t√©s statistiques des donn√©es changent et cela peut venir de plusieurs facteurs en fonction de votre mod√®le : changements de comportement, dynamique de march√©, nouvelles r√©glementations politiques, probl√®me de qualit√© des donn√©es, etc. Il n‚Äôest pas si simple de d√©tecter rapidement des <em>data drifts</em>, cela suppose de surveiller de mani√®re continue la distribution des donn√©es en entr√©e et en sortie de votre mod√®le sur un certain laps de temps et d‚Äôidentifier quand celles-ci diff√®rent significativement de la distribution des donn√©es d‚Äôentra√Ænement. Pour obtenir une id√©e visuelle, on peut cr√©er des repr√©sentations graphiques comme des histogrammes pour comparer les distributions √† plusieurs p√©riodes dans le temps, voire des bo√Ætes √† moustaches. On peut aussi calculer des m√©triques, qui seront plus simples d‚Äôutilisation si l‚Äôon souhaite automatiser un syst√®me d‚Äôalerte, comme des distances entre distributions (<a href="https://fr.wikipedia.org/wiki/Distance_de_Bhattacharyya">distance de Bhattacharyya</a>, <a href="https://fr.wikipedia.org/wiki/Divergence_de_Kullback-Leibler">divergence de Kullback-Leibler</a>, <a href="https://fr.wikipedia.org/wiki/Distance_de_Hellinger">distance de Hellinger</a>) ou effectuer des tests statistiques (<a href="https://fr.wikipedia.org/wiki/Test_de_Kolmogorov-Smirnov">Test de Kolmogorov-Smirnov</a>, <a href="https://fr.wikipedia.org/wiki/Test_du_%CF%87%C2%B2">Test du œá¬≤</a>). Pour r√©sumer, la d√©tection d‚Äôun <em>data drift</em> peut s‚Äôeffectuer en plusieurs √©tapes :</p>
<ol type="1">
<li><strong>D√©finition d‚Äôune r√©f√©rence</strong> : on d√©finit la distribution de r√©f√©rence (e.g.&nbsp;celle utilis√©e lors de l‚Äôentra√Ænement).</li>
<li><strong>D√©finition de seuils</strong> : on d√©termine en dessous de quelles valeurs de nos m√©triques cela peut √™tre consid√©r√© comme un <em>data drift</em>.</li>
<li><strong>Surveillance continue</strong> : soit en temps r√©el, soit de mani√®re p√©riodique (relativement courte), on compare nos distributions et on calcule les m√©triques d√©finies pr√©alablement.</li>
<li><strong>Alerte et correction</strong> : on met en place un syst√®me d‚Äôalerte automatique d√®s lors que nos m√©triques indiquent la pr√©sence d‚Äôun <em>data drift</em>, puis on agit en cons√©quence (r√©-entra√Ænement sur de nouvelles donn√©es, ajustement des param√®tres du mod√®le, etc.).</li>
</ol>
</section>
<section id="concept-drift" class="level3">
<h3 class="anchored" data-anchor-id="concept-drift">Concept drift</h3>
<p>On parle de <em>concept drift</em> lorsque l‚Äôon observe un changement dans la relation statistique entre les features (<span class="math inline">\(X\)</span>) et la variable √† pr√©dire (<span class="math inline">\(Y\)</span>) au cours du temps. En termes math√©matiques, on consid√®re qu‚Äôil y a un <em>concept drift</em> d√®s lors que <span class="math inline">\(P_{train}(Y|X) \neq P_{inference}(Y|X)\)</span> alors m√™me que <span class="math inline">\(P_{train}(X) = P_{inference}(X)\)</span>. Cela peut avoir un impact important sur les performances du mod√®le si la relation diff√®re fortement. Par exemple, un mod√®le de pr√©diction de la demande de masques chirurgicaux entra√Æn√© sur des donn√©es avant la pand√©mie de COVID-19 deviendra totalement inad√©quat pour effectuer des pr√©dictions lors de cette pand√©mie, car il y a eu un changement dans la relation entre la demande de masques chirurgicaux et les features utilis√©es pour pr√©dire cette demande. Dans le cas d‚Äôun <em>concept drift</em>, on sera plus tent√© de surveiller des m√©triques de performance pour rep√©rer une potentielle anomalie. Dans le cas o√π l‚Äôon poss√®de un jeu de test <em>gold standard</em>, alors on sera en capacit√© de calculer de nombreuses m√©triques usuelles de machine learning (√† savoir l‚Äô<em>accuracy</em>, la <em>precision</em>, le <em>recall</em> ou le <em>F1-score</em> pour des probl√®mes de classification, et toutes les m√©triques d‚Äôerreurs - MSE, RMSE, MAE, ‚Ä¶ - pour les probl√®mes de r√©gression) et rep√©rer une baisse tendancielle ou brutale des performances. Dans le cas o√π l‚Äôon n‚Äôa pas de jeu de test <em>gold standard</em>, on s‚Äôattachera √† d√©terminer des proxys qui peuvent √™tre li√©s √† des m√©triques de performance ou alors utiliser des algorithmes de d√©tection de changement dans le flux de donn√©es (<a href="https://riverml.xyz/0.11.0/api/drift/DDM/">Drift Detection Method</a>, <a href="https://www.researchgate.net/publication/245999704_Early_Drift_Detection_Method">Early Drift Detection Method</a>, <a href="https://riverml.xyz/dev/api/drift/ADWIN/">Adaptive Windowing</a>).</p>
</section>
</section>
<section id="r√©-entra√Ænement-dun-mod√®le-ml" class="level2">
<h2 class="anchored" data-anchor-id="r√©-entra√Ænement-dun-mod√®le-ml">4Ô∏è‚É£ R√©-entra√Ænement d‚Äôun mod√®le ML</h2>
<p>D√®s lors que l‚Äôon a constat√© une baisse de la performance de notre mod√®le gr√¢ce √† notre surveillance fine, il faut ensuite pallier au probl√®me et red√©ployer un mod√®le avec des performances satisfaisantes. On est donc √† la fin du cycle de vie de notre mod√®le, ce qui va nous reconduire au d√©but du cycle pour un nouveau mod√®le comme l‚Äôillustre la figure <a href="#fig-model-lifecycle" class="quarto-xref">Figure&nbsp;1</a>. Le r√©-entra√Ænement est partie int√©grante d‚Äôun projet de machine learning d√®s lors que celui-ci est mis en production. Il existe plusieurs m√©thodes pour r√©-entra√Æner de la plus basique √† la plus MLOps-compatible.</p>
<p>La m√©thode classique est de r√©aliser un nouvel entra√Ænement <em>from scratch</em> en ajoutant les nouvelles donn√©es √† notre disposition dans le jeu d‚Äôentra√Ænement. Cela permet au mod√®le de conna√Ætre les derni√®res relations entre les features et la variable √† pr√©dire. Cependant, r√©-entra√Æner un mod√®le peut √™tre particuli√®rement co√ªteux lorsque l‚Äôon travaille sur de gros mod√®les dont les ressources computationnelles n√©cessaires sont importantes. Il est aussi possible de <em>fine-tuner</em> un mod√®le d√©j√† pr√©-entra√Æn√©. Dans ce cas-l√†, on n‚Äôa pas besoin de repartir de z√©ro, on repart des poids optimis√©s lors du premier entra√Ænement et on les r√©-optimise en utilisant les nouvelles donn√©es √† notre disposition. Cette m√©thode est naturellement beaucoup moins longue √† r√©aliser et est moins co√ªteuse, notamment lorsque la quantit√© de nouvelles donn√©es est faible par rapport √† la quantit√© des donn√©es utilis√©es lors du premier entra√Ænement.</p>
<p>L‚Äôapproche MLOps consiste √† automatiser ce r√©-entra√Ænement, qu‚Äôon appelle √©galement entra√Ænement continu, de sorte √† obtenir un cycle de vie totalement automatis√©. En effet, le r√©-entra√Ænement est fondamental pour s‚Äôassurer que le mod√®le de machine learning est constamment en train de fournir des pr√©dictions coh√©rentes, tout en minimisant les interventions manuelles. L‚Äôobjectif est donc de cr√©er un processus qui lance de nouveaux entra√Ænements de mani√®re automatique en prenant en compte les derni√®res informations disponibles. Les entra√Ænements peuvent √™tre d√©clench√©s soit de mani√®re p√©riodique (tous les lundis √† 2h du matin), d√®s lors qu‚Äôune alerte a √©t√© d√©clench√©e dans notre syst√®me de monitoring, ou bien d√®s qu‚Äôon a une quantit√© de nouvelles donn√©es suffisante pour r√©aliser un <em>online training</em> par exemple.</p>
<p>L‚Äôutilisation d‚Äôoutils d‚Äôorchestration de <em>workflow</em> comme <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a> ou <a href="https://github.com/apache/airflow">Airflow</a> est donc indispensable pour r√©aliser cette automatisation de mani√®re pertinente.</p>
</section>
<section id="d√©fis-organisationnels-du-mlops" class="level2">
<h2 class="anchored" data-anchor-id="d√©fis-organisationnels-du-mlops">5Ô∏è‚É£ D√©fis organisationnels du MLOps</h2>
<p>Outre les sp√©cificit√©s techniques pr√©c√©demment explicit√©es, le MLOps pr√©sente √©galement plusieurs d√©fis en termes organisationnels et manag√©riaux. En effet, dans la plupart des organisations, les √©quipes data transverses ou int√©gr√©es dans diff√©rents d√©partements m√©tier sont relativement jeunes et peuvent manquer de ressources qualifi√©es pour g√©rer le d√©ploiement et le maintien en condition op√©rationnelle de syst√®mes ML complexes. Ces √©quipes se composent principalement de data scientists qui se concentrent sur le d√©veloppement des mod√®les de machine learning, mais n‚Äôont pas les comp√©tences n√©cessaires pour g√©rer le d√©ploiement et la maintenance d‚Äôapplications compl√®tes.</p>
<p>De plus, les √©quipes data √©voluent encore trop souvent en silo, sans communiquer avec les diff√©rentes √©quipes techniques avec lesquelles elles devraient interagir pour mettre en production leurs mod√®les. Or ces √©quipes techniques, souvent compos√©es d‚Äôinformaticiens/d√©veloppeurs, ne connaissent pas forc√©ment les sp√©cificit√©s des mod√®les de machine learning, accentuant d‚Äôautant plus la n√©cessit√© d‚Äôune communication continue entre ces √©quipes.</p>
<p>Une autre difficult√© pouvant intervenir lors du d√©ploiement est la diff√©rence d‚Äôenvironnements utilis√©s ainsi que les diff√©rents langages connus entre les deux √©quipes. Il n‚Äôest pas rare que les <em>data-scientists</em> d√©veloppent des mod√®les en Python tandis que les √©quipes informatiques g√®rent leur serveur de production dans un langage diff√©rent, comme Java par exemple.</p>
<p>Ainsi, l‚Äôapproche MLOps engendre aussi des d√©fis manag√©riaux qui impliquent de faire converger les comp√©tences entre les √©quipes afin de fluidifier la mise en production de mod√®les de machine learning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlops_lifecycle_complete.png" class="img-fluid figure-img"></p>
<figcaption>Gouvernance d‚Äôun projet de machine learning</figcaption>
</figure>
</div>
</section>
</section>
<section id="impl√©mentation-de-lapproche-mlops-avec-mlflow" class="level1">
<h1>Impl√©mentation de l‚Äôapproche MLOps avec MLflow</h1>
<section id="pourquoi-mlflow" class="level2">
<h2 class="anchored" data-anchor-id="pourquoi-mlflow">Pourquoi MLflow ?</h2>
<p>Il existe aujourd‚Äôhui de nombreux outils pour orchestrer des t√¢ches et des pipelines de donn√©es. Parmi les plus populaires (selon leur ‚≠ê GitHub), on peut citer <a href="https://github.com/apache/airflow">Airflow</a>, <a href="https://github.com/spotify/luigi">Luigi</a>, <a href="https://github.com/mlflow/mlflow">MLflow</a>, <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a>, <a href="https://github.com/PrefectHQ/prefect">Prefect</a> ou encore <a href="https://github.com/kubeflow/kubeflow">Kubeflow</a>, <a href="https://www.bentoml.com/"><code>BentoML</code></a>‚Ä¶ Il est difficile d‚Äôaffirmer s‚Äôil y en a un meilleur qu‚Äôun autre ; en r√©alit√©, votre choix d√©pend surtout de votre infrastructure informatique et de votre projet. En l‚Äôoccurrence ici, nous avons fait le choix d‚Äôutiliser <code>MLflow</code> pour sa simplicit√© d‚Äôutilisation gr√¢ce √† une interface web bien faite, parce qu‚Äôil int√®gre l‚Äôensemble du cycle de vie d‚Äôun mod√®le et √©galement parce qu‚Äôil s‚Äôint√®gre tr√®s bien avec Kubernetes. De plus, il est pr√©sent dans le catalogue du SSP Cloud, ce qui simplifie grandement son installation. Afin d‚Äôint√©grer les dimensions d‚Äôint√©gration et de d√©ploiement continus, nous utiliserons √©galement <a href="https://github.com/argoproj/argo-cd">Argo CD</a> et <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a> dans la boucle. Ceux-ci sont privil√©gi√©s par rapport √† <a href="https://github.com/apache/airflow">Airflow</a> car ils sont optimis√©s pour les clusters <em>Kubernetes</em> qui repr√©sentent aujourd‚Äôhui la norme des <em>cloud</em> en ligne ou <em>on premise</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ensae-reproductibilite.github.io/slides/img/mlflow-overview.png" class="img-fluid figure-img"></p>
<figcaption>Vue d‚Äôensemble de <code>MLFlow</code>. Source: <a href="https://dzlab.github.io/ml/2020/07/12/ml-ci-mlflow/">https://dzlab.github.io</a></figcaption>
</figure>
</div>
<p><code>MLflow</code> est une plateforme qui permet d‚Äôoptimiser le d√©veloppement du cycle de vie d‚Äôun mod√®le de <em>machine learning</em>. Elle permet de suivre en d√©tail les diff√©rentes exp√©rimentations, de <em>packager</em> son code pour garantir la reproductibilit√©, et de servir un mod√®le √† des utilisateurs. <code>MLFlow</code> poss√®de √©galement une API qui permet d‚Äô√™tre compatible avec la majorit√© des librairies de <em>machine learning</em> (<code>PyTorch</code>, <code>Scikit-learn</code>, <code>XGBoost</code>, etc.) mais √©galement diff√©rents langages (<code>Python</code>, <code>R</code> et <code>Java</code>).</p>
</section>
<section id="les-projets-mlflow" class="level2">
<h2 class="anchored" data-anchor-id="les-projets-mlflow">Les projets MLflow</h2>
<p>MLflow propose un format pour <em>packager</em> son projet de data science afin de favoriser la r√©utilisation et la reproductibilit√© du code. Ce format s‚Äôappelle tout simplement <em><a href="https://mlflow.org/docs/latest/projects.html">MLflow Project</a></em>. Concr√®tement, un <em>MLflow project</em> n‚Äôest rien d‚Äôautre qu‚Äôun r√©pertoire contenant le code et les ressources n√©cessaires (donn√©es, fichiers de configuration‚Ä¶) pour l‚Äôex√©cution de votre projet. Il est r√©sum√© par un fichier <code>MLproject</code> qui liste les diff√©rentes commandes pour ex√©cuter une pipeline ainsi que les d√©pendances n√©cessaires. En g√©n√©ral, un projet MLflow a la structure suivante :</p>
<pre data-code-line-numbers=""><code>Projet_ML/
‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îú‚îÄ‚îÄ model.bin
‚îÇ   ‚îî‚îÄ‚îÄ train_text.txt
‚îú‚îÄ‚îÄ code/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îî‚îÄ‚îÄ preprocessing.py
‚îú‚îÄ‚îÄ MLmodel
‚îú‚îÄ‚îÄ conda.yaml
‚îú‚îÄ‚îÄ python_env.yaml
‚îú‚îÄ‚îÄ python_model.pkl
‚îî‚îÄ‚îÄ requirements.txt</code></pre>
<p>En plus de <em>packager</em> son projet, MLflow permet √©galement de <em>packager</em> son mod√®le, <strong>quel que soit</strong> la librairie de machine learning sous-jacente utilis√©e (parmi celles <a href="https://mlflow.org/docs/latest/models.html#built-in-model-flavors">compatibles avec MLflow</a>, c‚Äôest-√†-dire toutes les librairies que vous utilisez !). Ainsi, deux mod√®les entra√Æn√©s avec des librairies diff√©rentes, disons PyTorch et Keras, peuvent √™tre d√©ploy√©s et requ√™t√©s de la m√™me mani√®re gr√¢ce √† cette surcouche ajout√©e par MLflow.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlflow-models.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Il est √©galement possible de <em>packager</em> son propre mod√®le personnalis√© ! Pour cela vous pouvez suivre le tutoriel pr√©sent dans la <a href="https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html?highlight=custom%20models">documentation</a>.</p>
</div>
</div>
<p>Autrement dit, un projet MLFlow archive l‚Äôensemble des √©l√©ments n√©cessaires pour reproduire un entra√Ænement donn√© d‚Äôun mod√®le ou pour r√©utiliser celui-ci √† tout moment.</p>
</section>
<section id="le-serveur-de-suivi-tracking-server" class="level2">
<h2 class="anchored" data-anchor-id="le-serveur-de-suivi-tracking-server">Le serveur de suivi (<em>tracking server</em>)</h2>
<p>Le tracking server est le lieu o√π sont archiv√©s l‚Äôensemble des entra√Ænements d‚Äôun mod√®le. Attention, il ne s‚Äôagit pas du serveur sur lequel les mod√®les sont entra√Æn√©s mais de celui o√π les entra√Ænements sont archiv√©s apr√®s avoir eu lieu. Au-del√† de stocker seulement les poids d‚Äôun mod√®le, c‚Äôest l‚Äôensemble de l‚Äôenvironnement n√©cessaire qui peut √™tre retrouv√© dans ce serveur.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../tracking-server.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Techniquement, cela prend la forme d‚Äôune API et d‚Äôune interface utilisateur pour enregistrer les param√®tres, les versions du code, les m√©triques ou encore les artefacts associ√©s √† un entra√Ænement.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ensae-reproductibilite.github.io/slides/img/mlflow-tracking.png" class="img-fluid figure-img"></p>
<figcaption>Source: Databricks</figcaption>
</figure>
</div>
<p>En arri√®re plan, MLFlow va enregistrer tout ceci dans un <em>bucket</em> S3. N√©anmoins, l‚Äôutilisateur n‚Äôaura pas √† se soucier de cela puisque c‚Äôest <code>MLFLow</code> qui fera l‚Äôinterface entre l‚Äôutilisateur et le syst√®me de stockage. Avec son API, <code>MLFLow</code> fournit m√™me une mani√®re simplifi√©e de r√©cup√©rer ces objets archiv√©s, par exemple avec un code prenant la forme</p>
<div class="sourceCode" id="cb2" data-code-line-numbers=""><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlflow</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> mlflow.pyfunc.load_model(model_uri<span class="op">=</span><span class="st">"runs:/d16076a3ec534311817565e6527539c"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Le <em>tracking server</em> est tr√®s utile pour comparer les diff√©rentes exp√©rimentations que vous avez effectu√©es, pour les stocker et √©galement pour √™tre capable de les reproduire. En effet, chaque <em>run</em> sauvegarde la source des donn√©es utilis√©es, mais √©galement le <em>commit</em> sur lequel le <em>run</em> est bas√©.</p>
<p>A la mani√®re de <code>Git</code> qui permet d‚Äôidentifier chaque moment de l‚Äôhistoire d‚Äôun projet √† partir d‚Äôun identifiant unique, <code>MLFlow</code> permet de r√©cup√©rer chaque entra√Ænement d‚Äôun mod√®le √† partir d‚Äôun SHA. N√©anmoins, en pratique, certains mod√®les ont un statut √† part, notamment ceux en production.</p>
</section>
<section id="lentrep√¥t-de-mod√®les-model-registry" class="level2">
<h2 class="anchored" data-anchor-id="lentrep√¥t-de-mod√®les-model-registry">L‚Äôentrep√¥t de mod√®les (<em>model registry</em>)</h2>
<p>Une fois que l‚Äôon a effectu√© diff√©rentes exp√©rimentations et pu s√©lectionner les mod√®les qui nous satisfont, il est temps de passer √† l‚Äô√©tape suivante du cycle de vie d‚Äôun mod√®le. En effet, le mod√®le choisi doit ensuite pouvoir passer dans un environnement de production ou de pr√©-production. Or, conna√Ætre l‚Äô√©tat d‚Äôun mod√®le dans son cycle de vie n√©cessite une organisation tr√®s rigoureuse et n‚Äôest pas si ais√©. MLflow a d√©velopp√© une fonctionnalit√© qui permet justement de simplifier cette gestion des versions des mod√®les gr√¢ce √† son <a href="https://mlflow.org/docs/latest/model-registry.html">Model Registry</a>. Cet entrep√¥t permet d‚Äôajouter des tags et des alias √† nos mod√®les pour d√©finir leur position dans leur cycle de vie et ainsi pouvoir les r√©cup√©rer de mani√®re efficace.</p>
<p>De mani√®re g√©n√©rale, un mod√®le de machine learning passe par 4 stades qu‚Äôil est n√©cessaire de conna√Ætre en tout temps :</p>
<ol type="1">
<li><strong>Exp√©rimental</strong></li>
<li><strong>En √©valuation</strong></li>
<li><strong>En production</strong></li>
<li><strong>Archiv√©</strong></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlflow-model-registry.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="mlflow-en-r√©sum√©" class="level2">
<h2 class="anchored" data-anchor-id="mlflow-en-r√©sum√©">MLflow en r√©sum√©</h2>
<p>MLflow est donc un projet open-source qui fournit une plateforme pour suivre le cycle de vie d‚Äôun mod√®le de machine learning de bout en bout. Ce n‚Äôest pas le seul outil disponible et il n‚Äôest peut-√™tre pas le plus adapt√© √† certains de vos projets pr√©cis. En revanche, il pr√©sente selon nous plusieurs avantages, en premier lieu sa prise en main tr√®s simple et sa capacit√© √† r√©pondre aux besoins de l‚Äôapproche MLOps. Il faut garder √† l‚Äôesprit que cet environnement est encore tr√®s r√©cent et que de nouveaux projets open-source √©mergent chaque jour, donc il est n√©cessaire de rester √† jour sur les derni√®res √©volutions.</p>
<p>Pour r√©sumer, MLFlow permet :</p>
<ul>
<li>de simplifier le suivi de l‚Äôentra√Ænement des mod√®les de machine learning gr√¢ce √† son API et √† son <em>tracking server</em></li>
<li>d‚Äôint√©grer les principaux frameworks de machine learning de mani√®re simple</li>
<li>d‚Äôint√©grer son propre framework si besoin</li>
<li>de standardiser son script d‚Äôentra√Ænement et donc de pouvoir l‚Äôindustrialiser, pour r√©aliser un <em>fine-tuning</em> des hyperparam√®tres, par exemple</li>
<li>de <em>packager</em> ses mod√®les, de sorte √† pouvoir les requ√™ter de mani√®re simple et harmonis√©e entre les diff√©rents frameworks</li>
<li>de stocker ses mod√®les de mani√®re pertinente en leur affectant des tags et en favorisant le suivi de leur cycle de vie</li>
</ul>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-kreuzberger2023machine" class="csl-entry" role="listitem">
Kreuzberger, Dominik, Niklas K√ºhl, and Sebastian Hirschl. 2023. <span>‚ÄúMachine Learning Operations (Mlops): Overview, Definition, and Architecture.‚Äù</span> <em>IEEE Access</em>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ensae-reproductibilite\.github\.io\/website\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>