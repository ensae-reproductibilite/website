<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Introduction aux principes du MLOps pour le passage en production des applications de machine learning.">

<title>Introduction aux enjeux du MLOps – Mise en production</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Mise en production</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../chapters/introduction.html"> 
<span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-les-bases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Les bases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-les-bases">    
        <li>
    <a class="dropdown-item" href="../chapters/linux-101.html">
 <span class="dropdown-text">Linux 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/git.html">
 <span class="dropdown-text">Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bonnes-pratiques-de-développement" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Bonnes pratiques de développement</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bonnes-pratiques-de-développement">    
        <li>
    <a class="dropdown-item" href="../chapters/code-quality.html">
 <span class="dropdown-text">Qualité du code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/projects-architecture.html">
 <span class="dropdown-text">Structure des projets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/big-data.html">
 <span class="dropdown-text">Traitement des données volumineuses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/portability.html">
 <span class="dropdown-text">Portabilité</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-mise-en-production" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Mise en production</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-mise-en-production">    
        <li>
    <a class="dropdown-item" href="../chapters/deployment.html">
 <span class="dropdown-text">Déploiement</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/mlops.html">
 <span class="dropdown-text">MLOps</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../chapters/application.html"> 
<span class="menu-text">Application</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projets</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projets">    
        <li>
    <a class="dropdown-item" href="../chapters/evaluation.html">
 <span class="dropdown-text">Modalités d’évaluation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/galerie.html">
 <span class="dropdown-text">Galerie des projets passés</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/website">
 <span class="dropdown-text">Site web</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/slides">
 <span class="dropdown-text">Slides</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/application-correction">
 <span class="dropdown-text">Application fil rouge</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#fondements-du-mlops" id="toc-fondements-du-mlops" class="nav-link active" data-scroll-target="#fondements-du-mlops">Fondements du MLOps</a>
  <ul class="collapse">
  <li><a href="#du-devops-au-mlops" id="toc-du-devops-au-mlops" class="nav-link" data-scroll-target="#du-devops-au-mlops">Du DevOps au MLOps</a></li>
  <li><a href="#principes-du-mlops" id="toc-principes-du-mlops" class="nav-link" data-scroll-target="#principes-du-mlops">Principes du MLOps</a></li>
  </ul></li>
  <li><a href="#spécificités-liées-à-la-mise-en-production-de-modèles-de-ml" id="toc-spécificités-liées-à-la-mise-en-production-de-modèles-de-ml" class="nav-link" data-scroll-target="#spécificités-liées-à-la-mise-en-production-de-modèles-de-ml">Spécificités liées à la mise en production de modèles de ML</a>
  <ul class="collapse">
  <li><a href="#entraînements-des-modèles" id="toc-entraînements-des-modèles" class="nav-link" data-scroll-target="#entraînements-des-modèles">1️⃣ Entraînements des modèles</a>
  <ul class="collapse">
  <li><a href="#batch-training" id="toc-batch-training" class="nav-link" data-scroll-target="#batch-training">Batch training</a></li>
  <li><a href="#online-training" id="toc-online-training" class="nav-link" data-scroll-target="#online-training">Online training</a></li>
  <li><a href="#distribuer-loptimisation-des-hyperparamètres" id="toc-distribuer-loptimisation-des-hyperparamètres" class="nav-link" data-scroll-target="#distribuer-loptimisation-des-hyperparamètres">Distribuer l’optimisation des hyperparamètres</a></li>
  </ul></li>
  <li><a href="#servir-un-modèle-ml-à-des-utilisateurs" id="toc-servir-un-modèle-ml-à-des-utilisateurs" class="nav-link" data-scroll-target="#servir-un-modèle-ml-à-des-utilisateurs">2️⃣ Servir un modèle ML à des utilisateurs</a></li>
  <li><a href="#observabilité-en-temps-réel-dun-modèle-de-ml" id="toc-observabilité-en-temps-réel-dun-modèle-de-ml" class="nav-link" data-scroll-target="#observabilité-en-temps-réel-dun-modèle-de-ml">3️⃣ Observabilité en temps réel d’un modèle de ML</a>
  <ul class="collapse">
  <li><a href="#data-drift" id="toc-data-drift" class="nav-link" data-scroll-target="#data-drift">Data drift</a></li>
  <li><a href="#concept-drift" id="toc-concept-drift" class="nav-link" data-scroll-target="#concept-drift">Concept drift</a></li>
  </ul></li>
  <li><a href="#ré-entraînement-dun-modèle-ml" id="toc-ré-entraînement-dun-modèle-ml" class="nav-link" data-scroll-target="#ré-entraînement-dun-modèle-ml">4️⃣ Ré-entraînement d’un modèle ML</a></li>
  <li><a href="#défis-organisationnels-du-mlops" id="toc-défis-organisationnels-du-mlops" class="nav-link" data-scroll-target="#défis-organisationnels-du-mlops">5️⃣ Défis organisationnels du MLOps</a></li>
  </ul></li>
  <li><a href="#implémentation-de-lapproche-mlops-avec-mlflow" id="toc-implémentation-de-lapproche-mlops-avec-mlflow" class="nav-link" data-scroll-target="#implémentation-de-lapproche-mlops-avec-mlflow">Implémentation de l’approche MLOps avec MLflow</a>
  <ul class="collapse">
  <li><a href="#pourquoi-mlflow" id="toc-pourquoi-mlflow" class="nav-link" data-scroll-target="#pourquoi-mlflow">Pourquoi MLflow ?</a></li>
  <li><a href="#les-projets-mlflow" id="toc-les-projets-mlflow" class="nav-link" data-scroll-target="#les-projets-mlflow">Les projets MLflow</a></li>
  <li><a href="#le-serveur-de-suivi-tracking-server" id="toc-le-serveur-de-suivi-tracking-server" class="nav-link" data-scroll-target="#le-serveur-de-suivi-tracking-server">Le serveur de suivi (<em>tracking server</em>)</a></li>
  <li><a href="#lentrepôt-de-modèles-model-registry" id="toc-lentrepôt-de-modèles-model-registry" class="nav-link" data-scroll-target="#lentrepôt-de-modèles-model-registry">L’entrepôt de modèles (<em>model registry</em>)</a></li>
  <li><a href="#mlflow-en-résumé" id="toc-mlflow-en-résumé" class="nav-link" data-scroll-target="#mlflow-en-résumé">MLflow en résumé</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Introduction aux enjeux du MLOps</h1>
</div>

<div>
  <div class="description">
    <p>Introduction aux principes du MLOps pour le passage en production des applications de machine learning.</p>
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Dans les chapitres précédents, nous avons vu qu’une majorité des projets <em>data-driven</em> restaient au stade de l’expérimentation, et qu’une des raisons pour expliquer ce phénomène était l’existence de <strong>frictions</strong> empêchant l’<strong>amélioration continue</strong> des projets. Dans le cadre des projets basés sur des modèles de <em>machine learning</em>, cette problématique devient encore plus cruciale : en supplément des enjeux sur le cycle de vie de la donnée intervient la dimension supplémentaire du cycle de vie des modèles. Parmi les principaux enjeux, une question souvent éludée dans les enseignements ou les nombreuses ressources en ligne sur le <em>machine learning</em> est la problématique des <strong>ré-entraînements périodiques</strong>, guidés par l’utilisation faite des modèles et les retours des utilisateurs, afin de maintenir à jour la base de connaissance des modèles et ainsi garantir leur pouvoir prédictif. Ce sujet du ré-entraînement des modèles rend les <strong>aller-retours entre les phases d’expérimentation et de production</strong> nécessairement fréquents. Pour faciliter la mise en place de <em>pipelines</em> favorisant ces boucles de rétroaction, une nouvelle approche a émergé : le <strong>MLOps</strong>, qui vise là encore à mobiliser les concepts et outils issus de l’approche <strong><em>DevOps</em></strong> tout en les adaptant au contexte et aux spécificités des projets de machine learning.</p>
<section id="fondements-du-mlops" class="level1">
<h1>Fondements du MLOps</h1>
<section id="du-devops-au-mlops" class="level2">
<h2 class="anchored" data-anchor-id="du-devops-au-mlops">Du DevOps au MLOps</h2>
<p>L’approche <em>MLOps</em> s’est construite sur les bases de l’approche <em>DevOps</em>. En cela, on peut considérer qu’il s’agit simplement d’une extension de l’approche <em>DevOps</em>, développée pour répondre aux défis spécifiques liés à la gestion du cycle de vie des modèles de machine learning. Le MLOps intègre les principes de collaboration et d’automatisation propres au <em>DevOps</em>, mais prend également en compte tous les aspects liés aux données et aux modèles de machine learning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlops.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<details>
<summary>
A mettre en regard à la boucle du <em>DevOps</em>
</summary>
<img src="https://ensae-reproductibilite.github.io/slides/img/exploration-production.png" class="img-fluid">
</details>
<p>Le <em>MLOps</em> implique l’<strong>automatisation des tâches</strong> telles que la gestion des données, le suivi des <strong>versions des modèles</strong>, leurs <strong>déploiements</strong>, ainsi que l’<strong>évaluation continue</strong> de la performance des modèles en production. De la même manière que le <em>DevOps</em>, le <em>MLOps</em> met l’accent sur la collaboration étroite entre les équipes de développement et d’administration système d’une part, ainsi que les équipes de data science d’autre part. Cette collaboration est clé pour garantir une communication efficace tout au long du cycle de vie du modèle de <em>machine learning</em> et fludifier le passage entre les étapes d’expérimentation et de passage en production.</p>
</section>
<section id="principes-du-mlops" class="level2">
<h2 class="anchored" data-anchor-id="principes-du-mlops">Principes du MLOps</h2>
<p>Puisque le <em>MLOps</em> est ainsi une extension des principes du <em>DevOps</em> aux enjeux du <em>machine learning</em>, les principes généraux sont les mêmes que ceux évoqués précédemment mais ceux-ci s’adaptent à la problématique de la gestion du cycle de vie d’un modèle:</p>
<ul>
<li><p>la <strong>reproductibilité</strong> : les résultats de chaque expérimentation, fructueuse comme infructueuse, doivent pouvoir être <strong>reproduits</strong> sans coût. Cela implique d’abord une certaine rigueur dans la gestion des packages, la gestion des environnements, la gestion des librairies système, le contrôle de version du code, etc.</p></li>
<li><p>le <strong>contrôle de version</strong>: au-delà du simple suivi des versions du code, pour reproduire de manière identique les résultats d’un code c’est l’ensemble des <em>inputs</em> et paramètres influençant l’entraînement d’un modèle (données d’entraînement, hyper-paramètres, etc.) qui doivent être <strong>versionnées</strong> avec le modèle ;</p></li>
<li><p>l’<strong>automatisation</strong> : afin de favoriser les boucles rétroactives d’amélioration continue, le cycle de vie du modèle (tests, <em>build</em>, validation, déploiement) doit être automatisé au maximum. Les outils issus de l’approche <em>DevOps</em>, en particulier l’<strong>intégration et déploiement continus (CI/CD)</strong>, doivent être mobilisés ;</p></li>
<li><p>la <strong>collaboration</strong> : valoriser une culture de travail collaborative autour des projets de ML, dans laquelle la communication au sein des équipes doit permettre de réduire le travail en silos et bénéficier des expertises des différents métiers parti prenantes d’un modèle (analystes, <em>data engineers</em>, devs..). Sur le plan technique, les outils MLOps utilisés doivent favoriser le travail collaboratif sur les données, le modèle et le code utilisés par le projet ;</p></li>
<li><p>l’<strong>amélioration continue</strong> : une fois déployé, il est essentiel de s’assurer que le modèle fonctionne bien comme attendu en évaluant ses performances sur des données réelles à l’aide d’outils de <strong>monitoring en continu</strong>. Dans le cas d’une dégradation des performances dans le temps, un <strong>ré-entraînement périodique</strong> ou un <strong>entraînement en continu</strong> du modèle doivent être envisagés.</p></li>
</ul>
<p>Pour plus de détails, voir <span class="citation" data-cites="kreuzberger2023machine">Kreuzberger, Kühl, and Hirschl (<a href="#ref-kreuzberger2023machine" role="doc-biblioref">2023</a>)</span>.</p>
</section>
</section>
<section id="spécificités-liées-à-la-mise-en-production-de-modèles-de-ml" class="level1">
<h1>Spécificités liées à la mise en production de modèles de ML</h1>
<section id="entraînements-des-modèles" class="level2">
<h2 class="anchored" data-anchor-id="entraînements-des-modèles">1️⃣ Entraînements des modèles</h2>
<p>La première étape d’un projet de <em>machine learning</em> correspond à tout ce que l’on effectue jusqu’à l’entraînement des premiers modèles. Cette étape est un processus itératif et fastidieux qui ne suit pas un développement linéaire : les méthodes de récupération des données peuvent être changeantes, le <em>preprocessing</em> peut varier, de même que la sélection des <em>features</em> pour le modèle (<em>feature engineering</em>), et les algorithmes testés peuvent être nombreux… On est donc aux antipodes des hypothèses habituelles de stabilité nécessaires à l’entraînement et la validité externe dans les enseignements de <em>machine learning</em>.</p>
<p>Garder une trace de tous les essais effectués apparaît indispensable afin de savoir ce qui a fonctionné ou non. Le besoin d’archiver ne concerne pas que les métriques de performances associées à un jeu de paramètres. Ceux-ci ne sont qu’une partie des ingrédients nécessaires pour aboutir à une estimation. L’ensemble des <em>inputs</em> d’un processus de production (code, données, configuration logicielle, etc.) est également à conserver pour être en mesure de répliquer une expérimentation.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Le <em>tracking server</em> de <code>MLFlow</code>, un environnement idéal pour archiver des expérimentations
</div>
</div>
<div class="callout-body-container callout-body">
<p>La phase exploratoire est rendue très simple grâce au <em>Tracking Server</em> de <code>MLFlow</code>. Comme cela sera expliqué ultérieurement, lors de l’exécution d’un <em>run</em>, MLflow enregistre tout un tas de métadonnées qui permettent de retrouver toutes les informations relatives à ce <em>run</em> : la date, le hash du commit, les paramètres du modèle, le dataset utilisé, les métriques spécifiées, etc. Cela permet non seulement de comparer les différents essais réalisés, mais aussi d’être capable de reproduire un <em>run</em> passé.</p>
</div>
</div>
<p>De manière générale, cette phase exploratoire est réalisée par le <em>data scientist</em> ou le <em>ML engineer</em> dans des <em>notebooks</em>. Ces <em>notebooks</em> sont en effet parfaitement adaptés pour cette étape puisqu’ils permettent une grande flexibilité et sont particulièrement commodes pour effectuer des tests. En revanche, lorsque l’on souhaite aller plus loin et que l’on vise une mise en production de son projet, les notebooks ne sont plus adaptés, et cela pour diverses raisons :</p>
<ul>
<li>la collaboration est grandement limitée à cause d’une compatibilité très faible avec les outils de contrôle de version standard (notamment <code>Git</code>).</li>
<li>l’automatisation de <em>pipeline</em> est beaucoup plus compliquée et peu lisible. Il existe certes des packages qui permettent d’automatiser des <em>pipelines</em> de notebooks comme <a href="https://github.com/elyra-ai/elyra">Elyra</a> par exemple, mais ce n’est clairement pas l’approche que nous vous recommandons car les scripts sont beaucoup moins usine à gaz.</li>
<li>Les <em>workflows</em> sont souvent moins clairs, mal organisés (toutes les fonctions définies dans le même fichier affectant la lisibilité du code par exemple) voire peu reproductibles car les cellules sont rarement ordonnées de sorte à exécuter le code de manière linéaire.</li>
<li>Les notebooks offrent généralement une modularité insuffisante lorsque l’on veut travailler avec des composants de <em>machine learning</em> complexes.</li>
</ul>
<p>Toutes ces raisons nous amènent à vous conseiller de réduire au maximum votre utilisation de notebooks et de restreindre leur utilisation à la phase exploratoire ou à la diffusion de résultats/rapports. Passer le plus tôt possible à des scripts <code>.py</code> vous permettra de réduire le coût de la mise en production. Pour reprendre ce qui a déjà été évoqué dans le chapitre <a href="../chapters/projects-architecture.html">Architecture des projets</a>, nous vous invitons à favoriser une structure modulaire de sorte à pouvoir industrialiser votre projet.</p>
<p>Une autre spécificité pouvant impacter la mise en production concerne la manière dont l’entraînement est réalisé. Il existe pour cela 2 écoles qui ont chacune leurs avantages et désavantages : le <em>batch training</em> et l’<em>online training</em>.</p>
<section id="batch-training" class="level3">
<h3 class="anchored" data-anchor-id="batch-training">Batch training</h3>
<p>Le <em>batch training</em> est la manière usuelle d’entraîner un modèle de machine learning. Cette méthode consiste à entraîner son modèle sur un jeu de données fixe d’une seule traite. Le modèle est entraîné sur l’intégralité des données disponibles et les prédictions sont réalisées sur de nouvelles données. Cela signifie que le modèle n’est pas mis à jour une fois qu’il est entraîné, et qu’il est nécessaire de le ré-entraîner si l’on souhaite ajuster ses poids. Cette méthode est relativement simple à mettre en œuvre : il suffit d’entraîner le modèle une seule fois, de le déployer, puis de le ré-entraîner ultérieurement en cas de besoin. Cependant, cette simplicité comporte des inconvénients : le modèle reste statique, nécessitant un ré-entraînement fréquent pour intégrer de nouvelles données. Par exemple, dans le cas de la détection de spams, si un nouveau type de spam apparaît, le modèle entraîné en batch ne sera pas capable de le détecter sans un ré-entraînement complet. De plus, cette méthode peut rapidement exiger une grande quantité de mémoire en fonction de la taille du jeu de données, ce qui peut poser des contraintes sur l’infrastructure et prolonger considérablement le temps d’entraînement.</p>
</section>
<section id="online-training" class="level3">
<h3 class="anchored" data-anchor-id="online-training">Online training</h3>
<p>L’<em>online training</em> se présente comme l’antithèse du <em>batch training</em>, car il se déroule de manière incrémentale. Dans ce mode d’entraînement, de petits lots de données sont envoyés séquentiellement à l’algorithme, ce qui permet à celui-ci de mettre à jour ses poids à chaque nouvelle donnée reçue. Cette approche permet au modèle de détecter efficacement les variations dans les données en temps réel. Il est toutefois crucial de bien ajuster le learning rate afin d’éviter que le modèle oublie les informations apprises sur les données précédentes. L’un des principaux avantages de cette méthode est sa capacité à permettre un entraînement continu même lorsque le modèle est en production, ce qui se traduit par une réduction des coûts computationnels. De plus, l’<em>online training</em> est particulièrement adapté aux situations où les données d’entrée évoluent fréquemment, comme dans le cas des prédictions de cours de bourse. Cependant, sa mise en œuvre dans un contexte de production est bien plus complexe que celle du <em>batch training</em>, et les <em>frameworks</em> traditionnels de machine learning tels que Scikit-learn, PyTorch, TensorFlow et Keras ne sont pas compatibles avec cette approche.</p>
</section>
<section id="distribuer-loptimisation-des-hyperparamètres" class="level3">
<h3 class="anchored" data-anchor-id="distribuer-loptimisation-des-hyperparamètres">Distribuer l’optimisation des hyperparamètres</h3>
<p>Une autre spécificité des modèles de machine learning réside dans le nombre important d’hyperparamètres à optimiser, lesquels peuvent sensiblement impacter les performances du modèle. L’approche standard pour réaliser cette optimisation est ce qu’on appelle un <em>Grid Search</em>. Il s’agit simplement de lister toutes les combinaisons d’hyperparamètres à tester et d’entraîner successivement des modèles avec ces combinaisons prédéfinies. Il n’est pas difficile de comprendre que cette technique est très coûteuse en temps de calcul lorsque le nombre d’hyperparamètres à optimiser et leurs modalités à tester sont élevés. Cependant, cette optimisation est indispensable pour entraîner le meilleur modèle pour notre tâche, et si s’inspirer de la littérature est crucial pour limiter le domaine d’optimisation de nos hyperparamètres, réaliser un <em>Grid Search</em> est une étape incontournable.</p>
<p>Ainsi, pour s’inscrire dans l’approche du MLOps, une bonne méthode est d’automatiser cette optimisation des hyperparamètres en la distribuant sur un <em>cluster</em> lorsqu’on dispose de l’infrastructure adéquate. L’idée est de créer des processus indépendants, chacun liés à une combinaison de nos hyperparamètres, et d’entraîner notre modèle sur ceux-ci puis d’enregister les informations à archiver dans un environnement adéquat, par exemple dans <code>MLFlow</code>.</p>
<p>Il existe un moteur de workflow populaire pour orchestrer des tâches parallèles sur un cluster Kubernetes : <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a>. Le principe est de définir un <em>workflow</em> dans lequel chaque étape correspond à un conteneur contenant uniquement ce qui est strictement nécessaire à l’exécution de cette étape. Ainsi, on s’approche de la perfection en ce qui concerne la reproductibilité, car on maîtrise totalement les installations nécessaires à l’exécution de notre entraînement. Un <em>workflow</em> à plusieurs étapes peut ainsi être modélisé comme un graphe acyclique orienté, et l’exemple ci-dessous représente un cas d’optimisation d’hyperparamètres :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../dag-argo-workflow.png" class="img-fluid figure-img"></p>
<figcaption>Workflow d’optimisation d’hyperparamètres en parallèle</figcaption>
</figure>
</div>
<p>Cette approche permet d’exécuter facilement en parallèle des tâches intensives en calcul de manière totalement reproductible. Évidemment, l’utilisation de tels workflows ne se limite pas à l’optimisation d’hyperparamètres mais peut également être utilisée pour le preprocessing de données, la création de pipelines d’ETL, etc. D’ailleurs, à l’origine, ces outils ont été pensé pour ces tâches et permettent ainsi de définir un processus de données comme un ensemble de transformations sous la forme de diagramme acyclique dirigé (DAG).</p>
</section>
</section>
<section id="servir-un-modèle-ml-à-des-utilisateurs" class="level2">
<h2 class="anchored" data-anchor-id="servir-un-modèle-ml-à-des-utilisateurs">2️⃣ Servir un modèle ML à des utilisateurs</h2>
<p>Une partie très importante, parfois négligée, des projets de <em>machine learning</em> est la mise à disposition des modèles entraînés à d’autres utilisateurs. Puisque vous avez parfaitement suivi les différents chapitres de ce cours, votre projet est en théorie totalement reproductible. Une manière triviale de transmettre le modèle que vous avez sélectionné serait de partager votre code et toutes les informations nécessaires pour qu’une personne tierce ré-entraîne votre modèle de son côté. Évidemment, ce procédé n’est pas optimal, car il suppose que tous les utilisateurs disposent des ressources/infrastructures/connaissances nécessaires pour réaliser l’entraînement.</p>
<p>L’objectif est donc de mettre à disposition votre modèle de manière simple et efficace. Pour cela, plusieurs possibilités s’offrent à vous en fonction de votre projet, et il est important de se poser quelques questions préalables :</p>
<ul>
<li>Quel format est le plus pertinent pour mettre à disposition des utilisateurs ?</li>
<li>Les prédictions du modèle doivent-elles être réalisées par lots (<em>batch</em>) ou en temps réel (<em>online</em>) ?</li>
<li>Quelle infrastructure utiliser pour déployer notre modèle de machine learning ?</li>
</ul>
<p>Dans le cadre de ce cours, nous avons choisi d’utiliser une API REST pour mettre à disposition un modèle de machine learning. Cela nous semble être la méthode la plus adaptée dans une grande majorité des cas, car elle répond à plusieurs critères :</p>
<ul>
<li><strong>Simplicité</strong> : les API REST permettent de créer une porte d’entrée qui peut cacher la complexité sous-jacente du modèle, facilitant ainsi sa mise à disposition.</li>
<li><strong>Standardisation</strong> : l’un des principaux avantages des API REST est qu’elles reposent sur le standard HTTP. Cela signifie qu’elles sont agnostiques au langage de programmation utilisé et que les requêtes peuvent être réalisées en XML, JSON, HTML, etc.</li>
<li><strong>Modularité</strong> : le client et le serveur sont indépendants. En d’autres termes, le stockage des données, l’interface utilisateur ou encore la gestion du modèle sont complètement séparés de la mise à disposition (le serveur).</li>
<li><strong>Passage à l’échelle</strong> : la séparation entre le serveur et le client permet aux API REST d’être très flexibles et facilite le passage à l’échelle (<em>scalability</em>). Elles peuvent ainsi s’adapter à la charge de requêtes concurrentes.</li>
</ul>
<p>L’exposition d’un modèle de machine learning peut être résumée par le schéma suivant :</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../API-diag.png" class="img-fluid figure-img"></p>
<figcaption>Exposer un modèle de ML via une API</figcaption>
</figure>
</div>
<p>Comme le montre le schéma, l’API est exécutée dans un conteneur afin de garantir un environnement totalement autonome et isolé. Seules les dépendances nécessaires à l’exécution du modèle et au fonctionnement de l’API ne sont intégrées à ce conteneur. Travailler avec des <em>images docker</em> légères présente plusieurs avantages. Tout d’abord, créer une image ne contenant que le strict nécessaire au fonctionnement de votre application permet justement de savoir ce qui est absolument indispensable et ce qui est superflu. De plus, plus votre image est légère, plus son temps de téléchargement depuis votre Hub d’images (e.g.&nbsp;<em>Dockerhub</em>) sera rapide à chaque création de conteneur de votre application. Les conteneurs ont l’avantage d’être totalement portables et offrent la possibilité de mettre à l’échelle votre application de manière simple et efficace. Par exemple, si l’on imagine que vous avez déployé votre modèle et que vous souhaitez le requêter un grand nombre de fois dans un laps de temps court, il est alors préférable de créer plusieurs instances de votre application pour que les calculs puissent être effectués en parallèle. L’avantage de procéder de cette manière est qu’une fois qu’on a créé l’image sous-jacente à notre application, il est ensuite très simple de créer une multitude de conteneurs (<em>replicas</em>) toutes basées sur l’image en question.</p>
<p>Pour tout ce qui concerne le déploiement de votre application, vous pouvez vous référer au chapitre <a href="../chapters/deployment.html">Mise en production</a>. Techniquement, il n’y a aucune difficulté supplémentaire lorsque l’on veut avoir une approche MLOps lors de cette étape. L’unique subtilité à avoir en tête est que l’on souhaite maintenant faire communiquer notre application avec MLflow. En effet, chaque déploiement est basé sur une version particulière du modèle et il est nécessaire de renseigner quelques informations afin de récupérer le bon modèle au sein de notre entrepôt de modèle. Comme pour tout déploiement sous Kubernetes, il faut tout d’abord créer les 3 fichiers YAML : <code>deployment.yaml</code>, <code>service.yaml</code>, <code>ingress.yaml</code>. Ensuite, comme vous pouvez le voir sur le schéma, notre API doit pouvoir être reliée à MLflow qui lui-même a besoin d’être connecté à un espace de stockage (ici s3/MinIO) qui contient l’entrepôt des modèles. Pour cela, dans le fichier <code>deployment.yaml</code>, on rajoute simplement quelques variables d’environnement qui nous permettent de créer de lien à savoir :</p>
<ul>
<li><strong>MLFLOW_S3_ENDPOINT_URL</strong> : L’URL de l’endpoint S3 utilisé par MLflow pour stocker les données (et modèles)</li>
<li><strong>MLFLOW_TRACKING_URI</strong> : L’URI du serveur de suivi MLflow, qui spécifie où les informations concernant les modèles sont stockées.</li>
<li><strong>AWS_ACCESS_KEY_ID</strong> : L’identifiant d’accès utilisé pour authentifier l’accès aux services de stockage s3.</li>
<li><strong>AWS_SECRET_ACCESS_KEY</strong> : La clé secrète utilisée pour authentifier l’accès aux services de stockage s3.</li>
<li><strong>AWS_DEFAULT_REGION</strong> : Identifie la région S3 pour laquelle vous souhaitez envoyer les demandes aux serveurs. <!--Trouvé dans la doc AWS pas sur du tout de vouloir mettre ca --></li>
</ul>
<p>Pour faciliter le déploiement continu (voir <a href="../chapters/deployment.html">chapitre Mise en production</a>), il est conseillé de rajouter des variables d’environnement spécifiant la version du modèle à déployer ainsi que le nom du modèle à déployer. En effet, en spécifiant ces valeurs dans le fichier <code>deployment.yaml</code>, cela va permettre de déclencher un nouveau déploiement dès lors que l’on modifiera ces valeurs.</p>
<p>Il est bon de noter que MLflow permet également de déployer directement un modèle MLflow. Vous pouvez aller regarder la <a href="https://mlflow.org/docs/latest/deployment/index.html">documentation</a> si cela vous intéresse. Cette option est relativement récente et pas encore tout à fait mature mais se base sur les mêmes technologies que celles présentées dans ce cours (Kubernetes, S3, etc.). C’est pour cela que nous avons préféré détailler le développement de notre propre API en utilisant le <em>framework</em> <a href="https://fastapi.tiangolo.com/">FastAPI</a>, qui est devenu le standard pour le développement d’API en Python.</p>
<ul>
<li><p>Déployer sur Kubernetes (plutot dans chap mise en prod ?) <!-- j'ai vu que dans les slides vous parlez de kubernetes vous pensez faut mettre un paragraphe dessus ? j'y connais R moi --></p></li>
<li><p>Batch vs real-time prediction</p></li>
</ul>
</section>
<section id="observabilité-en-temps-réel-dun-modèle-de-ml" class="level2">
<h2 class="anchored" data-anchor-id="observabilité-en-temps-réel-dun-modèle-de-ml">3️⃣ Observabilité en temps réel d’un modèle de ML</h2>
<p>Une fois la modélisation réalisée, le modèle entraîné, optimisé et mis à disposition des utilisateurs grâce à un déploiement sur un serveur, on peut considérer que le travail est fini. Du point de vue du <em>data-scientist</em> stricto sensu, cela peut être le cas, puisque l’on considère souvent que le domaine du <em>data-scientist</em> s’arrête à la sélection du modèle à déployer, le déploiement étant réalisé par ce qu’on appelle les <em>data-engineers</em>. Pourtant, une fois déployé dans un environnement de production, le modèle n’a pas réalisé l’intégralité de son cycle de vie. En production, le cycle de vie d’un modèle de machine learning suivant l’approche MLOps peut être schématisé de la manière suivante :</p>
<div id="fig-model-lifecycle" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-model-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../ML-model-lifecycle.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-model-lifecycle-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Source : <a href="https://martinfowler.com">martinfowler.com</a>
</figcaption>
</figure>
</div>
<p>On retrouve les différentes composantes du MLOps avec les données (DataOps), les modèles (ModelOps) et le code (DevOps). Ces composantes rendent le cycle de vie d’un modèle de machine learning complexe impliquant plusieurs parties prenantes autour du projet. En règle générale, on observe trois parties prenantes principales :</p>
<ul>
<li><em>Data-scientists</em>/<em>Data-engineers</em></li>
<li>IT/DevOps</li>
<li>Équipes métiers</li>
</ul>
<p>Quelques fois, les <em>data-scientists</em> peuvent être intégrés aux équipes métiers et les <em>data-engineers</em> aux équipes IT. Cela peut simplifier les échanges entre les deux équipes, mais cela peut également entraîner un travail en silos et cloisonner les deux équipes aux expertises, attentes et vocabulaires très différents. Or, la communication est primordiale pour permettre une bonne gestion du cycle de vie du modèle de machine learning et notamment pour surveiller le modèle dans son environnement de production.</p>
<p>Il est extrêmement important de surveiller comment le modèle se comporte une fois déployé pour s’assurer que les résultats renvoyés sont conformes aux attentes. Cela permet d’anticiper des changements dans les données, une baisse des performances ou encore d’améliorer le modèle de manière continue. Il est également nécessaire que notre modèle soit toujours accessible, que notre application soit bien dimensionnée, etc. C’est pour cela que la surveillance (<em>monitoring</em>) d’un modèle de machine learning est un enjeu capital dans l’approche MLOps.</p>
<p>Le terme surveillance peut renvoyer à plusieurs définitions en fonction de l’équipe dans laquelle l’on se situe. Pour une personne travaillant dans l’équipe informatique, surveiller une application signifie vérifier sa validité <strong>technique</strong>. Elle va donc s’assurer que la latence n’est pas trop élevée, que la mémoire est suffisante ou encore que le stockage sur le disque est bien proportionné. Pour un <em>data-scientist</em> ou une personne travaillant dans l’équipe métier, ce qui va l’intéresser est la surveillance du modèle d’un point de vue <strong>méthodologique</strong>. Malheureusement, il n’est pas souvent évident que contrôler la performance en temps réel d’un modèle de machine learning. Il est rare que l’on connaisse la vraie valeur au moment de la prédiction du modèle (sinon on ne s’embêterait pas à construire un modèle !) et on ne peut pas vraiment savoir s’il s’est trompé ou non. Il est donc commun d’utiliser des proxies pour anticiper une potentielle dégradation de la performance de notre modèle. On distingue généralement 2 principaux types de dégradation d’un modèle de machine learning : le <em>data drift</em> et le <em>concept drift</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../data-concept-drift.png" class="img-fluid figure-img"></p>
<figcaption>Source : <a href="https://whylabs.ai/">whylabs.ai</a></figcaption>
</figure>
</div>
<section id="data-drift" class="level3">
<h3 class="anchored" data-anchor-id="data-drift">Data drift</h3>
<p>On parle de <em>data drift</em> lorsque l’on observe un changement de distribution dans les données utilisées en entrée du modèle. En d’autres termes, il y a <em>data drift</em> lorsque les données utilisées lors de l’entraînement sont sensiblement différentes des données utilisées lors de l’inférence en production. Imaginons que vous souhaitez repérer des habitations à partir d’images satellites. Vous entraînez votre modèle sur des données datant par exemple de février 2022, et une fois en production vous essayer de repérer les habitations tous les mois suivants. Vous constatez finalement durant l’été que votre modèle n’est plus du tout aussi performant puisque les images satellites de juillet diffèrent fortement de celle de février. La distribution des données d’entraînement n’est plus proche de celle d’inférence, <span class="math inline">\(P_{train}(X) \neq P_{inference}(X)\)</span>. Les <em>data drifts</em> apparaissent dès lors que les propriétés statistiques des données changent et cela peut venir de plusieurs facteurs en fonction de votre modèle : changements de comportement, dynamique de marché, nouvelles réglementations politiques, problème de qualité des données, etc. Il n’est pas si simple de détecter rapidement des <em>data drifts</em>, cela suppose de surveiller de manière continue la distribution des données en entrée et en sortie de votre modèle sur un certain laps de temps et d’identifier quand celles-ci diffèrent significativement de la distribution des données d’entraînement. Pour obtenir une idée visuelle, on peut créer des représentations graphiques comme des histogrammes pour comparer les distributions à plusieurs périodes dans le temps, voire des boîtes à moustaches. On peut aussi calculer des métriques, qui seront plus simples d’utilisation si l’on souhaite automatiser un système d’alerte, comme des distances entre distributions (<a href="https://fr.wikipedia.org/wiki/Distance_de_Bhattacharyya">distance de Bhattacharyya</a>, <a href="https://fr.wikipedia.org/wiki/Divergence_de_Kullback-Leibler">divergence de Kullback-Leibler</a>, <a href="https://fr.wikipedia.org/wiki/Distance_de_Hellinger">distance de Hellinger</a>) ou effectuer des tests statistiques (<a href="https://fr.wikipedia.org/wiki/Test_de_Kolmogorov-Smirnov">Test de Kolmogorov-Smirnov</a>, <a href="https://fr.wikipedia.org/wiki/Test_du_%CF%87%C2%B2">Test du χ²</a>). Pour résumer, la détection d’un <em>data drift</em> peut s’effectuer en plusieurs étapes :</p>
<ol type="1">
<li><strong>Définition d’une référence</strong> : on définit la distribution de référence (e.g.&nbsp;celle utilisée lors de l’entraînement).</li>
<li><strong>Définition de seuils</strong> : on détermine en dessous de quelles valeurs de nos métriques cela peut être considéré comme un <em>data drift</em>.</li>
<li><strong>Surveillance continue</strong> : soit en temps réel, soit de manière périodique (relativement courte), on compare nos distributions et on calcule les métriques définies préalablement.</li>
<li><strong>Alerte et correction</strong> : on met en place un système d’alerte automatique dès lors que nos métriques indiquent la présence d’un <em>data drift</em>, puis on agit en conséquence (ré-entraînement sur de nouvelles données, ajustement des paramètres du modèle, etc.).</li>
</ol>
</section>
<section id="concept-drift" class="level3">
<h3 class="anchored" data-anchor-id="concept-drift">Concept drift</h3>
<p>On parle de <em>concept drift</em> lorsque l’on observe un changement dans la relation statistique entre les features (<span class="math inline">\(X\)</span>) et la variable à prédire (<span class="math inline">\(Y\)</span>) au cours du temps. En termes mathématiques, on considère qu’il y a un <em>concept drift</em> dès lors que <span class="math inline">\(P_{train}(Y|X) \neq P_{inference}(Y|X)\)</span> alors même que <span class="math inline">\(P_{train}(X) = P_{inference}(X)\)</span>. Cela peut avoir un impact important sur les performances du modèle si la relation diffère fortement. Par exemple, un modèle de prédiction de la demande de masques chirurgicaux entraîné sur des données avant la pandémie de COVID-19 deviendra totalement inadéquat pour effectuer des prédictions lors de cette pandémie, car il y a eu un changement dans la relation entre la demande de masques chirurgicaux et les features utilisées pour prédire cette demande. Dans le cas d’un <em>concept drift</em>, on sera plus tenté de surveiller des métriques de performance pour repérer une potentielle anomalie. Dans le cas où l’on possède un jeu de test <em>gold standard</em>, alors on sera en capacité de calculer de nombreuses métriques usuelles de machine learning (à savoir l’<em>accuracy</em>, la <em>precision</em>, le <em>recall</em> ou le <em>F1-score</em> pour des problèmes de classification, et toutes les métriques d’erreurs - MSE, RMSE, MAE, … - pour les problèmes de régression) et repérer une baisse tendancielle ou brutale des performances. Dans le cas où l’on n’a pas de jeu de test <em>gold standard</em>, on s’attachera à déterminer des proxys qui peuvent être liés à des métriques de performance ou alors utiliser des algorithmes de détection de changement dans le flux de données (<a href="https://riverml.xyz/0.11.0/api/drift/DDM/">Drift Detection Method</a>, <a href="https://www.researchgate.net/publication/245999704_Early_Drift_Detection_Method">Early Drift Detection Method</a>, <a href="https://riverml.xyz/dev/api/drift/ADWIN/">Adaptive Windowing</a>).</p>
</section>
</section>
<section id="ré-entraînement-dun-modèle-ml" class="level2">
<h2 class="anchored" data-anchor-id="ré-entraînement-dun-modèle-ml">4️⃣ Ré-entraînement d’un modèle ML</h2>
<p>Dès lors que l’on a constaté une baisse de la performance de notre modèle grâce à notre surveillance fine, il faut ensuite pallier au problème et redéployer un modèle avec des performances satisfaisantes. On est donc à la fin du cycle de vie de notre modèle, ce qui va nous reconduire au début du cycle pour un nouveau modèle comme l’illustre la figure <a href="#fig-model-lifecycle" class="quarto-xref">Figure&nbsp;1</a>. Le ré-entraînement est partie intégrante d’un projet de machine learning dès lors que celui-ci est mis en production. Il existe plusieurs méthodes pour ré-entraîner de la plus basique à la plus MLOps-compatible.</p>
<p>La méthode classique est de réaliser un nouvel entraînement <em>from scratch</em> en ajoutant les nouvelles données à notre disposition dans le jeu d’entraînement. Cela permet au modèle de connaître les dernières relations entre les features et la variable à prédire. Cependant, ré-entraîner un modèle peut être particulièrement coûteux lorsque l’on travaille sur de gros modèles dont les ressources computationnelles nécessaires sont importantes. Il est aussi possible de <em>fine-tuner</em> un modèle déjà pré-entraîné. Dans ce cas-là, on n’a pas besoin de repartir de zéro, on repart des poids optimisés lors du premier entraînement et on les ré-optimise en utilisant les nouvelles données à notre disposition. Cette méthode est naturellement beaucoup moins longue à réaliser et est moins coûteuse, notamment lorsque la quantité de nouvelles données est faible par rapport à la quantité des données utilisées lors du premier entraînement.</p>
<p>L’approche MLOps consiste à automatiser ce ré-entraînement, qu’on appelle également entraînement continu, de sorte à obtenir un cycle de vie totalement automatisé. En effet, le ré-entraînement est fondamental pour s’assurer que le modèle de machine learning est constamment en train de fournir des prédictions cohérentes, tout en minimisant les interventions manuelles. L’objectif est donc de créer un processus qui lance de nouveaux entraînements de manière automatique en prenant en compte les dernières informations disponibles. Les entraînements peuvent être déclenchés soit de manière périodique (tous les lundis à 2h du matin), dès lors qu’une alerte a été déclenchée dans notre système de monitoring, ou bien dès qu’on a une quantité de nouvelles données suffisante pour réaliser un <em>online training</em> par exemple.</p>
<p>L’utilisation d’outils d’orchestration de <em>workflow</em> comme <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a> ou <a href="https://github.com/apache/airflow">Airflow</a> est donc indispensable pour réaliser cette automatisation de manière pertinente.</p>
</section>
<section id="défis-organisationnels-du-mlops" class="level2">
<h2 class="anchored" data-anchor-id="défis-organisationnels-du-mlops">5️⃣ Défis organisationnels du MLOps</h2>
<p>Outre les spécificités techniques précédemment explicitées, le MLOps présente également plusieurs défis en termes organisationnels et managériaux. En effet, dans la plupart des organisations, les équipes data transverses ou intégrées dans différents départements métier sont relativement jeunes et peuvent manquer de ressources qualifiées pour gérer le déploiement et le maintien en condition opérationnelle de systèmes ML complexes. Ces équipes se composent principalement de data scientists qui se concentrent sur le développement des modèles de machine learning, mais n’ont pas les compétences nécessaires pour gérer le déploiement et la maintenance d’applications complètes.</p>
<p>De plus, les équipes data évoluent encore trop souvent en silo, sans communiquer avec les différentes équipes techniques avec lesquelles elles devraient interagir pour mettre en production leurs modèles. Or ces équipes techniques, souvent composées d’informaticiens/développeurs, ne connaissent pas forcément les spécificités des modèles de machine learning, accentuant d’autant plus la nécessité d’une communication continue entre ces équipes.</p>
<p>Une autre difficulté pouvant intervenir lors du déploiement est la différence d’environnements utilisés ainsi que les différents langages connus entre les deux équipes. Il n’est pas rare que les <em>data-scientists</em> développent des modèles en Python tandis que les équipes informatiques gèrent leur serveur de production dans un langage différent, comme Java par exemple.</p>
<p>Ainsi, l’approche MLOps engendre aussi des défis managériaux qui impliquent de faire converger les compétences entre les équipes afin de fluidifier la mise en production de modèles de machine learning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlops_lifecycle_complete.png" class="img-fluid figure-img"></p>
<figcaption>Gouvernance d’un projet de machine learning</figcaption>
</figure>
</div>
</section>
</section>
<section id="implémentation-de-lapproche-mlops-avec-mlflow" class="level1">
<h1>Implémentation de l’approche MLOps avec MLflow</h1>
<section id="pourquoi-mlflow" class="level2">
<h2 class="anchored" data-anchor-id="pourquoi-mlflow">Pourquoi MLflow ?</h2>
<p>Il existe aujourd’hui de nombreux outils pour orchestrer des tâches et des pipelines de données. Parmi les plus populaires (selon leur ⭐ GitHub), on peut citer <a href="https://github.com/apache/airflow">Airflow</a>, <a href="https://github.com/spotify/luigi">Luigi</a>, <a href="https://github.com/mlflow/mlflow">MLflow</a>, <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a>, <a href="https://github.com/PrefectHQ/prefect">Prefect</a> ou encore <a href="https://github.com/kubeflow/kubeflow">Kubeflow</a>, <a href="https://www.bentoml.com/"><code>BentoML</code></a>… Il est difficile d’affirmer s’il y en a un meilleur qu’un autre ; en réalité, votre choix dépend surtout de votre infrastructure informatique et de votre projet. En l’occurrence ici, nous avons fait le choix d’utiliser <code>MLflow</code> pour sa simplicité d’utilisation grâce à une interface web bien faite, parce qu’il intègre l’ensemble du cycle de vie d’un modèle et également parce qu’il s’intègre très bien avec Kubernetes. De plus, il est présent dans le catalogue du SSP Cloud, ce qui simplifie grandement son installation. Afin d’intégrer les dimensions d’intégration et de déploiement continus, nous utiliserons également <a href="https://github.com/argoproj/argo-cd">Argo CD</a> et <a href="https://github.com/argoproj/argo-workflows">Argo Workflow</a> dans la boucle. Ceux-ci sont privilégiés par rapport à <a href="https://github.com/apache/airflow">Airflow</a> car ils sont optimisés pour les clusters <em>Kubernetes</em> qui représentent aujourd’hui la norme des <em>cloud</em> en ligne ou <em>on premise</em>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ensae-reproductibilite.github.io/slides/img/mlflow-overview.png" class="img-fluid figure-img"></p>
<figcaption>Vue d’ensemble de <code>MLFlow</code>. Source: <a href="https://dzlab.github.io/ml/2020/07/12/ml-ci-mlflow/">https://dzlab.github.io</a></figcaption>
</figure>
</div>
<p><code>MLflow</code> est une plateforme qui permet d’optimiser le développement du cycle de vie d’un modèle de <em>machine learning</em>. Elle permet de suivre en détail les différentes expérimentations, de <em>packager</em> son code pour garantir la reproductibilité, et de servir un modèle à des utilisateurs. <code>MLFlow</code> possède également une API qui permet d’être compatible avec la majorité des librairies de <em>machine learning</em> (<code>PyTorch</code>, <code>Scikit-learn</code>, <code>XGBoost</code>, etc.) mais également différents langages (<code>Python</code>, <code>R</code> et <code>Java</code>).</p>
</section>
<section id="les-projets-mlflow" class="level2">
<h2 class="anchored" data-anchor-id="les-projets-mlflow">Les projets MLflow</h2>
<p>MLflow propose un format pour <em>packager</em> son projet de data science afin de favoriser la réutilisation et la reproductibilité du code. Ce format s’appelle tout simplement <em><a href="https://mlflow.org/docs/latest/projects.html">MLflow Project</a></em>. Concrètement, un <em>MLflow project</em> n’est rien d’autre qu’un répertoire contenant le code et les ressources nécessaires (données, fichiers de configuration…) pour l’exécution de votre projet. Il est résumé par un fichier <code>MLproject</code> qui liste les différentes commandes pour exécuter une pipeline ainsi que les dépendances nécessaires. En général, un projet MLflow a la structure suivante :</p>
<pre data-code-line-numbers=""><code>Projet_ML/
├── artifacts/
│   ├── model.bin
│   └── train_text.txt
├── code/
│   ├── main.py
│   └── preprocessing.py
├── MLmodel
├── conda.yaml
├── python_env.yaml
├── python_model.pkl
└── requirements.txt</code></pre>
<p>En plus de <em>packager</em> son projet, MLflow permet également de <em>packager</em> son modèle, <strong>quel que soit</strong> la librairie de machine learning sous-jacente utilisée (parmi celles <a href="https://mlflow.org/docs/latest/models.html#built-in-model-flavors">compatibles avec MLflow</a>, c’est-à-dire toutes les librairies que vous utilisez !). Ainsi, deux modèles entraînés avec des librairies différentes, disons PyTorch et Keras, peuvent être déployés et requêtés de la même manière grâce à cette surcouche ajoutée par MLflow.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlflow-models.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>Il est également possible de <em>packager</em> son propre modèle personnalisé ! Pour cela vous pouvez suivre le tutoriel présent dans la <a href="https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html?highlight=custom%20models">documentation</a>.</p>
</div>
</div>
<p>Autrement dit, un projet MLFlow archive l’ensemble des éléments nécessaires pour reproduire un entraînement donné d’un modèle ou pour réutiliser celui-ci à tout moment.</p>
</section>
<section id="le-serveur-de-suivi-tracking-server" class="level2">
<h2 class="anchored" data-anchor-id="le-serveur-de-suivi-tracking-server">Le serveur de suivi (<em>tracking server</em>)</h2>
<p>Le tracking server est le lieu où sont archivés l’ensemble des entraînements d’un modèle. Attention, il ne s’agit pas du serveur sur lequel les modèles sont entraînés mais de celui où les entraînements sont archivés après avoir eu lieu. Au-delà de stocker seulement les poids d’un modèle, c’est l’ensemble de l’environnement nécessaire qui peut être retrouvé dans ce serveur.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../tracking-server.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
<p>Techniquement, cela prend la forme d’une API et d’une interface utilisateur pour enregistrer les paramètres, les versions du code, les métriques ou encore les artefacts associés à un entraînement.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://ensae-reproductibilite.github.io/slides/img/mlflow-tracking.png" class="img-fluid figure-img"></p>
<figcaption>Source: Databricks</figcaption>
</figure>
</div>
<p>En arrière plan, MLFlow va enregistrer tout ceci dans un <em>bucket</em> S3. Néanmoins, l’utilisateur n’aura pas à se soucier de cela puisque c’est <code>MLFLow</code> qui fera l’interface entre l’utilisateur et le système de stockage. Avec son API, <code>MLFLow</code> fournit même une manière simplifiée de récupérer ces objets archivés, par exemple avec un code prenant la forme</p>
<div class="sourceCode" id="cb2" data-code-line-numbers=""><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> mlflow</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> mlflow.pyfunc.load_model(model_uri<span class="op">=</span><span class="st">"runs:/d16076a3ec534311817565e6527539c"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Le <em>tracking server</em> est très utile pour comparer les différentes expérimentations que vous avez effectuées, pour les stocker et également pour être capable de les reproduire. En effet, chaque <em>run</em> sauvegarde la source des données utilisées, mais également le <em>commit</em> sur lequel le <em>run</em> est basé.</p>
<p>A la manière de <code>Git</code> qui permet d’identifier chaque moment de l’histoire d’un projet à partir d’un identifiant unique, <code>MLFlow</code> permet de récupérer chaque entraînement d’un modèle à partir d’un SHA. Néanmoins, en pratique, certains modèles ont un statut à part, notamment ceux en production.</p>
</section>
<section id="lentrepôt-de-modèles-model-registry" class="level2">
<h2 class="anchored" data-anchor-id="lentrepôt-de-modèles-model-registry">L’entrepôt de modèles (<em>model registry</em>)</h2>
<p>Une fois que l’on a effectué différentes expérimentations et pu sélectionner les modèles qui nous satisfont, il est temps de passer à l’étape suivante du cycle de vie d’un modèle. En effet, le modèle choisi doit ensuite pouvoir passer dans un environnement de production ou de pré-production. Or, connaître l’état d’un modèle dans son cycle de vie nécessite une organisation très rigoureuse et n’est pas si aisé. MLflow a développé une fonctionnalité qui permet justement de simplifier cette gestion des versions des modèles grâce à son <a href="https://mlflow.org/docs/latest/model-registry.html">Model Registry</a>. Cet entrepôt permet d’ajouter des tags et des alias à nos modèles pour définir leur position dans leur cycle de vie et ainsi pouvoir les récupérer de manière efficace.</p>
<p>De manière générale, un modèle de machine learning passe par 4 stades qu’il est nécessaire de connaître en tout temps :</p>
<ol type="1">
<li><strong>Expérimental</strong></li>
<li><strong>En évaluation</strong></li>
<li><strong>En production</strong></li>
<li><strong>Archivé</strong></li>
</ol>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../mlflow-model-registry.png" class="img-fluid quarto-figure quarto-figure-center figure-img"></p>
</figure>
</div>
</section>
<section id="mlflow-en-résumé" class="level2">
<h2 class="anchored" data-anchor-id="mlflow-en-résumé">MLflow en résumé</h2>
<p>MLflow est donc un projet open-source qui fournit une plateforme pour suivre le cycle de vie d’un modèle de machine learning de bout en bout. Ce n’est pas le seul outil disponible et il n’est peut-être pas le plus adapté à certains de vos projets précis. En revanche, il présente selon nous plusieurs avantages, en premier lieu sa prise en main très simple et sa capacité à répondre aux besoins de l’approche MLOps. Il faut garder à l’esprit que cet environnement est encore très récent et que de nouveaux projets open-source émergent chaque jour, donc il est nécessaire de rester à jour sur les dernières évolutions.</p>
<p>Pour résumer, MLFlow permet :</p>
<ul>
<li>de simplifier le suivi de l’entraînement des modèles de machine learning grâce à son API et à son <em>tracking server</em></li>
<li>d’intégrer les principaux frameworks de machine learning de manière simple</li>
<li>d’intégrer son propre framework si besoin</li>
<li>de standardiser son script d’entraînement et donc de pouvoir l’industrialiser, pour réaliser un <em>fine-tuning</em> des hyperparamètres, par exemple</li>
<li>de <em>packager</em> ses modèles, de sorte à pouvoir les requêter de manière simple et harmonisée entre les différents frameworks</li>
<li>de stocker ses modèles de manière pertinente en leur affectant des tags et en favorisant le suivi de leur cycle de vie</li>
</ul>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-kreuzberger2023machine" class="csl-entry" role="listitem">
Kreuzberger, Dominik, Niklas Kühl, and Sebastian Hirschl. 2023. <span>“Machine Learning Operations (Mlops): Overview, Definition, and Architecture.”</span> <em>IEEE Access</em>.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/ensae-reproductibilite\.github\.io\/website\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>