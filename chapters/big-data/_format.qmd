::: {.content-visible when-profile="fr"}

# Formats de données {#sec-new-formats}

Une autre dimension majeure à considérer pour le traitement des données massives est la manière dont on stocke ces données. Le choix d’un format de données repose sur un arbitrage entre plusieurs critères, notamment la finalité (traitement, analyse, diffusion...), le public cible (population générale, membres du projet, etc.), la volumétrie et l’interopérabilité. Les formats classiques comme le CSV, le JSON ou le XML sont largement utilisés pour le traitement et la diffusion de données, en particulier pour leur praticité : ils sont au format texte, ce qui les rend facilement prévisualisables dans un éditeur — on dit qu'ils sont "*human-readable*". Par ailleurs, ils sont naturellement interopérables : le texte peut être lu simplement depuis n'importe quel langage de programmation, et les différentes librairies de lecture de fichiers intègre nativement leur lecture. Néanmoins, ces formats montrent rapidement leurs limites face aux besoins d’analyse sur des données massives. Leur absence de compression entraîne une consommation élevée d’espace disque. Par ailleurs, leur représentation sous forme de lignes (@fig-columnar-storage) à la fois sur disque et en mémoire les rend peu efficients, dans la mesure où il est nécessaire de charger un fichier entier pour pouvoir effectuer des opérations statistiques sur les colonnes et/ou les lignes.

Une innovation majeure de la dernière décennie au sein de l'éco-système de la donnée est l'émergence de formats de données qui pallient les différentes limites des formats traditionnels précédemment évoquées. Le format le plus populaire à ce titre, et qui est ainsi devenu un véritable standard pour le stockage de données, est le format `Apache Parquet`. Ce format présente en effet un ensemble de caractéristiques qui le rendent particulièrement adapté aux applications de *data science*. D'abord, il s'agit d'un format compressé, ce qui en fait un format très adapté au stockage de données volumineuses. Si le degré de compression dépend intimement de la structure des données, il n'est pas rare de voir un même jeu de données occuper 10 fois moins de place en `Parquet` qu'en `CSV`. Ensuite, le format `Parquet` est interopérable : les fichiers de ce format peuvent être aussi bien requêtés à partir de langages courants (comme `Python`, `R` ou `SQL`) qu'avec des langages dédiés au traitement des données massives comme `Spark`.

Mais le facteur essentiel qui explique l'adoption généralisée du format `Parquet` dans les applications de *data science* est sa performance en lecture. S'agissant d'un format compressé, on pourrait intuitivement s'attendre à des performances inférieures comparé à la lecture des mêmes données sous la forme d'un fichier texte : si l'on compresse un fichier `CSV` au format `zip` par exemple, il faut payer un coût de décompression pour pouvoir lire le fichier. Au contraire, la compression des données en `Parquet` est très optimisée, ce qui permet des performances en lecture bien supérieures à celle d'un fichier `CSV`. Une propriété essentielle du format `Parquet` pour comprendre cette performance en lecture est le fait qu'il soit "orienté-colonne", c'est à dire que les données sont stockées sous forme de colonnes et non de lignes comme dans les formats textuels traditionnels (@fig-columnar-storage). Cette propriété le rend particulièrement adapté pour la *data science* dans la mesure où la plupart des opérations statistiques sont de nature analytique (dites OLAP - *Online Analytical Processing*) : elles impliquent la sélection de colonnes spécifiques, le calcul de nouvelles variables, la réalisation d'agrégations basées sur des groupes, etc. Le stockage orienté ligne — comme dans un fichier CSV — n'est pas adapté à ces opérations analytiques, car il nécessite de charger l'ensemble du jeu de données en mémoire afin d'effectuer une requête. À l'inverse, le stockage orienté colonne permet de ne lire que les colonnes de données pertinentes, ce qui réduit considérablement les temps de lecture et de traitement pour ces charges de travail analytiques [@abdelaziz2023optimizing]. En pratique, les formats colonnes populaires tels que `Parquet` utilisent une représentation hybride : ils sont principalement orientés colonne, mais intègrent également un regroupement astucieux basé sur les lignes pour optimiser les requêtes de filtrage.

![Représentation orientée ligne et orientée colonne d'un même jeu de données.](/columnar-storage.png){#fig-columnar-storage}

Une autre propriété importante du format `Parquet` est sa capacité native à produire des fichiers partitionnés, c'est à dire à distribuer un fichier de données selon une ou plusieurs clés de partitionnement. Dans la majorité des cas, les traitements statistiques ne concernent pas l'ensemble des données d'une source de données : on voudra souvent restreindre les calculs à une zone géographique, une fenêtre temporelle, etc. Si les données à traiter sont disponibles sous la forme d'un unique fichier, il faudra généralement charger l'ensemble des données en mémoire — a minima, les colonnes pertinentes — pour réaliser les traitements. A contrario, `Parquet` offre la possibilité native de partitionner un jeu de données selon une variable de filtrage fréquente — à la manière d'un index dans une base `SQL` — ce qui permet d'optimiser les traitements et d'accroître encore leur efficience (@fig-parquet-partitions). Là encore, cette propriété rend le format `Parquet` particulièrement pertinent pour les traitements analytiques qui caractérisent les applications de *data science* [@dondon2023quels].

![Représentation sur le *filesystem* d'un fichier `Parquet` partitionné selon deux clés : l'année et le mois. Dans cet exemple, effectuer une requête faisant intervenir seulement un ou quelques mois de données serait très efficient dans la mesure où seules les partitions pertinentes auront besoin d'être chargées en mémoire.](/parquet-partitions.png){#fig-parquet-partitions fig-align="center" height=300}


:::

::: {.content-visible when-profile="en"}

# Data Formats {#sec-new-formats}

Another major dimension to consider for processing massive datasets is how data is stored. Choosing a data format involves balancing several factors, such as the purpose (processing, analysis, dissemination), the target audience (general public, project members, etc.), volume, and interoperability. Traditional formats like CSV, JSON, and XML are widely used due to their convenience: they are plain text formats, making them easily viewable in any text editor — they are considered *human-readable*. Additionally, they are naturally interoperable: plain text can be read by almost any programming language, and most libraries provide built-in support for reading these formats. However, these formats quickly show their limitations when dealing with massive datasets. The lack of compression results in high disk usage, and their row-based representation (@fig-columnar-storage) on disk and in memory makes them inefficient — you often need to load the entire file into memory to perform operations on specific rows or columns.

One of the major innovations in the data ecosystem over the past decade is the emergence of data formats that address the limitations of traditional formats. The most popular and now standard format for data storage is `Apache Parquet`. It offers several features that make it especially well-suited for *data science* applications. First, it is a compressed format, making it ideal for storing large datasets. Depending on data structure, it’s not uncommon for a dataset in `Parquet` format to take up 10 times less space than its `CSV` equivalent. Second, `Parquet` is interoperable: files in this format can be queried not only with common languages like `Python`, `R`, or `SQL`, but also with big data processing tools like `Spark`.

However, the key reason for `Parquet`’s widespread adoption in *data science* is its **read performance**. Intuitively, one might expect that a compressed format would be slower to read than a text format like `CSV`—after all, decompressing takes time. But `Parquet` uses highly optimized compression that actually **outperforms** reading from a plain CSV file. A crucial feature of `Parquet` that contributes to this performance is that it is **column-oriented**, meaning data is stored by columns rather than by rows as in traditional text formats (@fig-columnar-storage). This makes it highly efficient for analytical workloads (also known as OLAP — *Online Analytical Processing*), which often involve selecting specific columns, computing derived variables, and aggregating data by groups. Row-based formats like CSV require reading the entire dataset into memory to execute such queries. In contrast, columnar formats allow reading only the relevant columns, significantly reducing read and compute times for analytics tasks [@abdelaziz2023optimizing]. In practice, popular columnar formats like `Parquet` use a hybrid approach: they are mainly column-oriented, but also include row-grouping techniques to further optimize filtering operations.

![Row-based vs column-based data storage representation.](/columnar-storage.png){#fig-columnar-storage}

Another important feature of the `Parquet` format is its **native support for partitioned files**, which means a dataset can be split across multiple files based on one or more partition keys. In most statistical processing, the entire dataset isn't required at once — you typically filter by geographic area, time window, etc. If all data is stored in a single file, you’d still need to load all rows — at least the relevant columns — into memory to perform such filtering. With `Parquet`, datasets can be partitioned by frequently used filters — similar to indexes in a `SQL` database — enabling much faster and more efficient queries (@fig-parquet-partitions). This feature makes `Parquet` especially well-suited for analytical tasks common in *data science* [@dondon2023quels].

![Filesystem representation of a `Parquet` file partitioned by two keys: year and month. In this example, querying only a few months is highly efficient because only the relevant partitions are loaded into memory.](/parquet-partitions.png){#fig-parquet-partitions fig-align="center" height=300}

:::
