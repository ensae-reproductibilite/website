---
title: "Application"
subtitle: "Appliquer pas √† pas les concepts √©tudi√©s √† un projet de data science"
author: "Romain Avouac et Lino Galiana"
image: images/rocket.png
description: |
  Une application fil rouge pour illustrer l'int√©r√™t d'appliquer graduellement les bonnes pratiques dans une optique de mise en production d'une application de data science.
order: 7
href: chapters/application.html
---

<details>
<summary>
D√©rouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/title-slide)
pour afficher les slides en plein √©cran.
</summary>


<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><iframe class="sourceCode yaml code-with-copy" src="https://ensae-reproductibilite.github.io/slides/#/title-slide"></iframe></div>

</details>

L'objectif de cette mise en application est d'**illustrer les diff√©rentes √©tapes qui s√©parent la phase de d√©veloppement d'un projet de celle de la mise en production**. Elle permettra de mettre en pratique les diff√©rents concepts pr√©sent√©s tout au long du cours.

Celle-ci est un tutoriel pas √† pas pour avoir un projet reproductible et disponible sous plusieurs livrables. 
Toutes les √©tapes ne sont pas indispensables √† tous les projets de _data science_. 

Nous nous pla√ßons dans une situation initiale correspondant √† la fin de la phase de d√©veloppement d'un projet de data science.
On a un _notebook_ un peu monolithique, qui r√©alise les √©tapes classiques d'un *pipeline* de *machine learning* :

- Import de donn√©es ;
- Statistiques descriptives et visualisations ;
- *Feature engineering* ;
- Entra√Ænement d'un mod√®le ;
- Evaluation du mod√®le.

**L'objectif est d'am√©liorer le projet de mani√®re incr√©mentale jusqu'√† pouvoir le mettre en production, en le valorisant sous une forme adapt√©e.** 


<details>
<summary>
Illustration de notre point de d√©part
</summary>
![](/workflow1.png)
</details>

<details>
<summary>
Illustration de l'horizon vers lequel on se dirige
</summary>
![](/workflow2.png)
</details>

::: {.callout-important}
Il est important de bien lire les consignes et d'y aller progressivement.
Certaines √©tapes peuvent √™tre rapides, d'autres plus fastidieuses ;
certaines √™tre assez guid√©es, d'autres vous laisser plus de libert√©.
Si vous n'effectuez pas une √©tape, vous risquez de ne pas pouvoir passer √†
l'√©tape suivante qui en d√©pend.

Bien que l'exercice soit applicable sur toute configuration bien faite, nous 
recommandons de privil√©gier l'utilisation du [SSP Cloud](https://datalab.sspcloud.fr/home), o√π tous les 
outils n√©cessaires sont pr√©-install√©s et pr√©-configur√©s. Le service `VSCode`
ne sera en effet que le point d'entr√©e pour l'utilisation d'outils plus exigeants
sur le plan de l'infrastructure: _Argo_, _MLFLow_, etc.
:::


# Partie 0 : initialisation du projet

::: {.callout-tip}
## Application pr√©liminaire: forker le d√©p√¥t d'exemple

Les premi√®res √©tapes consistent √† mettre en place son environnement de travail sur `Github`:

- G√©n√©rer un jeton d'acc√®s (*token*) sur `GitHub` afin de permettre l'authentification en ligne de commande √† votre compte.
La proc√©dure est d√©crite [ici](https://docs.sspcloud.fr/onyxia-guide/controle-de-version#creer-un-jeton-dacces-token). 
__Vous ne voyez ce jeton qu'une fois, ne fermez pas la page de suite__. 

- Mettez de c√¥t√© ce jeton en l'enregistrant dans un gestionnaire de mot de passe ou dans 
l'espace _["Mon compte"](https://datalab.sspcloud.fr/account/third-party-integration)_
du `SSP Cloud`. 

- Forker le d√©p√¥t `Github` : [https://github.com/ensae-reproductibilite/application-correction](https://github.com/ensae-reproductibilite/application-correction) en faisant attention √† deux choses:
    + Renommer le d√©p√¥t en `ensae-reproductibilite-application-correction.git` ;
    + D√©cocher la case _"Copy the `main` branch only"_ afin de copier √©galement les _tags_ `Git` qui nous permettront de faire les _checkpoint_


<details>

<summary>
Ce que vous devriez voir sur la page de cr√©ation du _fork_
</summary>

![](/fork-example.png)

</details>

Il est maintenant possible de ce lancer dans la cr√©ation de l'environnement de travail:

- Ouvrir un service `VSCode` sur le [SSP Cloud](https://datalab.sspcloud.fr/home). Vous pouvez aller
dans la page `My Services` et cliquer sur `New service`. Sinon, vous
pouvez initialiser la cr√©ation du service en cliquant directement [ici](https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=false). __Modifier les options suivantes__:
    + Dans l'onglet `Kubernetes`, s√©lectionner le r√¥le `Admin` ;
    + Dans l'onglet `Networking`, cliquer sur "Enable a custom service port" et laisser la valeur par d√©faut 5000 pour le num√©ro du port

- Cl√¥ner __votre__ d√©p√¥t `Github` en utilisant le
terminal depuis `Visual Studio` (`Terminal > New Terminal`) et
en passant directement le token dans l'URL selon cette structure:

```{.bash filename="terminal"}
git clone https://<TOKEN>@github.com/<USERNAME>/ensae-reproductibilite-application-correction.git
```

o√π `<TOKEN>` et `<USERNAME>` sont √† remplacer, respectivement, 
par le jeton que vous avez g√©n√©r√© pr√©c√©demment et votre nom d'utilisateur.

- Se placer avec le terminal dans le dossier en question : 

```{.bash filename="terminal"}
cd ensae-reproductibilite-application-correction
```

- Se placer sur une branche de travail en faisant:

```{.bash filename="terminal"}
git checkout -b dev
```

:::


# Partie 1 : qualit√© du script

Cette premi√®re partie vise √† **rendre le projet conforme aux bonnes pratiques** pr√©sent√©es dans le cours.

Elle fait intervenir les notions suivantes : 

- Utilisation du **terminal** (voir [Linux 101](/chapters/linux-101.html)) ;
- **Qualit√© du code** (voir [Qualit√© du code](/chapters/code-quality.html)) ;
- **Architecture de projets** (voir [Architecture des projets](/chapters/projects-architecture.html)) ;
- **Contr√¥le de version** avec `Git` (voir [Rappels `Git`](/chapters/git.qmd)) ;
- **Travail collaboratif** avec `Git` et `GitHub` (voir [Rappels `Git`](/chapters/git.qmd)).

Nous allons partir de ce _Notebook_ `Jupyter`,
que vous pouvez pr√©visualiser voire tester
en cliquant sur l'un des liens suivants:

_to do bouton onyxia_
<a href="https://github.com/ensae-reproductibilite/application-correction/blob/main/titanic.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

Le plan de la partie est le suivant :

1. S'assurer que le script fonctionne ;
2. Nettoyer le code des scories formelles avec un _linter_ et un _formatter_ ;
3. Param√©trisation du script ;
4. Utilisation de fonctions.


## √âtape 1 : s'assurer que le script s'ex√©cute correctement

On va partir du fichier `notebook.py` qui reprend le contenu 
du _notebook_[^jupytext] mais dans un script classique.
Le travail de nettoyage en sera facilit√©. 

[^jupytext]: L'export dans un script `.py` a √©t√© fait
        directement depuis `VSCode`. Comme
        cela n'est pas vraiment l'objet du cours, nous passons cette √©tape et fournissons
        directement le script expurg√© du texte interm√©diaire. Mais n'oubliez
        pas que cette d√©marche, fr√©quente quand on a d√©marr√© sur un _notebook_ et
        qu'on d√©sire consolider en faisant la transition vers des 
        scripts, n√©cessite d'√™tre attentif pour ne pas risquer de faire une erreur. 

La premi√®re √©tape est simple, mais souvent oubli√©e : **v√©rifier que le code fonctionne correctement**. 
Pour cela, nous recommandons de faire un aller-retour entre le script ouvert dans `VSCode`
et un terminal pour le lancer. 


{{< include "./applications/_appli1.qmd" >}}


## √âtape 2: utiliser un _linter_ puis un _formatter_

On va maintenant am√©liorer la qualit√© de notre code en appliquant les standards communautaires.
Pour cela, on va utiliser le *linter* classique [`PyLint`](https://pylint.readthedocs.io/en/latest/)
et le _formatter_ [`Black`](https://github.com/psf/black).

::: {.callout-important}
[`PyLint`](https://pylint.readthedocs.io/en/latest/) et [`Black`](https://black.readthedocs.io/en/stable/)
sont des _packages_ `Python` qui 
s'utilisent principalement en ligne de commande.

Si vous avez une erreur qui sugg√®re
que votre terminal ne connait pas [`PyLint`](https://pylint.readthedocs.io/en/latest/)
ou [`Black`](https://black.readthedocs.io/en/stable/),
n'oubliez pas d'ex√©cuter la commande `pip install pylint` ou `pip install black`.
:::


Le _linter_ renvoie alors une s√©rie d'irr√©gularit√©s,
en pr√©cisant √† chaque fois la ligne de l'erreur et le message d'erreur associ√© (ex : mauvaise identation).
Il renvoie finalement une note sur 10,
qui estime la qualit√© du code √† l'aune des standards communautaires √©voqu√©s
dans la partie [Qualit√© du code](/chapters/code-quality.html).

{{< include "./applications/_appli2.qmd" >}}

Le code est maintenant lisible, il obtient √† ce stade une note formelle proche de 10.
Mais il n'est pas encore totalement intelligible ou fiable.
Il y a notamment 
beaucoup de redondance de code auxquelles nous allons nous attaquer par la suite. 
N√©anmoins, avant cela, occupons-nous de mieux g√©rer certains param√®tres du script: 
jetons d'API et chemin des fichiers.


## √âtape 3: gestion des param√®tres

L'ex√©cution du code et les r√©sultats obtenus
d√©pendent de certains param√®tres d√©finis dans le code. L'√©tude de r√©sultats
alternatifs, en jouant sur 
des variantes des (hyper)param√®tres, est √† ce stade compliqu√©e
car il est n√©cessaire de parcourir le code pour trouver
ces param√®tres. De plus, certains param√®tres personnels
comme des jetons
d'API ou des mots de passe n'ont pas vocation √† 
√™tre pr√©sents dans le code. 

Il est plus judicieux de consid√©rer ces param√®tres comme des
variables d'entr√©e du script. Cela peut √™tre fait de deux
mani√®res:

1. Avec des __arguments optionnels__ appel√©s depuis la ligne de commande _(Application 3a)_.
Cela peut √™tre pratique pour mettre en oeuvre des tests automatis√©s mais
n'est pas forc√©ment pertinent pour toutes les variables. Nous allons montrer
cet usage avec le nombre d'arbres de notre _random forest_ ;
2. En utilisant un __fichier de configuration__ dont les valeurs sont import√©es dans
le script principal _(Application 3b)_. 


<details>
<summary>
Un exemple de d√©finition d'un argument pour l'utilisation en ligne de commande
</summary>

```{.python filename="prenom.py"}
import argparse
parser = argparse.ArgumentParser(description="Qui √™tes-vous?")
parser.add_argument(
    "--prenom", type=str, default="Toto", help="Un pr√©nom √† afficher"
)
args = parser.parse_args()
print(args.prenom)
```

Exemples d'utilisations en ligne de commande

```{.bash filename="terminal"}
python prenom.py
python prenom.py --prenom "Zinedine"
```

</details>

{{< include "./applications/_appli3.qmd" >}}


## √âtape 4 : Privil√©gier la programmation fonctionnelle

Nous allons **mettre en fonctions les parties importantes de l'analyse**. 
Ceci facilitera l'√©tape ult√©rieure de modularisation de notre projet. 

Cet exercice √©tant chronophage, il n'est __pas obligatoire de le r√©aliser en entier__. L'important est de
comprendre la d√©marche et d'adopter fr√©quemment une approche fonctionnelle[^POO]. Pour obtenir 
une chaine enti√®rement fonctionnalis√©e, vous pouvez reprendre le _checkpoint_.

[^POO]: Nous proposons ici d'adopter le principe de la __programmation fonctionnelle__. Pour encore fiabiliser
un processus, il serait possible d'adopter le paradigme de la __programmation orient√©e objet (POO)__. Celle-ci est
plus rebutante et demande plus de temps au d√©veloppeur. L'arbitrage co√ªt-avantage est n√©gatif pour notre
exemple, nous proposons donc de nous en passer. N√©anmoins, pour une mise en production r√©elle d'un mod√®le,
il est recommand√© de l'adopter. C'est d'ailleurs obligatoire avec des [_pipelines_ `scikit`](https://pythonds.linogaliana.fr/pipeline-scikit/). 

{{< include "./applications/_appli4.qmd" >}}

Cela ne se remarque pas encore vraiment car nous avons de nombreuses d√©finitions de fonctions
mais notre chaine de production est beaucoup plus
concise (le script fait environ 300 lignes dont 250 de d√©finitions de fonctions g√©n√©riques).
Cette auto-discipline facilitera grandement
les √©tapes ult√©rieures. Cela aurait √©t√© n√©anmoins beaucoup moins co√ªteux en temps d'adopter
ces bons gestes de mani√®re plus pr√©coce. 


# Partie 2 : adoption d'une structure modulaire {#partie2}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues tout au long du cours.
Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'un
possible partage du code : celui-ci est lisible et intelligible. 
Le code est proprement versionn√© sur un
d√©p√¥t `GitHub`.
Cependant, le projet est encore perfectible: il est encore difficile de rentrer
dedans si on ne sait pas exactement ce qu'on recherche. L'objectif de cette partie
est d'isoler les diff√©rentes √©tapes de notre _pipeline_. 
Outre le gain de clart√© pour notre projet, nous √©conomiserons beaucoup de peines
pour la mise en production ult√©rieure de notre mod√®le. 

<details>
<summary>
Illustration de l'√©tat actuel du projet 
</summary>
![](/schema_post_appli4.png)
</details>

Dans cette partie nous allons continuer les am√©liorations
incr√©mentales de notre projet avec les √©tapes suivantes:

1. Modularisation du code `Python` pour s√©parer les diff√©rentes
√©tapes de notre _pipeline_ ; 
2. Adopter une structure standardis√©e pour notre projet afin
d'autodocumenter l'organisation de celui-ci ; 
3. Documenter les _packages_ indispensables √† l'ex√©cution du code ;
4. Stocker les donn√©es dans un environnement ad√©quat
afin de continuer la d√©marche de s√©parer conceptuellement les donn√©es du code en de la configuration.


## √âtape 1 : modularisation

Nous allons profiter de la modularisation pour adopter une structure
applicative pour notre code. Celui-ci n'√©tant en effet plus lanc√©
que la ligne de commande, on peut consid√©rer qu'on construit
une application g√©n√©rique o√π un script principal (`main.py`)
encapsule des √©l√©ments issus d'autres scripts. 

{{< include "./applications/_appli5.qmd" >}}


## √âtape 2 : adopter une architecture standardis√©e de projet

On dispose maintenant d'une application `Python` fonctionnelle. 
N√©anmoins, le projet est certes plus fiable mais sa structuration
laisse √† d√©sirer et il serait difficile de rentrer √† nouveau
dans le projet dans quelques temps. 

<details>
<summary>Etat actuel du projet üôà</summary>

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ test.csv
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ import_data.py
‚îú‚îÄ‚îÄ build_features.py
‚îú‚îÄ‚îÄ train_evaluate.py
‚îú‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ main.py
```

</details>

Comme cela est expliqu√© dans la
partie [Structure des projets](/chapters/projects-architecture.html),
on va adopter une structure certes arbitraire mais qui va 
faciliter l'autodocumentation de notre projet. De plus, une telle structure va faciliter des √©volutions optionnelles
comme la _packagisation_ du projet. Passer d'une structure modulaire
bien faite √† un _package_ est quasi-imm√©diat en `Python`. 

On va donc modifier l'architecture de notre projet pour la rendre plus standardis√©e.
Pour cela, on va s'inspirer des structures
[`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/)
qui g√©n√®rent des _templates_ de projet. En l'occurrence
notre source d'inspiration sera le [_template datascience_](https://drivendata.github.io/cookiecutter-data-science/)
issu d'un effort communautaire.

::: {.callout-note}
L'id√©e de [`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/) est de proposer des _templates_ que l'on utilise pour __initialiser__ un projet, afin de b√¢tir √† l'avance une structure √©volutive. La syntaxe √† utiliser dans ce cas est la suivante : 

```{.bash filename="terminal"}
pip install cookiecutter
cookiecutter https://github.com/drivendata/cookiecutter-data-science
```

Ici, on a d√©j√† un projet, on va donc faire les choses dans l'autre sens : on va s'inspirer de la structure propos√©e afin de r√©organiser celle de notre projet selon les standards communautaires.
:::

En s'inspirant du _cookiecutter data science_
on va adopter la structure suivante:

<details>
<summary>
Structure recommand√©e
</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îî‚îÄ‚îÄ raw
‚îÇ       ‚îú‚îÄ‚îÄ test.csv
‚îÇ       ‚îî‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ configuration
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ data
    ‚îÇ   ‚îî‚îÄ‚îÄ import_data.py
    ‚îú‚îÄ‚îÄ features
    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
    ‚îî‚îÄ‚îÄ models
        ‚îî‚îÄ‚îÄ train_evaluate.py
```

</details>

{{< include "./applications/_appli6.qmd" >}}


## √âtape 3: indiquer l'environnement minimal de reproductibilit√©

Le script `main.py` n√©cessite un certain nombre de packages pour
√™tre fonctionnel. Chez vous les packages n√©cessaires sont
bien s√ªr install√©s mais √™tes-vous assur√© que c'est le cas 
chez la personne qui testera votre code ? 

Afin de favoriser la portabilit√© du projet,
il est d'usage de _"fixer l'environnement"_,
c'est-√†-dire d'indiquer dans un fichier toutes les d√©pendances utilis√©es ainsi que leurs version.
Nous proposons de cr√©er un fichier `requirements.txt` minimal, sur lequel nous reviendrons
dans la partie consacr√©e aux environnements reproductibles. 

Le fichier `requirements.txt` est conventionnellement localis√© √† la racine du projet.
Ici on ne va pas fixer les versions, on raffinera ce fichier ult√©rieurement.

{{< include "./applications/_appli7.qmd" >}}

## √âtape 4 : stocker les donn√©es de mani√®re externe {#stockageS3}

::: {.callout-warning collapse="true"}
## Pour en savoir plus sur le syst√®me de stockage `S3`

Pour mettre en oeuvre cette √©tape, il peut √™tre utile de
comprendre un peu comme fonctionne le SSP Cloud.
Vous devrez suivre la [documentation du SSP Cloud](https://inseefrlab.github.io/docs.sspcloud.fr/docs/fr/storage.html) pour la r√©aliser. Une aide-m√©moire est √©galement disponible dans le cours
de 2e ann√©e de l'ENSAE [Python pour la _data science_](https://linogaliana-teaching.netlify.app/reads3/#).
:::


Le chapitre sur la [structure des projets](/chapters/project-structure.qmd)
d√©veloppe l'id√©e qu'il est recommand√© de converger vers un mod√®le
o√π environnements d'ex√©cution, de stockage du code et des donn√©es sont conceptuellement
s√©par√©s. Ce haut niveau d'exigence est un gain de temps important 
lors de la mise en production car au cours de cette derni√®re, le projet
est amen√© √† √™tre ex√©cut√© sur une infrastructure informatique d√©di√©e
qu'il est bon d'anticiper. 

A l'heure actuelle, les donn√©es sont stock√©es dans le d√©p√¥t. C'est une
mauvaise pratique. En premier lieu, `Git` n'est techniquement
pas bien adapt√© au stockage de donn√©es. Ici ce n'est pas tr√®s grave
car il ne s'agit pas de donn√©es volumineuses et ces derni√®res ne sont
pas modifi√©es au cours de notre chaine de traitement. 
La raison principale
est que les donn√©es trait√©es par les _data scientists_ 
sont g√©n√©ralement soumises √† des clauses de
confidentialit√©s ([RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on), [secret statistique](https://www.insee.fr/fr/information/1300624)...). Mettre ces donn√©es sous contr√¥le de version
c'est prendre le risque de les divulguer √† un public non habilit√©. 
Il est donc recommand√© de privil√©gier des outils techniques adapt√©s au
stockage de donn√©es.

L'id√©al, dans notre cas, est d'utiliser une solution de stockage externe. 
On va utiliser pour cela `MinIO`, la solution de stockage de type `S3` offerte par le SSP Cloud. 
Cela nous permettra de supprimer les donn√©es de `Github` tout en maintenant la reproductibilit√© 
de notre projet [^history].

[^history]: Attention, les donn√©es ont √©t√© _committ√©es_ au moins une fois. Les supprimer
du d√©p√¥t ne les efface pas de l'historique. Si cette erreur arrive, le mieux est de supprimer
le d√©p√¥t en ligne, cr√©er un nouvel historique `Git` et partir de celui-ci pour des publications
ult√©rieures sur `Github`. N√©anmoins l'id√©al serait de ne pas s'exposer √† cela. C'est justement
l'objet des bonnes pratiques de ce cours: un `.gitignore` bien construit et une s√©paration des
environnements de stockage du code et
des donn√©es seront bien plus efficaces pour vous √©viter ces probl√®mes que tout les conseils de 
vigilance que vous pourrez trouver ailleurs. 

{{< include "./applications/_appli8.qmd" >}}

# Partie 2bis: packagisation de son projet (optionnel)

Cette s√©rie d'actions n'est pas forc√©ment pertinente pour tous
les projets. Elle fait un peu la transition entre la modularit√©
et la portabilit√©. 

## √âtape 1 : proposer des tests unitaires (optionnel)

Notre code comporte un certain nombre de fonctions g√©n√©riques.
On peut vouloir tester leur usage sur des donn√©es standardis√©es,
diff√©rentes de celles du Titanic.

M√™me si la notion de tests unitaires
prend plus de sens dans un _package_, nous pouvons proposer
dans le projet des exemples d'utilisation de la fonction, ceci peut √™tre p√©dagogique. 

Nous allons utiliser [`unittest`](https://docs.python.org/3/library/unittest.html)
pour effectuer des tests unitaires. Cette approche n√©cessite quelques notions
de programmation orient√©e objet ou une bonne discussion avec `ChatGPT`.

{{< include "./applications/_appli9.qmd" >}}


::: {.callout-note}

Lorsqu'on effectue des tests unitaires, on cherche g√©n√©ralement
√† tester le plus de lignes possibles de son code. On parle de
__taux de couverture__ (_coverage rate_) pour d√©signer
la statistique mesurant cela. 

Cela peut s'effectuer de la mani√®re suivante avec le package
[`coverage`](https://coverage.readthedocs.io/en/7.2.2/):

```{.bash filename="terminal"}
coverage run -m unittest tests/test_create_variable_title.py
coverage report -m
```

```{.python}
Name                                  Stmts   Miss  Cover   Missing
-------------------------------------------------------------------
src/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113
tests/test_create_variable_title.py      21      1    95%   54
-------------------------------------------------------------------
TOTAL                                    55     22    60%
```

Le taux de couverture est souvent mis en avant par les gros
projets comme indicateur de leur qualit√©. Il existe d'ailleurs
des badges `Github` d√©di√©s. 
:::




## √âtape 2 : transformer son projet en package (optionnel)

Notre projet est modulaire, ce qui le rend assez simple √† transformer
en _package_, en s'inspirant de la structure du `cookiecutter` adapt√©, issu
de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

On va cr√©er un _package_ nomm√© `titanicml` qui encapsule
tout notre code et qui sera appel√©
par notre script `main.py`. La structure attendue
est la suivante:

<details>
<summary>Structure vis√©e</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ docs                                    ‚îê 
‚îÇ   ‚îú‚îÄ‚îÄ main.py                             ‚îÇ 
‚îÇ   ‚îî‚îÄ‚îÄ notebooks                           ‚îÇ Package documentation and examples
‚îÇ       ‚îî‚îÄ‚îÄ titanic.ipynb                   ‚îÇ 
‚îú‚îÄ‚îÄ configuration                           ‚îê Configuration (pas √† partager avec Git)
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                         ‚îò 
‚îú‚îÄ‚îÄ README.md                                
‚îú‚îÄ‚îÄ pyproject.toml                          ‚îê 
‚îú‚îÄ‚îÄ requirements.txt                        ‚îÇ
‚îú‚îÄ‚îÄ titanicml                               ‚îÇ                
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                         ‚îÇ Package source code, metadata
‚îÇ   ‚îú‚îÄ‚îÄ data                                ‚îÇ and build instructions 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                  ‚îÇ  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py   ‚îÇ   
‚îÇ   ‚îú‚îÄ‚îÄ features                            ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py               ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models                              ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ train_evaluate.py               ‚îò
‚îî‚îÄ‚îÄ tests                                   ‚îê
    ‚îî‚îÄ‚îÄ test_create_variable_title.py       ‚îò Package tests
```
</details>

<details>
<summary>Rappel: structure actuelle</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ notebooks                                 
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb                  
‚îú‚îÄ‚îÄ configuration                                 
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                  
‚îú‚îÄ‚îÄ main.py                              
‚îú‚îÄ‚îÄ README.md                 
‚îú‚îÄ‚îÄ requirements.txt                      
‚îî‚îÄ‚îÄ src 
    ‚îú‚îÄ‚îÄ data                                
    ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                    
    ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py      
    ‚îú‚îÄ‚îÄ features                           
    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py      
    ‚îî‚îÄ‚îÄ models                          
        ‚îî‚îÄ‚îÄ train_evaluate.py              
```
</details>

Il existe plusieurs 
_frameworks_ pour
construire un _package_. Nous
allons privil√©gier [`Poetry`](https://python-poetry.org/)
√† [`Setuptools`](https://pypi.org/project/setuptools/). 


::: {.callout-note}

Pour cr√©er la structure minimale d'un _package_, le plus simple est
d'utiliser le `cookiecutter` adapt√©,
issu de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

Comme on a d√©j√† une structure tr√®s modulaire, on va plut√¥t recr√©er cette
structure dans notre projet d√©j√† existant. En fait, il ne manque qu'un fichier essentiel, 
le principal distinguant un projet classique d'un package : `pyproject.toml`.

```{.bash filename="terminal"}
cookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git
```

<details>
<summary>D√©rouler pour voir les choix possibles</summary>
```{.python}
author_name [Monty Python]: Daffy Duck
package_name [mypkg]: titanicml
package_short_description []: Impressive Titanic survival analysis
package_version [0.1.0]: 
python_version [3.9]: 
Select open_source_license:
1 - MIT
2 - Apache License 2.0
3 - GNU General Public License v3.0
4 - Creative Commons Attribution 4.0
5 - BSD 3-Clause
6 - Proprietary
7 - None
Choose from 1, 2, 3, 4, 5, 6 [1]: 
Select include_github_actions:
1 - no
2 - ci
3 - ci+cd
Choose from 1, 2, 3 [1]:
```
</details>

:::

{{< include "./applications/_appli10.qmd" >}}

# Partie 3 : construction d'un projet portable et reproductible {#partie3}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues
dans les chapitres [Qualit√© du code](/chapters/code-quality.html)
et [Structure des projets](/chapters/projects-architecture.html)
tout au long du cours.

Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'une
possible mise en production : le code est lisible,
la structure du projet est normalis√©e et √©volutive,
et le code est proprement versionn√© sur un
d√©p√¥t `GitHub` {{< fa brands github >}}.


<details>
<summary>
Illustration de l'√©tat actuel du projet 
</summary>
![](/schema_post_appli8.png)
</details>



A pr√©sent, nous avons une version du projet qui est largement partageable.
Du moins en th√©orie, car la pratique est souvent plus compliqu√©e :
il y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement (typiquement, votre ordinateur personnel),
les choses ne se passent pas du tout comme attendu. Cela signifie qu'**en l'√©tat, le projet n'est pas portable : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.

Dans cette trois√®me partie de notre travail vers la mise en production,
nous allons voir 
comment **normaliser l'environnement d'ex√©cution afin de produire un projet portable**.
Autrement dit, nous n'allons plus nous contenter de modularit√© mais allons rechercher
la portabilit√©.
On sera alors tout proche de pouvoir mettre le projet en production.

On progressera dans l'√©chelle de la reproductibilit√© 
de la mani√®re suivante: 

1. [**Environnements virtuels**](#anaconda) ;
2. Cr√©er un [script shell](#shell) qui permet, depuis un environnement minimal, de construire l'application de A √† Z ;
3. [**Images et conteneurs `Docker`**](#docker).


Nous allons repartir de l'application 8, c'est-√†-dire d'un projet
modulaire mais qui n'est pas, √† strictement parler, un _package_
(objet des applications optionnelles suivantes 9 et 10). 

Pour se replacer dans l'√©tat du projet √† ce niveau,
il est possible d'utiliser le _tag_ _ad hoc_.

```{.bash filename="terminal"}
git checkout appli8
```


## √âtape 1 : un environnement pour rendre le projet portable {#anaconda}

Pour qu'un projet soit portable, il doit remplir deux conditions:

- Ne pas n√©cessiter de d√©pendance
qui ne soient pas renseign√©es quelque part ;
- Ne pas proposer des d√©pendances inutiles, qui ne
sont pas utilis√©es dans le cadre du projet. 

Le prochain exercice vise √† mettre ceci en oeuvre.
Comme expliqu√© dans le [chapitre portabilit√©](/chapters/portabilite.qmd),
le choix du gestionnaire d'environnement est laiss√©
libre. Il est recommand√© de privil√©gier `venv` si vous d√©couvrez
la probl√©matique de la portabilit√©. 

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

L'approche la plus l√©g√®re est l'environnement virtuel. 
Nous avons en fait implicitement d√©j√† commenc√© √† aller vers
cette direction
en cr√©ant un fichier `requirements.txt`. 

{{< include "./applications/_appli11a.qmd" >}}


## Environnement `conda`

Les environnements `conda` sont plus lourds √† mettre en oeuvre que les 
environnements virtuels mais peuvent permettre un contr√¥le
plus formel des d√©pendances. 

{{< include "./applications/_appli11b.qmd" >}}

:::


## √âtape 2: construire l'environnement de notre application via un script `shell` {#shell}

Les environnements virtuels permettent de mieux sp√©cifier les d√©pendances de notre projet, mais ne permettent pas de garantir une portabilit√© optimale. Pour cela, il faut recourir √† la technologie des conteneurs. L'id√©e est de construire une machine, en partant d'une base quasi-vierge, qui permette de construire √©tape par √©tape l'environnement n√©cessaire au bon fonctionnement de notre projet. C'est le principe des conteneurs `Docker` {{< fa brands docker >}}.

Leur m√©thode de construction √©tant un peu difficile √† prendre en main au d√©but, nous allons passer par une √©tape interm√©diaire afin de bien comprendre le processus de production. 

- Nous allons d'abord cr√©er un script `shell`, c'est √† dire une suite de commandes `Linux` permettant de construire l'environnement √† partir d'une machine vierge ;
- Nous transformerons celui-ci en `Dockerfile` dans un deuxi√®me temps. C'est l'objet de l'√©tape suivante. 

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

{{< include "./applications/_appli12a.qmd" >}}

## Environnement `conda`

{{< include "./applications/_appli12b.qmd" >}}

:::


## √âtape 3: conteneuriser l'application avec `Docker` {#docker}


::: {.callout-note}
Cette application n√©cessite l'acc√®s √† une version interactive de `Docker`.
Il n'y a pas beaucoup d'instances en ligne disponibles.

Nous proposons deux solutions:

- [Installer `Docker`](https://docs.docker.com/get-docker/) sur sa machine ;
- Se rendre sur l'environnement bac √† sable _[Play with Docker](https://labs.play-with-docker.com)_

Sinon, elle peut √™tre r√©alis√©e en essai-erreur par le biais des services d'int√©gration continue de `Github` {{< fa brands github >}} ou `Gitlab` {{< fa brands gitlab >}}. N√©anmoins, nous pr√©senterons l'utilisation de ces services plus tard, dans la prochaine partie. 
:::

Maintenant qu'on sait que ce script pr√©paratoire fonctionne, on va le transformer en `Dockerfile` pour anticiper la mise en production.  Comme la syntaxe `Docker` est l√©g√®rement diff√©rente de la syntaxe `Linux` classique (voir le [chapitre portabilit√©](/chapters/portabilite.qmd)), il va √™tre n√©cessaire de changer quelques instructions mais ceci sera tr√®s l√©ger.

On va tester le `Dockerfile` dans un environnement bac √† sable pour ensuite
pouvoir plus facilement automatiser la construction de l'image
`Docker`.

{{< include "./applications/_appli13.qmd" >}}


# Partie 4 : automatisation avec l'int√©gration continue


Imaginez que vous √™tes au restaurant
et qu'on ne vous serve pas le plat mais seulement la recette
et que, de plus, on vous demande de pr√©parer le plat
chez vous avec les ingr√©dients dans votre frigo.
Vous seriez quelque peu d√©√ßu. En revanche, si vous avez go√ªt√©
au plat, que vous √™tes un r√©el cordon bleu
et qu'on vous donne la recette pour refaire ce plat ult√©rieurement,
peut-√™tre
que vous appr√©ciriez plus. 

Cette analogie illustre l'enjeu de d√©finir
le public cible et ses attentes afin de fournir un livrable adapt√©. 
Une image `Docker` est un livrable qui n'est pas forc√©ment int√©ressant
pour tous les publics. Certains pr√©f√©reront avoir un plat bien pr√©par√©
qu'une recette ; certains appr√©cieront avoir une image `Docker` mais
d'autres ne seront pas en mesure de construire celle-ci ou ne sauront
pas la faire fonctionner. Une image `Docker` est plus souvent un 
moyen pour faciliter la mise en service d'une production qu'une fin en soi. 

Nous allons donc proposer
plusieurs types de livrables plus classiques par la suite. Ceux-ci
correspondront mieux aux attendus des publics utilisateurs de services
construits √† partir de techniques de _data science_. `Docker` est n√©anmoins
un passage oblig√© car l'ensemble des types de livrables que nous allons
explorer reposent sur la standardisation permise par les conteneurs. 

Cette approche nous permettra de quitter le domaine de l'artisanat pour
s'approcher d'une industrialisation de la mise √† disposition 
de notre projet. Ceci va notamment nous amener √† mettre en oeuvre
l'approche pragmatique du `DevOps` qui consiste √† int√©grer d√®s la phase de
d√©veloppement d'un projet les contraintes li√©es √† sa mise √† disposition
au public cible (cette approche est d√©taill√©e plus
amplement dans le chapitre sur la [mise en production](/chapters/deployment.qmd)). 

L'automatisation et la mise √† disposition automatis√©e de nos productions
sera faite progressivement, au cours des prochaines parties. Tous les 
projets n'ont pas vocation √† aller aussi loin dans ce domaine. 
L'opportunit√© doit √™tre compar√©e aux co√ªts humains et financiers
de leur mise en oeuvre et de leur cycle de vie. 
Avant de faire une production en s√©rie de nos mod√®les,
nous allons d√©j√† commencer
par automatiser quelques tests de conformit√© de notre code. 
On va ici utiliser l'int√©gration continue pour deux objectifs distincts:

- la mise √† disposition de l'image `Docker` ;
- la mise en place de tests automatis√©s de la qualit√© du code
sur le mod√®le de notre `linter` pr√©c√©dent.

Nous allons utiliser `Github Actions` pour cela. Il s'agit de serveurs
standardis√©s mis √† disposition gratuitement par `Github` {{<fa brands github >}}.
`Gitlab` {{<fa brands gitlab >}}, l'autre principal acteur du domaine,
propose des services similaires. L'impl√©mentation est l√©g√®rement diff√©rente
mais les principes sont identiques. 


::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli13
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


## √âtape 1: mise en place de tests automatis√©s

Avant d'essayer de mettre en oeuvre la cr√©ation de notre image
`Docker` de mani√®re automatis√©e, nous allons pr√©senter la logique
de l'int√©gration continue en testant de mani√®re automatis√©e
notre script `main.py`.

Pour cela, nous allons partir de la structure propos√©e dans l'[action officielle](https://github.com/actions/setup-python). 
La documentation associ√©e est [ici](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python).
Des √©l√©ments succincts de pr√©sentation de la logique d√©clarative des actions `Github` 
sont disponibles dans le chapitre sur la [mise en production](/chapters/deployment.qmd). N√©anmoins, la meilleure
√©cole pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d'observer
les actions `Github` mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !


{{< include "./applications/_appli14.qmd" >}}

 
Maintenant, nous pouvons observer que l'onglet `Actions`
s'est enrichi. Chaque `commit` va entra√Æner une s√©ries d'actions automatis√©es.

Si l'une des √©tapes √©choue, ou si la note de notre projet est mauvaise, nous aurons
une croix rouge (et nous recevrons un mail). On pourra ainsi d√©tecter,
en d√©veloppant son projet, les moments o√π on d√©grade la qualit√© du script 
afin de la r√©tablir imm√©diatemment. 



## √âtape 2: Automatisation de la livraison de l'image `Docker`

Maintenant, nous allons automatiser la mise √† disposition de notre image
sur `DockerHub` (le lieu de partage des images `Docker`). Cela facilitera sa r√©utilisation mais aussi des
valorisations ult√©rieures.

L√† encore, nous allons utiliser une s√©rie d'actions pr√©-configur√©es.

Pour que `Github` puisse s'authentifier aupr√®s de `DockerHub`, il va 
falloir d'abord interfacer les deux plateformes. Pour cela, nous allons utiliser
un jeton (_token_) `DockerHub` que nous allons mettre dans un espace
s√©curis√© associ√© √† votre d√©p√¥t `Github`.


{{< include "./applications/_appli15a.qmd" >}}


A ce stade, nous avons donn√© les moyens √† `Github` de s'authentifier avec
notre identit√© sur `Dockerhub`. Il nous reste √† mettre en oeuvre l'action
en s'inspirant de la [documentation officielle](https://github.com/docker/build-push-action/#usage).
On ne va modifier que trois √©l√©ments dans ce fichier. Effectuer les 
actions suivantes:


{{< include "./applications/_appli15b.qmd" >}}



# Partie 5: exp√©rimenter en local des valorisations puis automatiser leur production


Nous avons automatis√© les √©tapes interm√©diaires de notre projet. 
N√©anmoins nous n'avons pas encore r√©fl√©chi √† la valorisation
√† mettre en oeuvre pour notre projet. On va supposer que notre
projet s'adresse √† des _data scientists_ mais aussi √† une audience
moins technique. Pour ces premiers, nous pourrions nous contenter
de valorisations techniques, comme des API, 
mais pour ces derniers il est
conseill√© de privil√©gier des formats plus _user friendly_. 

Afin de faire le parall√®le avec les parcours possibles pour l'√©valuation,
nous allons proposer trois valorisations[^valorisation]:

- Une API facilitant la r√©utilisation du mod√®le en "production" ;
- Un site web statique exploitant cette API pour exposer les pr√©dictions
√† une audience moins technique. Pour illustrer
les enjeux sp√©cifiques aux applications r√©actives mises en oeuvre
avec `Streamlit`, nous proposerons aussi cette valorisation m√™me si, dans
notre cas, elle n'apportera pas plus que le site statique. 

[^valorisation]: Vous n'√™tes pas oblig√©s pour l'√©valuation de mettre en oeuvre
les jalons de plusieurs parcours. N√©anmoins, vous d√©couvrirez que 
chaque nouveau pas en avant est moins co√ªteux que le
pr√©c√©dent si vous avez mis en oeuvre les r√©flexes des bonnes
pratiques.  

::: {.callout-warning collapse="true"}
## Site statique vs application r√©active

La solution que nous allons proposer 
pour les sites statiques, `Quarto` associ√©
√† `Github Pages`, peut √™tre utilis√©e dans le cadre des parcours 
_"rapport reproductible"_ ou _"dashboard / application interactive"_. 

Pour ce dernier
parcours, d'autres approches techniques sont n√©anmoins possibles,
comme `Streamlit`. Celles-ci sont plus exigeantes sur le plan technique
puisqu'elles n√©cessitent de mettre en production sur des serveurs
conteuneuris√©s (comme la mise en production de l'API)
l√† o√π le site statique ne n√©cessite qu'un serveur web, mis √† disposition
gratuitement par `Github`. 


La distinction principale entre ces deux approches est qu'elles
s'appuient sur des serveurs diff√©rents. Un site statique repose
sur un serveur web l√† o√π `Streamlit` s'appuie sur 
serveur classique en _backend_. La diff√©rence principale
entre ces deux types de serveurs
r√©side principalement dans leur fonction et leur utilisation:

- Un serveur web est sp√©cifiquement con√ßu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web √©coutent les requ√™tes HTTP/HTTPS provenant des navigateurs des utilisateurs et y r√©pondent en envoyant les donn√©es demand√©es.
- Un serveur _backend_ classique est 

:::

## √âtape 1: cr√©ation d'un pipeline `scikit`

Notre code respecte des bonnes pratiques formelles. Cependant, la mise en
production n√©cessite d'√™tre exigeant sur la mise en oeuvre op√©rationnelle
de notre _pipeline_. 

Quand  on utilise `scikit`, la bonne pratique est d'utiliser
les [_pipelines_](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
qui s√©curisent les √©tapes de _feature engineering_ avant la mise en oeuvre d'un mod√®le (que
ce soit pour l'entra√Ænement ou le test sur un nouveau jeu de donn√©es). 

On va donc devoir refactoriser notre application pour utiliser un _pipeline_ `scikit`. 
Les raisons sont expliqu√©es [ici](https://scikit-learn.org/stable/common_pitfalls.html).
Cela aura
aussi l'avantage de rendre les √©tapes plus lisibles. 


::: {.callout-tip}

## Application 16: Un _pipeline_ de _machine learning_

- Refactoriser le code de `random_forest_titanic` pour cr√©er 
un vrai pipeline de _preprocessing_ avant la mod√©lisation

- Simplifier la fonction `split_train_test_titanic`
en la r√©duisant au d√©coupage train/test

- Modifier `main.py` pour que ce soit √† ce niveau
qu'a lieu le d√©coupage en train/test, l'entrainement
et l'√©valuation
du mod√®le

:::


::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git checkout appli16
```

:::

## √âtape 2: d√©velopper une API en local

::: {.callout-tip}

## Application 17: Mise √† disposition sous forme d'API locale

- Cr√©er un nouveau service `SSPCloud` en param√©trant dans l'onglet
`Networking` le port 5000 ;
- Cloner le d√©p√¥t et se placer au niveau de l'application pr√©c√©dente (`git checkout appli16`)
- Installer `fastAPI` et `uvicorn` puis les ajouter au `requirements.txt`
- Renommer le fichier `main.py` en `train.py` et ins√©rer le contenu suivant dedans :

<details>
<summary>
Fichier `train.py`
</summary>
R√©cup√©rer le contenu sur [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/appli17/train.py)
</details>

- Cr√©er le fichier `api.py` permettant d'initialiser l'API:

<details>
<summary>
Fichier `api.py`
</summary>
R√©cup√©rer le contenu sur [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/appli17/api.py)
</details>

- Ex√©cuter `train.py` pour stocker en local le mod√®le entra√Æn√©
- Ajouter `model.joblib` au `.gitignore`
- D√©ployer en local l'API avec la commande

```{.bash filename="terminal"}
uvicorn api:app --reload --host "0.0.0.0" --port 5000
```

- A partir du `README` du service, se rendre sur l'URL de d√©ploiement, 
ajouter `/docs/` √† celui-ci et observer la documentation de l'API 
- Se servir de la documentation pour tester les requ√™tes `/predict`
- R√©cup√©rer l'URL d'une des requ√™tes propos√©es. La tester dans le navigateur
et depuis `Python` avec `requests` (`requests.get(url).json()`)

:::

::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git checkout appli17
```

:::

## √âtape 3: d√©ployer l'API

A ce stade, nous avons d√©ploy√© l'API seulement localement, dans le cadre d'un service. Ce mode de d√©ploiement est tr√®s pratique pour la phase de d√©veloppement, afin de s'assurer que l'API fonctionne comme attendu. A pr√©sent, il est temps de passer √† l'√©tape de d√©ploiement, qui permettra √† notre API d'√™tre accessible via une URL sur le web, et donc aux utilisateurs potentiels de la requ√™ter. Pour se faire, on va utiliser les possibilit√©s offertes par `Kubernetes`, sur lequel est bas√© le [SSP Cloud](https://datalab.sspcloud.fr).

::: {.callout-tip}

## Application 18: Dockeriser l'API

- Modifier le `Dockerfile` pour tenir compte des changements dans les noms de fichier effecut√©s dans l'application pr√©c√©dente

- Cr√©er un script `run.sh` √† la racine du projet qui lance le script `train.py` puis d√©ploie localement l'API 

<details>
<summary>Fichier `run.sh`</summary>

```{.bash filename="terminal"}
#/bin/bash

python3 train.py
uvicorn api:app --reload --host "0.0.0.0" --port 5000
```
</details>

- Donner au script `run.sh` des permissions d'ex√©cution : `chmod +x run.sh`

- Changer l'instruction `CMD` du `Dockerfile` pour ex√©cuter le script `run.sh` au lancement du conteneur

- *Commit* et *push* les changements

- Une fois le CI termin√©, r√©cup√©rer la nouvelle image dans l'environnement de test et v√©rifier que l'API se d√©ploie correctement

:::

::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git checkout appli18
```
:::

::: {.callout-tip}

## Application 19: D√©ployer l'API

- Cr√©er un dossier `deployment` √† la racine du projet qui va contenir les fichiers de configuration n√©cessaires pour d√©ployer sur un cluster `Kubernetes`

- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment), y ajouter un premier fichier `deployment.yaml` qui va sp√©cifier la configuration du *Pod* √† lancer sur le cluster

<details>
<summary>Fichier `deployment/deployment.yaml`</summary>

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: titanic-deployment
  labels:
    app: titanic
spec:
  replicas: 1
  selector:
    matchLabels:
      app: titanic
  template:
    metadata:
      labels:
        app: titanic
    spec:
      containers:
      - name: titanic
        image: linogaliana/application-correction:latest
        ports:
        - containerPort: 5000
```
</details>

- En vous inspirant de la [documentation](https://kubernetes.io/fr/docs/concepts/services-networking/service/#d%C3%A9finition-d-un-service), y ajouter un second fichier `service.yaml` qui va cr√©er une ressource `Service` permettant de donner une identit√© fixe au `Pod` pr√©c√©demment cr√©√© au sein du cluster

<details>
<summary>Fichier `deployment/service.yaml`</summary>

```yaml
apiVersion: v1
kind: Service
metadata:
  name: titanic-service
spec:
  selector:
    app: titanic
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5000
```
</details>

- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resource), y ajouter un troisi√®me fichier `ingress.yaml` qui va cr√©er une ressource `Ingress` permettant d'exposer le service via une URL en dehors du cluster

<details>
<summary>Fichier `deployment/ingress.yaml`</summary>

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: titanic-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  ingressClassName: nginx
  tls:
  - hosts:
    - titanic.kub.sspcloud.fr
  rules:
  - host: titanic.kub.sspcloud.fr
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: titanic-service
            port:
              number: 80
```
</details>

- Appliquer ces fichiers de configuration sur le cluster : `kubectl apply -f deployement/`

- Si tout a correctement fonctionn√©, vous devriez pouvoir acc√©der √† l'API √† l'URL sp√©cifi√©e dans le fichier `deployment/ingress.yaml`

:::

::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git checkout appli19
```

:::


# Partie 6: un workflow complet de MLOps

Ce sera l'an prochain, d√©sol√© !

# Partie 7: livrer un site web de mani√®re automatis√©e

On va proposer un nouveau livrable pour parler √† un public plus large.
Pour cela, on va d√©ployer un site web statique qui permet de visualiser
rapidement les r√©sultats du mod√®le.

On propose de cr√©er un site web qui permet de comprendre, avec l'appui
des [valeurs de Shapley](https://christophm.github.io/interpretable-ml-book/shapley.html),
les facteurs qui auraient pu nous mettre la puce
√† l'oreille sur les destins de Jake et de Rose. 

Pour faire ce site web,
on va utiliser `Quarto` et d√©ployer sur `Github Pages`.
Des √©tapes pr√©liminaires sont r√©alis√©es en `Python` 
puis l'affichage interactif 
sera contr√¥l√© par du `JavaScript` gr√¢ce
√† des [blocs `Observable`](https://quarto.org/docs/interactive/ojs/). 


::: {.callout-tip}

## Application 19: D√©ploiement automatis√© d'un site web

Dans un premier temps, on va cr√©er un projet `Quarto`
au sein de notre d√©p√¥t: 

- Installer `Quarto` dans votre environnement local (s'il n'est pas d√©j√† disponible) ;
- Dans le projet, utiliser la commande `quarto create-project` pour initialiser le projet `Quarto` ;
- Supprimer le fichier automatiquement g√©n√©r√© avec l'extension `.qmd` ;
- R√©cup√©rer le contenu du mod√®le de fichier `Quarto Markdown` [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/index.qmd). Celui-ci permet de g√©n√©rer la page d'accueil de notre site. Enregistrer dans un fichier nomm√© `index.qmd`

On teste ensuite la compilation en local du fichier:

- Modifier le fichier `train.py` √† partir de [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/train.py) pour √™tre en mesure de compiler le fichier 
- Ex√©cuter le fichier `train.py`
- En ligne de commande, faire `quarto preview` (ajouter les arguments `--port 5000 --host 0.0.0.0` si vous passez par le `SSPCloud`)
- Observer le site web g√©n√©r√© en local

Enfin, on va construire et d√©ployer automatiquement ce site web gr√¢ce au
combo `Github Actions` et `Github Pages`:

- Cr√©er une branche `gh-pages` √† partir du contenu de [cette page](https://quarto.org/docs/publishing/github-pages.html)
- Cr√©er un fichier `.github/workflows/website.yaml` avec le contenu de [ce fichier](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/.github/workflows/publish.yaml)

:::

::: {.callout-note}

On doit dans cette application modifier le fichier `train.py`
pour enregistrer en local une duplication du mod√®le
de _machine learning_ et de l'ensemble d'entra√Ænement
car pour ces deux √©l√©ments
on n'est pas all√© au bout de la d√©marche MLOps
d'enregistrement dans un _model registry_ et un
_feature store_.

Dans la prochaine version de ce cours, qui
int√®grera `MLFlow`, on aura une d√©marche plus 
propre car on utilisera bien le mod√®le de production
et le jeu d'entrainement associ√©. 
:::


::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git checkout appli20
```

:::