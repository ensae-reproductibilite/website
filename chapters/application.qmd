---
title: "Application"
description: |
  Une application fil rouge pour illustrer l'int√©r√™t d'appliquer graduellement les bonnes pratiques dans une optique de mise en production d'une application de data science.
order: 10
href: chapters/application.html
image: /rocket.png
---


<details>
<summary>
D√©rouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/title-slide)
pour afficher les slides en plein √©cran.
</summary>


<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><iframe class="sourceCode yaml code-with-copy" src="https://ensae-reproductibilite.github.io/slides/#/title-slide"></iframe></div>

</details>

# Introduction

L'objectif de cette mise en application est d'**illustrer les diff√©rentes √©tapes qui s√©parent la phase de d√©veloppement d'un projet de celle de la mise en production**. Elle permettra de mettre en pratique les diff√©rents concepts pr√©sent√©s tout au long du cours.

L'objectif p√©dagogique principal de cette application est d'adopter un point de vue pragmatique en choisissant des outils et des m√©thodes de travail qui permettent de r√©aliser des objectifs ambitieux de valorisation de donn√©es. `Python` sera le trait d'union entre les diff√©rentes technologies ou infrastructures que nous utiliserons.

Cette application est un tutoriel pas √† pas pour avoir un projet reproductible et disponible sous plusieurs livrables.
Toutes les √©tapes ne sont pas indispensables √† tous les projets de _data science_ et il existe des outils alternatifs √† ceux pr√©sent√©s. N√©anmoins, les outils pr√©sent√©s ont l'avantage d'√™tre tr√®s bien int√©gr√©s √† `Python`, bien configur√©s si vous utilisez le `SSPCloud` comme nous le recommandons, tout en √©tant agnostiques sur le reste des outils que vous utilisez ; de sorte √† ne pas √™tre bloquants si on remplace l'une des briques logicielles par une autre.

Nous nous pla√ßons dans une situation initiale correspondant √† la fin de la phase de d√©veloppement d'un projet de data science.
On a un _notebook_ un peu monolithique, qui r√©alise les √©tapes classiques d'un *pipeline* de *machine learning* :

- Import de donn√©es ;
- Statistiques descriptives et visualisations ;
- *Feature engineering* ;
- Entra√Ænement d'un mod√®le ;
- Evaluation du mod√®le.

## Objectif {-}

**L'objectif est d'am√©liorer le projet de mani√®re incr√©mentale jusqu'√† pouvoir le mettre en production, en le valorisant sous une forme adapt√©e et en adoptant une m√©thode de travail fluidifiant les √©volutions futures.**

La @fig-start montre que notre point de d√©part initial, √† savoir un _notebook_, m√©lange tout. Ceci rend tr√®s complexe la mise √† jour de notre mod√®le ou l'exploitation de notre mod√®le sur de nouvelles donn√©es, ce qui est pourtant la raison d'√™tre du _machine learning_ qui est pens√© pour l'extrapolation. Si on vous demande de valoriser votre mod√®le sur de nouvelles donn√©es, vous risquez de devoir refaire tourner tout votre _notebook_, avec le risque de ne pas retrouver les m√™mes r√©sultats que dans la version pr√©c√©dente.

La @fig-end illustre l'horizon auquel nous aboutirons √† la fin de cette application. Nous d√©synchronisons les √©tapes d'entra√Ænement et de pr√©diction, en identifiant mieux les pr√©-requis de chacunes et en adoptant des briques technologiques adapt√©es √† celles-ci. Les noms pr√©sents sur cette figure sont encore obscurs, c'est normal, mais ils vous deviendrons familiers si vous adoptez une infrastructure et une m√©thode de travail √† l'√©tat de l'art.


![Illustration de notre point de d√©part](/drawio/starting_point.png){#fig-start width="60%"}


![Illustration de l'horizon vers lequel on se dirige](/drawio/end_point.png){#fig-end}



::: {.callout-important}
Il est important de bien lire les consignes et d'y aller progressivement.
Certaines √©tapes peuvent √™tre rapides, d'autres plus fastidieuses ;
certaines √™tre assez guid√©es, d'autres vous laisser plus de libert√©.
Si vous n'effectuez pas une √©tape, vous risquez de ne pas pouvoir passer √†
l'√©tape suivante qui en d√©pend.

Bien que l'exercice soit applicable sur toute configuration bien faite, nous
recommandons de privil√©gier l'utilisation du [SSP Cloud](https://datalab.sspcloud.fr/home), o√π tous les
outils n√©cessaires sont pr√©-install√©s et pr√©-configur√©s. Le service `VSCode`
ne sera en effet que le point d'entr√©e pour l'utilisation d'outils plus exigeants
sur le plan de l'infrastructure: _Argo_, _MLFLow_, etc.
:::

## Ce que cette application ne couvre pas (pour le moment)

A l'heure actuelle, cette application se concentre sur la mise en oeuvre fiable de l'entra√Ænement de mod√®les de machine learning. Comme vous pouvez le voir, quand on part d'aussi loin qu'un projet monolithique dans un _notebook_, c'est un travail cons√©quent d'en arriver √† un _pipeline_ pens√© pour la production. Cette application vise √† vous sensibiliser au fait qu'avoir la @fig-end en t√™te et adopter une organisation de travail et faire des choix techniques ad√©quats, vous fera √©conomiser des dizaines voire centaines d'heures lorsque votre mod√®le aura vocation √† passer en production.

A l'heure actuelle, cette application ne se concentre que sur une partie du cycle de vie d'un projet _data_ ; il y a d√©j√† fort √† faire. Nous nous concentrons sur l'entra√Ænement et la mise √† disposition d'un mod√®le √† des fins op√©rationnelles. C'est la premi√®re partie du cycle de vie d'un mod√®le. Dans une approche MLOps, il faut √©galement penser la maintenance de ce mod√®le et les enjeux que repr√©sentent l'arriv√©e continue de nouvelles donn√©es, ou le besoin d'en collecter de nouvelles √† travers des annotations, sur la qualit√© pr√©dictive d'un mod√®le. Toute entreprise qui ne pense pas cet apr√®s est vou√©e √† se faire doubler par un nouveau venu. Une prochaine version de cette application permettra certainement d'illustrer certains des enjeux aff√©rants √† la vie en production d'un mod√®le (supervision, annotations...) sur notre cas d'usage.

Il convient aussi de noter que nous ne faisons que parcourir la surface des sujets que nous √©voquons. Ce cours, d√©j√† dense, deviendrait indigeste si nous devions pr√©senter chaque outil dans le d√©tail. Nous laissons donc les curieux approfondir chacun des outils que nous pr√©sentons pour d√©couvrir comment en tirer le maximum (et si vous avez l'impression que nous oublions des √©l√©ments cruciaux, les [_issues_ et _pull requests {{< fa brands github >}}_](https://github.com/ensae-reproductibilite/website) sont bienvenues).

## Comment g√©rer les _checkpoints_ ?

Pour simplifier la reprise en cours de ce fil rouge, nous proposons un syst√®me de _checkpoints_ qui s'appuient sur des _tags_ `Git`. Ces _tags_ figent le projet tel qu'il est √† l'issue d'un exercice donn√©.

Si vous faites √©voluer votre projet de mani√®re exp√©rimentale mais d√©sirez tout de m√™me utiliser √† un moment ces checkpoints, il va falloir faire quelques acrobaties `Git`. Pour cela, nous mettons √† disposition un script qui permet de sauvegarder votre avanc√©e dans un _tag_ donn√© (au cas o√π, √† un moment, vous vouliez revenir dessus) et √©craser la branche `main` avec le _tag_ en question. Par exemple, si vous d√©sirez reprendre apr√®s l'exercice 9, vous devrez faire tourner le code dans cette boite :

{{< checkpoint appli9 "Checkpoint d'exemple">}}

Celui-ci sauvegarde votre avanc√©e dans un tag nomm√© `dev_before_appli9`, le pousse sur votre d√©p√¥t `Github` {{< fa brands github >}} puis force votre branche √† adopter l'√©tat du tag `appli9`.



# Partie 0 : initialisation du projet

Nous allons prendre comme point de d√©part un projet livr√© exclusivement avec un _notebook_, √† la mani√®re d'un challenge _Kaggle_. Vous pourrez ainsi voir √† quel point ce type de livrable est tr√®s loin d'√™tre satisfaisant si on veut que le projet soit r√©utilisable.

{{< include "./applications/_appli0.qmd" >}}

# Partie 1 : qualit√© du script

Cette premi√®re partie vise √† **rendre le projet conforme aux bonnes pratiques** pr√©sent√©es dans le cours.

Elle fait intervenir les notions suivantes :

- Utilisation du **terminal** (voir [Linux 101](/chapters/linux-101.qmd)) ;
- **Qualit√© du code** (voir [Qualit√© du code](/chapters/code-quality.qmd)) ;
- **Architecture de projets** (voir [Architecture des projets](/chapters/projects-architecture.html)) ;
- **Contr√¥le de version** avec `Git` (voir [Rappels `Git`](/chapters/git.qmd)) ;
- **Travail collaboratif** avec `Git` et `GitHub` (voir [Rappels `Git`](/chapters/git.qmd)).


Le plan de la partie est le suivant :

1. S'assurer que le script fonctionne ;
2. Nettoyer le code des scories formelles avec un _linter_ et un _formatter_ ;
3. Param√©trisation du script ;
4. Utilisation de fonctions.


## √âtape 1 : s'assurer que le script s'ex√©cute correctement

On va partir du fichier `notebook.py` qui reprend le contenu
du _notebook_[^jupytext] mais dans un script classique.
Le travail de nettoyage en sera facilit√©.

[^jupytext]: L'export dans un script `.py` a √©t√© fait
        directement depuis `VSCode`. Comme
        cela n'est pas vraiment l'objet du cours, nous passons cette √©tape et fournissons
        directement le script expurg√© du texte interm√©diaire. Mais n'oubliez
        pas que cette d√©marche, fr√©quente quand on a d√©marr√© sur un _notebook_ et
        qu'on d√©sire consolider en faisant la transition vers des
        scripts, n√©cessite d'√™tre attentif pour ne pas risquer de faire une erreur.

La premi√®re √©tape est simple, mais souvent oubli√©e : **v√©rifier que le code fonctionne correctement**.
Pour cela, nous recommandons de faire un aller-retour entre le script ouvert dans `VSCode`
et un terminal pour le lancer.


{{< include "./applications/_appli1.qmd" >}}


## √âtape 2: utiliser un _linter_ puis un _formatter_

On va maintenant am√©liorer la qualit√© de notre code en appliquant les standards communautaires.
Pour cela, on va utiliser le *linter* classique [`PyLint`](https://pylint.readthedocs.io/en/latest/)
et le _formatter_ [`Black`](https://github.com/psf/black).
Si vous d√©sirez un outil deux en un, il est possible d'utiliser [`Ruff`](https://github.com/astral-sh/ruff-vscode)
en compl√©ment ou substitut.


Ce nettoyage automatique du code permettra, au passage, de restructurer notre
script de mani√®re plus naturelle.


::: {.callout-important}
[`PyLint`](https://pylint.readthedocs.io/en/latest/), [`Black`](https://black.readthedocs.io/en/stable/) et [`Ruff`](https://docs.astral.sh/ruff/)
sont des _packages_ `Python` qui
s'utilisent principalement en ligne de commande.

Si vous avez une erreur qui sugg√®re
que votre terminal ne connait pas [`PyLint`](https://pylint.readthedocs.io/en/latest/), [`Black`](https://black.readthedocs.io/en/stable/),
ou [`Ruff`](https://docs.astral.sh/ruff/), n'oubliez pas d'ex√©cuter la commande `pip install pylint`, `pip install black` ou `pip install ruff`.
:::


Le _linter_ [`PyLint`](https://pylint.readthedocs.io/en/latest/) renvoie alors une s√©rie d'irr√©gularit√©s,
en pr√©cisant √† chaque fois la ligne de l'erreur et le message d'erreur associ√© (ex : mauvaise identation).
Il renvoie finalement une note sur 10,
qui estime la qualit√© du code √† l'aune des standards communautaires √©voqu√©s
dans la partie [Qualit√© du code](/chapters/code-quality.html).

{{< include "./applications/_appli2.qmd" >}}

Le code est maintenant lisible, il obtient √† ce stade une note formelle proche de 10.
Mais il n'est pas encore totalement intelligible ou fiable.
Il y a notamment
quelques redondances de code auxquelles nous allons nous attaquer par la suite.
N√©anmoins, avant cela, occupons-nous de mieux g√©rer certains param√®tres du script:
jetons d'API et chemin des fichiers.


## √âtape 3: gestion des param√®tres

{{< checkpoint appli2 "Reprendre √† partir d'ici" "true" "pre-appli3" >}}

L'ex√©cution du code et les r√©sultats obtenus
d√©pendent de certains param√®tres d√©finis dans le code. L'√©tude de r√©sultats
alternatifs, en jouant sur
des variantes des (hyper)param√®tres, est √† ce stade compliqu√©e
car il est n√©cessaire de parcourir le code pour trouver
ces param√®tres. De plus, certains param√®tres personnels
comme des jetons
d'API ou des mots de passe n'ont pas vocation √†
√™tre pr√©sents dans le code.

Il est plus judicieux de consid√©rer ces param√®tres comme des
variables d'entr√©e du script. Cela peut √™tre fait de deux
mani√®res:

1. Avec des __arguments optionnels__ appel√©s depuis la ligne de commande _(Application 3a)_.
Cela peut √™tre pratique pour mettre en oeuvre des tests automatis√©s mais
n'est pas forc√©ment pertinent pour toutes les variables. Nous allons montrer
cet usage avec le nombre d'arbres de notre _random forest_ ;
2. En utilisant un __fichier de configuration__ dont les valeurs sont import√©es dans
le script principal _(Application 3b)_.


<details>
<summary>
Un exemple de d√©finition d'un argument pour l'utilisation en ligne de commande
</summary>

```{.python filename="prenom.py"}
import argparse
parser = argparse.ArgumentParser(description="Qui √™tes-vous?")
parser.add_argument(
    "--prenom", type=str, default="Toto", help="Un pr√©nom √† afficher"
)
args = parser.parse_args()
print(args.prenom)
```

Exemples d'utilisations en ligne de commande

```{.bash filename="terminal"}
python prenom.py
python prenom.py --prenom "Zinedine"
```

</details>

{{< include "./applications/_appli3.qmd" >}}


## √âtape 4 : Privil√©gier la programmation fonctionnelle

Nous allons **mettre en fonctions les parties importantes de l'analyse**.
Ceci facilitera l'√©tape ult√©rieure de modularisation de notre projet. Comme cela est √©voqu√© dans les √©l√©ments magistraux de ce cours, l'utilisation de fonctions va rendre notre code plus concis, plus tra√ßable, mieux document√©.

Cet exercice √©tant chronophage, il n'est __pas obligatoire de le r√©aliser en entier__. L'important est de
comprendre la d√©marche et d'adopter fr√©quemment une approche fonctionnelle[^POO]. Pour obtenir
une chaine enti√®rement fonctionnalis√©e, vous pouvez reprendre le _checkpoint_.

[^POO]: Nous proposons ici d'adopter le principe de la __programmation fonctionnelle__. Pour encore fiabiliser
un processus, il serait possible d'adopter le paradigme de la __programmation orient√©e objet (POO)__. Celle-ci est
plus rebutante et demande plus de temps au d√©veloppeur. L'arbitrage co√ªt-avantage est n√©gatif pour notre
exemple, nous proposons donc de nous en passer. N√©anmoins, pour une mise en production r√©elle d'un mod√®le,
il peut √™tre utle de l'adopter car certains _frameworks_, √† commencer par les _pipelines_ `scikit`, exigeront certaines classes et m√©thodes si vous d√©sirez brancher des objets  _ad hoc_ √† ceux-ci.

{{< include "./applications/_appli4_optionnelle.qmd" >}}

{{< include "./applications/_appli4.qmd" >}}

Cela ne se remarque pas encore vraiment car nous avons de nombreuses d√©finitions de fonctions
mais notre chaine de production est beaucoup plus
concise (le script fait environ 150 lignes dont une centaine issues de d√©finitions de fonctions g√©n√©riques).
Cette auto-discipline facilitera grandement
les √©tapes ult√©rieures. Cela aurait √©t√© n√©anmoins beaucoup moins co√ªteux en temps d'adopter
ces bons gestes de mani√®re plus pr√©coce.


# Partie 2 : adoption d'une structure modulaire {#partie2}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues tout au long du cours.
Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'un
possible partage du code : celui-ci est lisible et intelligible.
Le code est proprement versionn√© sur un
d√©p√¥t `GitHub`.

Cependant, le projet est encore perfectible: il est encore difficile de rentrer
dedans si on ne sait pas exactement ce qu'on recherche. L'objectif de cette partie
est d'isoler les diff√©rentes √©tapes de notre _pipeline_.
Outre le gain de clart√© pour notre projet, nous √©conomiserons beaucoup de peines
pour la mise en production ult√©rieure de notre mod√®le.


![Etat du _pipeline_ avant la modularisation](/chapters/applications/figures/pipeline_post_appli4.png)


Dans cette partie nous allons continuer les am√©liorations
incr√©mentales de notre projet avec les √©tapes suivantes:

1. Modularisation du code `Python` pour s√©parer les diff√©rentes
√©tapes de notre _pipeline_ ;
1. Adopter une structure standardis√©e pour notre projet afin
d'autodocumenter l'organisation de celui-ci ;
1. Documenter les _packages_ indispensables √† l'ex√©cution du code ;
4. Stocker les donn√©es dans un environnement ad√©quat
afin de continuer la d√©marche de s√©parer conceptuellement les donn√©es du code en de la configuration.


## √âtape 1 : modularisation

Nous allons profiter de la modularisation pour adopter une structure
applicative pour notre code. Celui-ci n'√©tant en effet plus lanc√©
que depuis la ligne de commande, on peut consid√©rer qu'on construit
une application g√©n√©rique o√π un script principal (`main.py`)
encapsule des √©l√©ments issus d'autres scripts `Python`.


{{< include "./applications/_appli5.qmd" >}}


## √âtape 2 : adopter une architecture standardis√©e de projet

On dispose maintenant d'une application `Python` fonctionnelle.
N√©anmoins, le projet est certes plus fiable mais sa structuration
laisse √† d√©sirer et il serait difficile de rentrer √† nouveau
dans le projet dans quelques temps.

<details>
<summary>Etat actuel du projet üôà</summary>

```
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ data.csv
‚îú‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ test.csv
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ build_pipeline.py
‚îú‚îÄ‚îÄ train_evaluate.py
‚îú‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ main.py
```


</details>

Comme cela est expliqu√© dans la
partie [Structure des projets](/chapters/projects-architecture.html),
on va adopter une structure certes arbitraire mais qui va
faciliter l'autodocumentation de notre projet. De plus, une telle structure va faciliter des √©volutions optionnelles
comme la _packagisation_ du projet. Passer d'une structure modulaire
bien faite √† un _package_ est quasi-imm√©diat en `Python`.

On va donc modifier l'architecture de notre projet pour la rendre plus standardis√©e.
Pour cela, on va s'inspirer des structures
[`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/)
qui g√©n√®rent des _templates_ de projet. En l'occurrence
notre source d'inspiration sera le [_template datascience_](https://drivendata.github.io/cookiecutter-data-science/)
issu d'un effort communautaire.

::: {.callout-note}
L'id√©e de [`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/) est de proposer des _templates_ que l'on utilise pour __initialiser__ un projet, afin de b√¢tir √† l'avance une structure √©volutive. La syntaxe √† utiliser dans ce cas est la suivante :

```{.bash filename="terminal"}
pip install cookiecutter
cookiecutter https://github.com/drivendata/cookiecutter-data-science
```

Ici, on a d√©j√† un projet, on va donc faire les choses dans l'autre sens : on va s'inspirer de la structure propos√©e afin de r√©organiser celle de notre projet selon les standards communautaires.
:::

En s'inspirant du _cookiecutter data science_
on va adopter la structure suivante:

<details>
<summary>
Structure recommand√©e
</summary>

```
application
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ .env
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îú‚îÄ‚îÄ raw
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.csv
‚îÇ   ‚îî‚îÄ‚îÄ derived
‚îÇ       ‚îú‚îÄ‚îÄ test.csv
‚îÇ       ‚îî‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ pipeline
    ‚îÇ   ‚îî‚îÄ‚îÄ build_pipeline.py
    ‚îî‚îÄ‚îÄ models
        ‚îî‚îÄ‚îÄ train_evaluate.py
```

</details>

{{< include "./applications/_appli6.qmd" >}}


## √âtape 3: mieux tracer notre chaine de production

### Indiquer l'environnement minimal de reproductibilit√©

Le script `main.py` n√©cessite un certain nombre de packages pour
√™tre fonctionnel. Chez vous les packages n√©cessaires sont
bien s√ªr install√©s mais √™tes-vous assur√© que c'est le cas
chez la personne qui testera votre code ?

Afin de favoriser la portabilit√© du projet,
il est d'usage de _"fixer l'environnement"_,
c'est-√†-dire d'indiquer dans un fichier toutes les d√©pendances utilis√©es ainsi que leurs version.
Nous proposons de cr√©er un fichier `requirements.txt` minimal, sur lequel nous reviendrons
dans la partie consacr√©e aux environnements reproductibles.

Le fichier `requirements.txt` est conventionnellement localis√© √† la racine du projet.
Ici on ne va pas fixer les versions, on raffinera ce fichier ult√©rieurement.

{{< include "./applications/_appli7a.qmd" >}}

### Tracer notre cha√Æne

Quand votre projet passera en production, vous aurez un acc√®s limit√© √† celui-ci. Il est donc important de faire remonter, par le biais du _logging_ des informations critiques sur votre projet qui vous permettront de savoir o√π il en est (si vous avez acc√®s √† la console o√π il tourne) ou l√† o√π il s'est arr√™t√©.

L'utilisation de `print` montre rapidement ses limites pour cela. Les informations enregistr√©es ne persistent pas apr√®s la session et sont quelques peu rudimentaires.

Pour faire du _logging_, la librairie consacr√©e depuis longtemps en `Python` est... [`logging`](https://docs.python.org/3/library/logging.html). Il existe aussi une librairie nomm√©e [`loguru`](https://github.com/Delgan/loguru) qui est un peu plus simple √† configurer (l'instanciation du _logger_ est plus ais√©e) et plus agr√©able gr√¢ce √† ses messages en couleurs qui permettent de visuellement trier les informations.

![](https://raw.githubusercontent.com/Delgan/loguru/master/docs/_static/img/demo.gif)

L'exercice suivant peut √™tre fait avec les deux librairies, cela ne change pas grand chose. Les prochaines applications repartiront de la version utilisant la librairie standard `logging`.


{{< include "./applications/_appli7b.qmd" >}}


## √âtape 4 : stocker les donn√©es de mani√®re externe {#stockageS3}

Pour cette partie, il faut avoir un service `VSCode` dont les jetons d'authentification √† `S3` sont valides. Pour cela, si vous √™tes sur le `SSPCloud`, le plus simple est de recr√©er un nouveau service avec le bouton suivant

<a href="https://datalab.sspcloud.fr/launcher/ide/vscode-python?name=ENSAE%20Mise%20en%20production&version=2.1.24&s3=region-ec97c721&init.personalInit=¬´https%3A%2F%2Fraw.githubusercontent.com%2Fensae-reproductibilite%2Fwebsite%2Frefs%2Fheads%2Fmain%2Fchapters%2Fapplications%2Finit.sh¬ª&kubernetes.role=¬´admin¬ª&networking.user.enabled=true&autoLaunch=false" target="_blank" rel="noopener" data-original-href="https://datalab.sspcloud.fr/launcher/ide/vscode-python?name=ENSAE%20Mise%20en%20production&version=2.1.24&s3=region-ec97c721&init.personalInit=¬´https%3A%2F%2Fraw.githubusercontent.com%2Fensae-reproductibilite%2Fwebsite%2Frefs%2Fheads%2Fmain%2Fchapters%2Fapplications%2Finit.sh¬ª&kubernetes.role=¬´admin¬ª&networking.user.enabled=true&autoLaunch=false"><img src="https://img.shields.io/badge/SSP%20Cloud-Lancer_avec_VSCode-blue?logo=visualstudiocode&amp;logoColor=blue" alt="Onyxia"></a>

et remplir l'onglet `Git` comme √ßa votre `VSCode` sera pr√© √† l'emploi (cf. application 0).

Une fois que vous avez un `VSCode` fonctionnel, il est possible de reprendre cette application fil rouge depuis le _checkpoint_ pr√©c√©dent.

{{< checkpoint appli7 "Reprendre √† partir d'ici" "true" "pre-appli8" >}}

Enfin, il vous suffira d'ouvrir un terminal et faire `pip install -r requirements.txt && python main.py` pour pouvoir d√©marrer l'application.

L'√©tape pr√©c√©dente nous a permis d'isoler la configuration. Nous avons conceptuellement isol√© les donn√©es du code lors des applications pr√©c√©dentes. Cependant, nous n'avons pas √©t√© au bout du chemin car le stockage des donn√©es reste conjoint √† celui du code. Nous allons maintenant dissocier ces deux √©l√©ments.

::: {.callout-warning collapse="true"}
## Pour en savoir plus sur le syst√®me de stockage `S3`

Pour mettre en oeuvre cette √©tape, il peut √™tre utile de
comprendre un peu comme fonctionne le SSP Cloud.
Vous devrez suivre la [documentation du SSP Cloud](https://inseefrlab.github.io/docs.sspcloud.fr/docs/fr/storage.html) pour la r√©aliser. Une aide-m√©moire est √©galement disponible dans le cours
de 2e ann√©e de l'ENSAE [Python pour la _data science_](https://linogaliana-teaching.netlify.app/reads3/#).
:::

::: {.callout-warning collapse="true"}
## Pour en savoir plus sur le format `Parquet`

L'objectif de cette application est de montrer comment utiliser le format `Parquet` dans une cha√Æne production  ; un objectif somme toute modeste.

Si vous voulez aller plus loin dans la d√©couverte du format `Parquet`, vous pouvez consulter [cette ressource `R`](https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/slides/complete.html#/application-3-2) tr√®s similaire √† ce cours (oui elle est faite par les m√™mes auteurs...) et essayer de faire les exercices avec votre librairie `Python` de pr√©dilection (`PyArrow` ou `DuckDB`)

:::


::: {.callout-important collapse="true"}
## Et si vous utilisez une infrastructure _cloud_ qui n'est pas le `SSPCloud` ? (une id√©e saugrenue mais sait-on jamais)

Les exemples √† venir peuvent tr√®s bien √™tre r√©pliqu√©s sur n'importe quel _cloud provider_ qui propose une solution de type `S3`, qu'il s'agisse d'un _cloud provider_ priv√© (AWS, GCP, Azure, etc.) ou d'une r√©instanciation _ad hoc_ du projet [`Onyxia`](https://www.onyxia.sh/), le logiciel derri√®re le `SSPCloud`.

Pour un syst√®me de stockage `S3`, il suffit de changer les param√®tres de connexion de `s3fs` (_endpoint_, _region_, etc.). Pour les stockages sur `GCP`, les codes sont presque √©quivalents, il suffit de remplacer la librairie [`s3fs`](https://pypi.org/project/s3fs/) par [`gcfs`](https://github.com/fsspec/gcsfs); ces deux librairies sont en fait des briques d'un standard plus g√©n√©ral de gestion de syst√®mes de fichiers en `Python` [`ffspec`](https://filesystem-spec.readthedocs.io/en/latest/).

:::


Le chapitre sur la [structure des projets](/chapters/projects-architecture.qmd)
d√©veloppe l'id√©e qu'il est recommand√© de converger vers un mod√®le
o√π environnements d'ex√©cution, de stockage du code et des donn√©es sont conceptuellement
s√©par√©s. Ce haut niveau d'exigence est un gain de temps important
lors de la mise en production car au cours de cette derni√®re, le projet
est amen√© √† √™tre ex√©cut√© sur une infrastructure informatique d√©di√©e
qu'il est bon d'anticiper. Sch√©matiquement, nous visons la structure de projet suivante:

![](https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/slides/img/environment_clean.png)

A l'heure actuelle, les donn√©es sont stock√©es dans le d√©p√¥t. C'est une
mauvaise pratique. En premier lieu, `Git` n'est techniquement
pas bien adapt√© au stockage de donn√©es. Ici ce n'est pas tr√®s grave
car il ne s'agit pas de donn√©es volumineuses et ces derni√®res ne sont
pas modifi√©es au cours de notre chaine de traitement.

La raison principale
est que les donn√©es trait√©es par les _data scientists_
sont g√©n√©ralement soumises √† des clauses de
confidentialit√©s ([RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on), [secret statistique](https://www.insee.fr/fr/information/1300624)...). Mettre ces donn√©es sous contr√¥le de version
c'est prendre le risque de les divulguer √† un public non habilit√©.
Il est donc recommand√© de privil√©gier des outils techniques adapt√©s au
stockage de donn√©es.

L'id√©al, dans notre cas, est d'utiliser une solution de stockage externe.
On va utiliser pour cela `MinIO`, la solution de stockage de type `S3` offerte par le SSP Cloud.
Cela nous permettra de supprimer les donn√©es de `Github` tout en maintenant la reproductibilit√©
de notre projet [^history].

[^history]: Attention, les donn√©es ont √©t√© _committ√©es_ au moins une fois. Les supprimer
du d√©p√¥t ne les efface pas de l'historique. Si cette erreur arrive, le mieux est de supprimer
le d√©p√¥t en ligne, cr√©er un nouvel historique `Git` et partir de celui-ci pour des publications
ult√©rieures sur `Github`. N√©anmoins l'id√©al serait de ne pas s'exposer √† cela. C'est justement
l'objet des bonnes pratiques de ce cours: un `.gitignore` bien construit et une s√©paration des
environnements de stockage du code et
des donn√©es seront bien plus efficaces pour vous √©viter ces probl√®mes que tout les conseils de
vigilance que vous pourrez trouver ailleurs.

Plus concr√®tement, nous allons adopter le pipeline suivant pour notre projet:

![](/chapters/applications/figures/pipeline_appli8.png)

Le sc√©nario type est que nous avons une source brute, re√ßue sous forme de CSV, dont on ne peut changer le format. Il aurait √©t√© id√©al d'avoir un format plus adapt√© au traitement de donn√©es pour ce fichier mais ce n'√©tait pas de notre ressort. Notre chaine va aller chercher ce fichier, travailler dessus jusqu'√† valoriser celui-ci sous la forme de notre matrice de confusion. Si on imagine que notre chaine prend un certain temps, il n'est pas inutile d'√©crire des donn√©es interm√©diaires. Pour faire cela, puisque nous avons la main, autant choisir un format adapt√©, √† savoir le format `Parquet`.

Cette application va se d√©rouler en trois temps:

1. _Upload_ de notre source brute (CSV) sur S3
2. Illustration de l'usage des librairies _cloud native_ pour lire celle-ci
3. Partage public de cette donn√©e pour la rendre accessible de mani√®re plus simple √† nos futures applications.

{{< include "./applications/_appli8.qmd" >}}


# Partie 2bis: packagisation de son projet (optionnel)

Cette s√©rie d'actions n'est pas forc√©ment pertinente pour tous
les projets. Elle fait un peu la transition entre la modularit√©
et la portabilit√©.

## √âtape 1 : proposer des tests unitaires (optionnel)

Notre code comporte un certain nombre de fonctions g√©n√©riques.
On peut vouloir tester leur usage sur des donn√©es standardis√©es,
diff√©rentes de celles du Titanic.

M√™me si la notion de tests unitaires
prend plus de sens dans un _package_, nous pouvons proposer
dans le projet des exemples d'utilisation de la fonction, ceci peut √™tre p√©dagogique.

Nous allons utiliser [`unittest`](https://docs.python.org/3/library/unittest.html)
pour effectuer des tests unitaires. Cette approche n√©cessite quelques notions
de programmation orient√©e objet ou une bonne discussion avec `ChatGPT`.

{{< include "./applications/_appli9.qmd" >}}


::: {.callout-note}

Lorsqu'on effectue des tests unitaires, on cherche g√©n√©ralement
√† tester le plus de lignes possibles de son code. On parle de
__taux de couverture__ (_coverage rate_) pour d√©signer
la statistique mesurant cela.

Cela peut s'effectuer de la mani√®re suivante avec le package
[`coverage`](https://coverage.readthedocs.io/en/7.2.2/):

```{.bash filename="terminal"}
coverage run -m unittest tests/test_create_variable_title.py
coverage report -m
```

```{.python}
Name                                  Stmts   Miss  Cover   Missing
-------------------------------------------------------------------
src/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113
tests/test_create_variable_title.py      21      1    95%   54
-------------------------------------------------------------------
TOTAL                                    55     22    60%
```

Le taux de couverture est souvent mis en avant par les gros
projets comme indicateur de leur qualit√©. Il existe d'ailleurs
des badges `Github` d√©di√©s.
:::




## √âtape 2 : transformer son projet en package (optionnel)

Notre projet est modulaire, ce qui le rend assez simple √† transformer
en _package_, en s'inspirant de la structure du `cookiecutter` adapt√©, issu
de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

On va cr√©er un _package_ nomm√© `titanicml` qui encapsule
tout notre code et qui sera appel√©
par notre script `main.py`. La structure attendue
est la suivante:

<details>
<summary>Structure vis√©e</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ docs                                    ‚îê
‚îÇ   ‚îú‚îÄ‚îÄ main.py                             ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ notebooks                           ‚îÇ Package documentation and examples
‚îÇ       ‚îî‚îÄ‚îÄ titanic.ipynb                   ‚îÇ
‚îú‚îÄ‚îÄ configuration                           ‚îê Configuration (pas √† partager avec Git)
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                         ‚îò
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ pyproject.toml                          ‚îê
‚îú‚îÄ‚îÄ requirements.txt                        ‚îÇ
‚îú‚îÄ‚îÄ titanicml                               ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                         ‚îÇ Package source code, metadata
‚îÇ   ‚îú‚îÄ‚îÄ data                                ‚îÇ and build instructions
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                  ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ features                            ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py               ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models                              ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ train_evaluate.py               ‚îò
‚îî‚îÄ‚îÄ tests                                   ‚îê
    ‚îî‚îÄ‚îÄ test_create_variable_title.py       ‚îò Package tests
```
</details>

<details>
<summary>Rappel: structure actuelle</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb
‚îú‚îÄ‚îÄ configuration
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ data
    ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py
    ‚îú‚îÄ‚îÄ features
    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
    ‚îî‚îÄ‚îÄ models
        ‚îî‚îÄ‚îÄ train_evaluate.py
```
</details>

Il existe plusieurs
_frameworks_ pour
construire un _package_. Nous
allons privil√©gier [`Poetry`](https://python-poetry.org/)
√† [`Setuptools`](https://pypi.org/project/setuptools/).


::: {.callout-note}

Pour cr√©er la structure minimale d'un _package_, le plus simple est
d'utiliser le `cookiecutter` adapt√©,
issu de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

Comme on a d√©j√† une structure tr√®s modulaire, on va plut√¥t recr√©er cette
structure dans notre projet d√©j√† existant. En fait, il ne manque qu'un fichier essentiel,
le principal distinguant un projet classique d'un package : `pyproject.toml`.

```{.bash filename="terminal"}
cookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git
```

<details>
<summary>D√©rouler pour voir les choix possibles</summary>
```{.python}
author_name [Monty Python]: Daffy Duck
package_name [mypkg]: titanicml
package_short_description []: Impressive Titanic survival analysis
package_version [0.1.0]:
python_version [3.9]:
Select open_source_license:
1 - MIT
2 - Apache License 2.0
3 - GNU General Public License v3.0
4 - Creative Commons Attribution 4.0
5 - BSD 3-Clause
6 - Proprietary
7 - None
Choose from 1, 2, 3, 4, 5, 6 [1]:
Select include_github_actions:
1 - no
2 - ci
3 - ci+cd
Choose from 1, 2, 3 [1]:
```
</details>

:::

{{< include "./applications/_appli10.qmd" >}}

# Partie 3 : construction d'un projet portable et reproductible {#partie3}

{{< checkpoint appli8 "Reprendre √† partir d'ici" "true" "pre-appli10" >}}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues
dans les chapitres [Qualit√© du code](/chapters/code-quality.html)
et [Structure des projets](/chapters/projects-architecture.html)
tout au long du cours.

Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'une
possible mise en production : le code est lisible,
la structure du projet est normalis√©e et √©volutive,
et le code est proprement versionn√© sur un
d√©p√¥t `GitHub` {{< fa brands github >}}.


<details>
<summary>
Illustration de l'√©tat actuel du projet
</summary>
![](/chapters/applications/figures/_pipeline_avant_partie3.png)

</details>



A pr√©sent, nous avons une version du projet qui est largement partageable.
Du moins en th√©orie, car la pratique est souvent plus compliqu√©e :
il y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement (typiquement, votre ordinateur personnel),
les choses ne se passent pas du tout comme attendu. Cela signifie qu'**en l'√©tat, le projet n'est pas portable : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.

Dans cette trois√®me partie de notre travail vers la mise en production,
nous allons voir
comment **normaliser l'environnement d'ex√©cution afin de produire un projet portable**.
Autrement dit, nous n'allons plus nous contenter de modularit√© mais allons rechercher
la portabilit√©.
On sera alors tout proche de pouvoir mettre le projet en production.

On progressera dans l'√©chelle de la reproductibilit√©
de la mani√®re suivante:

1. [**Environnements virtuels**](#anaconda) ;
2. Cr√©er un [script shell](#shell) qui permet, depuis un environnement minimal, de construire l'application de A √† Z ;
3. [**Images et conteneurs `Docker`**](#docker).


Nous allons repartir de l'application 8, c'est-√†-dire d'un projet
modulaire mais qui n'est pas, √† strictement parler, un _package_
(objet des applications optionnelles suivantes 9 et 10).

Pour se replacer dans l'√©tat du projet √† ce niveau,
il est possible d'utiliser le _tag_ _ad hoc_.

```{.bash filename="terminal"}
git stash
git checkout appli8
```


## √âtape 1 : un environnement pour rendre le projet portable {#anaconda}

Pour qu'un projet soit portable, il doit remplir deux conditions:

- Ne pas n√©cessiter de d√©pendance
qui ne soient pas renseign√©es quelque part ;
- Ne pas proposer des d√©pendances inutiles, qui ne
sont pas utilis√©es dans le cadre du projet.

Le prochain exercice vise √† mettre ceci en oeuvre.
Comme expliqu√© dans le [chapitre portabilit√©](/chapters/portability.qmd),
le choix du gestionnaire d'environnement est laiss√©
libre. Il est recommand√© de privil√©gier `venv` si vous d√©couvrez
la probl√©matique de la portabilit√©.

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

L'approche la plus l√©g√®re est l'environnement virtuel.
Nous avons en fait implicitement d√©j√† commenc√© √† aller vers
cette direction
en cr√©ant un fichier `requirements.txt`.

{{< include "./applications/_appli11a.qmd" >}}


## Environnement `conda`

Les environnements `conda` sont plus lourds √† mettre en oeuvre que les
environnements virtuels mais peuvent permettre un contr√¥le
plus formel des d√©pendances.

{{< include "./applications/_appli11b.qmd" >}}


## Environnement virtuel via `uv`

`uv` est le _new kid in the game_ pour g√©rer les environnements virtuels avec `Python`.

{{< include "./applications/_appli11c.qmd" >}}


:::


## √âtape 2: construire l'environnement de notre application via un script `shell` {#shell}

Les environnements virtuels permettent de mieux sp√©cifier les d√©pendances de notre projet, mais ne permettent pas de garantir une portabilit√© optimale. Pour cela, il faut recourir √† la technologie des conteneurs. L'id√©e est de construire une machine, en partant d'une base quasi-vierge, qui permette de construire √©tape par √©tape l'environnement n√©cessaire au bon fonctionnement de notre projet. C'est le principe des conteneurs `Docker` {{< fa brands docker >}}.

Leur m√©thode de construction √©tant un peu difficile √† prendre en main au d√©but, nous allons passer par une √©tape interm√©diaire afin de bien comprendre le processus de production.

- Nous allons d'abord cr√©er un script `shell`, c'est √† dire une suite de commandes `Linux` permettant de construire l'environnement √† partir d'une machine vierge ;
- Nous transformerons celui-ci en `Dockerfile` dans un deuxi√®me temps. C'est l'objet de l'√©tape suivante.

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

{{< include "./applications/_appli12a.qmd" >}}

## Environnement `conda`

{{< include "./applications/_appli12b.qmd" >}}

:::


## √âtape 3: conteneuriser l'application avec `Docker` {#docker}


::: {.callout-note}
Cette application n√©cessite l'acc√®s √† une version interactive de `Docker`.
Il n'y a pas beaucoup d'instances en ligne disponibles.

Nous proposons deux solutions:

- [Installer `Docker`](https://docs.docker.com/get-docker/) sur sa machine ;
- Se rendre sur l'environnement bac √† sable _[Play with Docker](https://labs.play-with-docker.com)_

Sinon, elle peut √™tre r√©alis√©e en essai-erreur par le biais des services d'int√©gration continue de `Github` {{< fa brands github >}} ou `Gitlab` {{< fa brands gitlab >}}. N√©anmoins, nous pr√©senterons l'utilisation de ces services plus tard, dans la prochaine partie.
:::

Maintenant qu'on sait que ce script pr√©paratoire fonctionne, on va le transformer en `Dockerfile` pour anticiper la mise en production.  Comme la syntaxe `Docker` est l√©g√®rement diff√©rente de la syntaxe `Linux` classique (voir le [chapitre portabilit√©](/chapters/portability.qmd)), il va √™tre n√©cessaire de changer quelques instructions mais ceci sera tr√®s l√©ger.

On va tester le `Dockerfile` dans un environnement bac √† sable pour ensuite
pouvoir plus facilement automatiser la construction de l'image
`Docker`.

{{< include "./applications/_appli13.qmd" >}}


# Partie 4 : automatisation avec l'int√©gration continue


Imaginez que vous √™tes au restaurant
et qu'on ne vous serve pas le plat mais seulement la recette
et que, de plus, on vous demande de pr√©parer le plat
chez vous avec les ingr√©dients dans votre frigo.
Vous seriez quelque peu d√©√ßu. En revanche, si vous avez go√ªt√©
au plat, que vous √™tes un r√©el cordon bleu
et qu'on vous donne la recette pour refaire ce plat ult√©rieurement,
peut-√™tre
que vous appr√©ciriez plus.

Cette analogie illustre l'enjeu de d√©finir
le public cible et ses attentes afin de fournir un livrable adapt√©.
Une image `Docker` est un livrable qui n'est pas forc√©ment int√©ressant
pour tous les publics. Certains pr√©f√©reront avoir un plat bien pr√©par√©
qu'une recette ; certains appr√©cieront avoir une image `Docker` mais
d'autres ne seront pas en mesure de construire celle-ci ou ne sauront
pas la faire fonctionner. Une image `Docker` est plus souvent un
moyen pour faciliter la mise en service d'une production qu'une fin en soi.

Nous allons donc proposer
plusieurs types de livrables plus classiques par la suite. Ceux-ci
correspondront mieux aux attendus des publics utilisateurs de services
construits √† partir de techniques de _data science_. `Docker` est n√©anmoins
un passage oblig√© car l'ensemble des types de livrables que nous allons
explorer reposent sur la standardisation permise par les conteneurs.

Cette approche nous permettra de quitter le domaine de l'artisanat pour
s'approcher d'une industrialisation de la mise √† disposition
de notre projet. Ceci va notamment nous amener √† mettre en oeuvre
l'approche pragmatique du `DevOps` qui consiste √† int√©grer d√®s la phase de
d√©veloppement d'un projet les contraintes li√©es √† sa mise √† disposition
au public cible (cette approche est d√©taill√©e plus
amplement dans le chapitre sur la [mise en production](/chapters/deployment.qmd)).

L'automatisation et la mise √† disposition automatis√©e de nos productions
sera faite progressivement, au cours des prochaines parties. Tous les
projets n'ont pas vocation √† aller aussi loin dans ce domaine.
L'opportunit√© doit √™tre compar√©e aux co√ªts humains et financiers
de leur mise en oeuvre et de leur cycle de vie.
Avant de faire une production en s√©rie de nos mod√®les,
nous allons d√©j√† commencer
par automatiser quelques tests de conformit√© de notre code.
On va ici utiliser l'int√©gration continue pour deux objectifs distincts:

- la mise √† disposition de l'image `Docker` ;
- la mise en place de tests automatis√©s de la qualit√© du code
sur le mod√®le de notre `linter` pr√©c√©dent.

Nous allons utiliser `Github Actions` pour cela. Il s'agit de serveurs
standardis√©s mis √† disposition gratuitement par `Github` {{<fa brands github >}}.
`Gitlab` {{<fa brands gitlab >}}, l'autre principal acteur du domaine,
propose des services similaires. L'impl√©mentation est l√©g√®rement diff√©rente
mais les principes sont identiques.


{{< checkpoint appli13 "Reprendre √† partir d'ici" "true" "pre-appli14" >}}


## √âtape 1: mise en place de tests automatis√©s

Avant d'essayer de mettre en oeuvre la cr√©ation de notre image
`Docker` de mani√®re automatis√©e, nous allons pr√©senter la logique
de l'int√©gration continue en testant de mani√®re automatis√©e
notre script `main.py`.

Pour cela, nous allons partir de la structure propos√©e dans l'[action officielle](https://github.com/actions/setup-python).
La documentation associ√©e est [ici](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python).
Des √©l√©ments succincts de pr√©sentation de la logique d√©clarative des actions `Github`
sont disponibles dans le chapitre sur la [mise en production](/chapters/deployment.qmd). N√©anmoins, la meilleure
√©cole pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d'observer
les actions `Github` mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !


{{< include "./applications/_appli14.qmd" >}}


Maintenant, nous pouvons observer que l'onglet `Actions`
s'est enrichi. Chaque `commit` va entra√Æner une s√©rie d'actions automatis√©es.

Si l'une des √©tapes √©choue, ou si la note de notre projet est mauvaise, nous aurons
une croix rouge (et nous recevrons un mail). On pourra ainsi d√©tecter,
en d√©veloppant son projet, les moments o√π on d√©grade la qualit√© du script
afin de la r√©tablir imm√©diatemment.



## √âtape 2: Automatisation de la livraison de l'image `Docker`

Maintenant, nous allons automatiser la mise √† disposition de notre image
sur `DockerHub` (le lieu de partage des images `Docker`). Cela facilitera sa r√©utilisation mais aussi des
valorisations ult√©rieures.

L√† encore, nous allons utiliser une s√©rie d'actions pr√©-configur√©es.

Pour que `Github` puisse s'authentifier aupr√®s de `DockerHub`, il va
falloir d'abord interfacer les deux plateformes. Pour cela, nous allons utiliser
un jeton (_token_) `DockerHub` que nous allons mettre dans un espace
s√©curis√© associ√© √† votre d√©p√¥t `Github`.


{{< include "./applications/_appli15a.qmd" >}}


A ce stade, nous avons donn√© les moyens √† `Github` de s'authentifier avec
notre identit√© sur `Dockerhub`. Il nous reste √† mettre en oeuvre l'action
en s'inspirant de la [documentation officielle](https://github.com/docker/build-push-action/#usage).
On ne va modifier que trois √©l√©ments dans ce fichier. Effectuer les
actions suivantes:


{{< include "./applications/_appli15b.qmd" >}}



# Partie 5: exp√©rimenter en local des valorisations puis automatiser leur production


Nous avons automatis√© les √©tapes interm√©diaires de notre projet.
N√©anmoins nous n'avons pas encore r√©fl√©chi √† la valorisation
√† mettre en oeuvre pour notre projet. On va supposer que notre
projet s'adresse √† des _data scientists_ mais aussi √† une audience
moins technique. Pour ces premiers, nous pourrions nous contenter
de valorisations techniques, comme des API,
mais pour ces derniers il est
conseill√© de privil√©gier des formats plus _user friendly_.

Afin de faire le parall√®le avec les parcours possibles pour l'√©valuation,
nous allons proposer deux valorisations[^valorisation]:

- Une [API](https://titanic.kub.sspcloud.fr/docs) facilitant la r√©utilisation du mod√®le en "production" ;
- Un [site web statique](https://ensae-reproductibilite.github.io/application/) exploitant cette API pour exposer les pr√©dictions
√† une audience moins technique.


[^valorisation]: Vous n'√™tes pas oblig√©s pour l'√©valuation de mettre en oeuvre
les jalons de plusieurs parcours. N√©anmoins, vous d√©couvrirez que
chaque nouveau pas en avant est moins co√ªteux que le
pr√©c√©dent si vous avez mis en oeuvre les r√©flexes des bonnes
pratiques.



::: {.callout-warning collapse="true"}
## Site statique vs application r√©active

La solution que nous allons proposer
pour les sites statiques, `Quarto` associ√©
√† `Github Pages`, peut √™tre utilis√©e dans le cadre des parcours
_"rapport reproductible"_ ou _"dashboard / application interactive"_.

Pour ce dernier
parcours, d'autres approches techniques sont n√©anmoins possibles,
comme `Streamlit`. Celles-ci sont plus exigeantes sur le plan technique
puisqu'elles n√©cessitent de mettre en production sur des serveurs
conteuneuris√©s (comme la mise en production de l'API)
l√† o√π le site statique ne n√©cessite qu'un serveur web, mis √† disposition
gratuitement par `Github`.


La distinction principale entre ces deux approches est qu'elles
s'appuient sur des serveurs diff√©rents. Un site statique repose
sur un serveur web l√† o√π `Streamlit` s'appuie sur
serveur classique en _backend_. La diff√©rence principale
entre ces deux types de serveurs
r√©side principalement dans leur fonction et leur utilisation:

- Un __serveur web__ est sp√©cifiquement con√ßu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web √©coutent les requ√™tes HTTP/HTTPS provenant des navigateurs des utilisateurs et y r√©pondent en envoyant les donn√©es demand√©es.
- Un **serveur _backend_** classique est con√ßu pour effectuer des op√©rations en r√©ponse √† un _front_, en l'occurrence une page web.
Dans le contexte d'une application `Streamlit`, il s'agit d'un serveur avec l'environnement `Python` _ad hoc_ pour
ex√©cuter le code n√©cessaire √† r√©pondre √† toute action d'un utilisateur de l'appliacation.

:::


## √âtape 1: d√©velopper une API en local

Le premier livrable devenu classique dans un projet
impliquant du _machine learning_ est la mise √†
disposition d'un mod√®le par le biais d'une
API (voir chapitre sur la [mise en production](/chapters/deployment.qmd)).
Le _framework_ [`FastAPI`](https://fastapi.tiangolo.com/) va permettre
de rapidement transformer notre application `Python` en une API fonctionnelle.


{{< checkpoint appli15 "Reprendre √† partir d'ici" "true" "pre-appli16" >}}


{{< include "./applications/_appli16.qmd" >}}


## √âtape 2: d√©ployer l'API de mani√®re manuelle

{{< checkpoint appli16 "Reprendre √† partir d'ici" "true" "pre-appli17" >}}


A ce stade, nous avons d√©ploy√© l'API seulement localement, dans le cadre d'un terminal qui tourne en arri√®re-plan.
C'est une mise en production manuelle, pas franchement p√©renne.
Ce mode de d√©ploiement est tr√®s pratique pour la phase de d√©veloppement, afin de s'assurer que l'API fonctionne comme attendu.
Pour p√©renniser la mise en production, on va √©liminer l'aspect artisanal de celle-ci.

Il est temps de passer √† l'√©tape de d√©ploiement, qui permettra √† notre API d'√™tre accessible via une URL sur le web
et d'avoir un serveur, en arri√®re plan, qui effectuera les op√©rations pour r√©pondre √† une
requ√™te. Pour se faire, on va utiliser les possibilit√©s offertes par `Kubernetes`, sur lequel est bas√© le [SSP Cloud](https://datalab.sspcloud.fr).


{{< include "./applications/_appli17.qmd" >}}


Nous avons pr√©par√© la mise √† disposition de notre API mais √† l'heure
actuelle elle n'est pas disponible de mani√®re ais√©e car il est n√©cessaire
de lancer manuellement une image `Docker` pour pouvoir y acc√©der.
Ce type de travail est la sp√©cialit√© de `Kubernetes` que nous allons
utiliser pour g√©rer la mise √† disposition de notre API.

{{< include "./applications/_appli18.qmd" >}}

::: {.callout-note title="G√©rer le CORS" collapse="true"}
Notre API est accessible sans probl√®me depuis `Python` ou notre navigateur.

En revanche, si on d√©sire utiliser `JavaScript` pour cr√©er une application
interactive il est indispensable de mettre
les lignes un peu obscure sur le CORS dans le fichier `ingress.yaml`.

Comme c'est un point technique qui ne concerne pas les comp√©tences
li√©es √† ce cours, nous avons donn√© directement les lignes correspondantes dans ce fichier.

:::


On peut remarquer quelques voies d'am√©lioration de notre approche qui
seront ult√©rieurement trait√©es:

- L'entra√Ænement du mod√®le
est r√©-effectu√© √† chaque lancement d'un nouveau conteneur.
On relance donc autant de fois un entra√Ænement qu'on d√©ploie
de conteneurs pour r√©pondre √† nos utilisateurs. Ce sera
l'objet de la partie MLOps de fiabiliser et optimiser
cette partie du _pipeline_.
- il est n√©cessaire de (re)lancer manuellement  `kubectl apply -f deployment/`
√† chaque changement de notre code. Autrement dit, lors de cette application,
on a am√©lior√©
la fiabilit√© du lancement de notre API mais un lancement manuel est encore indispensable.
Comme dans le reste de ce cours, on va essayer d'√©viter un geste manuel pouvant
√™tre source d'erreur en privil√©giant l'automatisation et l'archivage dans des
scripts. C'est l'objet de la prochaine √©tape.


## Etape 3: automatiser le d√©ploiement (d√©ploiement en continu)

::: {.callout-important}
## Clarification sur la branche de travail et les _tags_

A partir de maintenant, il est n√©cessaire de clarifier la
branche principale sur laquelle nous travaillons. De mani√®re
traditionnelle, on utilise la branche `main`. Si vous avez chang√© de branche,
vous pouvez continuer 1/ continuer mais en tenir compte dans les exemples ult√©rieurs ou 2/ fusionner celle-ci √† `main`.

Si vous avez utilis√© un `tag` pour sauter une ou plusieurs √©tapes, il va
√™tre n√©cessaire de se placer sur une branche car vous √™tes en _head detached_.
Pour cela, apr√®s avoir _committ√©_ les fichiers que vous d√©sirez garder

```{.python}
#| file: "terminal"
#| filename: "terminal"
$ git branch -D dev #<1>
$ git push origin -d dev #<2>
$ git checkout -b dev #<3>
$ git push --set-upstream origin dev #<4>
```
1. Supprime la branche `dev` *locale* (si elle existe).
2. Supprime la branche `dev` *remote* (si elle existe).
3. Cr√©e une nouvelle branche `dev` *locale* et on se place sur cette branche.
4. Pousse la branche `dev` et active la synchronisation entre la branche *locale* et la branche *remote*.
:::

Qu'est-ce qui peut d√©clencher une √©volution n√©cessitant de mettre √† jour l'ensemble de notre processus de production ?

Regardons √† nouveau notre _pipeline_:

![](/drawio/end_point.png)

Les _inputs_ de notre _pipeline_ sont donc:

- La __configuration__. Ici, on peut consid√©rer que notre `.env` de configuration ou les secrets renseign√©s √† `Github` rel√®vent de cette cat√©gorie  ;
- Les __donn√©es__. Nos donn√©es sont statiques et n'ont pas vocation √† √©voluer. Si c'√©tait le cas, il faudrait en tenir compte dans notre automatisation[^versionning-data]. ;
- Le __code__. C'est l'√©l√©ment principal qui √©volue chez nous. Id√©alement, on veut automatiser le processus au maximum en faisant en sorte qu'√† chaque mise √† jour de notre code (un _push_ sur `Github`), les √©tapes ult√©rieures (production de l'image `Docker`, etc.) se lancent. N√©anmoins, on veut aussi √©viter qu'une erreur puisse donner lieu √† une mise en production non-fonctionnelle, on va donc maintenir une action manuelle minimale comme garde-fou.


::: {.callout-note}
## Et le _versionning_ des donn√©es ?

Ici, nous nous pla√ßons dans le cas simple o√π les donn√©es brutes re√ßues sont fig√©es. Ce qui peut changer est la mani√®re dont on constitue nos √©chantillons train/test. Il sera donc utile de logguer les donn√©es en question par le biais de `MLFlow`. Mais il n'est pas n√©cessaire de versionner les donn√©es brutes.

Si celles-ci √©voluaient, il pourrait √™tre utile de versionner les donn√©es, √† la mani√®re dont on le fait pour le code. `Git` n'est pas l'outil appropri√© pour cela. Parmi les outils populaires de versionning de donn√©es, bien int√©gr√©s avec S3, il y a sur le SSPCloud [`lakefs`](https://lakefs.io/).
:::

Pour automatiser au maximum la mise en production, on va utiliser un nouvel outil : `ArgoCD`. Ainsi, au lieu de devoir appliquer manuellement la commande `kubectl apply` √† chaque modification des fichiers de d√©ploiement (pr√©sents dans le dossier `kubernetes/`), c'est l'**op√©rateur** `ArgoCD`, d√©ploy√© sur le cluster, qui va d√©tecter les changements de configuration du d√©ploiement et les appliquer automatiquement.

C'est l'approche dite **GitOps** : le d√©p√¥t `Git` du d√©ploiement fait office de **source de v√©rit√© unique** de l'√©tat voulu de l'application, tout changement sur ce dernier doit donc se r√©percuter imm√©diatement sur le d√©ploiement effectif.

{{< include "./applications/_appli19a.qmd" >}}

A pr√©sent, nous avons tous les outils √† notre disposition pour construire un vrai **pipeline de CI/CD, automatis√© de bout en bout**. Il va nous suffire pour cela de mettre √† bout les composants :

- dans la partie 4 de l'application, nous avons construit un **pipeline de CI** : on a donc seulement √† faire un commit sur le d√©p√¥t de l'application pour lancer l'√©tape de **build** et de mise √† disposition de la nouvelle image sur le `DockerHub` ;

- dans l'application pr√©c√©dente, nous avons construit un **pipeline de CD** : `ArgoCD` suit en permanence l'√©tat du d√©p√¥t `GitOps`, tout commit sur ce dernier lancera donc automatiquement un red√©ploiement de l'application.

Il y a donc un √©l√©ment qui fait la liaison entre ces deux pipelines et qui nous sert de garde-fou en cas d'erreur : la **version de l'application**.

{{< include "./applications/_appli19b.qmd" >}}




## Etape 4: construire un site web

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli19
git checkout -b dev
git push origin dev
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

On va proposer un nouveau livrable pour parler √† un public plus large.
Pour faire ce site web,
on va utiliser `Quarto` et d√©ployer sur `Github Pages`.

{{< include "./applications/_appli20.qmd" >}}


# Partie 6: adopter une approche MLOps pour am√©liorer notre mod√®le

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli20
git checkout -b dev
git push origin dev
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

Maintenant que nous avons tout pr√©par√© pour mettre √† disposition rapidement un mod√®le,
nous pouvons revenir en arri√®re pour am√©liorer ce mod√®le. Pour cela, nous allons mettre en oeuvre une validation crois√©e.

Le probl√®me que nous allons rencontrer va √™tre que nous voudrions facilement tracer les √©volutions de notre mod√®le, la qualit√© pr√©dictive de celui-ci dans diff√©rentes situations. Il s'agira d'√† nouveau mettre en place du _logging_ mais, cette fois, de suivre la qualit√© du mod√®le et pas seulement s'il fonctionne. L'outil `MLFlow` va r√©pondre √† ce probl√®me et va, au passage, fluidifier la mise √† disposition du mod√®le de production, c'est-√†-dire de celui qu'on d√©sire mettre √† disposition du public.

## Revenir sur le code d'entra√Ænement du mod√®le pour faire de la validation crois√©e

Pour pouvoir faire ceci, il va falloir changer un tout petit peu notre code applicatif dans sa phase d'entra√Ænement.

{{< include "./applications/_appli21.qmd" >}}


## Garder une trace des entra√Ænements de notre mod√®le gr√¢ce au _register_ de `MLFlow`

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git stash
git checkout appli21
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

## Enregistrer nos premiers entra√Ænements

{{< include "./applications/_appli22.qmd" >}}

Cette appplication illustre l'un des premiers apports de `MLFlow`: on garde
une trace de nos exp√©rimentations: le mod√®le est archiv√© avec les param√®tres et des m√©triques de performance. On peut donc retrouver de plusieurs mani√®res un mod√®le qui nous avait tap√© dans l'oeil.

N√©anmoins, persistent un certain nombre de voies d'am√©lioration dans notre _pipeline_.

- On entra√Æne le mod√®le en local, de mani√®re s√©quentielle, et en lan√ßant nous-m√™mes le script `train.py`.
- Pis encore, √† l'heure actuelle, cette √©tape d'estimation n'est pas s√©par√©e de la mise √† disposition du mod√®le par le biais de notre API. On archive des mod√®les mais on les utilise pas ult√©rieurement.


Les prochaines applications permettront d'am√©liorer ceci.

## Consommation d'un mod√®le archiv√© sur `MLFlow`

A l'heure actuelle, notre _pipeline_ est lin√©aire:

![](/chapters/applications/figures/pipeline_avant_appli23.png)

Ceci nous g√™ne pour faire √©voluer notre mod√®le: on ne dissocie pas ce qui rel√®ve de l'entra√Ænement du mod√®le de son utilisation. Un _pipeline_ plus cyclique permettra de mieux dissocier l'exp√©rimentation de la production:

![](/chapters/applications/figures/pipeline_apres_appli23.png)


{{< include "./applications/_appli23.qmd" >}}

A ce stade, nous avons am√©lior√© la fiabilit√© de notre application car
nous utilisons le meilleur mod√®le. N√©anmoins, nos entra√Ænements sont encore manuels. L√† encore il y a des gains √† avoir car cela para√Æt p√©nible √† la longue de devoir syst√©matiquement relancer des entra√Ænements manuellement pour tester des variations de tel ou tel param√®tre. Heureusement, nous allons pouvoir automatiser ceci √©galement.


::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git stash #<1>
git checkout appli23
```
1. Pour annuler les modifications depuis le dernier _commit_


![](/checkpoint.jpg){width=80% fig-align="center"}

:::



### Industrialiser les entra√Ænements de nos mod√®les

Pour industrialiser nos entra√Ænements, nous allons cr√©er des processus
parall√®les ind√©pendants pour chaque combinaison de nos hyperparam√®tres.
Pour cela, l'outil pratique sur le SSPCloud est `Argo workflows`.

Chaque combinaison d'hyperparam√®tres sera un processus isol√© √† l'issue duquel sera
loggu√© le r√©sultat dans `MLFlow`. Ces entra√Ænements auront lieu en parall√®le.


![](https://inseefrlab.github.io/formation-mlops/slides/img/pokemon_workflow.png)



1. Lancer un service Argo Workflows
2. Dans le d√©p√¥t GitOps, cr√©er un fichier `argo-workflow/manifest.yaml`

```{.python}
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: titanic-training-workflow-
  namespace: user-lgaliana
spec:
  entrypoint: main
  serviceAccountName: workflow
  arguments:
    parameters:
      # The MLflow tracking server is responsible to log the hyper-parameter and model metrics.
      - name: mlflow-tracking-uri
        value: https://user-lgaliana-argo-workflows.user.lab.sspcloud.fr #<1>
      - name: mlflow-experiment-name
        value: titanicml #<2>
      - name: model-training-conf-list
        value: |
          [
            { "n_trees": 10, "max_features": "log2" },
            { "n_trees": 20, "max_features": "sqrt" },
            { "n_trees": 20, "max_features": "log2" },
            { "n_trees": 50, "max_features": "sqrt" }
          ]
  templates:
    # Entrypoint DAG template
    - name: main
      dag:
        tasks:
          # Task 0: Start pipeline
          - name: start-pipeline
            template: start-pipeline-wt
          # Task 1: Train model with given params
          - name: train-model-with-params
            dependencies: [ start-pipeline ]
            template: run-model-training-wt
            arguments:
              parameters:
                - name: max_features
                  value: "{{item.max_features}}"
                - name: n_trees
                  value: "{{item.n_trees}}"
            # Pass the inputs to the task using "withParam"
            withParam: "{{workflow.parameters.model-training-conf-list}}"

    # Now task container templates are defined
    # Worker template for task 0 : start-pipeline
    - name: start-pipeline-wt
      inputs:
      container:
        image: busybox
        command: [ sh, -c ]
        args: [ "echo Starting pipeline" ]

    # Worker template for task-1 : train model with params
    - name: run-model-training-wt
      inputs:
        parameters:
          - name: n_trees
          - name: max_features
      container:
        image: linogaliana/application:v0.0.5 #<3>
        imagePullPolicy: Always
        command: [sh, -c]
        args: [
          "python train.py --n_trees={{inputs.parameters.n_trees}} --max_features={{inputs.parameters.max_features}}"
          ]
        env:
          - name: MLFLOW_TRACKING_URI
            value: "{{workflow.parameters.mlflow-tracking-uri}}"
          - name: MLFLOW_EXPERIMENT_NAME
            value: "{{workflow.parameters.mlflow-experiment-name}}"
          - name: AWS_DEFAULT_REGION
            value: us-east-1
          - name: AWS_S3_ENDPOINT
            value: minio.lab.sspcloud.fr
```
1. Changer pour votre entrepot de mod√®le
2. Le nom de l'exp√©rimentation `MLFLow` dont nous allons avoir besoin (on propose de continuer sur `titanicml`)
3. Changer l'application ici



## Pour aller plus loin

Cr√©er un service label studio pour √©valuer la qualit√© du mod√®le
