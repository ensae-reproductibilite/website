---
title: "Application"
description: |
  Une application fil rouge pour illustrer l'int√©r√™t d'appliquer graduellement les bonnes pratiques dans une optique de mise en production d'une application de data science.
order: 10
href: chapters/application.html
image: /rocket.png
---

<details>
<summary>
D√©rouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/title-slide)
pour afficher les slides en plein √©cran.
</summary>


<div class="sourceCode" id="cb1"><pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre><iframe class="sourceCode yaml code-with-copy" src="https://ensae-reproductibilite.github.io/slides/#/title-slide"></iframe></div>

</details>

L'objectif de cette mise en application est d'**illustrer les diff√©rentes √©tapes qui s√©parent la phase de d√©veloppement d'un projet de celle de la mise en production**. Elle permettra de mettre en pratique les diff√©rents concepts pr√©sent√©s tout au long du cours.

Celle-ci est un tutoriel pas √† pas pour avoir un projet reproductible et disponible sous plusieurs livrables. 
Toutes les √©tapes ne sont pas indispensables √† tous les projets de _data science_. 

Nous nous pla√ßons dans une situation initiale correspondant √† la fin de la phase de d√©veloppement d'un projet de data science.
On a un _notebook_ un peu monolithique, qui r√©alise les √©tapes classiques d'un *pipeline* de *machine learning* :

- Import de donn√©es ;
- Statistiques descriptives et visualisations ;
- *Feature engineering* ;
- Entra√Ænement d'un mod√®le ;
- Evaluation du mod√®le.

**L'objectif est d'am√©liorer le projet de mani√®re incr√©mentale jusqu'√† pouvoir le mettre en production, en le valorisant sous une forme adapt√©e.** 


<details>
<summary>
Illustration de notre point de d√©part
</summary>
![](/workflow1.png)
</details>

<details>
<summary>
Illustration de l'horizon vers lequel on se dirige
</summary>
![](/workflow2.png)
</details>

::: {.callout-important}
Il est important de bien lire les consignes et d'y aller progressivement.
Certaines √©tapes peuvent √™tre rapides, d'autres plus fastidieuses ;
certaines √™tre assez guid√©es, d'autres vous laisser plus de libert√©.
Si vous n'effectuez pas une √©tape, vous risquez de ne pas pouvoir passer √†
l'√©tape suivante qui en d√©pend.

Bien que l'exercice soit applicable sur toute configuration bien faite, nous 
recommandons de privil√©gier l'utilisation du [SSP Cloud](https://datalab.sspcloud.fr/home), o√π tous les 
outils n√©cessaires sont pr√©-install√©s et pr√©-configur√©s. Le service `VSCode`
ne sera en effet que le point d'entr√©e pour l'utilisation d'outils plus exigeants
sur le plan de l'infrastructure: _Argo_, _MLFLow_, etc.
:::


# Partie 0 : initialisation du projet

::: {.callout-tip}
## Application pr√©liminaire: forker le d√©p√¥t d'exemple

Les premi√®res √©tapes consistent √† mettre en place son environnement de travail sur `Github`:

- G√©n√©rer un jeton d'acc√®s (*token*) sur `GitHub` afin de permettre l'authentification en ligne de commande √† votre compte.
La proc√©dure est d√©crite [ici](https://docs.sspcloud.fr/onyxia-guide/controle-de-version#creer-un-jeton-dacces-token). 
__Vous ne voyez ce jeton qu'une fois, ne fermez pas la page de suite__. 

- Mettez de c√¥t√© ce jeton en l'enregistrant dans un gestionnaire de mot de passe ou dans 
l'espace _["Mon compte"](https://datalab.sspcloud.fr/account/third-party-integration)_
du `SSP Cloud`. 

- Forker le d√©p√¥t `Github` : [https://github.com/ensae-reproductibilite/application-correction](https://github.com/ensae-reproductibilite/application-correction) en faisant attention √† deux choses:
    + Renommer le d√©p√¥t en `ensae-reproductibilite-application-correction.git` ;
    + D√©cocher la case _"Copy the `main` branch only"_ afin de copier √©galement les _tags_ `Git` qui nous permettront de faire les _checkpoint_


<details>

<summary>
Ce que vous devriez voir sur la page de cr√©ation du _fork_
</summary>

![](/fork-example.png)

</details>

Il est maintenant possible de ce lancer dans la cr√©ation de l'environnement de travail:

- Ouvrir un service `VSCode` sur le [SSP Cloud](https://datalab.sspcloud.fr/home). Vous pouvez aller
dans la page `My Services` et cliquer sur `New service`. Sinon, vous
pouvez initialiser la cr√©ation du service en cliquant directement [ici](https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=false). __Modifier les options suivantes__:
    + Dans l'onglet `Kubernetes`, s√©lectionner le r√¥le `Admin` ;
    + Dans l'onglet `Networking`, cliquer sur "Enable a custom service port" et laisser la valeur par d√©faut 5000 pour le num√©ro du port

- Cl√¥ner __votre__ d√©p√¥t `Github` en utilisant le
terminal depuis `Visual Studio` (`Terminal > New Terminal`) et
en passant directement le token dans l'URL selon cette structure:

```{.bash filename="terminal"}
git clone https://<TOKEN>@github.com/<USERNAME>/ensae-reproductibilite-application-correction.git
```

o√π `<TOKEN>` et `<USERNAME>` sont √† remplacer, respectivement, 
par le jeton que vous avez g√©n√©r√© pr√©c√©demment et votre nom d'utilisateur.

- Se placer avec le terminal dans le dossier en question : 

```{.bash filename="terminal"}
cd ensae-reproductibilite-application-correction
```

- Se placer sur une branche de travail en faisant:

```{.bash filename="terminal"}
git checkout -b dev
```

:::


# Partie 1 : qualit√© du script

Cette premi√®re partie vise √† **rendre le projet conforme aux bonnes pratiques** pr√©sent√©es dans le cours.

Elle fait intervenir les notions suivantes : 

- Utilisation du **terminal** (voir [Linux 101](/chapters/linux-101.qmd)) ;
- **Qualit√© du code** (voir [Qualit√© du code](/chapters/code-quality.qmd)) ;
- **Architecture de projets** (voir [Architecture des projets](/chapters/projects-architecture.html)) ;
- **Contr√¥le de version** avec `Git` (voir [Rappels `Git`](/chapters/git.qmd)) ;
- **Travail collaboratif** avec `Git` et `GitHub` (voir [Rappels `Git`](/chapters/git.qmd)).

Nous allons partir de ce _Notebook_ `Jupyter`,
que vous pouvez pr√©visualiser voire tester
en cliquant sur l'un des liens suivants:

_to do bouton onyxia_
<a href="https://github.com/ensae-reproductibilite/application-correction/blob/main/titanic.ipynb" target="_blank" rel="noopener"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"></a>

Le plan de la partie est le suivant :

1. S'assurer que le script fonctionne ;
2. Nettoyer le code des scories formelles avec un _linter_ et un _formatter_ ;
3. Param√©trisation du script ;
4. Utilisation de fonctions.


## √âtape 1 : s'assurer que le script s'ex√©cute correctement

On va partir du fichier `notebook.py` qui reprend le contenu 
du _notebook_[^jupytext] mais dans un script classique.
Le travail de nettoyage en sera facilit√©. 

[^jupytext]: L'export dans un script `.py` a √©t√© fait
        directement depuis `VSCode`. Comme
        cela n'est pas vraiment l'objet du cours, nous passons cette √©tape et fournissons
        directement le script expurg√© du texte interm√©diaire. Mais n'oubliez
        pas que cette d√©marche, fr√©quente quand on a d√©marr√© sur un _notebook_ et
        qu'on d√©sire consolider en faisant la transition vers des 
        scripts, n√©cessite d'√™tre attentif pour ne pas risquer de faire une erreur. 

La premi√®re √©tape est simple, mais souvent oubli√©e : **v√©rifier que le code fonctionne correctement**. 
Pour cela, nous recommandons de faire un aller-retour entre le script ouvert dans `VSCode`
et un terminal pour le lancer. 


{{< include "./applications/_appli1.qmd" >}}


## √âtape 2: utiliser un _linter_ puis un _formatter_

On va maintenant am√©liorer la qualit√© de notre code en appliquant les standards communautaires.
Pour cela, on va utiliser le *linter* classique [`PyLint`](https://pylint.readthedocs.io/en/latest/)
et le _formatter_ [`Black`](https://github.com/psf/black).

::: {.callout-important}
[`PyLint`](https://pylint.readthedocs.io/en/latest/) et [`Black`](https://black.readthedocs.io/en/stable/)
sont des _packages_ `Python` qui 
s'utilisent principalement en ligne de commande.

Si vous avez une erreur qui sugg√®re
que votre terminal ne connait pas [`PyLint`](https://pylint.readthedocs.io/en/latest/)
ou [`Black`](https://black.readthedocs.io/en/stable/),
n'oubliez pas d'ex√©cuter la commande `pip install pylint` ou `pip install black`.
:::


Le _linter_ renvoie alors une s√©rie d'irr√©gularit√©s,
en pr√©cisant √† chaque fois la ligne de l'erreur et le message d'erreur associ√© (ex : mauvaise identation).
Il renvoie finalement une note sur 10,
qui estime la qualit√© du code √† l'aune des standards communautaires √©voqu√©s
dans la partie [Qualit√© du code](/chapters/code-quality.html).

{{< include "./applications/_appli2.qmd" >}}

Le code est maintenant lisible, il obtient √† ce stade une note formelle proche de 10.
Mais il n'est pas encore totalement intelligible ou fiable.
Il y a notamment 
beaucoup de redondance de code auxquelles nous allons nous attaquer par la suite. 
N√©anmoins, avant cela, occupons-nous de mieux g√©rer certains param√®tres du script: 
jetons d'API et chemin des fichiers.


## √âtape 3: gestion des param√®tres

L'ex√©cution du code et les r√©sultats obtenus
d√©pendent de certains param√®tres d√©finis dans le code. L'√©tude de r√©sultats
alternatifs, en jouant sur 
des variantes des (hyper)param√®tres, est √† ce stade compliqu√©e
car il est n√©cessaire de parcourir le code pour trouver
ces param√®tres. De plus, certains param√®tres personnels
comme des jetons
d'API ou des mots de passe n'ont pas vocation √† 
√™tre pr√©sents dans le code. 

Il est plus judicieux de consid√©rer ces param√®tres comme des
variables d'entr√©e du script. Cela peut √™tre fait de deux
mani√®res:

1. Avec des __arguments optionnels__ appel√©s depuis la ligne de commande _(Application 3a)_.
Cela peut √™tre pratique pour mettre en oeuvre des tests automatis√©s mais
n'est pas forc√©ment pertinent pour toutes les variables. Nous allons montrer
cet usage avec le nombre d'arbres de notre _random forest_ ;
2. En utilisant un __fichier de configuration__ dont les valeurs sont import√©es dans
le script principal _(Application 3b)_. 


<details>
<summary>
Un exemple de d√©finition d'un argument pour l'utilisation en ligne de commande
</summary>

```{.python filename="prenom.py"}
import argparse
parser = argparse.ArgumentParser(description="Qui √™tes-vous?")
parser.add_argument(
    "--prenom", type=str, default="Toto", help="Un pr√©nom √† afficher"
)
args = parser.parse_args()
print(args.prenom)
```

Exemples d'utilisations en ligne de commande

```{.bash filename="terminal"}
python prenom.py
python prenom.py --prenom "Zinedine"
```

</details>

{{< include "./applications/_appli3.qmd" >}}


## √âtape 4 : Privil√©gier la programmation fonctionnelle

Nous allons **mettre en fonctions les parties importantes de l'analyse**. 
Ceci facilitera l'√©tape ult√©rieure de modularisation de notre projet. 

Cet exercice √©tant chronophage, il n'est __pas obligatoire de le r√©aliser en entier__. L'important est de
comprendre la d√©marche et d'adopter fr√©quemment une approche fonctionnelle[^POO]. Pour obtenir 
une chaine enti√®rement fonctionnalis√©e, vous pouvez reprendre le _checkpoint_.

[^POO]: Nous proposons ici d'adopter le principe de la __programmation fonctionnelle__. Pour encore fiabiliser
un processus, il serait possible d'adopter le paradigme de la __programmation orient√©e objet (POO)__. Celle-ci est
plus rebutante et demande plus de temps au d√©veloppeur. L'arbitrage co√ªt-avantage est n√©gatif pour notre
exemple, nous proposons donc de nous en passer. N√©anmoins, pour une mise en production r√©elle d'un mod√®le,
il est recommand√© de l'adopter. C'est d'ailleurs obligatoire avec des [_pipelines_ `scikit`](https://pythonds.linogaliana.fr/pipeline-scikit/). 

{{< include "./applications/_appli4.qmd" >}}

Cela ne se remarque pas encore vraiment car nous avons de nombreuses d√©finitions de fonctions
mais notre chaine de production est beaucoup plus
concise (le script fait environ 300 lignes dont 250 de d√©finitions de fonctions g√©n√©riques).
Cette auto-discipline facilitera grandement
les √©tapes ult√©rieures. Cela aurait √©t√© n√©anmoins beaucoup moins co√ªteux en temps d'adopter
ces bons gestes de mani√®re plus pr√©coce. 


# Partie 2 : adoption d'une structure modulaire {#partie2}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues tout au long du cours.
Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'un
possible partage du code : celui-ci est lisible et intelligible. 
Le code est proprement versionn√© sur un
d√©p√¥t `GitHub`.
Cependant, le projet est encore perfectible: il est encore difficile de rentrer
dedans si on ne sait pas exactement ce qu'on recherche. L'objectif de cette partie
est d'isoler les diff√©rentes √©tapes de notre _pipeline_. 
Outre le gain de clart√© pour notre projet, nous √©conomiserons beaucoup de peines
pour la mise en production ult√©rieure de notre mod√®le. 

<details>
<summary>
Illustration de l'√©tat actuel du projet 
</summary>
![](/schema_post_appli4.png)
</details>

Dans cette partie nous allons continuer les am√©liorations
incr√©mentales de notre projet avec les √©tapes suivantes:

1. Modularisation du code `Python` pour s√©parer les diff√©rentes
√©tapes de notre _pipeline_ ; 
2. Adopter une structure standardis√©e pour notre projet afin
d'autodocumenter l'organisation de celui-ci ; 
3. Documenter les _packages_ indispensables √† l'ex√©cution du code ;
4. Stocker les donn√©es dans un environnement ad√©quat
afin de continuer la d√©marche de s√©parer conceptuellement les donn√©es du code en de la configuration.


## √âtape 1 : modularisation

Nous allons profiter de la modularisation pour adopter une structure
applicative pour notre code. Celui-ci n'√©tant en effet plus lanc√©
que depuis la ligne de commande, on peut consid√©rer qu'on construit
une application g√©n√©rique o√π un script principal (`main.py`)
encapsule des √©l√©ments issus d'autres scripts `Python`. 


{{< include "./applications/_appli5.qmd" >}}


## √âtape 2 : adopter une architecture standardis√©e de projet

On dispose maintenant d'une application `Python` fonctionnelle. 
N√©anmoins, le projet est certes plus fiable mais sa structuration
laisse √† d√©sirer et il serait difficile de rentrer √† nouveau
dans le projet dans quelques temps. 

<details>
<summary>Etat actuel du projet üôà</summary>

```
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ test.csv
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ import_data.py
‚îú‚îÄ‚îÄ build_features.py
‚îú‚îÄ‚îÄ train_evaluate.py
‚îú‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ main.py
```

</details>

Comme cela est expliqu√© dans la
partie [Structure des projets](/chapters/projects-architecture.html),
on va adopter une structure certes arbitraire mais qui va 
faciliter l'autodocumentation de notre projet. De plus, une telle structure va faciliter des √©volutions optionnelles
comme la _packagisation_ du projet. Passer d'une structure modulaire
bien faite √† un _package_ est quasi-imm√©diat en `Python`. 

On va donc modifier l'architecture de notre projet pour la rendre plus standardis√©e.
Pour cela, on va s'inspirer des structures
[`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/)
qui g√©n√®rent des _templates_ de projet. En l'occurrence
notre source d'inspiration sera le [_template datascience_](https://drivendata.github.io/cookiecutter-data-science/)
issu d'un effort communautaire.

::: {.callout-note}
L'id√©e de [`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/) est de proposer des _templates_ que l'on utilise pour __initialiser__ un projet, afin de b√¢tir √† l'avance une structure √©volutive. La syntaxe √† utiliser dans ce cas est la suivante : 

```{.bash filename="terminal"}
pip install cookiecutter
cookiecutter https://github.com/drivendata/cookiecutter-data-science
```

Ici, on a d√©j√† un projet, on va donc faire les choses dans l'autre sens : on va s'inspirer de la structure propos√©e afin de r√©organiser celle de notre projet selon les standards communautaires.
:::

En s'inspirant du _cookiecutter data science_
on va adopter la structure suivante:

<details>
<summary>
Structure recommand√©e
</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ main.py
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ data
‚îÇ   ‚îî‚îÄ‚îÄ raw
‚îÇ       ‚îú‚îÄ‚îÄ test.csv
‚îÇ       ‚îî‚îÄ‚îÄ train.csv
‚îú‚îÄ‚îÄ configuration
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml
‚îú‚îÄ‚îÄ notebooks
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb
‚îî‚îÄ‚îÄ src
    ‚îú‚îÄ‚îÄ data
    ‚îÇ   ‚îî‚îÄ‚îÄ import_data.py
    ‚îú‚îÄ‚îÄ features
    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py
    ‚îî‚îÄ‚îÄ models
        ‚îî‚îÄ‚îÄ train_evaluate.py
```

</details>

{{< include "./applications/_appli6.qmd" >}}


## √âtape 3: indiquer l'environnement minimal de reproductibilit√©

Le script `main.py` n√©cessite un certain nombre de packages pour
√™tre fonctionnel. Chez vous les packages n√©cessaires sont
bien s√ªr install√©s mais √™tes-vous assur√© que c'est le cas 
chez la personne qui testera votre code ? 

Afin de favoriser la portabilit√© du projet,
il est d'usage de _"fixer l'environnement"_,
c'est-√†-dire d'indiquer dans un fichier toutes les d√©pendances utilis√©es ainsi que leurs version.
Nous proposons de cr√©er un fichier `requirements.txt` minimal, sur lequel nous reviendrons
dans la partie consacr√©e aux environnements reproductibles. 

Le fichier `requirements.txt` est conventionnellement localis√© √† la racine du projet.
Ici on ne va pas fixer les versions, on raffinera ce fichier ult√©rieurement.

{{< include "./applications/_appli7.qmd" >}}

## √âtape 4 : stocker les donn√©es de mani√®re externe {#stockageS3}

::: {.callout-warning collapse="true"}
## Pour en savoir plus sur le syst√®me de stockage `S3`

Pour mettre en oeuvre cette √©tape, il peut √™tre utile de
comprendre un peu comme fonctionne le SSP Cloud.
Vous devrez suivre la [documentation du SSP Cloud](https://inseefrlab.github.io/docs.sspcloud.fr/docs/fr/storage.html) pour la r√©aliser. Une aide-m√©moire est √©galement disponible dans le cours
de 2e ann√©e de l'ENSAE [Python pour la _data science_](https://linogaliana-teaching.netlify.app/reads3/#).
:::


Le chapitre sur la [structure des projets](/chapters/projects-architecture.qmd)
d√©veloppe l'id√©e qu'il est recommand√© de converger vers un mod√®le
o√π environnements d'ex√©cution, de stockage du code et des donn√©es sont conceptuellement
s√©par√©s. Ce haut niveau d'exigence est un gain de temps important 
lors de la mise en production car au cours de cette derni√®re, le projet
est amen√© √† √™tre ex√©cut√© sur une infrastructure informatique d√©di√©e
qu'il est bon d'anticiper. 

A l'heure actuelle, les donn√©es sont stock√©es dans le d√©p√¥t. C'est une
mauvaise pratique. En premier lieu, `Git` n'est techniquement
pas bien adapt√© au stockage de donn√©es. Ici ce n'est pas tr√®s grave
car il ne s'agit pas de donn√©es volumineuses et ces derni√®res ne sont
pas modifi√©es au cours de notre chaine de traitement. 
La raison principale
est que les donn√©es trait√©es par les _data scientists_ 
sont g√©n√©ralement soumises √† des clauses de
confidentialit√©s ([RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on), [secret statistique](https://www.insee.fr/fr/information/1300624)...). Mettre ces donn√©es sous contr√¥le de version
c'est prendre le risque de les divulguer √† un public non habilit√©. 
Il est donc recommand√© de privil√©gier des outils techniques adapt√©s au
stockage de donn√©es.

L'id√©al, dans notre cas, est d'utiliser une solution de stockage externe. 
On va utiliser pour cela `MinIO`, la solution de stockage de type `S3` offerte par le SSP Cloud. 
Cela nous permettra de supprimer les donn√©es de `Github` tout en maintenant la reproductibilit√© 
de notre projet [^history].

[^history]: Attention, les donn√©es ont √©t√© _committ√©es_ au moins une fois. Les supprimer
du d√©p√¥t ne les efface pas de l'historique. Si cette erreur arrive, le mieux est de supprimer
le d√©p√¥t en ligne, cr√©er un nouvel historique `Git` et partir de celui-ci pour des publications
ult√©rieures sur `Github`. N√©anmoins l'id√©al serait de ne pas s'exposer √† cela. C'est justement
l'objet des bonnes pratiques de ce cours: un `.gitignore` bien construit et une s√©paration des
environnements de stockage du code et
des donn√©es seront bien plus efficaces pour vous √©viter ces probl√®mes que tout les conseils de 
vigilance que vous pourrez trouver ailleurs. 

{{< include "./applications/_appli8.qmd" >}}

# Partie 2bis: packagisation de son projet (optionnel)

Cette s√©rie d'actions n'est pas forc√©ment pertinente pour tous
les projets. Elle fait un peu la transition entre la modularit√©
et la portabilit√©. 

## √âtape 1 : proposer des tests unitaires (optionnel)

Notre code comporte un certain nombre de fonctions g√©n√©riques.
On peut vouloir tester leur usage sur des donn√©es standardis√©es,
diff√©rentes de celles du Titanic.

M√™me si la notion de tests unitaires
prend plus de sens dans un _package_, nous pouvons proposer
dans le projet des exemples d'utilisation de la fonction, ceci peut √™tre p√©dagogique. 

Nous allons utiliser [`unittest`](https://docs.python.org/3/library/unittest.html)
pour effectuer des tests unitaires. Cette approche n√©cessite quelques notions
de programmation orient√©e objet ou une bonne discussion avec `ChatGPT`.

{{< include "./applications/_appli9.qmd" >}}


::: {.callout-note}

Lorsqu'on effectue des tests unitaires, on cherche g√©n√©ralement
√† tester le plus de lignes possibles de son code. On parle de
__taux de couverture__ (_coverage rate_) pour d√©signer
la statistique mesurant cela. 

Cela peut s'effectuer de la mani√®re suivante avec le package
[`coverage`](https://coverage.readthedocs.io/en/7.2.2/):

```{.bash filename="terminal"}
coverage run -m unittest tests/test_create_variable_title.py
coverage report -m
```

```{.python}
Name                                  Stmts   Miss  Cover   Missing
-------------------------------------------------------------------
src/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113
tests/test_create_variable_title.py      21      1    95%   54
-------------------------------------------------------------------
TOTAL                                    55     22    60%
```

Le taux de couverture est souvent mis en avant par les gros
projets comme indicateur de leur qualit√©. Il existe d'ailleurs
des badges `Github` d√©di√©s. 
:::




## √âtape 2 : transformer son projet en package (optionnel)

Notre projet est modulaire, ce qui le rend assez simple √† transformer
en _package_, en s'inspirant de la structure du `cookiecutter` adapt√©, issu
de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

On va cr√©er un _package_ nomm√© `titanicml` qui encapsule
tout notre code et qui sera appel√©
par notre script `main.py`. La structure attendue
est la suivante:

<details>
<summary>Structure vis√©e</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ docs                                    ‚îê 
‚îÇ   ‚îú‚îÄ‚îÄ main.py                             ‚îÇ 
‚îÇ   ‚îî‚îÄ‚îÄ notebooks                           ‚îÇ Package documentation and examples
‚îÇ       ‚îî‚îÄ‚îÄ titanic.ipynb                   ‚îÇ 
‚îú‚îÄ‚îÄ configuration                           ‚îê Configuration (pas √† partager avec Git)
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                         ‚îò 
‚îú‚îÄ‚îÄ README.md                                
‚îú‚îÄ‚îÄ pyproject.toml                          ‚îê 
‚îú‚îÄ‚îÄ requirements.txt                        ‚îÇ
‚îú‚îÄ‚îÄ titanicml                               ‚îÇ                
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                         ‚îÇ Package source code, metadata
‚îÇ   ‚îú‚îÄ‚îÄ data                                ‚îÇ and build instructions 
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                  ‚îÇ  
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py   ‚îÇ   
‚îÇ   ‚îú‚îÄ‚îÄ features                            ‚îÇ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py               ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ models                              ‚îÇ
‚îÇ       ‚îî‚îÄ‚îÄ train_evaluate.py               ‚îò
‚îî‚îÄ‚îÄ tests                                   ‚îê
    ‚îî‚îÄ‚îÄ test_create_variable_title.py       ‚îò Package tests
```
</details>

<details>
<summary>Rappel: structure actuelle</summary>

```
ensae-reproductibilite-application
‚îú‚îÄ‚îÄ notebooks                                 
‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb                  
‚îú‚îÄ‚îÄ configuration                                 
‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                  
‚îú‚îÄ‚îÄ main.py                              
‚îú‚îÄ‚îÄ README.md                 
‚îú‚îÄ‚îÄ requirements.txt                      
‚îî‚îÄ‚îÄ src 
    ‚îú‚îÄ‚îÄ data                                
    ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                    
    ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py      
    ‚îú‚îÄ‚îÄ features                           
    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py      
    ‚îî‚îÄ‚îÄ models                          
        ‚îî‚îÄ‚îÄ train_evaluate.py              
```
</details>

Il existe plusieurs 
_frameworks_ pour
construire un _package_. Nous
allons privil√©gier [`Poetry`](https://python-poetry.org/)
√† [`Setuptools`](https://pypi.org/project/setuptools/). 


::: {.callout-note}

Pour cr√©er la structure minimale d'un _package_, le plus simple est
d'utiliser le `cookiecutter` adapt√©,
issu de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).

Comme on a d√©j√† une structure tr√®s modulaire, on va plut√¥t recr√©er cette
structure dans notre projet d√©j√† existant. En fait, il ne manque qu'un fichier essentiel, 
le principal distinguant un projet classique d'un package : `pyproject.toml`.

```{.bash filename="terminal"}
cookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git
```

<details>
<summary>D√©rouler pour voir les choix possibles</summary>
```{.python}
author_name [Monty Python]: Daffy Duck
package_name [mypkg]: titanicml
package_short_description []: Impressive Titanic survival analysis
package_version [0.1.0]: 
python_version [3.9]: 
Select open_source_license:
1 - MIT
2 - Apache License 2.0
3 - GNU General Public License v3.0
4 - Creative Commons Attribution 4.0
5 - BSD 3-Clause
6 - Proprietary
7 - None
Choose from 1, 2, 3, 4, 5, 6 [1]: 
Select include_github_actions:
1 - no
2 - ci
3 - ci+cd
Choose from 1, 2, 3 [1]:
```
</details>

:::

{{< include "./applications/_appli10.qmd" >}}

# Partie 3 : construction d'un projet portable et reproductible {#partie3}

Dans la partie pr√©c√©dente,
on a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues
dans les chapitres [Qualit√© du code](/chapters/code-quality.html)
et [Structure des projets](/chapters/projects-architecture.html)
tout au long du cours.

Ce faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'une
possible mise en production : le code est lisible,
la structure du projet est normalis√©e et √©volutive,
et le code est proprement versionn√© sur un
d√©p√¥t `GitHub` {{< fa brands github >}}.


<details>
<summary>
Illustration de l'√©tat actuel du projet 
</summary>
![](/schema_post_appli8.png)
</details>



A pr√©sent, nous avons une version du projet qui est largement partageable.
Du moins en th√©orie, car la pratique est souvent plus compliqu√©e :
il y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement (typiquement, votre ordinateur personnel),
les choses ne se passent pas du tout comme attendu. Cela signifie qu'**en l'√©tat, le projet n'est pas portable : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.

Dans cette trois√®me partie de notre travail vers la mise en production,
nous allons voir 
comment **normaliser l'environnement d'ex√©cution afin de produire un projet portable**.
Autrement dit, nous n'allons plus nous contenter de modularit√© mais allons rechercher
la portabilit√©.
On sera alors tout proche de pouvoir mettre le projet en production.

On progressera dans l'√©chelle de la reproductibilit√© 
de la mani√®re suivante: 

1. [**Environnements virtuels**](#anaconda) ;
2. Cr√©er un [script shell](#shell) qui permet, depuis un environnement minimal, de construire l'application de A √† Z ;
3. [**Images et conteneurs `Docker`**](#docker).


Nous allons repartir de l'application 8, c'est-√†-dire d'un projet
modulaire mais qui n'est pas, √† strictement parler, un _package_
(objet des applications optionnelles suivantes 9 et 10). 

Pour se replacer dans l'√©tat du projet √† ce niveau,
il est possible d'utiliser le _tag_ _ad hoc_.

```{.bash filename="terminal"}
git checkout appli8
```


## √âtape 1 : un environnement pour rendre le projet portable {#anaconda}

Pour qu'un projet soit portable, il doit remplir deux conditions:

- Ne pas n√©cessiter de d√©pendance
qui ne soient pas renseign√©es quelque part ;
- Ne pas proposer des d√©pendances inutiles, qui ne
sont pas utilis√©es dans le cadre du projet. 

Le prochain exercice vise √† mettre ceci en oeuvre.
Comme expliqu√© dans le [chapitre portabilit√©](/chapters/portability.qmd),
le choix du gestionnaire d'environnement est laiss√©
libre. Il est recommand√© de privil√©gier `venv` si vous d√©couvrez
la probl√©matique de la portabilit√©. 

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

L'approche la plus l√©g√®re est l'environnement virtuel. 
Nous avons en fait implicitement d√©j√† commenc√© √† aller vers
cette direction
en cr√©ant un fichier `requirements.txt`. 

{{< include "./applications/_appli11a.qmd" >}}


## Environnement `conda`

Les environnements `conda` sont plus lourds √† mettre en oeuvre que les 
environnements virtuels mais peuvent permettre un contr√¥le
plus formel des d√©pendances. 

{{< include "./applications/_appli11b.qmd" >}}

:::


## √âtape 2: construire l'environnement de notre application via un script `shell` {#shell}

Les environnements virtuels permettent de mieux sp√©cifier les d√©pendances de notre projet, mais ne permettent pas de garantir une portabilit√© optimale. Pour cela, il faut recourir √† la technologie des conteneurs. L'id√©e est de construire une machine, en partant d'une base quasi-vierge, qui permette de construire √©tape par √©tape l'environnement n√©cessaire au bon fonctionnement de notre projet. C'est le principe des conteneurs `Docker` {{< fa brands docker >}}.

Leur m√©thode de construction √©tant un peu difficile √† prendre en main au d√©but, nous allons passer par une √©tape interm√©diaire afin de bien comprendre le processus de production. 

- Nous allons d'abord cr√©er un script `shell`, c'est √† dire une suite de commandes `Linux` permettant de construire l'environnement √† partir d'une machine vierge ;
- Nous transformerons celui-ci en `Dockerfile` dans un deuxi√®me temps. C'est l'objet de l'√©tape suivante. 

::: {.panel-tabset group="language"}

## Environnement virtuel `venv`

{{< include "./applications/_appli12a.qmd" >}}

## Environnement `conda`

{{< include "./applications/_appli12b.qmd" >}}

:::


## √âtape 3: conteneuriser l'application avec `Docker` {#docker}


::: {.callout-note}
Cette application n√©cessite l'acc√®s √† une version interactive de `Docker`.
Il n'y a pas beaucoup d'instances en ligne disponibles.

Nous proposons deux solutions:

- [Installer `Docker`](https://docs.docker.com/get-docker/) sur sa machine ;
- Se rendre sur l'environnement bac √† sable _[Play with Docker](https://labs.play-with-docker.com)_

Sinon, elle peut √™tre r√©alis√©e en essai-erreur par le biais des services d'int√©gration continue de `Github` {{< fa brands github >}} ou `Gitlab` {{< fa brands gitlab >}}. N√©anmoins, nous pr√©senterons l'utilisation de ces services plus tard, dans la prochaine partie. 
:::

Maintenant qu'on sait que ce script pr√©paratoire fonctionne, on va le transformer en `Dockerfile` pour anticiper la mise en production.  Comme la syntaxe `Docker` est l√©g√®rement diff√©rente de la syntaxe `Linux` classique (voir le [chapitre portabilit√©](/chapters/portability.qmd)), il va √™tre n√©cessaire de changer quelques instructions mais ceci sera tr√®s l√©ger.

On va tester le `Dockerfile` dans un environnement bac √† sable pour ensuite
pouvoir plus facilement automatiser la construction de l'image
`Docker`.

{{< include "./applications/_appli13.qmd" >}}


# Partie 4 : automatisation avec l'int√©gration continue


Imaginez que vous √™tes au restaurant
et qu'on ne vous serve pas le plat mais seulement la recette
et que, de plus, on vous demande de pr√©parer le plat
chez vous avec les ingr√©dients dans votre frigo.
Vous seriez quelque peu d√©√ßu. En revanche, si vous avez go√ªt√©
au plat, que vous √™tes un r√©el cordon bleu
et qu'on vous donne la recette pour refaire ce plat ult√©rieurement,
peut-√™tre
que vous appr√©ciriez plus. 

Cette analogie illustre l'enjeu de d√©finir
le public cible et ses attentes afin de fournir un livrable adapt√©. 
Une image `Docker` est un livrable qui n'est pas forc√©ment int√©ressant
pour tous les publics. Certains pr√©f√©reront avoir un plat bien pr√©par√©
qu'une recette ; certains appr√©cieront avoir une image `Docker` mais
d'autres ne seront pas en mesure de construire celle-ci ou ne sauront
pas la faire fonctionner. Une image `Docker` est plus souvent un 
moyen pour faciliter la mise en service d'une production qu'une fin en soi. 

Nous allons donc proposer
plusieurs types de livrables plus classiques par la suite. Ceux-ci
correspondront mieux aux attendus des publics utilisateurs de services
construits √† partir de techniques de _data science_. `Docker` est n√©anmoins
un passage oblig√© car l'ensemble des types de livrables que nous allons
explorer reposent sur la standardisation permise par les conteneurs. 

Cette approche nous permettra de quitter le domaine de l'artisanat pour
s'approcher d'une industrialisation de la mise √† disposition 
de notre projet. Ceci va notamment nous amener √† mettre en oeuvre
l'approche pragmatique du `DevOps` qui consiste √† int√©grer d√®s la phase de
d√©veloppement d'un projet les contraintes li√©es √† sa mise √† disposition
au public cible (cette approche est d√©taill√©e plus
amplement dans le chapitre sur la [mise en production](/chapters/deployment.qmd)). 

L'automatisation et la mise √† disposition automatis√©e de nos productions
sera faite progressivement, au cours des prochaines parties. Tous les 
projets n'ont pas vocation √† aller aussi loin dans ce domaine. 
L'opportunit√© doit √™tre compar√©e aux co√ªts humains et financiers
de leur mise en oeuvre et de leur cycle de vie. 
Avant de faire une production en s√©rie de nos mod√®les,
nous allons d√©j√† commencer
par automatiser quelques tests de conformit√© de notre code. 
On va ici utiliser l'int√©gration continue pour deux objectifs distincts:

- la mise √† disposition de l'image `Docker` ;
- la mise en place de tests automatis√©s de la qualit√© du code
sur le mod√®le de notre `linter` pr√©c√©dent.

Nous allons utiliser `Github Actions` pour cela. Il s'agit de serveurs
standardis√©s mis √† disposition gratuitement par `Github` {{<fa brands github >}}.
`Gitlab` {{<fa brands gitlab >}}, l'autre principal acteur du domaine,
propose des services similaires. L'impl√©mentation est l√©g√®rement diff√©rente
mais les principes sont identiques. 


::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli13
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


## √âtape 1: mise en place de tests automatis√©s

Avant d'essayer de mettre en oeuvre la cr√©ation de notre image
`Docker` de mani√®re automatis√©e, nous allons pr√©senter la logique
de l'int√©gration continue en testant de mani√®re automatis√©e
notre script `main.py`.

Pour cela, nous allons partir de la structure propos√©e dans l'[action officielle](https://github.com/actions/setup-python). 
La documentation associ√©e est [ici](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python).
Des √©l√©ments succincts de pr√©sentation de la logique d√©clarative des actions `Github` 
sont disponibles dans le chapitre sur la [mise en production](/chapters/deployment.qmd). N√©anmoins, la meilleure
√©cole pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d'observer
les actions `Github` mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !


{{< include "./applications/_appli14.qmd" >}}

 
Maintenant, nous pouvons observer que l'onglet `Actions`
s'est enrichi. Chaque `commit` va entra√Æner une s√©rie d'actions automatis√©es.

Si l'une des √©tapes √©choue, ou si la note de notre projet est mauvaise, nous aurons
une croix rouge (et nous recevrons un mail). On pourra ainsi d√©tecter,
en d√©veloppant son projet, les moments o√π on d√©grade la qualit√© du script 
afin de la r√©tablir imm√©diatemment. 



## √âtape 2: Automatisation de la livraison de l'image `Docker`

Maintenant, nous allons automatiser la mise √† disposition de notre image
sur `DockerHub` (le lieu de partage des images `Docker`). Cela facilitera sa r√©utilisation mais aussi des
valorisations ult√©rieures.

L√† encore, nous allons utiliser une s√©rie d'actions pr√©-configur√©es.

Pour que `Github` puisse s'authentifier aupr√®s de `DockerHub`, il va 
falloir d'abord interfacer les deux plateformes. Pour cela, nous allons utiliser
un jeton (_token_) `DockerHub` que nous allons mettre dans un espace
s√©curis√© associ√© √† votre d√©p√¥t `Github`.


{{< include "./applications/_appli15a.qmd" >}}


A ce stade, nous avons donn√© les moyens √† `Github` de s'authentifier avec
notre identit√© sur `Dockerhub`. Il nous reste √† mettre en oeuvre l'action
en s'inspirant de la [documentation officielle](https://github.com/docker/build-push-action/#usage).
On ne va modifier que trois √©l√©ments dans ce fichier. Effectuer les 
actions suivantes:


{{< include "./applications/_appli15b.qmd" >}}



# Partie 5: exp√©rimenter en local des valorisations puis automatiser leur production


Nous avons automatis√© les √©tapes interm√©diaires de notre projet. 
N√©anmoins nous n'avons pas encore r√©fl√©chi √† la valorisation
√† mettre en oeuvre pour notre projet. On va supposer que notre
projet s'adresse √† des _data scientists_ mais aussi √† une audience
moins technique. Pour ces premiers, nous pourrions nous contenter
de valorisations techniques, comme des API, 
mais pour ces derniers il est
conseill√© de privil√©gier des formats plus _user friendly_. 

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli15
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


Afin de faire le parall√®le avec les parcours possibles pour l'√©valuation,
nous allons proposer trois valorisations[^valorisation]:

- Une [API](https://titanic.kub.sspcloud.fr/docs) facilitant la r√©utilisation du mod√®le en "production" ;
- Un [site web statique](https://ensae-reproductibilite.github.io/application-correction/) exploitant cette API pour exposer les pr√©dictions
√† une audience moins technique.


[^valorisation]: Vous n'√™tes pas oblig√©s pour l'√©valuation de mettre en oeuvre
les jalons de plusieurs parcours. N√©anmoins, vous d√©couvrirez que 
chaque nouveau pas en avant est moins co√ªteux que le
pr√©c√©dent si vous avez mis en oeuvre les r√©flexes des bonnes
pratiques.  



::: {.callout-warning collapse="true"}
## Site statique vs application r√©active

La solution que nous allons proposer 
pour les sites statiques, `Quarto` associ√©
√† `Github Pages`, peut √™tre utilis√©e dans le cadre des parcours 
_"rapport reproductible"_ ou _"dashboard / application interactive"_. 

Pour ce dernier
parcours, d'autres approches techniques sont n√©anmoins possibles,
comme `Streamlit`. Celles-ci sont plus exigeantes sur le plan technique
puisqu'elles n√©cessitent de mettre en production sur des serveurs
conteuneuris√©s (comme la mise en production de l'API)
l√† o√π le site statique ne n√©cessite qu'un serveur web, mis √† disposition
gratuitement par `Github`. 


La distinction principale entre ces deux approches est qu'elles
s'appuient sur des serveurs diff√©rents. Un site statique repose
sur un serveur web l√† o√π `Streamlit` s'appuie sur 
serveur classique en _backend_. La diff√©rence principale
entre ces deux types de serveurs
r√©side principalement dans leur fonction et leur utilisation:

- Un __serveur web__ est sp√©cifiquement con√ßu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web √©coutent les requ√™tes HTTP/HTTPS provenant des navigateurs des utilisateurs et y r√©pondent en envoyant les donn√©es demand√©es.
- Un **serveur _backend_** classique est con√ßu pour effectuer des op√©rations en r√©ponse √† un _front_, en l'occurrence une page web. 
Dans le contexte d'une application `Streamlit`, il s'agit d'un serveur avec l'environnement `Python` _ad hoc_ pour
ex√©cuter le code n√©cessaire √† r√©pondre √† toute action d'un utilisateur de l'appliacation. 

:::


## √âtape pr√©liminaire: cr√©ation d'un _pipeline_ `scikit`

La mise en
production n√©cessite d'√™tre exigeant sur la mise en oeuvre op√©rationnelle
de notre _pipeline_. Nous avons n√©anmoins un _pipeline_ un peu bancal
car il requiert d'√™tre vigilant dans la mani√®re d'encha√Æner les
√©tapes de _preprocessing_, d'entra√Ænement et d'√©valuation.

Quand on utilise `scikit`, la bonne pratique est d'utiliser
les [_pipelines_](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)
qui s√©curisent les √©tapes de _feature engineering_ n√©cessaires avant la mise en oeuvre d'un mod√®le, qu'il
que
ce soit pour l'entra√Ænement ou pour appliquer les m√™mes op√©rations avec les m√™mes param√®tres sur 
sur un nouveau jeu de donn√©es avant de faire un _predict_. 

On va donc devoir refactoriser notre application pour utiliser un _pipeline_ `scikit`. 
Les raisons sont expliqu√©es plus en d√©tail [ici](https://scikit-learn.org/stable/common_pitfalls.html).
Cela aura
√©galement l'avantage de rendre les √©tapes de notre _pipeline_ plus lisibles lorsqu'on passera √†
l'√©tape d'industrialisation avec `MLFLow`. 

{{< include "./applications/_appli16.qmd" >}}


## √âtape 1: d√©velopper une API en local

Le premier livrable devenu classique dans un projet
impliquant du _machine learning_ est la mise √†
disposition d'un mod√®le par le biais d'une
API (voir chapitre sur la [mise en production](/chapters/deployment.qmd)).
Le _framework_ [`FastAPI`](https://fastapi.tiangolo.com/) va permettre
de rapidement transformer notre application `Python` en une API fonctionnelle.

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli16
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


{{< include "./applications/_appli17.qmd" >}}


## √âtape 2: d√©ployer l'API de mani√®re manuelle

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli18
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

A ce stade, nous avons d√©ploy√© l'API seulement localement, dans le cadre d'un terminal qui tourne en arri√®re-plan.
C'est une mise en production manuelle, pas franchement p√©renne. 
Ce mode de d√©ploiement est tr√®s pratique pour la phase de d√©veloppement, afin de s'assurer que l'API fonctionne comme attendu. 
Pour p√©renniser la mise en production, on va √©liminer l'aspect artisanal de celle-ci. 

Il est temps de passer √† l'√©tape de d√©ploiement, qui permettra √† notre API d'√™tre accessible via une URL sur le web
et d'avoir un serveur, en arri√®re plan, qui effectuera les op√©rations pour r√©pondre √† une
requ√™te. Pour se faire, on va utiliser les possibilit√©s offertes par `Kubernetes`, sur lequel est bas√© le [SSP Cloud](https://datalab.sspcloud.fr).


{{< include "./applications/_appli18a.qmd" >}}


Nous avons pr√©par√© la mise √† disposition de notre API mais √† l'heure
actuelle elle n'est pas disponible de mani√®re ais√©e car il est n√©cessaire
de lancer manuellement une image `Docker` pour pouvoir y acc√©der. 
Ce type de travail est la sp√©cialit√© de `Kubernetes` que nous allons
utiliser pour g√©rer la mise √† disposition de notre API. 

{{< include "./applications/_appli18b.qmd" >}}

On peut remarquer quelques voies d'am√©lioration de notre approche qui
seront ult√©rieurement trait√©es:

- L'entra√Ænement du mod√®le
est r√©-effectu√© √† chaque lancement d'un nouveau conteneur. 
On relance donc autant de fois un entra√Ænement qu'on d√©ploie
de conteneurs pour r√©pondre √† nos utilisateurs. Ce sera
l'objet de la partie MLOps de fiabiliser et optimiser
cette partie du _pipeline_. 
- il est n√©cessaire de (re)lancer manuellement  `kubectl apply -f deployment/`
√† chaque changement de notre code. Autrement dit, lors de cette application,
on a am√©lior√©
la fiabilit√© du lancement de notre API mais un lancement manuel est encore indispensable. 
Comme dans le reste de ce cours, on va essayer d'√©viter un geste manuel pouvant 
√™tre source d'erreur en privil√©giant l'automatisation et l'archivage dans des
scripts. C'est l'objet de la prochaine √©tape. 


## Etape 3: automatiser le d√©ploiement (d√©ploiement en continu)

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli19
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


::: {.callout-important}
## Clarification sur la branche de travail

A partir de maintenant, il est n√©cessaire de clarifier la
branche principale sur laquelle nous travaillons. De mani√®re
traditionnelle, on utilise la branche `main`. N√©anmoins,
pour √™tre coh√©rent avec les instructions du d√©but, qui √©taient 
de cr√©er une branche `dev`, tous les exemples ult√©rieures
partiront de cette hypoth√®se. 

Si vous avez fait les applications les unes apr√®s les autres, et
que vous vous situez toujours sur `dev`, vous pouvez passer 
aux applications suivantes. Si vous avez chang√© de branche,
vous pouvez continuer mais en tenir compte dans les exemples ult√©rieurs.

Si vous avez utilis√© un `tag` pour sauter une ou plusieurs √©tapes, il va
√™tre n√©cessaire de se placer sur une branche car vous √™tes en _head detached_. 
Pour cela, apr√®s avoir _committ√©_ les fichiers que vous d√©sirez garder

```{python}
#| eval: false
#| file: "terminal"
#| filename: "terminal"
$ git branch -D dev #<1>
$ git checkout -b dev
$ git push origin dev
```
1. Pas indispensable, mais permet de supprimer la branche `dev` si elle existe.
:::

Qu'est-ce qui peut d√©clencher une √©volution n√©cessitant de mettre √† 
jour l'ensemble de notre processus de production ? 

Regardons √† nouveau notre _pipeline_:

![](/workflow2.png)

Les _inputs_ de notre _pipeline_ sont donc:

- La __configuration__. Ici, on peut consid√©rer que notre YAML de configuration rel√®vent de cette cat√©gorie  ;
- Les __donn√©es__. Nos donn√©es sont statiques et n'ont pas vocation √† √©voluer. Si c'√©tait le cas, il faudrait en tenir compte dans notre automatisation. ;
- Le __code__. C'est l'√©l√©ment principal qui √©volue chez nous. On va donc faire en sorte qu'√† chaque mise √† jour de notre code (un _push_ sur `Github`), les √©tapes ult√©rieures (production de l'image `Docker`, etc.) se mettent √† compiler. N√©anmoins, il va √™tre n√©cessaire de se discipliner pour ne pas mettre en production n'importe quel code. 

Gr√¢ce √† `ArgoCD` il est possible d'automatiser la mise en production de notre
application. Au lieu d'√™tre fait manuellement par l'appel √† `kubectl apply`,
cela se fera en modifiant les instructions pr√©sentes dans le dossier `kubernetes/`
de notre d√©p√¥t. Un changement de ces fichiers
va entra√Æner le red√©ploiement automatique en synchronisant avec notre d√©p√¥t `Github`.

{{< include "./applications/_appli19a.qmd" >}}

La page n'a pas chang√©. En pratique, nous n'avons pas vraiment organis√© la mise en production
et `ArgoCD` n√©cessite un certain formalisme. 
Dor√©navant, il convient de versionner nos
productions pour d√©clencher dans `ArgoCD` des op√©rations. 
Ce versionnement va se faire √† deux niveaux[^gitopsrepo]:

- Dans le fichier `deployment.yaml` o√π on va sp√©cifier 
la version de l'image Docker utilis√©e en production
- Dans le YAML qui nous permet de _pusher_ une image sur `Dockerhub` (`.github/workflows/prod.yml`),
on va versionner notre image `Docker`. 


[^gitopsrepo]: 
    Techniquement, il serait plus judicieux de s√©parer notre
    projet en deux d√©p√¥ts: un d√©p√¥t pour le code source et un visant √† fournir
    les fichiers YAML pour la mise en production.

    ![](https://inseefrlab.github.io/formation-mlops/slides/img/ci-cd.png)


{{< include "./applications/_appli19b.qmd" >}}


Notre API est accessible sans probl√®me depuis `Python` ou notre navigateur
mais si on d√©sire utiliser `JavaScript` pour cr√©er une application
interactive, on va essuyer un refus √† cause du [CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS).

Permettre √† n'importe quel client de se connecter √† 
notre API permettra de faire un site web exploitant notre API. 
Comme c'est un point technique qui ne concerne pas les comp√©tences
li√©es √† ce cours, nous donnons directement les mises √† jour n√©cessaires
du projet:

{{< include "./applications/_cors.qmd" >}}

## Etape 4: construire un site web

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli19
git checkout -b dev
git push origin dev
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

On va proposer un nouveau livrable pour parler √† un public plus large.
Pour faire ce site web,
on va utiliser `Quarto` et d√©ployer sur `Github Pages`.

{{< include "./applications/_appli20.qmd" >}}


# Partie 6: adopter une approche MLOps pour am√©liorer notre mod√®le

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli20
git checkout -b dev
git push origin dev
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::

Nous allons dans cette partie faire de la
validation crois√©e. Pour √©viter le probl√®me
du [_data leakage_](https://machinelearningmastery.com/data-leakage-machine-learning/),
nous proposons de revoir notre _pipeline_ pour 
exclure la variable `Title` dont certaines modalit√©s
rares posent probl√®me dans les d√©coupages
multiples d'√©chantillons lors de la validation
crois√©e. 

## Restructurer le _pipeline_ pour fluidifier la mise en production


{{< include "./applications/_appli21.qmd" >}}


## Garder une trace des entra√Ænements de notre mod√®le gr√¢ce au _register_ de `MLFlow`

::: {.callout-caution collapse="true"}
## Si vous prenez ce projet fil rouge en cours de route

```{.bash filename="terminal"}
git checkout appli21
git checkout -b dev
git push origin dev
```

![](/checkpoint.jpg){width=80% fig-align="center"}

:::


::: {.callout-tip}
## Application 22 : archiver nos entra√Ænements avec `MLFlow`

1. Lancer `MLFlow` depuis l'onflet [Mes services](https://datalab.sspcloud.fr/catalog/automation) du SSPCloud.
Attendre que le service soit bien lanc√©. 
Cela cr√©era un service dont l'URL est de la forme `https://user-{username}-{pod_id}.user.lab.sspcloud.fr`,
o√π `pod_id` est un identifiant al√©atoire. Ce service `MLFlow` communiquera avec les `VSCode` que vous
ouvrirez ult√©rieurement √† partir de cet URL ainsi qu'avec le syst√®me de stockage `S3`[^tokenMLFlow].

2. Regarder la page `Experiments`. Elle est vide √† ce stade, c'est normal

[^tokenMLFlow]: Par cons√©quent, `MLFLow` b√©n√©ficie de l'injection automatique des _tokens_
pour pouvoir lire/√©crire sur S3. Ces jetons ont la m√™me dur√©e avant expiration que ceux
de vos services interactifs `VSCode`. Il faut donc supprimer et rouvrir un service `MLFLow`
r√©guli√®rement. La mani√®re d'√©viter cela
est de cr√©er des _service account_ sur [https://minio-console.lab.sspcloud.fr/](https://minio-console.lab.sspcloud.fr/login)
et de les renseigner sur [la page](https://datalab.sspcloud.fr/project-settings/s3-configs). 


2. Une fois le service `MLFlow` fonctionnel,
lancer un nouveau `VSCode` pour b√©n√©ficier de la configuration
automatis√©e

2. Cl√¥ner votre projet, vous situer sur la branche de travail (nous
supposerons qu'il s'agit de `dev`).

4. Depuis un terminal `Python`, lancer les commandes suivantes:

```python
import mlflow
mlflow_experiment_name = "titanicml"
mlflow.set_experiment(experiment_name=mlflow_experiment_name)
```

Retourner sur l'UI et observer la diff√©rence, √† gauche. 

5. Cr√©er un fichier `src/models/log.py`

<details>
<summary>
Contenu du fichier `src/models/log.py`
</summary>
```{.python include="./applications/code/appli22_log.py" filename="src/models/log.py"}
```

</details>


6. Modifier le fichier `train.py` pour ajouter la ligne

```{.python}
mlog.log_gsvc_to_mlflow(pipe_cross_validation, EXPERIMENT_NAME, APPLI_ID)
```

avec 

```{.python}
import src.models.log as mlog
```

7. Faire tourner avec le param√®tre `--appli appli22`:

```{.bash filename="terminal"}
python train.py --appli appli22
```

8. Observer l'√©volution de la page `Experiments`. Cliquer sur un des _run_. 
Observer toutes les m√©tadonn√©es archiv√©es (hyperparam√®tres, m√©triques d'√©valuation, `requirements.txt` dont `MLFlow` a fait l'inf√©rence, etc.)

9. Observer le code propos√© par `MLFlow` pour r√©cup√©rer le _run_ en question. Modifier le fichier `eval.py` √† partir de cet exemple et du mod√®le suivant pour utiliser un des mod√®les archiv√©s dans `MLFlow` 

10. Retourner √† la liste des _runs_ en cliquant √† nouveau sur _"titanicml"_ dans les exp√©rimentations
11. Dans l'onglet `Table`, s√©lectionner plusieurs exp√©rimentations, cliquer sur `Columns` et ajouter `mean_test_f1`. 
Ajuster la taille des colonnes pour la voir et classer les mod√®les par score d√©croissants
12. Cliquer sur `Compare` apr√®s en avoir s√©lectionn√© plusieurs. Afficher un _scatterplot_ des performances
en fonction du nombre d'estimateurs. Conclure. 

:::


::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git stash #<1>
git checkout appli22
```
1. Pour annuler les modifications depuis le dernier _commit_


![](/checkpoint.jpg){width=80% fig-align="center"}

:::

Cette appplication illustre l'un des premiers apports de `MLFlow`: on garde
une trace de nos exp√©rimentations et on peut d√©j√† mieux comprendre
la mani√®re dont certains param√®tres de notre mod√®le peuvent influencer
la qualit√© de nos pr√©dictions. 

N√©anmoins, persistent un certain nombre de voies d'am√©lioration:

- On entra√Æne le mod√®le en local, de mani√®re s√©quentielle, et en lan√ßant nous-m√™mes le script `train.py`
- On n'archive pas les jeux de donn√©es associ√©s √† ces mod√®les (les jeux d'entra√Ænement et de test). On doit alors 
le faire manuellement si on d√©sire √©valuer les performances _ex post_, ce qui est p√©nible.
- On r√©cup√®re manuellement les mod√®les ce qui n'est pas tr√®s p√©renne.
- Notre API n'utilise pas encore l'un des mod√®les archiv√© sur `MLFlow`. 

Les prochaines applications permettront d'am√©liorer ceci.


### Mise en production d'un mod√®le

{{< include "./applications/_appli23.qmd" >}}

::: {.callout-caution collapse="true"}
## Checkpoint

```{.bash filename="terminal"}
git stash #<1>
git checkout appli23
```
1. Pour annuler les modifications depuis le dernier _commit_


![](/checkpoint.jpg){width=80% fig-align="center"}

:::

### Exo entra√Ænements sur MLFLow

y a que √ßa de vrai
