---
  title: "Déployer et valoriser son projet de data science"
date: 2022-03-03
author: "Romain Avouac et Lino Galiana"
draft: false
# layout options: single, single-sidebar
layout: single
---
  

# Qu'est-ce que la mise en production ?

Dans les chapitres précédents, nous avons exploré la manière
dont une structure de projet et de code adéquate facilite
la réutilisation d'un projet. Cependant, le code est rarement,
en soi, le produit final mais un moyen. Le code peut
servir à mettre en oeuvre une application, à effectuer
des traitements sur une base de données pour un papier ou 
un rapport, etc. La fréquence de ré-utilisation du code peut
elle-même être variable: certains projets vont être utilisés
quotidiennement alors que d'autres ne le seront qu'à des
échéances diverses. 

Comme tout produit, un projet a un cycle de vie. Pour faire
simple, on peut séparer celui-ci en trois phases:

- la phase de développement correspond à l'écriture du code et
à des exploitations exploratoires ;
- la phase de mise en production correspond à l'adaptation du prototype
à des contraintes nécessaires pour qu'un projet produise un _output_ à
la demande ;
- la phase de maintenance correspond à la situation où on ne met plus
en oeuvre de nouvelles fonctionalités mais où on s'assure qu'un projet
informatique continue de produire les _output_ désirés malgré l'évolution
du contexte. 

En pratique, la distinction entre ces moments d'un projet peut être 
floue. Par exemple, grâce à `Git`, on peut ainsi mettre en oeuvre de 
nouvelles fonctionalités (protypage correspond à la
phase de développement) parallèles à celles déjà existantes (phase 
de maintenance). Néanmoins, ces différences conceptuelles sont intéressantes
pour appréhender les contraintes différentes de ces phases
d'un projet. 


## Importance des bonnes pratiques

Les bonnes pratiques mises en oeuvre jusqu'à présent avaient pour
objectif de faciliter la compréhension et la réutilisation d'un 
projet. Elles sont donc particulièrement appropriées pour réduire
le coût en temps de la mise en production et de la maintenance
d'un projet. Ces coûts pourraient amener un projet, même utile,
à être abandonné. 


## Environnements de production

De même, l'emphase du chapitre précédent sur la portabilité
vise à faciliter la mise en production. En effet, en créant
un environnement normalisé qui créé des conditions simples
pour reproduire certains _output_, on évite un hiatus 
entre le protypage et la mise en production. 


# Différents types de livrable

L'écosystème de la _data-science_ est florissant et permet
une grande variété d'_output_ qui vont toucher des publics
différents. Selon le type de projet, on peut retrouver
plusieurs livrables: 

- base de données ;
- API pour mettre à disposition un modèle  ;
- application  ;
- rapport automatisé ;
- site internet  ;
- ...


L'objectif du présent chapitre est de proposer des
méthodes pour anticiper la mise en production d'un
projet en intégrant, dès la phase de prototypage,
la production de livrables valorisant un projet
de _data-science_. 

Ces méthodes nous amèneront à explorer plusieurs écosystèmes, pour lesquels 
on retrouve quelques _buzz-words_ dont voici les définitions :

| Terme | Définition|
|------|--------|
| [`devops`](https://fr.wikipedia.org/wiki/Devops) | mouvement en ingénierie informatique et une pratique technique visant à l'unification du développement logiciel (dev) et de l'administration des infrastructures informatiques (ops) |
| [`MLOps`](https://fr.wikipedia.org/wiki/MLOps) | ensemble de pratiques qui vise à déployer et maintenir des modèles de machine learning en production de manière fiable et efficace |
| `CI/CD` | combinaison des pratiques d'intégration continue et de livraison continue ou de déploiement continu |



# Approches

## Pipelines de données

Une chaine de production implique plusieurs étapes qui peuvent éventuellement 
nécessiter plusieurs langages. Ces étapes peuvent être vues comme des 
transformations à la chaine d'un ou plusieurs inputs afin de produire
un ou plusieurs output.

La représentation de ces étapes peut être faite à l'aide des diagrammes
acycliques dirigés (DAG):

![](https://miro.medium.com/max/1400/1*grWvT-3jUcrnbTrsVtRHAg.png)

Un _workflow_ complet sera ainsi reproductible si on peut, en ayant accès
aux _inputs_ et à l'ensemble des règles de transformation reproduire
exactement les outputs. 
Si les inputs ou le code change, on peut être en mesure de mettre à jour
les outputs, si possible sans faire retourner les parties du projet non
concernés. 

Une première manière de développer est l'approche manuelle, qui est une tâche
digne de Sisyphe:

1. Ecriture du code
2. Exécution du code jusqu'à sa fin
3. Découverte d'une erreur ou mise à jour du code ou des données
4. Relance le code dans son ensemble

Pour éviter ce cycle interminable, on est tenté d'écrire des bases
intermédiaires et de ne faire tourner qu'une partie du code. 
Cette approche, si elle a l'avantage de faire gagner du temps, est 
néanmoins dangereuse car on peut facilement oublier de mettre à jour
une base intermédiaire qui a changé ou au contraire refaire tourner
une partie du code qui n'a pas été mise à jour. 

Il existe des méthodes plus fiables pour éviter ces gestes manuels. 
Celles-ci sont inspirées de [GNU Make](https://www.gnu.org/software/make/)
et consistent à créer le chemin de dépendance de la chaine de production 
(lister l'environnement, les inputs et les outputs à produire), à déterminer
les chemins affectés par un changement de code ou de données pour
ne faire tourner à nouveau que les étapes nécessaires. 

Les implémentations en `Python` et `R` sont nombreuses. Parmi celles-ci, on
peut mettre en valeur

- [`snakemake`](https://snakemake.readthedocs.io/en/stable/) pour `Python`
- [`targets`](https://books.ropensci.org/targets/) pour `R`


## Orchestration

Certains outils vont plus loin:

- argo
- mlflow
- airflow

# CI/CD

## Définition

> L’intégration continue est un ensemble de pratiques utilisées en génie logiciel consistant à vérifier à chaque modification de code source que le résultat des modifications ne produit pas de régression dans l’application développée. […] Elle permet d’automatiser l’exécution des suites de tests et de voir l’évolution du développement du logiciel.

> La livraison continue est une approche d’ingénierie logicielle dans laquelle les équipes produisent des logiciels dans des cycles courts, ce qui permet de le mettre à disposition à n’importe quel moment. Le but est de construire, tester et diffuser un logiciel plus rapidement.

![](/cicd_exemple.png)

## Avantages

L'approche CI/CD garantit une automatisation et une surveillance continues
tout au long du cycle de vie d'un projet. 

Cela présente de nombreux avantages:

- on peut anticiper les contraintes de la mise en production grâce à des environnements
normalisés partant d'image docker standardisées
- on peut tester les changements apportés à un livrable par un nouveau prototype 
- on peut déterminer très rapidement l'introduction de bugs dans un projet

## Mise en oeuvre

L'idée de l'approche CI/CD est ainsi d'associer chaque changement de 
code (`commit`) à l'exécution de scripts automatisés.
Bien que mis en oeuvre de manière différente, `Gitlab` et `Github`
proposent tous les deux ce type de fonctionalités.

Les actions `Github` sont un ensemble de règles qui se suivent au 
format `YAML`. Cela permet de définir différentes étapes du processus
avec, pour chaque étape, des éléments de configuration. 

Voici, par exemple, l'action qui sert de modèle à modifier dans l'exercice
d'application 

```yaml
name: Python Package using Conda

on: [push]

jobs:
  build-linux:
    runs-on: ubuntu-latest
    strategy:
      max-parallel: 5

    steps:
    - uses: actions/checkout@v3
    - name: Set up Python 3.10
      uses: actions/setup-python@v3
      with:
        python-version: 3.10
    - name: Add conda to system path
      run: |
        # $CONDA is an environment variable pointing to the root of the miniconda directory
        echo $CONDA/bin >> $GITHUB_PATH
    - name: Install dependencies
      run: |
        conda env update --file environment.yml --name base
    - name: Lint with flake8
      run: |
        conda install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    - name: Test with pytest
      run: |
        conda install pytest
        pytest
```

# Valoriser son projet avec un site web automatisé


Un code ou une API intéressent des publics très ciblés. D'autres
publics seront intéressés par une autre valorisation
d'un projet: les chercheurs apprécieront un papier académique, 
d'autres personnes préfèreront un site web ergonomique...

## Qu'est-ce qu'un site _web_ ?

Pour simplifier,
on peut voir un site _web_ comme la combinaison de trois éléments:

- une arborescence de fichiers `HTML` qui présentent le contenu du site
dans un balisage lourd
- des fichiers `CSS` qui gèrent la mise en forme[^1]
- des fonctions `javascript`

[^1]: Cette séparation entre le fond et la forme renvoie au paradigme du
_What you see is what you mean_ (WYSIWYM) dont l'un des
logiciels les plus connus est `LaTeX` et s'oppose au principe
du _What you see is what you get_ (WYSIWYG) des éditeurs de texte.

Il existe énormément d'outils aujourd'hui qui permettent, sans connaissance
en HTML, CSS ou JS, de créer un site _web_. Dans le domaine de la
_data-science_, le format `Markdown` (fichiers `.md`) s'est imposé. 

`Markdown` est un système d’édition doté d’une syntaxe simplifiée souvent
utilisé pour faire de la documentation de projet.
Le format est utilisé sur de nombreux sites internet,
notamment `Gitlab` et `Stackoverflow`.
L’extension de ce type de fichier est `.md`.
`Markdown` présente plusieurs avantages: 

- il est facile d’inclure des blocs de code informatique et des équations mathématiques dans un document Markdown ; 
- le formatage de blocs de texte ou de code est simple et très bien fait (et beaucoup plus léger qu’en LaTeX par exemple) ;
- il existe des outils de conversion de `Markdown` en `HTML` très bien faits.

Plus d'éléments sur la logique de `Markdown` et ses intérêts
sont disponibles dans le
chapitre [R Markdown de la documentation  `utilitR`](https://www.book.utilitr.org/rmarkdown.html)

## Comment faire un site _web_ ? 

Il existe historiquement plusieurs approches dans l'écosystème de la
_data-science_, selon le langage utilisé et l'output désiré. 

Si on part de fichiers qui présentent des blocs de
code qui ne nécessitent pas d'être exécutés, l'écosystème le plus riche
est [Hugo](https://gohugo.io/content-management/formats/). Celui-ci permet
de générer des sites web à l'architecture complexe à partir d'une
arborescence de `.md`. C'est l'approche adoptée 
pour ce site _web_ 

Cependant, il est souvent nécessaire d'exécuter des bouts de code pour tester
les exemples présentés, ou générer des tableaux ou sorties graphiques.
Pour cela, historiquement, il existe deux paradigmes: 

- [`JupyterBook`](https://jupyterbook.org/intro.html) qui vise à générer des
sites web et des notebooks à partir de fichiers `markdown`. Le notebook n'est
donc pas le produit de départ (cf. XXXX) mais un livrable. 
- [`R Markdown`](https://rmarkdown.rstudio.com/): l'écosystème le plus riche
avec de nombreux modèles de documents customisables (documents HTML ou articles PDF, sites web de documentation
avec `bookdown`, blogs avec `blogdown`,  _dashboards_, etc.) Le principe de `R Markdown`
est d'offrir une surcouche à `Markdown` pour que les blocs de code soient exécutés afin de créer
un _output_ reproductible.

`R Markdown` est un système d'une grande richesse. Initialement pensé pour les
utilisateurs de `R`, ce paradigme permet maintenant de créer des documents
executant d'autres langages, notamment
du `Python` ([le cours de python de 2e année](https://pythonds.linogaliana.fr/)
de l'ENSAE est testé et construit grâce à `R Markdown`).

`Quarto` est le petit nouveau dans cet écosystème, amené à devenir un 
outil standard des _data-scientists_ comme peuvent l'être, aujourd'hui,
les Notebooks `Jupyter`.
Successeur de `R Markdown`,
il vise à améliorer l'aspect universel des documents produits en n'obligeant
plus à utiliser `R` pour compiler le document qui ne le nécessitent pas. 
C'est un outil particulièrement adapté aux utilisateurs de `Python`

![](/quarto.png)

Un document `quarto` hérite des principes de base d'un document `R Markdown`, notamment
la structure. Il comporte ainsi deux parties principales :

- L’en-tête (`YAML` header) qui gère les éléments de style et les paramètres globaux;
- Le contenu qui gère le fond et permet d’alterner librement texte et code :
    + Les __blocs de texte brut__ mis en forme selon la syntaxe markdown 
    + Les __blocs de code__ sont présentés dans des _chunks_ identifiés par un
langage (ici `python`) qui seront exécutés de manière linéaire et produiront
l'output désiré (ici une figure `matplotlib`).  

## Comment mettre à disposition un site _web_ ?

Mettre à jour manuellement un site _web_ après l'avoir compilé
est une tâche pénible et source d'erreur dans un projet actif de
_data-science_.
L'automatisation issue de l'approche CI/CD permet un gain de confort 
aussi dans ce domaine.

Supposons qu'on ait mis en oeuvre une routine pour automatiser la construction
d'un site _web_ à partir de fichiers _Markdown_. Comment les mettre à
disposition ?

Il existe plusieurs manières de déployer automatiquement un site web : 

- [Gitlab pages](https://docs.gitlab.com/ee/user/project/pages/) ;
- [Github pages](https://pages.github.com/) ;
- [Netlify](https://www.netlify.com/).

Ces trois services sont gratuits. Ils consistent à mettre 
à disposition un DNS sur lequel des fichiers HTML peuvent être mis à
disposition automatiquement pour assurer que chaque `commit` 

L'[exercice d'application](../application) supposant l'utilisation
de `Github`, il présentera `Netlify` qui est
plus pratique que `Github Pages`[^2].
Le résultat de cette chaine de production d'un site
web reproductible est accessible à l'url
https://spiffy-florentine-c913b9.netlify.app/

[^2]: `Gitlab Pages` permet une mise en lien plus directe entre les
output de l'intégration continue et le déploiement. Cependant, avec
les scripts présentés dans l'exercice d'application on peut
avoir une intégration très flexible de `Netlify` dans un pipeline
plus riche. 
