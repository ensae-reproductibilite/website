::: {.content-visible when-profile="fr"}

# Vue d'ensemble

Ce cours s'adresse aux praticiens de la *data science*, discipline entendue ici au sens large comme la combinaison de techniques issues des mathématiques, de la statistique et de l'informatique pour produire de la connaissance utile à partir de données.
Comme la _data science_ n'est pas qu'une discipline scientique mais vise à fournir un ensemble d'outils pour
répondre à des
objectifs opérationnels, la notion de mise en production est centrale pour les _data scientists_, qu'ils se trouvent
dans le secteur privé ou public.

Ce cours part du constat que les formations académiques dans le domaine de la _data science_ adoptent souvent une orientation essentiellement technique, visant une compréhension fine des modèles manipulés, mais ne discutent que rarement des problèmes pratiques qui forment le quotidien du *data scientist* dans un contexte professionnel. Ces derniers sont pourtant structurants sur l'approche scientifique
pouvant être mise en oeuvre, en pratique.
Ce cours vise à combler le manque de ces formations en proposant des pistes de solution à diverses questions que peuvent se poser les *data scientists* lorsqu'ils transitionnent du contexte de la formation initiale à des projets réels :

- Comment __travailler de manière collaborative__ sur un projet ?
- Comment __partager du code__ et s'assurer que celui-ci va __tourner sans erreur__ sur un autre environnement d'exécution ?
- Comment passer d'un environnement de développement[^nb] à un __environnement de production__[^2]?
- Comment __déployer__ un modèle de *data science*, et rendre celui-ci accessible à des utilisateurs afin de le valoriser ?
- Comment __automatiser__ les différentes étapes de son projet afin de __simplifier sa maintenance__ ?

[^nb]: Celui que vous connaissez certainement le mieux est le _Notebook `Jupyter`_. Très pratique pour produire du code
exploratoire ou pour transmettre un code avec de la documentation, nous aurons l'occasion de découvrir ses limites
dans le cadre d'un projet collaboratif ou un projet à grande échelle.
[^2]: Nous aurons l'occasion ultérieurement de définir de manière formelle cette notion centrale. En attendant, on peut entendre ce concept comme un environnement disponible en continu afin de mettre à disposition une valorisation de données. Cela prend souvent la forme d'un serveur de production ou d'un _cluster_ informatique qui doit être disponible en continu.

:::: {.callout-note}

## Ressource complémentaire: le _missing semester_ du MIT

Beaucoup de praticiens ont pris conscience de certains manques
dans les cursus de formations en statistiques ou en informatique.
Certaines ressources très utiles ont été regroupées dans le
[_missing semester_ du MIT](https://missing.csail.mit.edu/)
dont une partie des contenus présente des thèmes communs
avec ce cours.
::::

Afin de proposer des réponses à ces interrogations, ce cours présente **un ensemble de bonnes pratiques et d'outils issus de différents domaines de l'informatique**, comme le développement logiciel, l'infrastructure, l'administration de serveurs, le déploiement applicatif, etc. L'objectif n'est bien entendu pas de développer une expertise dans chacun de ces domaines, dans la mesure où ces compétences font l'objet de métiers à part entière, que sont les développeurs, les *data architects*, les *sysadmin*, ou encore les *data engineers*.

En revanche, face à la taille croissante des projets de *data science* et donc des équipes qui les portent, le *data scientist* tend à se retrouver à l'interface de ces différentes professions, avec lesquelles il doit communiquer de manière efficiente pour mener ces projets à bien. **Ce cours vise à fournir, plus que des connaissances techniques pointues, les élements de langage nécessaires pour pouvoir jouer ce rôle d'interface en communiquant à la fois avec les équipes métiers et les équipes techniques qui entourent un projet de *data science***.

Un projet de _data science_ comporte un __cycle de vie complet__ qui est généralement passé sous
silence dans les enseignements de _data science_ ou dans de nombreux manuels spécialisés.
La solution la plus complexe sur le plan méthodologique ou technique
est rarement la meilleure. Celle-ci est en effet souvent coûteuse à développer et encore
plus difficile à mettre en oeuvre. Elle peut même être dépassée avant même d'être
finalisée: les algorithmes apprennent du passé ce qui est un défi dans le monde réel
pour conserver
des performances équivalentes à mesure qu'on collecte de nouvelles données.
La phase de développement n'est ainsi qu'un moment dans la vie d'un projet
de _data science_ et y concentrer tous ses efforts amène régulièrement à des
projets à faible validité externe.

Ce cours présente ainsi un ensemble de techniques et de principes qui ont
pour objet de fluidifier la mise en production[^notenom]
d'un projet de _data science_. La mise en production est entendue,
de manière abstraite,
comme une manière de __faire vivre une application dans l'espace de ses utilisateurs__.
Cette définition peut apparaître obscure mais elle
permet, en pratique, de rappeler que l'approche technique est avant
tout une réponse à un besoin, celui du public cible dont les attentes,
les niveaux de technicité et les moyens d'accès aux données sont variables. Le
fait de parler d'application peut apparaître comme une manière restrictive de
répondre à ce besoin mais, comme nous aurons l'occasion de le voir ultérieurement,
ce terme peut être appréhendé de manière large pour répondre à une grande
diversité de cas d'usage.

[^notenom]: L'aspect très intriqué des notions de bonnes pratiques, de reproductibilité
et de mise en production nous
a d'ailleurs longtemps fait hésiter sur le nom à donner à ce cours.
Parmi la _shortlist_ des noms possibles, nous
avions _"Bonnes pratiques en data science"_ ou _"Bonnes pratiques pour la reproductibilité en data science_.
Néanmoins, les bonnes
pratiques restent un moyen là où la mise en production est la finalité, nous avons ainsi
privilégié le fait de mettre en avant cette dernière notion.

L'objectif principal de cours est de montrer la manière dont une approche pragmatique
et l'adoption des bons outils et bons principes permet de sortir facilement
de la phase artisanale d'expérimentation pour amener un projet plus facilement vers
l'industrialisation.

:::
::: {.content-visible when-profile="en"}

# Overview

This course is intended for *data science* practitioners, understood here in a broad sense as the combination of techniques from mathematics, statistics, and computer science to generate useful insights from data. Since data science is not just a scientific discipline but aims to provide tools to meet operational objectives, the notion of production deployment is central for *data scientists*, whether in the private or public sector.

This course starts from the observation that academic training in *data science* often takes a primarily technical approach, focusing on a deep understanding of models, but rarely addresses the practical problems that make up the daily work of a *data scientist* in a professional setting. Yet these issues significantly shape the scientific approach that can be implemented in practice.

This course aims to fill that gap by offering potential solutions to various questions *data scientists* may face when transitioning from academic training to real-world projects:

- How to __collaborate effectively__ on a project?
- How to __share code__ and ensure it will __run without errors__ on a different execution environment?
- How to transition from a development environment[^nb] to a __production environment__[^2]?
- How to __deploy__ a *data science* model and make it accessible to users to create value?
- How to __automate__ different steps of the project to __ease maintenance__?

[^nb]: You're probably most familiar with the _Jupyter Notebook_. While very convenient for writing exploratory code or sharing annotated code, we’ll see its limitations in collaborative or large-scale projects.
[^2]: We will define this central concept more formally later. For now, you can think of it as an always-on environment designed to deliver data products—often in the form of a production server or a computing cluster that must remain continuously available.

:::: {.callout-note}

## Additional Resource: MIT's _Missing Semester_

Many practitioners have realized the lack of certain skills in statistics or computer science curricula. Some very useful resources have been compiled in the [MIT _Missing Semester_](https://missing.csail.mit.edu/), part of which overlaps with topics covered in this course.

::::

To address these questions, the course introduces **a set of best practices and tools from various computer science domains**, such as software development, infrastructure, server administration, and application deployment. The goal is not to become an expert in each of these fields, as they are professions in their own right—developers, *data architects*, *sysadmins*, and *data engineers*.

However, as *data science* projects and the teams supporting them grow larger, *data scientists* increasingly find themselves at the intersection of these roles. They must communicate effectively across domains to see projects through. **This course is designed to equip you not just with technical knowledge, but with the vocabulary and concepts necessary to act as a bridge between business and technical teams involved in a *data science* project.**

A *data science* project goes through a __full lifecycle__, which is often overlooked in data science education or specialized manuals. The most complex methodological or technical solution is rarely the best one. It tends to be costly to develop and even harder to implement. It may even become obsolete before completion: algorithms learn from the past, and it is challenging in the real world to maintain equivalent performance as new data accumulates.

The development phase is just one moment in the life of a *data science* project. Focusing solely on it often leads to low external validity.

This course introduces a set of techniques and principles intended to streamline the process of production deployment[^notenom] for a *data science* project. Production deployment is understood, abstractly, as the act of __making an application live in the user's environment__. While this definition may seem vague, it helps remind us that technical solutions are above all a response to user needs—needs which vary in expertise level and data access.

Speaking of “application” might seem restrictive, but as we will see, this term can be interpreted broadly to fit a wide range of use cases.

[^notenom]: The strong entanglement of best practices, reproducibility, and deployment actually made it hard for us to settle on a course title. Some names on our shortlist were _“Best Practices in Data Science”_ or _“Best Practices for Reproducibility in Data Science”_. However, since best practices are a means and deployment is the end, we decided to emphasize the latter.

The main goal of the course is to show how a pragmatic approach, along with the right tools and principles, allows projects to move beyond experimental tinkering and toward production-grade solutions.

:::

