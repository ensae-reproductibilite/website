<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.27">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="PrÃ©sentation des architectures informatiques et des outils logiciels permettant de faciliter le traitement de donnÃ©es volumineuses.">

<title>Traitement des donnÃ©es volumineuses â€“ Mise en production</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-ed96de9b727972fe78a7b5d16c58bf87.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap-b66d9f3da4d84aca26cc7cc1c94b0445.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>
div.callout-application.callout {
  border-left-color: #9c5bd9;
}
div.callout-application.callout-style-default > .callout-header {
  background-color: rgba(156, 91, 217, 0.13);
}
div.callout-application .callout-toggle::before {  background-image: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="rgb(33, 37, 41)" class="bi bi-chevron-down" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1.646 4.646a.5.5 0 0 1 .708 0L8 10.293l5.646-5.647a.5.5 0 0 1 .708.708l-6 6a.5.5 0 0 1-.708 0l-6-6a.5.5 0 0 1 0-.708z"/></svg>');}
div.callout-application.callout-style-default .callout-icon::before, div.callout-application.callout-titled .callout-icon::before {
  content: 'ğŸ§ ';
  background-image: none;
}
</style>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://ensae-reproductibilite.github.io/"> 
<span class="menu-text">Mise en production</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../chapters/introduction.html"> 
<span class="menu-text">Introduction</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-les-bases" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Les bases</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-les-bases">    
        <li>
    <a class="dropdown-item" href="../chapters/linux101.html">
 <span class="dropdown-text">Linux 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/git.html">
 <span class="dropdown-text">Git</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bonnes-pratiques-de-dÃ©veloppement" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Bonnes pratiques de dÃ©veloppement</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bonnes-pratiques-de-dÃ©veloppement">    
        <li>
    <a class="dropdown-item" href="../chapters/code-quality.html">
 <span class="dropdown-text">QualitÃ© du code</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/projects-architecture.html">
 <span class="dropdown-text">Structure des projets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/big-data.html">
 <span class="dropdown-text">Traitement des donnÃ©es volumineuses</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/portability.html">
 <span class="dropdown-text">PortabilitÃ©</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-mise-en-production" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Mise en production</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-mise-en-production">    
        <li>
    <a class="dropdown-item" href="../chapters/yaml101.html">
 <span class="dropdown-text">YAML 101</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/deployment.html">
 <span class="dropdown-text">DÃ©ploiement</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/mlops.html">
 <span class="dropdown-text">MLOps</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="../chapters/application.html"> 
<span class="menu-text">Application</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-projets" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Projets</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-projets">    
        <li>
    <a class="dropdown-item" href="../chapters/evaluation.html">
 <span class="dropdown-text">ModalitÃ©s dâ€™Ã©valuation</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../chapters/galerie.html">
 <span class="dropdown-text">Galerie des projets passÃ©s</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-bi-github" role="link" data-bs-toggle="dropdown" aria-expanded="false">
      <i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-bi-github">    
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/website">
 <span class="dropdown-text">Site web</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/slides">
 <span class="dropdown-text">Slides</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://github.com/ensae-reproductibilite/application">
 <span class="dropdown-text">Application fil rouge</span></a>
  </li>  
    </ul>
  </li>
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#infrastructures" id="toc-infrastructures" class="nav-link active" data-scroll-target="#infrastructures">Infrastructures</a>
  <ul class="collapse">
  <li><a href="#evolution-des-infrastructures-de-donnÃ©es" id="toc-evolution-des-infrastructures-de-donnÃ©es" class="nav-link" data-scroll-target="#evolution-des-infrastructures-de-donnÃ©es">Evolution des infrastructures de donnÃ©es</a></li>
  <li><a href="#lapport-des-technologies-cloud" id="toc-lapport-des-technologies-cloud" class="nav-link" data-scroll-target="#lapport-des-technologies-cloud">Lâ€™apport des technologies <em>cloud</em></a></li>
  </ul></li>
  <li><a href="#sec-new-formats" id="toc-sec-new-formats" class="nav-link" data-scroll-target="#sec-new-formats">Formats de donnÃ©es</a></li>
  <li><a href="#frameworks-de-traitement" id="toc-frameworks-de-traitement" class="nav-link" data-scroll-target="#frameworks-de-traitement"><em>Frameworks</em> de traitement</a></li>
  <li><a href="#applications" id="toc-applications" class="nav-link" data-scroll-target="#applications">Applications</a>
  <ul class="collapse">
  <li><a href="#application-3" id="toc-application-3" class="nav-link" data-scroll-target="#application-3">Application 3</a></li>
  <li><a href="#pour-aller-plus-loin" id="toc-pour-aller-plus-loin" class="nav-link" data-scroll-target="#pour-aller-plus-loin">Pour aller plus loin</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<script>
  const langButton = document.createElement("div");
  langButton.className = "lang-switch-button";
  langButton.style.textAlign = "right";
  langButton.style.marginTop = "1rem";
  langButton.style.marginBottom = "1rem";

  const currentPath = window.location.pathname;

  // GÃ©rer les cas avec un sous-rÃ©pertoire comme /website
  const normalizedPath = currentPath.replace(/^\/website/, "");
  const isEnglish = normalizedPath.includes("/en/");
  let targetHref, label, svg;

  if (isEnglish) {
    targetHref = currentPath.replace("/en/", "/");  // conserve le prÃ©fixe /website si prÃ©sent
    label = "Passer Ã  la version franÃ§aise";
    svg = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20" style="vertical-align: middle; margin-left: 0.5em; display: inline-block;"><mask id="circleFlagsLangFr"><circle cx="256" cy="256" r="256" fill="#fff"/></mask><g mask="url(#circleFlagsLangFr)"><path fill="#0055A4" d="M0 0h512v512H0z"/><path fill="#fff" d="M170.7 0h170.6v512H170.7z"/><path fill="#EF4135" d="M341.3 0H512v512H341.3z"/></g></svg>`;
  } else {
    const prefix = currentPath.startsWith("/website") ? "/website" : "";
    targetHref = prefix + "/en" + currentPath.slice(prefix.length);
    label = "Switch to English version";
    svg = `<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20" style="vertical-align: middle; margin-left: 0.5em; display: inline-block;"><mask id="circleFlagsLangEn"><circle cx="256" cy="256" r="256" fill="#fff"/></mask><g mask="url(#circleFlagsLangEn)"><path fill="#eee" d="M256 0L0 256v64l32 32l-32 32v128l22-8l23 8h23l54-32l54 32h32l48-32l48 32h32l54-32l54 32h68l-8-22l8-23v-23l-32-54l32-54v-32l-32-48l32-48v-32l-32-54l32-54V0z"/><path fill="#d80027" d="M224 64v64h160l64-64zm0 128l32 64l-48 48v208h96V304h208v-96H304l16-16zM0 320v64h128l-64 64H0v64h45l131-131v-45l16-16zm336 16l176 176v-45L381 336Z"/><path fill="#0052b4" d="M0 0v256h256V0zm512 68L404 176h108zM404 336l108 108V336zm-228 68L68 512h108zm160 0v108h108z"/><path fill="#eee" d="m187 243l57-41h-70l57 41l-22-67zm-81 0l57-41H93l57 41l-22-67zm-81 0l57-41H12l57 41l-22-67zm162-81l57-41h-70l57 41l-22-67zm-81 0l57-41H93l57 41l-22-67zm-81 0l57-41H12l57 41l-22-67Zm162-82l57-41h-70l57 41l-22-67zm-81 0l57-41H93l57 41l-22-67Zm-81 0l57-41H12l57 41l-22-67Z"/></g></svg>`;
  }

  langButton.innerHTML = `
    <a href="${targetHref}" class="button-cta">
      <button class="btn"><i class="fa fa-language"></i> ${label} ${svg}</button>
    </a>
  `;

  const main = document.querySelector("main#quarto-document-content");
  if (main) main.insertAdjacentElement("afterbegin", langButton);
</script>
    

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Traitement des donnÃ©es volumineuses</h1>
</div>

<div>
  <div class="description">
    <p>PrÃ©sentation des architectures informatiques et des outils logiciels permettant de faciliter le traitement de donnÃ©es volumineuses.</p>
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<details>
<summary>
DÃ©rouler les <em>slides</em> ci-dessous ou <a href="https://ensae-reproductibilite.github.io/slides/#/traitement-des-donn%C3%A9es-volumineuses">cliquer ici</a> pour afficher les slides en plein Ã©cran.
</summary>
<div class="code-copy-outer-scaffold"><div id="cb1" class="sourceCode">
<pre class="sourceCode yaml code-with-copy"><code class="sourceCode yaml"></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre>
<iframe class="sourceCode yaml code-with-copy" src="https://ensae-reproductibilite.github.io/slides/#/traitement-des-donn%C3%A9es-volumineuses">
</iframe>
</div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<p>Le phÃ©nomÃ¨ne du <em>big data</em> est maintenant bien documentÃ© : la gÃ©nÃ©ration et la collecte de donnÃ©es par une multitude de sources (capteurs IoT, interactions quotidiennes sur les rÃ©seaux sociaux, transactions en ligne, dispositifs mobiles, etc.) dÃ©multiplie les volumes de donnÃ©es disponibles pour lâ€™analyse. Les raisons pouvant mener Ã  sâ€™intÃ©resser Ã  de telles donnÃ©es pour des projets de data science sont nombreuses : haute disponibilitÃ©, plus grande finesse des phÃ©nomÃ¨nes observÃ©s, bases pour lâ€™entraÃ®nement de modÃ¨les de ML de plus en plus gourmands (comme les LLM), etc.</p>
<p>On dÃ©finit souvent le <em>big data</em> comme Ã©tant la situation oÃ¹ les donnÃ©es sont volumineuses au point quâ€™on ne soit plus en mesure de les traiter sur une unique machine. Cette dÃ©finition relativiste peut sembler rÃ©ductrice mais prÃ©sente nÃ©anmoins lâ€™intÃ©rÃªt de souligner quâ€™une source de donnÃ©es peut, selon les Ã©poques et les environnements, faire appel Ã  des compÃ©tences diffÃ©rentes. Le fait de passer Ã  des donnÃ©es <em>big data</em> nâ€™est en effet pas seulement un changement de volume: on change souvent de nature dâ€™infrastructure informatique et cela a des implications fortes sur les compÃ©tences Ã  mettre en oeuvre pour traiter des donnÃ©es et lâ€™Ã©volutivitÃ© des chaines de production en question.</p>
<p>En contrepartie, le traitement de ces donnÃ©es gÃ©nÃ¨re de nouveaux dÃ©fis. Ces derniers peuvent Ãªtre rÃ©sumÃ©s par les <strong>â€œtrois Vâ€</strong>, une maniÃ¨re dÃ©sormais admise de caractÃ©riser ces nouvelles sources de donnÃ©es <span class="citation" data-cites="sagiroglu2013big">(<a href="#ref-sagiroglu2013big" role="doc-biblioref">Sagiroglu and Sinanc 2013</a>)</span> :</p>
<ul>
<li><p><strong>Volume</strong> : des <strong>volumes massifs de donnÃ©es</strong>, souvent Ã  une Ã©chelle bien supÃ©rieure Ã  ce que les systÃ¨mes traditionnels peuvent traiter efficacement. Par consÃ©quent, de nouvelles architectures de stockage et de traitement sont nÃ©cessaires afin de gÃ©rer de telles volumÃ©tries.</p></li>
<li><p><strong>Vitesse</strong> : ces donnÃ©es sont gÃ©nÃ©ralement produites Ã  <strong>haute frÃ©quence, jusquâ€™au temps rÃ©el</strong>. LÃ  encore, cela nÃ©cessite des ajustements dans les architectures et les mÃ©thodes de traitement, comme les mÃ©thodes de <em>stream processing</em> par exemple.</p></li>
<li><p><strong>VariÃ©tÃ©</strong> : ces donnÃ©es prÃ©sentent <strong>des sources et des formats trÃ¨s variÃ©s</strong>, allant des bases structurÃ©es (donnÃ©es tabulaires) aux donnÃ©es non-structurÃ©es (texte, image, vidÃ©o, etc.). LÃ  encore, les techniques de traitement adaptÃ©es vont dÃ©pendre des formes prises par les donnÃ©es. Dans ce cours, nous nous concentrerons sur des donnÃ©es relativement structurÃ©es, dans la mesure oÃ¹ ces derniÃ¨res restent centrales dans les projets analytiques de data science.</p></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../vvv.png" height="350" class="figure-img"></p>
<figcaption>Les â€œ3 Vâ€ du <em>big data</em>. Source : <a href="https://www.packtpub.com/product/artificial-intelligence-with-python-second-edition/9781839219535">AI with Python</a></figcaption>
</figure>
</div>
<p>Lorsque lâ€™on envisage de passer en production un projet de data science basÃ© sur des donnÃ©es volumineuses, <strong>lâ€™adoption de bonnes pratiques de dÃ©veloppement nâ€™est pas seulement recommandÃ©e, elle est indispensable</strong>. En effet, les donnÃ©es volumineuses voire massives introduisent une complexitÃ© significative dans tous les aspects du cycle de vie dâ€™un projet de data science, de la collecte et du stockage des donnÃ©es Ã  leur traitement et analyse. Les systÃ¨mes doivent Ãªtre conÃ§us pour non seulement gÃ©rer le volume actuel de donnÃ©es, mais aussi pour Ãªtre <strong>Ã©volutifs</strong> face Ã  une croissance future inÃ©vitable. Les bonnes pratiques de dÃ©veloppement facilitent cette Ã©volutivitÃ© en promouvant des <strong>architectures modulaires</strong>, des codes rÃ©utilisables, et des technologies adaptÃ©es au traitement des grandes quantitÃ©s de donnÃ©es.</p>
<p>Face Ã  ces enjeux, le choix des technologies est primordial. Dans ce cours, nous prÃ©senterons trois axes principaux qui peuvent guider ces choix : <strong>lâ€™infrastructure informatique</strong>, des <strong>formats de donnÃ©es</strong> adaptÃ©s aux donnÃ©es volumineuses, et des <strong><em>frameworks</em></strong> (solutions logicielles et leur Ã©cosystÃ¨me) utilisÃ©s pour le traitement de la donnÃ©e.</p>
<section id="infrastructures" class="level1">
<h1>Infrastructures</h1>
<section id="evolution-des-infrastructures-de-donnÃ©es" class="level2">
<h2 class="anchored" data-anchor-id="evolution-des-infrastructures-de-donnÃ©es">Evolution des infrastructures de donnÃ©es</h2>
<p>Historiquement, les donnÃ©es ont Ã©tÃ© stockÃ©es dans des bases de donnÃ©es, câ€™est Ã  dire des systÃ¨mes de stockage et dâ€™organisation de la donnÃ©e. Ces objets ont vu le jour dans les annÃ©es 1950, et ont connu un essor particulier avec les bases de donnÃ©es relationnelles dans les annÃ©es 1980. Cette technologie se rÃ©vÃ©lant particuliÃ¨rement pertinente pour organiser le stockage des donnÃ©es â€œmÃ©tierâ€ des entreprises, elle a Ã©tÃ© Ã  la base des <em>data warehouses</em>, qui ont longtemps constituÃ© la rÃ©fÃ©rence des infrastructures de stockage de la donnÃ©e <span class="citation" data-cites="chaudhuri1997overview">(<a href="#ref-chaudhuri1997overview" role="doc-biblioref">Chaudhuri and Dayal 1997</a>)</span>. Si leur implÃ©mentation technique peut Ãªtre de nature variÃ©e, leur principe est simple : des donnÃ©es de sources multiples et hÃ©tÃ©rogÃ¨nes sont intÃ©grÃ©es dans un systÃ¨me de bases de donnÃ©es relationnel selon des rÃ¨gles mÃ©tier grÃ¢ce Ã  des processus dits <em>ETL</em> (<em>extract-transform-load</em>), afin de les rendre directement accessibles pour une variÃ©tÃ© dâ€™usages (analyse statistique, <em>reporting</em>, etc.) Ã  lâ€™aide dâ€™un langage normalisÃ© : <code>SQL</code> (<a href="#fig-datawarehouse" class="quarto-xref">Figure&nbsp;1</a>).</p>
<div id="fig-datawarehouse" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-datawarehouse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../datawharehouse.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-datawarehouse-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Architecture dâ€™un <em>data warehouse</em>. Source : <a href="https://airbyte.com/data-engineering-resources/business-intelligence-data-warehouse">airbyte.com</a>
</figcaption>
</figure>
</div>
<p>Au dÃ©but des annÃ©es 2000, la montÃ©e en puissance des usages de nature <em>big data</em> dans les entreprises met en lumiÃ¨re les limites des <em>data warehouses</em> traditionnels. Dâ€™une part, les donnÃ©es traitÃ©s prÃ©sentent une diversitÃ© croissante de formats (structurÃ©s, semi-structurÃ©s et non structurÃ©s) et un format changeant au grÃ© de lâ€™ajout de fonctionnalitÃ©s sur les plateformes web collectant des donnÃ©es. Ces Ã©lÃ©ments rentre difficilement dans le monde ordonnÃ© des <em>data warehouses</em>, qui nÃ©cessite de spÃ©cifier <em>a priori</em> le schÃ©ma des donnÃ©es. Pour pallier ces limites, de nouvelles infrastructures de stockage vont Ãªtre dÃ©veloppÃ©es : les <em>data lakes</em>, qui permettent la collecte et le stockage de quantitÃ©s massives de donnÃ©es de nature diverse (<a href="#fig-datalake" class="quarto-xref">Figure&nbsp;2</a>).</p>
<div id="fig-datalake" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-datalake-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../datalake.png" class="img-fluid quarto-figure quarto-figure-center figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-datalake-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Architecture dâ€™un <em>data lake</em>. Source : <a href="https://www.cartelis.com/blog/data-lake-definition-enjeux/">cartelis.com</a>
</figcaption>
</figure>
</div>
<p>Dâ€™autre part, la taille considÃ©rable de ces donnÃ©es rend de plus en plus difficile leur exploitation sur une unique machine. Câ€™est dans ce contexte que Google publie le paradigme <code>MapReduce</code> <span class="citation" data-cites="ghemawat2003google dean2008mapreduce">(<a href="#ref-ghemawat2003google" role="doc-biblioref">Ghemawat, Gobioff, and Leung 2003</a>; <a href="#ref-dean2008mapreduce" role="doc-biblioref">Dean and Ghemawat 2008</a>)</span>, posant les bases dâ€™une nouvelle gÃ©nÃ©ration de systÃ¨mes permettant de traiter de larges volumes de donnÃ©es de maniÃ¨re distribuÃ©e. Dans les infrastructures traditionnelles, le passage Ã  lâ€™Ã©chelle Ã©tait rÃ©alisÃ© selon un principe de scalabilitÃ© verticale, câ€™est Ã  dire en augmentant la puissance dâ€™une machine de calcul ou en choisissant une machine plus performante. Cette approche devient nÃ©anmoins rapidement trÃ¨s coÃ»teuse et se heurte aux limites physiques des composants. A lâ€™inverse, les architectures distribuÃ©es adoptent le principe de scalabitÃ© horizontale : en installant des serveurs â€” chacun dâ€™une puissance limitÃ©e â€” en parallÃ¨le et en adaptant les algorithmes Ã  cette logique distribuÃ©e, on parvient Ã  traiter des donnÃ©es massives avec du matÃ©riel standard. Dans la lignÃ©e de ces travaux, Ã©merge lâ€™Ã©cosystÃ¨me <code>Hadoop</code> qui offre une combinaison de technologies complÃ©mentaires : un <em>data lake</em> (<code>HDFS</code> - <em>Hadoop Distributed File System</em>), un moteur de calcul distribuÃ© (<code>MapReduce</code>) et des outils dâ€™intÃ©gration et de transformation de la donnÃ©e (<a href="#fig-hadoop" class="quarto-xref">Figure&nbsp;3</a>). Cet Ã©co-systÃ¨me est progressivement complÃ©tÃ© par des outils qui vont dÃ©mocratiser la capacitÃ© Ã  traiter des donnÃ©es <em>big data</em> : <code>Hive</code>, qui convertit des requÃªtes <code>SQL</code> en traitements <code>MapReduce</code> distribuÃ©s, puis <code>Spark</code>, qui lÃ¨ve certaines limites techniques de <code>MapReduce</code> et fournit des API dans plusieurs langages (<code>Java</code>, <code>Scala</code>, <code>Python</code>, etc.). Le succÃ¨s de lâ€™Ã©co-systÃ¨me <code>Hadoop</code> dans les entreprises est considÃ©rable dans la mesure oÃ¹ il permet de traiter des volumes de donnÃ©es sans prÃ©cÃ©dent â€” jusquâ€™au pÃ©ta-octet â€” et des vÃ©locitÃ©s considÃ©rables â€” jusquâ€™au temps rÃ©el â€” Ã  lâ€™aide de langages de programmation non rÃ©servÃ©s aux seuls informaticiens.</p>
<p>Câ€™est ce mouvement technologique qui a permis lâ€™engouement pour le <em>big data</em>, offrant les moyens techniques pour rÃ©pondre Ã  de nouvelles questions Ã  partir de sources de donnÃ©es volumineuses. Au delÃ  du sujet technique, ces changements ont entraÃ®nÃ© une rÃ©volution paradigmatique dans le domaine de la <em>data</em>. PlutÃ´t que de collecter un volume limitÃ© de donnÃ©es correspondant Ã  quelques besoins bien identifiÃ©s, il est plus simple dâ€™empiler la donnÃ©e dans des entrepÃ´ts et, seulement ensuite, lors du traitement, se poser la question de la valeur de celles-ci. Cette philosophie est typique des environnements reposant sur lâ€™approche <a href="https://en.wikipedia.org/wiki/NoSQL">NoSQL</a> (<em>â€œNot only SQLâ€</em>) oÃ¹ les donnÃ©es sont, comme dans lâ€™Ã©cosystÃ¨me SQL, enregistrÃ©es Ã  chaque Ã©vÃ©nement transactionnel, mais oÃ¹ celles-ci sont empilÃ©es dans des formats plus flexibles que dans les bases de donnÃ©es traditionnelles. Parmi les formats de prÃ©dilection de ce domaine, le JSON, issu de transactions web, tient la dragÃ©e haute. Selon la nature plus ou moins structurÃ©e des donnÃ©es, il existe des outils diffÃ©rents pour les requÃªter: <code>ElasticSearch</code> ou <code>MongoDB</code> pour des donnÃ©es textuelles, <code>Spark</code> pour des donnÃ©es tabulaires, etc. Le trait commun entre ces outils et quâ€™ils sont trÃ¨s scalables horizontalement, ce qui les rend idÃ©aux pour Ãªtre utilisÃ©s dans des fermes de serveurs.</p>
<div id="fig-hadoop" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hadoop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../mapreduce-hdfs.png" class="quarto-figure quarto-figure-center figure-img" height="350">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hadoop-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: ReprÃ©sentation schÃ©matique dâ€™une architecture <code>Hadoop</code>. La donnÃ©e volumineuse est dÃ©coupÃ©e en blocs, et le stockage ainsi que le traitement des diffÃ©rents blocs sont distribuÃ©s sur plusieurs nÅ“uds de calcul. Les algorithmes utilisÃ©s pour traiter la donnÃ©e sont adaptÃ©s au mode distribuÃ© via le paradigme <code>MapReduce</code> : on applique Ã  chaque bloc une fonction (Ã©tape â€œ<em>map</em>â€ ; par exemple, compter les frÃ©quences des mots qui apparaissent dans les documents dâ€™un bloc), puis on effectue une Ã©tape dâ€™agrÃ©gation (Ã©tape â€œ<em>reduce</em>â€ ; par exemple, agrÃ©ger les frÃ©quences des diffÃ©rents blocs pour obtenir des frÃ©quences agrÃ©gÃ©es sur lâ€™ensemble des donnÃ©es initiales). Les donnÃ©es en sortie de ces deux Ã©tapes sont gÃ©nÃ©ralement de taille bien infÃ©rieure Ã  celle des donnÃ©es source, et peuvent donc Ãªtre rapatriÃ©es en local pour des traitements ultÃ©rieurs (ex : faire de la visualisation de donnÃ©es). Source : <a href="https://www.glennklockwood.com/data-intensive/hadoop/overview.html">glennklockwood.com</a>
</figcaption>
</figure>
</div>
<p>Ã€ la fin des annÃ©es 2010, les architectures basÃ©es sur <code>Hadoop</code> connaissent nÃ©anmoins un net dÃ©clin de popularitÃ©. Dans les environnements <code>Hadoop</code> traditionnels, le stockage et le calcul sont co-localisÃ©s par construction : si les donnÃ©es Ã  traiter sont rÃ©parties sur plusieurs serveurs, chaque section des donnÃ©es est directement traitÃ©e sur la machine hÃ©bergeant cette section, afin dâ€™Ã©viter les transferts rÃ©seau entre serveurs. Dans ce paradigme, la mise Ã  lâ€™Ã©chelle de lâ€™architecture implique une augmentation linÃ©aire Ã  la fois des capacitÃ©s de calcul et de stockage, indÃ©pendamment de la demande rÃ©elle. Dans un article volontairement provocateur et intitulÃ© â€œ<em>Big Data is Dead</em>â€ <span class="citation" data-cites="Tigani_2023">(<a href="#ref-Tigani_2023" role="doc-biblioref">Tigani 2023</a>)</span>, Jordan Tigani, lâ€™un des ingÃ©nieurs fondateurs de Google BigQuery, explique pourquoi ce modÃ¨le ne correspond plus Ã  la rÃ©alitÃ© de la plupart des organisations exploitant intensivement de la donnÃ©e. PremiÃ¨rement, parce que â€œdans la pratique, la taille des donnÃ©es augmente beaucoup plus rapidement que les besoins en calculâ€. MÃªme si la quantitÃ© de donnÃ©es gÃ©nÃ©rÃ©es et nÃ©cessitant donc dâ€™Ãªtre stockÃ©es croÃ®t de maniÃ¨re rapide au fil du temps, il nâ€™est gÃ©nÃ©ralement pas nÃ©cessaire dâ€™interroger lâ€™ensemble des donnÃ©es stockÃ©es mais seulement les portions les plus rÃ©centes, ou seulement certaines colonnes et/ou groupes de lignes. Par ailleurs, Tigani souligne que â€œla frontiÃ¨re du <em>big data</em> ne cesse de reculerâ€ : les avancÃ©es dans les capacitÃ©s des serveurs et la baisse des coÃ»ts du matÃ©riel signifient que le nombre de charges de travail ne tenant pas sur une seule machine â€” une dÃ©finition simple mais efficace du <em>big data</em> â€” a diminuÃ© de maniÃ¨re continue (<a href="#fig-bigdata-frontier" class="quarto-xref">Figure&nbsp;4</a>). Lâ€™apparition de nouveaux formats de donnÃ©es rendant plus efficients Ã  la fois le stockage et le traitement de la donnÃ©e en mÃ©moire participent Ã©galement Ã  cette dynamique (voir <a href="#sec-new-formats" class="quarto-xref">Section&nbsp;2</a>). En consÃ©quence, en sÃ©parant correctement les fonctions de stockage et de calcul, mÃªme les traitements de donnÃ©es substantiels peuvent finir par utiliser â€œbeaucoup moins de calcul que prÃ©vu [â€¦] et pourraient mÃªme ne pas avoir besoin dâ€™un traitement distribuÃ© du toutâ€. Ces enseignements plaident donc de maniÃ¨re gÃ©nÃ©rale pour le choix dâ€™infrastructures dans lesquelles ressources de calcul et de stockage sont le plus faiblement couplÃ©es possibles.</p>
<div id="fig-bigdata-frontier" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-bigdata-frontier-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../bigdatafrontier.jpg" class="quarto-figure quarto-figure-center figure-img" height="350">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-bigdata-frontier-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: â€œ<em>The big data frontier keeps receding</em>â€ : la part des traitements de donnÃ©es ne pouvant Ãªtre rÃ©alisÃ©s sur une seule machine a continuellement diminuÃ© au cours de la derniÃ¨re dÃ©cennie. Source : <a href="https://motherduck.com/blog/big-data-is-dead/">motherduck.com</a>
</figcaption>
</figure>
</div>
</section>
<section id="lapport-des-technologies-cloud" class="level2">
<h2 class="anchored" data-anchor-id="lapport-des-technologies-cloud">Lâ€™apport des technologies <em>cloud</em></h2>
<p>Dans la lignÃ©e des observations de Tigani, on observe ces derniÃ¨res annÃ©es une transition marquÃ©e des organisations vers des architectures plus flexibles et faiblement couplÃ©es. Lâ€™avÃ¨nement des technologies <em>cloud</em> a jouÃ© un rÃ´le dÃ©terminant dans cette transition, et ce pour plusieurs raisons. Dâ€™abord, une raison technique : par rapport Ã  lâ€™Ã©poque oÃ¹ <code>Hadoop</code> constituait lâ€™infrastructure <em>big data</em> de rÃ©fÃ©rence, la latence des flux rÃ©seaux est devenue une prÃ©occupation bien moindre, rendant le modÃ¨le de co-localisation du stockage et des ressources de calcul sur de mÃªmes machines moins pertinent. Ensuite, une raison liÃ©e aux usages : si le volume des donnÃ©es gÃ©nÃ©rÃ©es continue de croÃ®tre, câ€™est surtout la diversification des donnÃ©es exploitÃ©es qui marque lâ€™Ã©volution rÃ©cente de lâ€™Ã©co-systÃ¨me. Les infrastructures modernes doivent doivent non seulement Ãªtre capables de traiter de grands volumes, mais aussi Ãªtre adaptables sur de multiples dimensions. Elles doivent pouvoir prendre en charge diverses structures de donnÃ©es (allant des formats structurÃ©s et tabulaires aux formats non structurÃ©s comme le texte, les images, le son et la vidÃ©o) et permettre une large gamme de techniques computationnelles, du calcul parallÃ¨le aux modÃ¨les dâ€™apprentissage profond qui nÃ©cessitent des GPU, ainsi que le dÃ©ploiement et la gestion dâ€™applications <span class="citation" data-cites="li2020big">(<a href="#ref-li2020big" role="doc-biblioref">Li et al. 2020</a>)</span>.</p>
<p>Ces derniÃ¨res annÃ©es, deux technologies intimement liÃ©e au <em>cloud</em> â€” justifiant leur qualificatif de technologies <em>cloud-native</em> â€” ont Ã©mergÃ© comme des solutions essentielles pour atteindre ce besoin dâ€™environnements de calcul plus flexibles : la conteneurisation et le stockage objet. La conteneurisation est une technologie centrale dÃ¨s lors quâ€™on aborde le sujet de la mise en production, dans la mesure oÃ¹ elle permet de garantir la reproductibilitÃ© et la portabilitÃ© des projets, câ€™est Ã  dire leur capacitÃ© Ã  fonctionner correctement dans diffÃ©rents environnements de traitement. Par consÃ©quent, la technologie des conteneurs sera prÃ©sentÃ©e en dÃ©tail dans les chapitres concernant la <a href="../chapters/portability.html">PortabilitÃ©</a> et le <a href="../chapters/deployment.html">DÃ©ploiement</a>. Nous nous concentrons dans cette section sur la deuxiÃ¨me technologie <em>cloud-native</em> devenue un standard dans les infrastructures de donnÃ©es modernes : le stockage objet.</p>
<p>Les conteneurs Ã©tant par construction sans Ã©tat (<em>stateless</em>), il est nÃ©cessaire dans une infrastructure conteneurisÃ©e de prÃ©voir une couche de persistence pour stocker Ã  la fois les donnÃ©es brutes en entrÃ©e des traitements et les donnÃ©es transformÃ©es en sortie de ces derniers (<a href="#fig-types-storage" class="quarto-xref">Figure&nbsp;5</a>). Dans lâ€™Ã©cosystÃ¨me des infrastructures de donnÃ©es conteneurisÃ©es, le stockage dit â€œobjetâ€ sâ€™est progressivement imposÃ© comme rÃ©fÃ©rence, largement popularisÃ©e par lâ€™implÃ©mentation <code>S3</code> (<em>Amazon Simple Storage Service</em>) dâ€™Amazon <span class="citation" data-cites="mesnier2003object samundiswary2017object">(<a href="#ref-mesnier2003object" role="doc-biblioref">Mesnier, Ganger, and Riedel 2003</a>; <a href="#ref-samundiswary2017object" role="doc-biblioref">Samundiswary and Dongre 2017</a>)</span>. Afin de comprendre cette prÃ©dominance, il est utile de comparer ce mode de stockage aux autres modes existants.</p>
<p>SchÃ©matiquement, on peut distinguer trois grandes approches en matiÃ¨re de stockage : le stockage de fichiers (<em>filesystem</em>), le stockage par bloc (<em>block storage</em>) et le stockage dâ€™objets (<em>object storage</em>) (<a href="#fig-types-storage" class="quarto-xref">Figure&nbsp;5</a>). Le stockage de fichiers est le plus intuitif : les donnÃ©es sont organisÃ©es sous forme dâ€™une structure hiÃ©rarchique de rÃ©pertoires et de fichiers â€” comme sur un ordinateur personnel. Facile dâ€™utilisation et adaptÃ© aux environnements traditionnels, ce mode de stockage passe difficilement Ã  lâ€™Ã©chelle et requiert des interventions manuelles pour monter et gÃ©rer les accÃ¨s aux fichiers, ce qui restreint lâ€™autonomie des utilisateurs et nâ€™est pas adaptÃ© aux environnements de traitement Ã©phÃ©mÃ¨res comme les conteneurs. Le stockage par bloc propose un accÃ¨s de bas niveau aux donnÃ©es sous forme de blocs contigus â€” Ã  lâ€™image du stockage sur un disque dur â€” garantissant des performances Ã©levÃ©es et une faible latence. Il sâ€™avÃ¨re donc trÃ¨s pertinent pour des applications qui exigent un accÃ¨s rapide aux donnÃ©es stockÃ©es, comme une base de donnÃ©es. En revanche, il passe lÃ  encore difficilement Ã  lâ€™Ã©chelle du fait du coÃ»t de la technologie et de la difficultÃ© Ã  faire croÃ®tre horizontalement ce type de stockage. Enfin, le stockage objet divise quant Ã  lui les fichiers de donnÃ©es en morceaux appelÃ©s â€œobjetsâ€ qui sont ensuite stockÃ©s dans un rÃ©fÃ©rentiel unique, qui peut Ãªtre distribuÃ© sur plusieurs machines. Chaque objet se voit attribuer un certain nombre de mÃ©tadonnÃ©es (nom de lâ€™objet, taille, date de crÃ©ation, etc.) dont un identifiant unique qui permet au systÃ¨me de retrouver lâ€™objet sans la nÃ©cessitÃ© dâ€™une structure hiÃ©rarchique comme celle dâ€™un <em>filesystem</em>, ce qui rÃ©duit drastiquement le coÃ»t du stockage.</p>
<div id="fig-types-storage" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-types-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../types-storage.png" class="quarto-figure quarto-figure-center figure-img" height="250">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-types-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;5: Comparaison des principaux systÃ¨mes de stockage de la donnÃ©e. Source : <a href="https://blog.bytebytego.com/p/storage-systems-overview">bytebytego.com</a>
</figcaption>
</figure>
</div>
<p>Les diffÃ©rentes propriÃ©tÃ©s du stockage objet le rendent particuliÃ¨rement pertinent pour construire une infrastructure conteneurisÃ©e pour la <em>data science</em>. Dâ€™abord, il est optimisÃ© pour la scalabilitÃ© : les objets stockÃ©s ne sont pas limitÃ©s en taille et la technologie sous-jacente permet un stockage efficient de fichiers potentiellement trÃ¨s volumineux, si besoin en les distribuant horizontalement. Ensuite, il est source dâ€™autonomie pour les utilisateurs : en stockant les donnÃ©es sous forme dâ€™objets enrichis de mÃ©tadonnÃ©es et accessibles via lâ€™API standardisÃ©e <code>S3</code> dâ€™Amazon (<a href="#fig-types-storage" class="quarto-xref">Figure&nbsp;5</a>), il permet aux utilisateurs dâ€™interagir directement avec le stockage via leur code applicatif (en <code>R</code>, <code>Python</code>, etc.) tout en offrant une gestion trÃ¨s fine des permissions â€” jusquâ€™aux droits sur un fichier â€” vie des jetons dâ€™accÃ¨s, garantissant ainsi une traÃ§abilitÃ© accrue des opÃ©rations effectuÃ©es. Enfin, le stockage objet joue un rÃ´le clÃ© dans lâ€™objectif de construction dâ€™une infrastructure dÃ©couplÃ©e comme celle Ã©voquÃ©e prÃ©cÃ©demment. Dans la mesure oÃ¹ les dÃ©pÃ´ts de donnÃ©es â€” appelÃ©s <em>â€œbucketsâ€</em> â€” sont interrogeables via des requÃªtes <code>HTTP</code> standards, les environnements de calcul peuvent importer par le biais du rÃ©seau les donnÃ©es nÃ©cessaires aux traitements rÃ©alisÃ©s. Ainsi, les ressources de stockage et de calcul nâ€™ont plus besoin dâ€™Ãªtre sur les mÃªmes machines ni mÃªme nÃ©cessairement dans le mÃªme lieu, et peuvent ainsi Ã©voluer indÃ©pendamment en fonction des besoins spÃ©cifiques de lâ€™organisation.</p>
<div id="fig-minio-s3" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-minio-s3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../minio-s3.png" class="quarto-figure quarto-figure-center figure-img" height="300">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-minio-s3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;6: Dans une infrastructure basÃ©e sur des conteneurs â€” <em>stateless</em> par construction â€” le stockage objet permet de fournir la couche de persistence. MinIO est une solution open-source de stockage objet qui sâ€™intÃ¨gre nativement avec Kubernetes. Par ailleurs, elle est compatible avec lâ€™API S3, qui est devenu le standard dominant pour lâ€™interaction avec des systÃ¨mes de stockage objet. Ce systÃ¨me de stockage est donc par construction interopÃ©rable avec diffÃ©rents environnements de calcul. Source : <a href="https://www.lemondeinformatique.fr/actualites/lire-les-donnees-sont-plus-importantes-que-le-cloud--assure-minio%C2%A0%C2%A0-77730.html">lemondeinformatique.fr</a>
</figcaption>
</figure>
</div>
</section>
</section>
<section id="sec-new-formats" class="level1">
<h1>Formats de donnÃ©es</h1>
<p>Une autre dimension majeure Ã  considÃ©rer pour le traitement des donnÃ©es massives est la maniÃ¨re dont on stocke ces donnÃ©es. Le choix dâ€™un format de donnÃ©es repose sur un arbitrage entre plusieurs critÃ¨res, notamment la finalitÃ© (traitement, analyse, diffusionâ€¦), le public cible (population gÃ©nÃ©rale, membres du projet, etc.), la volumÃ©trie et lâ€™interopÃ©rabilitÃ©. Les formats classiques comme le CSV, le JSON ou le XML sont largement utilisÃ©s pour le traitement et la diffusion de donnÃ©es, en particulier pour leur praticitÃ© : ils sont au format texte, ce qui les rend facilement prÃ©visualisables dans un Ã©diteur â€” on dit quâ€™ils sont â€œ<em>human-readable</em>â€. Par ailleurs, ils sont naturellement interopÃ©rables : le texte peut Ãªtre lu simplement depuis nâ€™importe quel langage de programmation, et les diffÃ©rentes librairies de lecture de fichiers intÃ¨gre nativement leur lecture. NÃ©anmoins, ces formats montrent rapidement leurs limites face aux besoins dâ€™analyse sur des donnÃ©es massives. Leur absence de compression entraÃ®ne une consommation Ã©levÃ©e dâ€™espace disque. Par ailleurs, leur reprÃ©sentation sous forme de lignes (<a href="#fig-columnar-storage" class="quarto-xref">Figure&nbsp;7</a>) Ã  la fois sur disque et en mÃ©moire les rend peu efficients, dans la mesure oÃ¹ il est nÃ©cessaire de charger un fichier entier pour pouvoir effectuer des opÃ©rations statistiques sur les colonnes et/ou les lignes.</p>
<p>Une innovation majeure de la derniÃ¨re dÃ©cennie au sein de lâ€™Ã©co-systÃ¨me de la donnÃ©e est lâ€™Ã©mergence de formats de donnÃ©es qui pallient les diffÃ©rentes limites des formats traditionnels prÃ©cÃ©demment Ã©voquÃ©es. Le format le plus populaire Ã  ce titre, et qui est ainsi devenu un vÃ©ritable standard pour le stockage de donnÃ©es, est le format <code>Apache Parquet</code>. Ce format prÃ©sente en effet un ensemble de caractÃ©ristiques qui le rendent particuliÃ¨rement adaptÃ© aux applications de <em>data science</em>. Dâ€™abord, il sâ€™agit dâ€™un format compressÃ©, ce qui en fait un format trÃ¨s adaptÃ© au stockage de donnÃ©es volumineuses. Si le degrÃ© de compression dÃ©pend intimement de la structure des donnÃ©es, il nâ€™est pas rare de voir un mÃªme jeu de donnÃ©es occuper 10 fois moins de place en <code>Parquet</code> quâ€™en <code>CSV</code>. Ensuite, le format <code>Parquet</code> est interopÃ©rable : les fichiers de ce format peuvent Ãªtre aussi bien requÃªtÃ©s Ã  partir de langages courants (comme <code>Python</code>, <code>R</code> ou <code>SQL</code>) quâ€™avec des langages dÃ©diÃ©s au traitement des donnÃ©es massives comme <code>Spark</code>.</p>
<p>Mais le facteur essentiel qui explique lâ€™adoption gÃ©nÃ©ralisÃ©e du format <code>Parquet</code> dans les applications de <em>data science</em> est sa performance en lecture. Sâ€™agissant dâ€™un format compressÃ©, on pourrait intuitivement sâ€™attendre Ã  des performances infÃ©rieures comparÃ© Ã  la lecture des mÃªmes donnÃ©es sous la forme dâ€™un fichier texte : si lâ€™on compresse un fichier <code>CSV</code> au format <code>zip</code> par exemple, il faut payer un coÃ»t de dÃ©compression pour pouvoir lire le fichier. Au contraire, la compression des donnÃ©es en <code>Parquet</code> est trÃ¨s optimisÃ©e, ce qui permet des performances en lecture bien supÃ©rieures Ã  celle dâ€™un fichier <code>CSV</code>. Une propriÃ©tÃ© essentielle du format <code>Parquet</code> pour comprendre cette performance en lecture est le fait quâ€™il soit â€œorientÃ©-colonneâ€, câ€™est Ã  dire que les donnÃ©es sont stockÃ©es sous forme de colonnes et non de lignes comme dans les formats textuels traditionnels (<a href="#fig-columnar-storage" class="quarto-xref">Figure&nbsp;7</a>). Cette propriÃ©tÃ© le rend particuliÃ¨rement adaptÃ© pour la <em>data science</em> dans la mesure oÃ¹ la plupart des opÃ©rations statistiques sont de nature analytique (dites OLAP - <em>Online Analytical Processing</em>) : elles impliquent la sÃ©lection de colonnes spÃ©cifiques, le calcul de nouvelles variables, la rÃ©alisation dâ€™agrÃ©gations basÃ©es sur des groupes, etc. Le stockage orientÃ© ligne â€” comme dans un fichier CSV â€” nâ€™est pas adaptÃ© Ã  ces opÃ©rations analytiques, car il nÃ©cessite de charger lâ€™ensemble du jeu de donnÃ©es en mÃ©moire afin dâ€™effectuer une requÃªte. Ã€ lâ€™inverse, le stockage orientÃ© colonne permet de ne lire que les colonnes de donnÃ©es pertinentes, ce qui rÃ©duit considÃ©rablement les temps de lecture et de traitement pour ces charges de travail analytiques <span class="citation" data-cites="abdelaziz2023optimizing">(<a href="#ref-abdelaziz2023optimizing" role="doc-biblioref">Abdelaziz et al. 2023</a>)</span>. En pratique, les formats colonnes populaires tels que <code>Parquet</code> utilisent une reprÃ©sentation hybride : ils sont principalement orientÃ©s colonne, mais intÃ¨grent Ã©galement un regroupement astucieux basÃ© sur les lignes pour optimiser les requÃªtes de filtrage.</p>
<div id="fig-columnar-storage" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-columnar-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../columnar-storage.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-columnar-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;7: ReprÃ©sentation orientÃ©e ligne et orientÃ©e colonne dâ€™un mÃªme jeu de donnÃ©es.
</figcaption>
</figure>
</div>
<p>Une autre propriÃ©tÃ© importante du format <code>Parquet</code> est sa capacitÃ© native Ã  produire des fichiers partitionnÃ©s, câ€™est Ã  dire Ã  distribuer un fichier de donnÃ©es selon une ou plusieurs clÃ©s de partitionnement. Dans la majoritÃ© des cas, les traitements statistiques ne concernent pas lâ€™ensemble des donnÃ©es dâ€™une source de donnÃ©es : on voudra souvent restreindre les calculs Ã  une zone gÃ©ographique, une fenÃªtre temporelle, etc. Si les donnÃ©es Ã  traiter sont disponibles sous la forme dâ€™un unique fichier, il faudra gÃ©nÃ©ralement charger lâ€™ensemble des donnÃ©es en mÃ©moire â€” a minima, les colonnes pertinentes â€” pour rÃ©aliser les traitements. A contrario, <code>Parquet</code> offre la possibilitÃ© native de partitionner un jeu de donnÃ©es selon une variable de filtrage frÃ©quente â€” Ã  la maniÃ¨re dâ€™un index dans une base <code>SQL</code> â€” ce qui permet dâ€™optimiser les traitements et dâ€™accroÃ®tre encore leur efficience (<a href="#fig-parquet-partitions" class="quarto-xref">Figure&nbsp;8</a>). LÃ  encore, cette propriÃ©tÃ© rend le format <code>Parquet</code> particuliÃ¨rement pertinent pour les traitements analytiques qui caractÃ©risent les applications de <em>data science</em> <span class="citation" data-cites="dondon2023quels">(<a href="#ref-dondon2023quels" role="doc-biblioref">Dondon and Lamarche 2023</a>)</span>.</p>
<div id="fig-parquet-partitions" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-parquet-partitions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../parquet-partition.png" class="quarto-figure quarto-figure-center figure-img" height="300">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-parquet-partitions-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;8: ReprÃ©sentation sur le <em>filesystem</em> dâ€™un fichier <code>Parquet</code> partitionnÃ© selon deux clÃ©s : lâ€™annÃ©e et le mois. Dans cet exemple, effectuer une requÃªte faisant intervenir seulement un ou quelques mois de donnÃ©es serait trÃ¨s efficient dans la mesure oÃ¹ seules les partitions pertinentes auront besoin dâ€™Ãªtre chargÃ©es en mÃ©moire.
</figcaption>
</figure>
</div>
</section>
<section id="frameworks-de-traitement" class="level1">
<h1><em>Frameworks</em> de traitement</h1>
<p>Le format <code>Parquet</code> rend le stockage de donnÃ©es au format tabulaire beaucoup plus efficient. Mais pour pleinement bÃ©nÃ©ficier de cette structure de donnÃ©es, il est Ã©galement nÃ©cessaire de sâ€™intÃ©resser Ã  lâ€™Ã©tape suivante : le traitement des donnÃ©es en mÃ©moire.</p>
<p>Deux outils majeurs ont Ã©mergÃ© Ã  cette fin au cours des derniÃ¨res annÃ©es. Le premier est <a href="https://arrow.apache.org/">Apache Arrow</a>, un format tabulaire de donnÃ©es en mÃ©moire interopÃ©rable entre de nombreux langages (<code>Python</code>, <code>R</code>, <code>Java</code>, etc.). Le second est <a href="https://duckdb.org/"><code>DuckDB</code></a>, un systÃ¨me de base de donnÃ©es portable et interopÃ©rable permettant de requÃªter des sources de donnÃ©es de nature trÃ¨s variÃ©e (<a href="#fig-duckdb-multisrc" class="quarto-xref">Figure&nbsp;10</a>). Ces deux outils, bien que techniquement trÃ¨s diffÃ©rents en termes dâ€™implÃ©mentation, prÃ©sentent des avantages et des gains de performance semblables. Dâ€™abord, ils sont tous deux orientÃ©s-colonne et travaillent ainsi en synergie avec le format <code>Parquet</code>, dans la mesure oÃ¹ ils font persister les bÃ©nÃ©fices de ce format de stockage dans la mÃ©moire (<a href="#fig-arrow-memory" class="quarto-xref">Figure&nbsp;9</a>).</p>
<div id="fig-arrow-memory" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-arrow-memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../arrow-memory.png" class="quarto-figure quarto-figure-center figure-img" height="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-arrow-memory-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;9: ReprÃ©sentation en mÃ©moire des donnÃ©es au format <code>Arrow</code>. Avec ce format, le stockage en mÃ©moire est Ã©galement orientÃ©-colonne. Cela permet dâ€™une part de faire perdurer en mÃ©moire les avantages du format <code>Parquet</code> pour le stockage, et dâ€™autre part dâ€™exploiter les avancÃ©es des processeurs rÃ©cents en matiÃ¨re de vectorisation des opÃ©rations. Dans cet exemple, la reprÃ©sentation en colonne des donnÃ©es dans la mÃ©moire permet Ã  la requÃªte de filtrage sur les donnÃ©es de la colonne <code>session_id</code> dâ€™Ãªtre beaucoup plus efficiente que dans un format en mÃ©moire traditionnel. <em>Source</em>: <a href="https://arrow.apache.org/overview/">Documentation officielle du projet <code>Arrow</code></a>
</figcaption>
</figure>
</div>
<p>Par ailleurs, <code>Arrow</code> comme <code>DuckDB</code> permettent tous deux dâ€™augmenter considÃ©rablement les performances des requÃªtes sur les donnÃ©es grÃ¢ce Ã  lâ€™utilisation de la <em>lazy evaluation</em> (â€œÃ©valuation paresseuseâ€). LÃ  oÃ¹ les opÃ©rations sur des donnÃ©es sont gÃ©nÃ©ralement exÃ©cutÃ©es de maniÃ¨re linÃ©aire par les langages de programmation â€” par exemple, sÃ©lectionner des colonnes et/ou filtrer des lignes, puis calculer de nouvelles colonnes, puis effectuer des agrÃ©gations, etc. â€” <code>Arrow</code> et <code>DuckDB</code> exÃ©cutent quant Ã  eux ces derniÃ¨res selon un plan dâ€™exÃ©cution prÃ©-calculÃ© qui optimise de maniÃ¨re globale la chaÃ®ne de traitements. Dans ce paradigme, les calculs sont non seulement beaucoup plus performants, mais Ã©galement beaucoup plus efficients dans la mesure oÃ¹ ils nâ€™impliquent de rÃ©cupÃ©rer que les donnÃ©es effectivement nÃ©cessaires pour les traitements demandÃ©s. Ces innovations permettent ainsi dâ€™envisager des traitements basÃ©s sur des donnÃ©es dont le volume total dÃ©passe la mÃ©moire RAM effectivement disponible sur une machine.</p>
<div id="fig-duckdb-multisrc" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-duckdb-multisrc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../duckdb-multisrc.png" class="quarto-figure quarto-figure-center figure-img" height="400">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-duckdb-multisrc-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;10: Un avantage majeur de <code>DuckDB</code> est sa capacitÃ© Ã  requÃªter de maniÃ¨re standardisÃ©e des sources de donnÃ©es trÃ¨s variÃ©es. DuckDB Ã©tant un format de base de donnÃ©es en mÃ©moire, il est naturellement trÃ¨s adaptÃ© au requÃªtage de bases de donnÃ©es relationnelles (comme PostgreSQL ou MySQL). Mais ce <em>framework</em> peut Ã©galement requÃªter de la mÃªme maniÃ¨re des fichiers de donnÃ©es (<code>CSV</code>, <code>Parquet</code>, etc.), quâ€™ils soient locaux ou stockÃ©s dans le <em>cloud</em>. <em>Source</em>: <a href="https://motherduck.com/blog/duckdb-enterprise-5-key-categories/"><code>MotherDuck</code></a>
</figcaption>
</figure>
</div>
<p>La meilleure maniÃ¨re de se convaincre de lâ€™apport du format <code>Parquet</code> consiste Ã  tester celui-ci et Ã  la comparer avec la mÃªme donnÃ©e enregistrÃ©e sous la forme dâ€™un CSV, Ã  la maniÃ¨re de la <a href="#fig-tableau-parquet" class="quarto-xref">Figure&nbsp;11</a>. Les applications proposÃ©es ci-dessous proposent dâ€™illustrer les concepts Ã©voquÃ©s prÃ©cÃ©demment (<em>lazy evaluation</em>, partionnemement, etc.) et les deux Ã©cosystÃ¨mes mentionnÃ©s (<code>Arrow</code> et <code>DuckDB</code>) Ã  partir dâ€™exemples simples, montrant la simplicitÃ© dâ€™usage de ceux-ci lorsquâ€™on est familier du traitement de donnÃ©es. Lâ€™<a href="../chapters/application.html">application fil rouge</a> est plus succincte sur la partie <code>Parquet</code>.</p>
<div id="fig-tableau-parquet" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-tableau-parquet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/slides/img/tableau-perf-parquet.png" class="img-fluid figure-img" style="width:80.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-tableau-parquet-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;11: Exemple de comparaison des performances du format <code>Parquet</code> dans plusieurs cas dâ€™usage sur les donnÃ©es dÃ©taillÃ©es du recensement de la population diffusÃ©es par lâ€™Insee en 2023
</figcaption>
</figure>
</div>
</section>
<section id="applications" class="level1">
<h1>Applications</h1>
<p>Tout au long de cette application, nous allons voir comment utiliser le format <code>Parquet</code> de la maniÃ¨re la plus efficiente possible. Afin de comparer les diffÃ©rents formats et mÃ©thodes dâ€™utilisation, nous allons <strong>comparer le temps dâ€™exÃ©cution et lâ€™usage mÃ©moire dâ€™une requÃªte standard</strong>. CommenÃ§ons dÃ©jÃ , sur un premier exemple avec une donnÃ©e lÃ©gÃ¨re, pour comparer les formats <code>CSV</code> et <code>Parquet</code>.</p>
<p>Pour cela, nous allons avoir besoin de rÃ©cupÃ©rer des donnÃ©es au format <code>Parquet</code>. Nous proposons dâ€™utiliser les donnÃ©es dÃ©taillÃ©es et anonymisÃ©es du recensement de la population franÃ§aise : environ 20 millions de lignes pour 80 colonnes. Le code pour rÃ©cupÃ©rer celles-ci est donnÃ© ci-dessous</p>
<div id="c9f6d089" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Code</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="annotated-cell-1" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-1-1"><a href="#annotated-cell-1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.parquet <span class="im">as</span> pq</span>
<span id="annotated-cell-1-2"><a href="#annotated-cell-1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow <span class="im">as</span> pa</span>
<span id="annotated-cell-1-3"><a href="#annotated-cell-1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="annotated-cell-1-4"><a href="#annotated-cell-1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-5"><a href="#annotated-cell-1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># DÃ©finir le fichier de destination</span></span>
<span id="annotated-cell-1-6"><a href="#annotated-cell-1-6" aria-hidden="true" tabindex="-1"></a>filename_table_individu <span class="op">=</span> <span class="st">"data/RPindividus.parquet"</span></span>
<span id="annotated-cell-1-7"><a href="#annotated-cell-1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-8"><a href="#annotated-cell-1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Copier le fichier depuis le stockage distant (remplacer par une mÃ©thode adaptÃ©e si nÃ©cessaire)</span></span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-1" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-1-9" class="code-annotation-target"><a href="#annotated-cell-1-9" aria-hidden="true" tabindex="-1"></a>os.system(<span class="st">"mc cp s3/projet-formation/bonnes-pratiques/data/RPindividus.parquet data/RPindividus.parquet"</span>)</span>
<span id="annotated-cell-1-10"><a href="#annotated-cell-1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-11"><a href="#annotated-cell-1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Charger le fichier Parquet</span></span>
<span id="annotated-cell-1-12"><a href="#annotated-cell-1-12" aria-hidden="true" tabindex="-1"></a>table <span class="op">=</span> pq.read_table(filename_table_individu)</span>
<span id="annotated-cell-1-13"><a href="#annotated-cell-1-13" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> table.to_pandas()</span>
<span id="annotated-cell-1-14"><a href="#annotated-cell-1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-15"><a href="#annotated-cell-1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Filtrer les donnÃ©es pour REGION == "24"</span></span>
<span id="annotated-cell-1-16"><a href="#annotated-cell-1-16" aria-hidden="true" tabindex="-1"></a>df_filtered <span class="op">=</span> df.loc[df[<span class="st">"REGION"</span>] <span class="op">==</span> <span class="st">"24"</span>]</span>
<span id="annotated-cell-1-17"><a href="#annotated-cell-1-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-18"><a href="#annotated-cell-1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Sauvegarder en CSV</span></span>
<span id="annotated-cell-1-19"><a href="#annotated-cell-1-19" aria-hidden="true" tabindex="-1"></a>df_filtered.to_csv(<span class="st">"data/RPindividus_24.csv"</span>, index<span class="op">=</span><span class="va">False</span>)</span>
<span id="annotated-cell-1-20"><a href="#annotated-cell-1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-1-21"><a href="#annotated-cell-1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Sauvegarder en Parquet</span></span>
<span id="annotated-cell-1-22"><a href="#annotated-cell-1-22" aria-hidden="true" tabindex="-1"></a>pq.write_table(pa.Table.from_pandas(df_filtered), <span class="st">"data/RPindividus_24.parquet"</span>)</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-1" data-target-annotation="1">1</dt>
<dd>
<span data-code-cell="annotated-cell-1" data-code-lines="9" data-code-annotation="1">Cette ligne de code utilise lâ€™utilitaire Minio Client disponible sur le <code>SSPCloud</code>. Si vous nâ€™Ãªtes pas sur cette infrastructure, vous pouvez vous rÃ©fÃ©rer Ã  la boite dÃ©diÃ©e</span>
</dd>
</dl>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Si vous nâ€™Ãªtes pas sur le <code>SSPCloud</code>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Vous devrez remplacer la ligne</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" data-code-line-numbers=""><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>os.system(<span class="st">"mc cp s3/projet-formation/bonnes-pratiques/data/RPindividus.parquet data/RPindividus.parquet"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p>qui utilise lâ€™outil en ligne de commande <code>mc</code> par un code tÃ©lÃ©chargeant cette donnÃ©e Ã  partir de lâ€™URL <a href="https://projet-formation.minio.lab.sspcloud.fr/bonnes-pratiques/data/RPindividus.parquet">https://projet-formation.minio.lab.sspcloud.fr/bonnes-pratiques/data/RPindividus.parquet</a>.</p>
<p>Il y a de nombreuses maniÃ¨res de faire. Vous pouvez par exemple le faire en pur <code>Python</code> avec <code>requests</code>. Si vous avez <code>curl</code> installÃ©, vous pouvez aussi lâ€™utiliser. Par lâ€™intermÃ©diaire de <code>Python</code>, cela donnera la commande <code>os.system("curl -o data/RPindividus.parquet https://projet-formation/bonnes-pratiques/data/RPindividus.parquet")</code>.</p>
</div>
</div>
</div>
<p>Ces exercices vont utiliser des dÃ©corateurs <code>Python</code>, câ€™est-Ã -dire des fonctions qui surchargent le comportement dâ€™une autre fonction. En lâ€™occurrence, nous allons crÃ©er une fonction exÃ©cutant une chaine dâ€™opÃ©rations et la surcharger avec une autre chargÃ©e de contrÃ´ler lâ€™usage mÃ©moire et le temps dâ€™exÃ©cution.</p>
<div class="callout callout-style-default callout-application callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Application</span>Partie 1 : Du <code>CSV</code> au <code>Parquet</code>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<ul>
<li><p>CrÃ©er un notebook <code>benchmark_parquet.ipynb</code> afin de rÃ©aliser les diffÃ©rentes comparaisons de performance de lâ€™application</p></li>
<li><p>CrÃ©ons notre dÃ©corateur, en charge de <em>benchmarker</em> le code <code>Python</code>:</p>
<div id="172c35de" class="cell" data-execution_count="3">
<details class="code-fold">
<summary>DÃ©rouler pour retrouver le code du dÃ©corateur permettant de mesurer la performance</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb2" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> memory_profiler <span class="im">import</span> memory_usage</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> wraps</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> convert_size(size_bytes):</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> size_bytes <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> <span class="st">"0B"</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>  size_name <span class="op">=</span> (<span class="st">"B"</span>, <span class="st">"KB"</span>, <span class="st">"MB"</span>, <span class="st">"GB"</span>, <span class="st">"TB"</span>, <span class="st">"PB"</span>, <span class="st">"EB"</span>, <span class="st">"ZB"</span>, <span class="st">"YB"</span>)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  i <span class="op">=</span> <span class="bu">int</span>(math.floor(math.log(size_bytes, <span class="dv">1024</span>)))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>  p <span class="op">=</span> math.<span class="bu">pow</span>(<span class="dv">1024</span>, i)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>  s <span class="op">=</span> <span class="bu">round</span>(size_bytes <span class="op">/</span> p, <span class="dv">2</span>)</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="st">"</span><span class="sc">%s</span><span class="st"> </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> (s, size_name[i])</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Decorator to measure execution time and memory usage</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>  <span class="kw">def</span> measure_performance(func, return_output<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">@wraps</span>(func)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>      <span class="kw">def</span> wrapper(return_output<span class="op">=</span><span class="va">False</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>          warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>          start_time <span class="op">=</span> time.time()</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a>          mem_usage <span class="op">=</span> memory_usage((func, args, kwargs), interval<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a>          end_time <span class="op">=</span> time.time()</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>          warnings.filterwarnings(<span class="st">"always"</span>)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>          exec_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>          peak_mem <span class="op">=</span> <span class="bu">max</span>(mem_usage)  <span class="co"># Peak memory usage</span></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>          exec_time_formatted <span class="op">=</span> <span class="ss">f"</span><span class="ch">\033</span><span class="ss">[92m</span><span class="sc">{</span>exec_time<span class="sc">:.4f}</span><span class="ss"> sec</span><span class="ch">\033</span><span class="ss">[0m"</span></span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>          peak_mem_formatted <span class="op">=</span> <span class="ss">f"</span><span class="ch">\033</span><span class="ss">[92m</span><span class="sc">{</span>convert_size(<span class="dv">1024</span><span class="op">*</span>peak_mem)<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m"</span></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>          <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>func<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss"> - Execution Time: </span><span class="sc">{</span>exec_time_formatted<span class="sc">}</span><span class="ss"> | Peak Memory Usage: </span><span class="sc">{</span>peak_mem_formatted<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> return_output <span class="kw">is</span> <span class="va">True</span>:</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a>              <span class="cf">return</span> func(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> wrapper</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div></li>
<li><p>La requÃªte suivante permet de calculer les donnÃ©es pour construire une pyramide des Ã¢ges sur un dÃ©partement donnÃ©, Ã  partir du fichier <code>CSV</code> du recensement. La tester dans votre <em>notebook</em>:</p>
<div id="581b17f8" class="cell" data-execution_count="4">
<details class="code-fold">
<summary>DÃ©rouler pour rÃ©cupÃ©rer le code de lecture du CSV</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb3" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Charger le fichier CSV</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.read_csv(<span class="st">"data/RPindividus_24.csv"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>res <span class="op">=</span> (</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    df.loc[df[<span class="st">"DEPT"</span>] <span class="op">==</span> <span class="dv">36</span>]</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    .groupby([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])[<span class="st">"IPONDI"</span>]</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    .<span class="bu">sum</span>().reset_index()</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    .rename(columns<span class="op">=</span>{<span class="st">"IPONDI"</span>: <span class="st">"n_indiv"</span>})</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div></li>
<li><p>Reprendre ce code pour encapsuler ces opÃ©rations dans une fonction <code>process_csv_appli1</code> :</p>
<div id="24c88c0a" class="cell" data-execution_count="5">
<details class="code-fold">
<summary>DÃ©rouler pour rÃ©cupÃ©rer le code pour mesurer les performances de la lecture en CSV</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb4" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the decorator to functions</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_csv_appli1(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(<span class="st">"data/RPindividus_24.csv"</span>)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        df.loc[df[<span class="st">"DEPT"</span>] <span class="op">==</span> <span class="dv">36</span>]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])[<span class="st">"IPONDI"</span>]</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">sum</span>().reset_index()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>        .rename(columns<span class="op">=</span>{<span class="st">"IPONDI"</span>: <span class="st">"n_indiv"</span>})</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div></li>
<li><p>ExÃ©cuter <code>process_csv_appli1()</code> et <code>process_csv_appli1(return_output=True)</code></p></li>
<li><p>Sur le mÃªme modÃ¨le, construire une fonction <code>process_parquet_appli1</code> basÃ©e cette fois sur le fichier <code>data/RPindividus_24.parquet</code> chargÃ© avec la fonction <a href="https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html">read_parquet</a> de <code>Pandas</code></p></li>
<li><p>Comparer les performances (temps dâ€™exÃ©cution et allocation mÃ©moire) de ces deux mÃ©thodes grÃ¢ce Ã  la fonction.</p></li>
</ul>
<div id="b5a5f756" class="cell" data-execution_count="6">
<details class="code-fold">
<summary>Code complet de lâ€™application</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb5" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> math</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> memory_profiler <span class="im">import</span> memory_usage</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> wraps</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> warnings</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> convert_size(size_bytes):</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>   <span class="cf">if</span> size_bytes <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>       <span class="cf">return</span> <span class="st">"0B"</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>   size_name <span class="op">=</span> (<span class="st">"B"</span>, <span class="st">"KB"</span>, <span class="st">"MB"</span>, <span class="st">"GB"</span>, <span class="st">"TB"</span>, <span class="st">"PB"</span>, <span class="st">"EB"</span>, <span class="st">"ZB"</span>, <span class="st">"YB"</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>   i <span class="op">=</span> <span class="bu">int</span>(math.floor(math.log(size_bytes, <span class="dv">1024</span>)))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>   p <span class="op">=</span> math.<span class="bu">pow</span>(<span class="dv">1024</span>, i)</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>   s <span class="op">=</span> <span class="bu">round</span>(size_bytes <span class="op">/</span> p, <span class="dv">2</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>   <span class="cf">return</span> <span class="st">"</span><span class="sc">%s</span><span class="st"> </span><span class="sc">%s</span><span class="st">"</span> <span class="op">%</span> (s, size_name[i])</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Decorator to measure execution time and memory usage</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> measure_performance(func, return_output<span class="op">=</span><span class="va">False</span>):</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">@wraps</span>(func)</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> wrapper(return_output<span class="op">=</span><span class="va">False</span>, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>        warnings.filterwarnings(<span class="st">"ignore"</span>)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>        start_time <span class="op">=</span> time.time()</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>        mem_usage <span class="op">=</span> memory_usage((func, args, kwargs), interval<span class="op">=</span><span class="fl">0.1</span>)</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        end_time <span class="op">=</span> time.time()</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        warnings.filterwarnings(<span class="st">"always"</span>)</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>        exec_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>        peak_mem <span class="op">=</span> <span class="bu">max</span>(mem_usage)  <span class="co"># Peak memory usage</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>        exec_time_formatted <span class="op">=</span> <span class="ss">f"</span><span class="ch">\033</span><span class="ss">[92m</span><span class="sc">{</span>exec_time<span class="sc">:.4f}</span><span class="ss"> sec</span><span class="ch">\033</span><span class="ss">[0m"</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>        peak_mem_formatted <span class="op">=</span> <span class="ss">f"</span><span class="ch">\033</span><span class="ss">[92m</span><span class="sc">{</span>convert_size(<span class="dv">1024</span><span class="op">*</span>peak_mem)<span class="sc">}</span><span class="ch">\033</span><span class="ss">[0m"</span></span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>func<span class="sc">.</span><span class="va">__name__</span><span class="sc">}</span><span class="ss"> - Execution Time: </span><span class="sc">{</span>exec_time_formatted<span class="sc">}</span><span class="ss"> | Peak Memory Usage: </span><span class="sc">{</span>peak_mem_formatted<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> return_output <span class="kw">is</span> <span class="va">True</span>:</span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> func(<span class="op">*</span>args, <span class="op">**</span>kwargs)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> wrapper</span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Apply the decorator to functions</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_csv(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_csv(<span class="st">"data/RPindividus_24.csv"</span>)</span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a>        df.loc[df[<span class="st">"DEPT"</span>] <span class="op">==</span> <span class="dv">36</span>]</span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])[<span class="st">"IPONDI"</span>]</span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">sum</span>().reset_index()</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a>        .rename(columns<span class="op">=</span>{<span class="st">"IPONDI"</span>: <span class="st">"n_indiv"</span>})</span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_parquet(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> pd.read_parquet(<span class="st">"data/RPindividus_24.parquet"</span>)</span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a>        df.loc[df[<span class="st">"DEPT"</span>] <span class="op">==</span> <span class="st">"36"</span>]</span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a>        .groupby([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])[<span class="st">"IPONDI"</span>]</span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>        .<span class="bu">sum</span>().reset_index()</span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a>        .rename(columns<span class="op">=</span>{<span class="st">"IPONDI"</span>: <span class="st">"n_indiv"</span>})</span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a>process_csv()</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a>process_parquet()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</div>
</div>
</div>
<p><em>â“ï¸ Quelle semble Ãªtre la limite de la fonction <code>read_parquet</code> ?</em></p>
<p>On gagne dÃ©jÃ  un temps consÃ©quent en lecture mais on ne bÃ©nÃ©ficie pas vraiment de lâ€™optimisation permise par <code>Parquet</code> car on transforme les donnÃ©es directement aprÃ¨s la lecture en <code>DataFrame</code> <code>Pandas</code>. On nâ€™utilise donc pas lâ€™une des fonctionnalitÃ©s principales du format <code>Parquet</code>, qui explique ses excellentes performances: le <em>predicate pushdown</em> qui consiste Ã  optimiser notre traitement pour faire remonter, le plus tÃ´t possible, les filtres sur les colonnes pour ne garder que celles vraiment utilisÃ©es dans le traitement.</p>
<div class="callout callout-style-default callout-application callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Application</span>Partie 2 : Exploiter la <em>lazy evaluation</em> et les optimisations dâ€™<code>Arrow</code> ou de <code>DuckDB</code>
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>La partie prÃ©cÃ©dente a montrÃ© un <strong>gain de temps considÃ©rable</strong> du passage de <code>CSV</code> Ã  <code>Parquet</code>. NÃ©anmoins, lâ€™<strong>utilisation mÃ©moire Ã©tait encore trÃ¨s Ã©levÃ©e</strong> alors quâ€™on utilise de fait quâ€™une infime partie du fichier.</p>
<p>Dans cette partie, on va voir comment utiliser la <strong><em>lazy evaluation</em></strong> et les <strong>optimisations du plan dâ€™exÃ©cution</strong> effectuÃ©es par <code>Arrow</code> pour exploiter pleinement la puissance du format <code>Parquet</code>.</p>
<ul>
<li>Ouvrir le fichier <code>data/RPindividus_24.parquet</code> avec <a href="https://arrow.apache.org/docs/python/dataset.html">pyarrow.dataset</a>. Regarder la classe de lâ€™objet obtenu.</li>
<li>Tester le code ci-dessous pour lire un Ã©chantillon de donnÃ©es:</li>
</ul>
<div id="41858b2b" class="cell" data-execution_count="11">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb6" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>(</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    dataset.scanner()</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    .head(<span class="dv">5</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    .to_pandas()</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</div>
<p>Comprenez-vous la diffÃ©rence avec prÃ©cÃ©demment ? Observez dans la documentation la mÃ©thode <code>to_table</code> : comprenez-vous son principe ?</p>
<ul>
<li>Construire une fonction <code>summarize_parquet_arrow</code> (resp. <code>summarize_parquet_duckdb</code>) qui importe cette fois les donnÃ©es avec la fonction <a href="https://arrow.apache.org/docs/python/dataset.html"><code>pyarrow.dataset</code></a> (resp. avec <code>DuckDB</code>) et effectue lâ€™agrÃ©gation voulue.</li>
<li>Comparer les performances (temps dâ€™exÃ©cution et allocation mÃ©moire) des trois mÃ©thodes (<code>Parquet</code> lu et processÃ© avec <code>Pandas</code>, <code>Arrow</code> et <code>DuckDB</code>) grÃ¢ce Ã  notre fonction.</li>
</ul>
<div id="e687fe8c" class="cell" data-execution_count="12">
<details class="code-fold">
<summary>Code complet de lâ€™application</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb7" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.dataset <span class="im">as</span> ds</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_parquet_duckdb(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    con <span class="op">=</span> duckdb.<span class="ex">connect</span>(<span class="st">":memory:"</span>)</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="st">    FROM read_parquet('data/RPindividus_24.parquet')</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="st">    SELECT AGED, DEPT, SUM(IPONDI) AS n_indiv</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="st">    GROUP BY AGED, DEPT</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (con.sql(query).to_df())</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_parquet_arrow(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ds.dataset(<span class="st">"data/RPindividus_24.parquet"</span>, <span class="bu">format</span><span class="op">=</span><span class="st">"parquet"</span>)</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> dataset.to_table()</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    grouped_table <span class="op">=</span> (</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        table</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        .group_by([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        .aggregate([(<span class="st">"IPONDI"</span>, <span class="st">"sum"</span>)])</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        .rename_columns([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>, <span class="st">"n_indiv"</span>])</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        .to_pandas()</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        grouped_table</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>process_parquet()</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>summarize_parquet_duckdb()</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>summarize_parquet_arrow()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</div>
</div>
</div>
<p>Avec lâ€™Ã©valuation diffÃ©rÃ©e, on obtient donc un processus en plusieurs temps:</p>
<ul>
<li><code>Arrow</code> ou <code>DuckDB</code> reÃ§oit des instructions, les optimise, exÃ©cute les requÃªtes</li>
<li>Seules les donnÃ©es en sortie de cette chaÃ®ne sont renvoyÃ©es Ã  <code>Python</code></li>
</ul>
<p><img src="https://linogaliana.github.io/parquet-recensement-tutomate/img/duckdb-delegation1.png" class="img-fluid"></p>
<section id="application-3" class="level2 smaller">
<h2 class="smaller anchored" data-anchor-id="application-3">Application 3</h2>
<div class="callout callout-style-default callout-application callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Application</span>Partie 3a : Et si on filtrait sur les lignes ?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>Ajoutez une Ã©tape de filtre sur les lignes dans nos requÃªtes:</p>
<ul>
<li>Avec <code>DuckDB</code>, vous devez modifier la requÃªte avec un <code>WHERE DEPT IN ('18', '28', '36')</code></li>
<li>Avec <code>Arrow</code>, vous devez modifier lâ€™Ã©tape <code>to_table</code> de cette maniÃ¨re: <code>dataset.to_table(filter=pc.field("DEPT").isin(['18', '28', '36']))</code></li>
</ul>
<div id="355d1ca1" class="cell" data-execution_count="15">
<details class="code-fold">
<summary>Correction de cet exercice</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb8" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.dataset <span class="im">as</span> ds</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.compute <span class="im">as</span> pc</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_arrow(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ds.dataset(<span class="st">"data/RPindividus.parquet"</span>, <span class="bu">format</span><span class="op">=</span><span class="st">"parquet"</span>)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> dataset.to_table(<span class="bu">filter</span><span class="op">=</span>pc.field(<span class="st">"DEPT"</span>).isin([<span class="st">'18'</span>, <span class="st">'28'</span>, <span class="st">'36'</span>]))</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>    grouped_table <span class="op">=</span> (</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>        table</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>        .group_by([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>        .aggregate([(<span class="st">"IPONDI"</span>, <span class="st">"sum"</span>)])</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        .rename_columns([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>, <span class="st">"n_indiv"</span>])</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>        .to_pandas()</span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>        grouped_table</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_duckdb(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    con <span class="op">=</span> duckdb.<span class="ex">connect</span>(<span class="st">":memory:"</span>)</span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="st">    FROM read_parquet('data/RPindividus_24.parquet')</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="st">    SELECT AGED, DEPT, SUM(IPONDI) AS n_indiv</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="st">    WHERE DEPT IN ('11','31','34')</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="st">    GROUP BY AGED, DEPT</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (con.sql(query).to_df())</span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_arrow()</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_duckdb()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</div>
</div>
</div>
<p><em>â“ï¸ Pourquoi ne gagne-t-on pas de temps avec nos filtres sur les lignes (voire pourquoi en perdons nous?) comme câ€™est le cas avec les filtres sur les colonnes ?</em></p>
<p>La donnÃ©e nâ€™est pas organisÃ©e par blocs de lignes comme elle lâ€™est pas bloc de colonne. Heureusement, il existe pour cela un moyen: le partitionnement !</p>
<div class="callout callout-style-default callout-application callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="true" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Application</span>Partie 3 : Le <code>Parquet</code> partitionnÃ©
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse show">
<div class="callout-body-container callout-body">
<p>La <em>lazy evaluation</em> et les optimisations dâ€™<code>Arrow</code> apportent des gain de performance considÃ©rables. Mais on peut encore faire mieux ! Lorsquâ€™on sait quâ€™on va Ãªtre amenÃ© Ã  <strong>filter rÃ©guliÃ¨rement les donnÃ©es selon une variable dâ€™intÃ©rÃªt</strong>, on a tout intÃ©rÃªt Ã  <strong>partitionner</strong> le fichier <code>Parquet</code> selon cette variable.</p>
<ol type="1">
<li><p>Parcourir la documentation de la fonction <a href="https://arrow.apache.org/docs/python/parquet.html#writing-to-partitioned-datasets"><code>pyarrow.parquet.write_to_dataset</code></a> pour comprendre comment spÃ©cifier une clÃ© de partitionnement lors de lâ€™Ã©criture dâ€™un fichier <code>Parquet</code>. Plusieurs mÃ©thodes sont possibles.</p></li>
<li><p>Importer la table complÃ¨te des individus du recensement depuis <code>"data/RPindividus.parquet"</code> avec la fonction <a href="https://arrow.apache.org/docs/python/generated/pyarrow.dataset.dataset.html"><code>pyarrow.dataset.dataset</code></a> et lâ€™exporter en une table partitionnÃ©e <code>"data/RPindividus_partitionne.parquet"</code>, partitionnÃ©e par la rÃ©gion (<code>REGION</code>) et le dÃ©partement (<code>DEPT</code>).</p></li>
<li><p>Observer lâ€™arborescence des fichiers de la table exportÃ©e pour voir comment la partition a Ã©tÃ© appliquÃ©e.</p></li>
<li><p>Modifier nos fonctions dâ€™import, filtre et agrÃ©gations via <code>Arrow</code> ou <code>DuckDB</code> pour utiliser, cette fois, le <code>Parquet</code> partitionnÃ©. Comparer Ã  lâ€™utilisation du fichier non partitionnÃ©.</p></li>
</ol>
<div id="2ce71413" class="cell" data-execution_count="16">
<details class="code-fold">
<summary>Correction de la question 2 (Ã©criture du Parquet partitionnÃ©)</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb9" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.parquet <span class="im">as</span> pq</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> ds.dataset(</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">"data/RPindividus.parquet"</span>, <span class="bu">format</span><span class="op">=</span><span class="st">"parquet"</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>).to_table()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>pq.write_to_dataset(</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    dataset,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>    root_path<span class="op">=</span><span class="st">"data/RPindividus_partitionne"</span>,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    partition_cols<span class="op">=</span>[<span class="st">"REGION"</span>, <span class="st">"DEPT"</span>]</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
<div id="7af050c1" class="cell" data-execution_count="17">
<details class="code-fold">
<summary>Correction de la question 4 (lecture du Parquet partitionnÃ©)</summary>
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code" id="cb10" data-source-line-numbers="nil" data-code-line-numbers="nil"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.dataset <span class="im">as</span> ds</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pyarrow.compute <span class="im">as</span> pc</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> duckdb</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_partitioned_arrow(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ds.dataset(<span class="st">"data/RPindividus_partitionne/"</span>, partitioning<span class="op">=</span><span class="st">"hive"</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> dataset.to_table(<span class="bu">filter</span><span class="op">=</span>pc.field(<span class="st">"DEPT"</span>).isin([<span class="st">'18'</span>, <span class="st">'28'</span>, <span class="st">'36'</span>]))</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    grouped_table <span class="op">=</span> (</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>        table</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>        .group_by([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>        .aggregate([(<span class="st">"IPONDI"</span>, <span class="st">"sum"</span>)])</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>        .rename_columns([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>, <span class="st">"n_indiv"</span>])</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>        .to_pandas()</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>        grouped_table</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_complete_arrow(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> ds.dataset(<span class="st">"data/RPindividus.parquet"</span>)</span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>    table <span class="op">=</span> dataset.to_table(<span class="bu">filter</span><span class="op">=</span>pc.field(<span class="st">"DEPT"</span>).isin([<span class="st">'18'</span>, <span class="st">'28'</span>, <span class="st">'36'</span>]))</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>    grouped_table <span class="op">=</span> (</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>        table</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>        .group_by([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>])</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>        .aggregate([(<span class="st">"IPONDI"</span>, <span class="st">"sum"</span>)])</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>        .rename_columns([<span class="st">"AGED"</span>, <span class="st">"DEPT"</span>, <span class="st">"n_indiv"</span>])</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>        .to_pandas()</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (</span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>        grouped_table</span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_complete_duckdb(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>    con <span class="op">=</span> duckdb.<span class="ex">connect</span>(<span class="st">":memory:"</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a><span class="st">    FROM read_parquet('data/RPindividus.parquet')</span></span>
<span id="cb10-47"><a href="#cb10-47" aria-hidden="true" tabindex="-1"></a><span class="st">    SELECT AGED, DEPT, SUM(IPONDI) AS n_indiv</span></span>
<span id="cb10-48"><a href="#cb10-48" aria-hidden="true" tabindex="-1"></a><span class="st">    WHERE DEPT IN ('11','31','34')</span></span>
<span id="cb10-49"><a href="#cb10-49" aria-hidden="true" tabindex="-1"></a><span class="st">    GROUP BY AGED, DEPT</span></span>
<span id="cb10-50"><a href="#cb10-50" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span></span>
<span id="cb10-51"><a href="#cb10-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-52"><a href="#cb10-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (con.sql(query).to_df())</span>
<span id="cb10-53"><a href="#cb10-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-54"><a href="#cb10-54" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-55"><a href="#cb10-55" aria-hidden="true" tabindex="-1"></a><span class="at">@measure_performance</span></span>
<span id="cb10-56"><a href="#cb10-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> summarize_filter_parquet_partitioned_duckdb(<span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb10-57"><a href="#cb10-57" aria-hidden="true" tabindex="-1"></a>    con <span class="op">=</span> duckdb.<span class="ex">connect</span>(<span class="st">":memory:"</span>)</span>
<span id="cb10-58"><a href="#cb10-58" aria-hidden="true" tabindex="-1"></a>    query <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb10-59"><a href="#cb10-59" aria-hidden="true" tabindex="-1"></a><span class="st">    FROM read_parquet('data/RPindividus_partitionne/**/*.parquet', hive_partitioning = True)</span></span>
<span id="cb10-60"><a href="#cb10-60" aria-hidden="true" tabindex="-1"></a><span class="st">    SELECT AGED, DEPT, SUM(IPONDI) AS n_indiv</span></span>
<span id="cb10-61"><a href="#cb10-61" aria-hidden="true" tabindex="-1"></a><span class="st">    WHERE DEPT IN ('11','31','34')</span></span>
<span id="cb10-62"><a href="#cb10-62" aria-hidden="true" tabindex="-1"></a><span class="st">    GROUP BY AGED, DEPT</span></span>
<span id="cb10-63"><a href="#cb10-63" aria-hidden="true" tabindex="-1"></a><span class="st">    """</span></span>
<span id="cb10-64"><a href="#cb10-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-65"><a href="#cb10-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (con.sql(query).to_df())</span>
<span id="cb10-66"><a href="#cb10-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-67"><a href="#cb10-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-68"><a href="#cb10-68" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_complete_arrow()</span>
<span id="cb10-69"><a href="#cb10-69" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_partitioned_arrow()</span>
<span id="cb10-70"><a href="#cb10-70" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_complete_duckdb()</span>
<span id="cb10-71"><a href="#cb10-71" aria-hidden="true" tabindex="-1"></a>summarize_filter_parquet_partitioned_duckdb()</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
</details>
</div>
</div>
</div>
</div>
<p><em>â“ï¸ Dans le cadre dâ€™une mise Ã  disposition de donnÃ©es en <code>Parquet</code>, comment bien choisir la/les clÃ©(s) de partitionnement ? Quelle est la limite Ã  garder en tÃªte ?</em></p>
</section>
<section id="pour-aller-plus-loin" class="level2">
<h2 class="anchored" data-anchor-id="pour-aller-plus-loin">Pour aller plus loin</h2>
<ul>
<li>La <a href="https://inseefrlab.github.io/formation-bonnes-pratiques-git-R/">formation aux bonnes pratiques <code>R</code> et <code>Git</code></a> dÃ©veloppÃ©e par lâ€™Insee avec des Ã©lÃ©ments trÃ¨s similaires Ã  ceux prÃ©sentÃ©s dans ce chapitre.</li>
<li>Un <a href="https://linogaliana.github.io/parquet-recensement-tutomate/">atelier</a> sur le format <code>Parquet</code> et lâ€™Ã©cosystÃ¨me <code>DuckDB</code> pour lâ€™EHESS avec des exemples <code>R</code> et <code>Python</code> utilisant la mÃªme source de donnÃ©es que lâ€™application.</li>
<li>Le <a href="https://ssphub.netlify.app/post/parquetrp/">guide de prise en main</a> des donnÃ©es du recensement au format <code>Parquet</code> avec des exemples dâ€™utilisation de <code>DuckDB</code> en WASM (directement depuis le navigateur, sans installation <code>R</code> ou <code>Python</code>)</li>
</ul>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-abdelaziz2023optimizing" class="csl-entry" role="listitem">
Abdelaziz, Abdullah I, Kent A Hanson, Charles E Gaber, and Todd A Lee. 2023. <span>â€œOptimizing Large Real-World Data Analysis with Parquet Files in r: A Step-by-Step Tutorial.â€</span> <em>Pharmacoepidemiology and Drug Safety</em>.
</div>
<div id="ref-chaudhuri1997overview" class="csl-entry" role="listitem">
Chaudhuri, Surajit, and Umeshwar Dayal. 1997. <span>â€œAn Overview of Data Warehousing and OLAP Technology.â€</span> <em>ACM Sigmod Record</em> 26 (1): 65â€“74.
</div>
<div id="ref-dean2008mapreduce" class="csl-entry" role="listitem">
Dean, Jeffrey, and Sanjay Ghemawat. 2008. <span>â€œMapReduce: Simplified Data Processing on Large Clusters.â€</span> <em>Communications of the ACM</em> 51 (1): 107â€“13.
</div>
<div id="ref-dondon2023quels" class="csl-entry" role="listitem">
Dondon, Alexis, and Pierre Lamarche. 2023. <span>â€œQuels Formats Pour Quelles Donn<span>Ã©</span>es?â€</span> <em>Courrier Des Statistiques</em>, 86â€“103.
</div>
<div id="ref-ghemawat2003google" class="csl-entry" role="listitem">
Ghemawat, Sanjay, Howard Gobioff, and Shun-Tak Leung. 2003. <span>â€œThe Google File System.â€</span> In <em>Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles</em>, 29â€“43.
</div>
<div id="ref-li2020big" class="csl-entry" role="listitem">
Li, Yun, Manzhu Yu, Mengchao Xu, Jingchao Yang, Dexuan Sha, Qian Liu, and Chaowei Yang. 2020. <span>â€œBig Data and Cloud Computing.â€</span> <em>Manual of Digital Earth</em>, 325â€“55.
</div>
<div id="ref-mesnier2003object" class="csl-entry" role="listitem">
Mesnier, Mike, Gregory R Ganger, and Erik Riedel. 2003. <span>â€œObject-Based Storage.â€</span> <em>IEEE Communications Magazine</em> 41 (8): 84â€“90.
</div>
<div id="ref-sagiroglu2013big" class="csl-entry" role="listitem">
Sagiroglu, Seref, and Duygu Sinanc. 2013. <span>â€œBig Data: A Review.â€</span> In <em>2013 International Conference on Collaboration Technologies and Systems (CTS)</em>, 42â€“47. IEEE.
</div>
<div id="ref-samundiswary2017object" class="csl-entry" role="listitem">
Samundiswary, S, and Nilma M Dongre. 2017. <span>â€œObject Storage Architecture in Cloud for Unstructured Data.â€</span> In <em>2017 International Conference on Inventive Systems and Control (ICISC)</em>, 1â€“6. IEEE.
</div>
<div id="ref-Tigani_2023" class="csl-entry" role="listitem">
Tigani, Jordan. 2023. <span>â€œBig Data Is Dead.â€</span> <a href="https://motherduck.com/blog/big-data-is-dead/">https://motherduck.com/blog/big-data-is-dead/</a>.
</div>
</div></section><section class="quarto-appendix-contents" id="quarto-reuse"><h2 class="anchored quarto-appendix-heading">Reuse</h2><div class="quarto-appendix-contents"><div><a rel="license" href="https://creativecommons.org/licenses/by-nc/4.0/">CC BY-NC 4.0</a></div></div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




<script src="../site_libs/quarto-contrib/line-highlight-1.0.0/line-highlight.js" defer="true"></script>
</body></html>