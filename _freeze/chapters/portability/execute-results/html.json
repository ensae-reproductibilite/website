{
  "hash": "9d5d471b42445396f77c5bc2f4ee24c9",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Rendre son projet de data science portable et reproductible\"\ndescription: |\n  Pr√©sentation des principes et des techniques permettant de rendre un projet ex√©cutable sur diff√©rents environnements.\nimage: images/box.png\norder: 4\nhref: chapters/portability.html\n---\n\n<details>\n<summary>\nD√©rouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/portabilit√©)\npour afficher les slides en plein √©cran.\n</summary>\n\n\n<div class=\"sourceCode\" id=\"cb1\"><pre class=\"sourceCode yaml code-with-copy\"><code class=\"sourceCode yaml\"></code><button title=\"Copy to Clipboard\" class=\"code-copy-button\"><i class=\"bi\"></i></button></pre><iframe class=\"sourceCode yaml code-with-copy\" src=\"https://ensae-reproductibilite.github.io/slides/#/portabilit√©\"></iframe></div>\n\n</details>\n\n# Introduction : la notion de portabilit√©\n\nDans les chapitres pr√©c√©dents, nous avons vu un ensemble de bonnes pratiques qui permettent de consid√©rablement am√©liorer la qualit√© d'un projet : rendre le code plus lisible, adopter une structure du projet normalis√©e et √©volutive et versionner proprement son code sur un d√©p√¥t `GitHub` {{< fa brands github >}}.\n\nUne fois ces bonnes pratiques appliqu√©es √† notre projet, ce dernier appara√Æt largement partageable. Du moins en th√©orie, car la pratique est souvent plus compliqu√©e : il y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement d'ex√©cution (un autre ordinateur, un serveur, etc.), les choses ne se passent pas du tout comme attendu. Cela signifie que qu'**en l'√©tat, le projet n'est pas [portable]{.colorized} : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.\n\nLa raison principale est qu'un code ne vit pas dans une bulle isol√©e, il contient en g√©n√©ral de nombreuses adh√©rences, plus ou moins visibles, au langage et √† l'environnement dans lesquels il a √©t√© d√©velopp√© :\n\n- des __d√©pendances `Python`__ propres au langage du projet. C'est l'environnement des _packages_ n√©cessaires √† ex√©cuter le code ;\n- des __d√©pendances dans d'autres langages__ n√©cessaires au fonctionnement de certaines librairies `Python`. En effet, `Python` est un langage de haut niveau et certains _packages_ n√©cessitent des librairies bas-niveau pour √™tre efficaces. Par exemple, `NumPy` est √©crit en `C` et n√©cessite donc un compilateur `C` et `Pytorch` a quant √† lui besoin de `C++` ;\n- des __d√©pendances √† des librairies syst√®mes__ n√©cessaires pour installer certains _packages_\nqui ne seront pas les m√™mes selon le syst√®me d'exploitation utilis√© et certains param√®tres mat√©riels (par exemple, selon que Windows utilise une version 32 ou 64 bits). Par exemple, les librairies\nde manipulation ou de visualisation de donn√©es spatiales (`GeoPandas`, `Folium`) reposent sur des librairies syst√®mes `GDAL` qui sont propres √† chaque syst√®me d'exploitation[^wheels].\n\n[^wheels]: Nous reviendrons plus tard sur la mani√®re dont la mise √† disposition de _packages_ sous forme pr√©compil√©e par le biais de _wheels_ offre une solution √† ce probl√®me. \n\nLe premier probl√®me peut √™tre g√©r√© relativement facilement en adoptant une structure de projet ([chapitre pr√©c√©dent](/chapters/projects-architecture.qmd)) avec un fichier\n`requirements.txt` bien structur√© et versionn√©.\nLes deux autres n√©cessitent en g√©n√©ral des outils plus avanc√©s.\n\nNous allons progresser dans la d√©marche de reproductibilit√© en visant un projet\nportable, c'est-√†-dire qui peut √™tre \nex√©cut√© dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©. \nNous allons avoir besoin de nouveaux outils qui \nseront, chacun, des avanc√©es sur l'√©chelle de la \nreproductibilit√©:\n\n* Les [environnements virtuels](#virtualenv) ;\n* Les [conteneurs](#conteneurs).\n\nCes outils vont nous permettre de **normaliser l'environnement afin de produire un projet portable**. Cette √©tape est primordiale lorsque l'on se pr√©occupe de la mise en production d'un projet, car elle assure une transition relativement indolore entre l'environnement de d√©veloppement et celui de production.\n\n![Image emprunt√©e √† [devrant.com](https://devrant.com/rants/174386/when-i-say-but-it-works-on-my-machine)](https://img.devrant.com/devrant/rant/r_174386_yx6zV.jpg){fig-align=\"center\"}\n\nLe choix de la m√©thode √† privil√©gier d√©pend d'un arbitrage temps-opportunit√©. Tous les projets\nn'ont pas vocation √† √™tre mis √† disposition par\nle biais de conteneurs. N√©anmoins, \nl'int√©r√™t d'adopter une d√©marche de bonnes \npratiques est que si le projet gagne en ambition\net que la conteneurisation s'av√®re ad√©quate, celle-ci\nsera peu co√ªteuse √† mettre en oeuvre.\n\n\n# Les environnements virtuels {{< fa brands python >}} {#virtualenv}\n\n## Introduction\n\nPour illustrer l'importance de travailler avec des environnements virtuels, mettons-nous √† la place d'un.e aspirant.e *data scientist* qui commencerait ses premiers projets.\n\nSelon toute vraisemblance, on va commencer par installer une distribution de `Python` ‚Äî souvent, via `Anaconda` ‚Äî sur son poste et commencer √† d√©velopper, projet apr√®s projet. S'il est n√©cessaire d'installer une librairie suppl√©mentaire, on le fera sans trop se poser de question. Puis, on passera au projet suivant en adoptant la m√™me d√©marche. Et ainsi de suite. \n\nCette d√©marche naturelle pr√©sentera l'avantage de permettre d'aller vite dans les exp√©rimentations. \nN√©anmoins, elle deviendra probl√©matique s'il devient\nn√©cessaire de partager son projet, ou de reprendre celui-ci dans le futur. \n\nDans cette approche, les diff√©rents *packages* qu'on va √™tre amen√© √† utiliser vont √™tre install√©s au m√™me endroit. Ceci peut appara√Ætre secondaire, apr√®s tout nous utilisons `Python` pour sa simplicit√© d'usage qui ne n√©cessite pas de passer des heures √† se poser des questions avant d'√©crire la moindre ligne de code, mais cela va finir par nous poser plusieurs probl√®mes :\n\n- **conflits de version** : une application A peut d√©pendre de la version 1 d'un package l√† o√π une application B peut d√©pendre de la version 2 de ce m√™me package. Ces versions d'un m√™me package peuvent avoir des incompatibilit√©s[^release]. Une seule application peut donc fonctionner dans cette configuration ;\n- **version de `Python` fixe** ‚Äî on ne peut avoir qu'une seule installation par syst√®me ‚Äî l√† o√π on voudrait pouvoir avoir des versions diff√©rentes selon le projet ;\n- **reproductiblit√© limit√©e** : difficile de dire quel projet repose sur tel package, dans la mesure o√π ceux-ci s'accumulent en un m√™me endroit au fil des projets ;\n- **portabilit√© limit√©e** : cons√©quence du point pr√©c√©dent, il est difficile de fixer dans un fichier les d√©pendances sp√©cifiques √† un projet, et exclusivement celles-ci.\n\nLes environnements virtuels constituent une solution √† ces diff√©rents probl√®mes.\n\n[^release]: S'il est impossible de suivre les √©volutions de tous les _packages_ de la _data science_,\nil est recommand√© de faire une veille sur les principaux comme `Pandas` ou `Scikit` en suivant\nles _release notes_ des versions majeures qui introduisent\ng√©n√©ralement des non-compatibilit√©s.  \n\n## Fonctionnement\n\nLe concept d'environnement virtuel est techniquement tr√®s simple.\nOn peut lui donner la d√©finition suivante pour `Python` :\n\n> _\"dossier auto-suffisant qui contient une installation de `Python`\npour une version particuli√®re de `Python` ainsi que des *packages* additionnels\net qui est isol√© des autres environnements existants.\"_\n\nOn peut donc simplement voir les environnements virtuels comme un moyen de faire cohabiter sur un m√™me syst√®me diff√©rentes installations de `Python` avec chacune leur propre liste de packages install√©s et leurs versions. D√©velopper dans des environnements virtuels vierges √† chaque d√©but de projet est une tr√®s bonne pratique pour accro√Ætre la reproductibilit√© des analyses.\n\n## Impl√©mentations\n\nIl existe diff√©rentes impl√©mentations des environnements virtuels en `Python`, dont chacune ont leurs sp√©cificit√©s et leur communaut√© d'utilisateurs : \n\n* L'impl√©mentation standard en `Python` est `venv`.\n* `conda` propose une impl√©mentation plus compl√®te.\n\nEn pratique pour les utilisateurs, ces impl√©mentations sont relativement proches. La diff√©rence conceptuelle majeure est que `conda` est √† la fois un *package manager* (comme `pip`) et un gestionnaire d'environnements virtuels (comme `venv`).\n\nPendant longtemps, `conda` en tant que *package manager* s'est av√©r√© tr√®s pratique en *data science*, dans la mesure o√π il g√©rait non seulement les d√©pendances `Python` mais aussi dans d'autres langages, comme des d√©pendances `C`, tr√®s utilis√©es\npar les principales librairies de _data science_ et dont l'installation peut √™tre complexe sur certains syst√®mes d'exploitation. N√©anmoins, depuis quelques ann√©es, l'installation de _packages_ par `pip` se fait de plus en plus par le biais de [_wheels_](https://pythonwheels.com/) qui sont des versions pr√©-compil√©es des librairies syst√®mes, propres √† chaque configuration syst√®me. \n\n::: {.callout-note collapse=\"true\"}\n## Une diff√©rence conceptuelle entre `pip` et `conda`\n\nL'autre diff√©rence majeure avec `pip` est que `Conda` utilise une m√©thode plus avanc√©e ‚Äî et donc √©galement plus co√ªteuse en temps ‚Äî de r√©solution des d√©pendances.\n\nEn effet, diff√©rents packages peuvent sp√©cifier diff√©rentes versions d'un m√™me package dont ils d√©pendent tous les deux, ce qui provoque un conflit de version. `Conda` va par d√©faut appliquer un algorithme qui vise √† g√©rer au mieux ces conflits, l√† o√π `pip` va choisir une approche plus minimaliste[^2]. \n:::\n\n[^2]: Le _solver_ de `conda`, qui est un algorithme de recherche de chemin optimal dans des graphes pour g√©rer\nles (in)compatibilit√©s de versions, est\nlourd √† mettre en oeuvre. Le projet [`mamba`](https://mamba.readthedocs.io/en/latest/) a permis d'offrir\nune r√©impl√©mentation de `Conda` en `C++` par le biais d'un _solver_ plus efficace. Cela a permis de franchement acc√©l√©rer la vitesse d'installation des _packages_ par le biais de `conda`. N√©anmoins, \nl'acc√®s de plus en plus fr√©quent √† des [_wheels_](https://pythonwheels.com/) a permis un retour en gr√¢ce des environnements virtuels impl√©ment√©s par `venv` au cours des derni√®res ann√©es. \n\n`pip+venv` pr√©sente l'avantage de la simplicit√©, `conda` de la fiabilit√©. Selon les projets, on\nprivil√©giera l'un ou l'autre. N√©anmoins, si \nle projet est amen√© √† fonctionner de mani√®re isol√©e\ndans un conteneur, `venv` suffira amplement car\nl'isolation sera fournie par le conteneur comme\nnous le verrons ult√©rieurement. \n\n::: {.callout-note collapse=\"true\"}\n## C'est diff√©rent en {{< fa brands r-project >}} ?\n\nOn lit souvent, notamment chez les _afficionados_ de {{< fa brands r-project >}} que la gestion des environnements en `Python` est chaotique. C'√©tait vrai au d√©but des ann√©es 2010 mais c'est quelques peu exag√©r√© aujourd'hui. \n\nLa qualit√© sup√©rieure des outils {{< fa brands r-project >}} pour la gestion des d√©pendances ne saute pas aux yeux: [`renv`](https://rstudio.github.io/renv/articles/renv.html) est tr√®s int√©ressant mais [ne permet pas de d√©finir la version de \n{{< fa brands r-project >}}](https://rstudio.github.io/renv/articles/renv.html#caveats) :\n\n> R version: renv tracks, but doesn‚Äôt help with, the version of R used with the packge. renv can‚Äôt easily help with this because it‚Äôs run inside of R, but you might find tools like rig helpful, as they make it easier to switch between multiple version of R on one computer.\n\nC'est, en fait, le probl√®me principal des outils {{< fa brands r-project >}} pour la reproductibilit√©. Pour les utiliser, il faut souvent se trouver dans une session {{< fa brands r-project >}}, avec ses sp√©cificit√©s. Les outils {{< fa brands python >}} qui s'utilisent pas le biais de la ligne de commande offrent une robustesse plus importante. `venv` est certes d√©pendant de la version de {{< fa brands python >}} utilis√©e lors de la cr√©ation de l'environnement mais le fait de passer par le terminal permet de choisir la version de {{< fa brands python >}} qui servira √† cr√©er l'environnement. Quant √† `conda`, la version de {{< fa brands python >}} est d√©finie dans le `environment.yml` ce qui donne une grande libert√©.\n:::\n\nPuisqu'il n'y a pas de raison absolue d'imposer `pip+venv` ou `conda`, nous recommandons le pragmatisme. Personnellement, nous utilisons plut√¥t `venv` car nous travaillons principalement dans des microservices bas√©s sur des conteneurs et non sur des postes personnels, ce qui est l'approche moderne dans le monde de la _data science_. Nous pr√©sentons n√©anmoins les deux approches par la suite. L'[application fil rouge](/chapters/application.qmd) propose les deux approches, √† vous de choisir celle que vous d√©sirez privil√©gier. \n\n## Guide pratique d'utilisation d'un environnement virtuel\n\n\n### Installation\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\n`venv` est un module inclus par d√©faut dans `Python`, ce qui le rend facilement accessible pour la gestion d'environnements virtuels.\n\nLes instructions pour utiliser `venv`, l'outil de cr√©ation d'environnements virtuels int√©gr√© √† Python, sont d√©taill√©es dans la [documentation officielle de Python](https://docs.python.org/fr/3/library/venv.html).\n\n![Illustration du principe (Source: [dataquest](https://www.dataquest.io/blog/a-complete-guide-to-python-virtual-environments/))](https://www.dataquest.io/wp-content/uploads/2022/01/python-virtual-envs1-1024x576.webp)\n\n## `conda`\n\nLes instructions √† suivre pour installer `conda` sont d√©taill√©es dans la [documentation officielle](https://docs.conda.io/projects/conda/en/latest/user-guide/install/index.html). `conda` seul √©tant peu utile en pratique, il est g√©n√©ralement install√© dans le cadre de distributions. Les deux plus populaires sont :\n\n- `Miniconda` : une distribution minimaliste contenant `conda`, `Python` ainsi qu'un petit nombre de packages techniques tr√®s utiles ;\n- `Anaconda` : une distribution assez volumineuse contenant `conda`, `Python`, d'autres logiciels (`R`, `Spyder`, etc.) ainsi qu'un ensemble de packages utiles pour la *data science* (`SciPy`, `NumPy`, etc.).\n\n![](/conda-eco.png)\n\nLe choix de la distribution importe assez peu en pratique, dans la mesure o√π nous allons de toute mani√®re utiliser des environnements virtuels vierges pour d√©velopper nos projets.\n\n:::\n\n### Cr√©er un environnement\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\nPour commencer √† utiliser `venv`, commen√ßons par cr√©er un environnement vierge, nomm√© `dev`. Pour cr√©er\nun environnement virtuel, cela se fait en ligne de commande par le biais de \n`Python`. Cela signifie que la version de `Python` utilis√©e\npar cet environnement sera celle utilis√©e lors de la cr√©ation de celui-ci. \n\n```{.bash filename=\"terminal\"}\npython -m venv dev #<1>\n```\n1. Sur un syst√®me `Windows`, ce sera `python.exe -m venv dev` \n\nCette commande cr√©e un dossier nomm√© `dev/` contenant une installation Python isol√©e.\n\n<details>\n<summary>\nExemple sur un syst√®me `Linux`\n</summary>\n![Exemple sur un syst√®me `Linux`](/venv_local.png)\n</details>\n\nCelle-ci est de la version de `Python` enregistr√©e par d√©faut dans le `PATH`, en l'occurrence\n`Python 3.11`. Pour cr√©er un environnement virtuel avec une autre version de `Python`, il faudra\nd√©finir le chemin de mani√®re formelle, par exemple:\n\n```{.bash filename=\"terminal\"}\n/chemin_local/python3.8 -m venv dev-old #<1>\n```\n\n\n## `conda`\n\n\nPour commencer √† utiliser `conda`, commen√ßons par cr√©er un environnement vierge, nomm√© `dev`, en sp√©cifiant la version de Python que l'on souhaite installer pour notre projet.\n\n```{.bash filename=\"terminal\"}\nconda create -n dev python=3.9.7\n```\n\n```{.python}\nRetrieving notices: ...working... done\nChannels:\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/mamba/envs/dev\n\n  added / updated specs:\n    - python=3.9.7\n\n\nThe following packages will be downloaded:\n...\nThe following NEW packages will be INSTALLED:\n...\nProceed ([y]/n)? y\nDownloading and Extracting Packages\n...\n```\n\n\nComme indiqu√© dans les _logs_,\n`Conda` a cr√©√© notre environnement et nous indique son emplacement sur le *filesystem*.\nEn r√©alit√©, l'environnement n'est jamais vraiment vierge :\n`Conda` nous demande ‚Äî et il faut r√©pondre oui en tapant `y` ‚Äî \nd'installer un certain nombre de packages,\nqui sont ceux qui viennent avec la distribution `Miniconda`.\n\nOn peut v√©rifier que l'environnement a bien √©t√© cr√©√© en listant les environnements install√©s sur le syst√®me.\n\n```{.bash filename=\"terminal\"}\nconda info --envs\n```\n\n```{.python}\n# conda environments:                                                                                                                             \n#                                                                                                                                                 \nbase                  *  /opt/mamba                                                                                                               \ndev                      /opt/mamba/envs/dev\n```\n\n:::\n\n\n### Activer un environnement\n\nComme plusieurs environnements peuvent coexister sur un m√™me syst√®me,\nil faut dire √† notre gestionnaire d'environnement d'activer celui-ci.\nD√®s lors, ce sera celui-ci qui sera utilis√© implicitement lorsqu'on\nutilisera `python`, `pip`, etc. dans\nla ligne de commande active[^sourceactivate].\n\n[^sourceactivate]: Cela signifie que si on ouvre un nouveau terminal, il faudra √† nouveau activer cet environnement si on d√©sire l'utiliser. Si on d√©sire activer par d√©faut un environnement, \nil est possible de configurer le terminal pour qu'il active automatiquement un environnement sp√©cifique lors de son ouverture. Cela peut √™tre r√©alis√© en modifiant les fichiers de configuration du shell, par le biais par exemple du script `.bashrc` sur `Linux`. \n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\n```{.bash filename=\"terminal\"}\nsource dev/bin/activate\n```\n\n`venv` active l'environnement virtuel `dev`, indiqu√© par le changement du nom de l'environnement qui appara√Æt au d√©but de la ligne de commande dans le terminal. Une fois activ√©, `dev` devient temporairement notre environnement par d√©faut pour les op√©rations `Python`. Pour confirmer cela, nous pouvons utiliser la commande `which` pour d√©terminer l'emplacement de l'interpr√©teur Python qui sera utilis√© pour ex√©cuter des scripts comme `python mon-script.py`.\n\n```{.bash filename=\"terminal\" env=dev}\nwhich python\n```\n\n```{.python}\n/home/onyxia/work/dev/bin/python\n```\n\n## `conda`\n\n```{.bash filename=\"terminal\"}\nconda activate dev\n```\n\n`Conda` nous indique que l'on travaille √† partir de maintenant dans l'environnement `dev` en indiquant son nom entre parenth√®ses au d√©but de la ligne de commandes. Autrement dit, `dev` devient pour un temps notre \nenvironnement par d√©faut. \nPour s'en assurer,\nv√©rifions avec la commande `which` l'emplacement de l'interpr√©teur Python qui sera utilis√© si on lance une commande du type `python mon-script.py`.\n\n```{.bash filename=\"terminal\" env=dev}\nwhich python \n```\n\n```{.python}\n/opt/mamba/envs/dev/bin/python\n```\n\n:::\n\n\nOn travaille bien dans l'environnement attendu : l'interpr√©teur qui se lance n'est pas celui du syst√®me global, mais bien celui sp√©cifique √† notre environnement virtuel.\n\n### Lister les packages install√©s\n\nUne fois l'environnement activ√©, on peut lister les packages install√©s et leur version.\nCela confirme qu'un certain nombre de packages sont install√©s par d√©faut lors de la cr√©ation d'un environnement virtuel.\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\nOn part d'un environnement vraiment r√©duit √† l'os:\n\n```{.bash filename=\"terminal\" env=dev}\npip list\n```\n\n```{.python}\nPackage    Version\n---------- -------\npip        23.3.2\nsetuptools 69.0.3\nwheel      0.42.0\n```\n\n\n## `conda`\n\nL'environnement est assez minimaliste, quoique plus garni que lors\nde la cr√©ation d'un environnement virtuel par `venv`\n\n```{.bash filename=\"terminal\" env=\"dev\"}\nconda list\n```\n\n```{.python}\n# packages in environment at /opt/mamba/envs/dev:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                 conda_forge    conda-forge\n_openmp_mutex             4.5                       2_gnu    conda-forge\nca-certificates           2023.11.17           hbcca054_0    conda-forge\n...\n```\n\n:::\n\nPour se convaincre, on peut v√©rifier que `Numpy` \nest bien absent de notre environnement:\n\n```{.bash filename=\"terminal\" env=\"dev\"}\npython -c \"import numpy as np\"\n```\n\n```{.python}\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\nModuleNotFoundError: No module named 'numpy'\n```\n\n\n### Installer un package\n\nNotre environnement peut √™tre enrichi, lorsque n√©cessaire,\navec l'installation d'un _package_ par le biais de la ligne\nde commande. La proc√©dure\nest tr√®s similaire entre `pip` (pour les environnements `venv`) et `conda`.\n\n::: {.callout-caution collapse=\"true\"}\n## M√©langer `pip` et `conda`\n\nIl est techniquement possible d'installer des _packages_ par le biais de `pip` \nen √©tant situ√© dans un environnement virtuel `conda`[^sspcloud-note].\nCe n'est pas un probl√®me pour de l'exp√©rimentation et √ßa permet de d√©velopper\nrapidement.\n\nN√©anmoins, dans un environnement\nde production c'est une [pratique √† √©viter](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#using-pip-in-an-environment). \n\n- Soit on initialise un environnement\n`conda` autosuffisant avec un `env.yml` (voir plus bas) ;\n- Soit on cr√©e un environnement `venv` et on fait exclusivement des `pip install`.\n:::\n\n[^sspcloud-note]: D'ailleurs, si vous utilisez `pip` sur le SSPCloud, \nc'est ce que vous faites, sans vous en rendre compte. \n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\n```{.bash filename=\"terminal\" env=\"dev\"}\npip install nom_du_package\n```\n\n## `conda` \n\n```{.bash filename=\"terminal\" env=\"dev\"}\nconda install nom_du_package\n```\n\n:::\n\nLa diff√©rence est que l√† o√π `pip install` va installer un package √† partir du r√©pertoire [PyPI](https://pypi.org/), `conda install` va chercher le package sur les r√©pertoires maintenus par les d√©veloppeurs de Conda[^1].\n\nInstallons par exemple le package phare de *machine learning* `scikit-learn`.\n\n[^1]: Ces r√©pertoires sont, dans le langage `conda`, les _canaux_.\nLe canal par d√©faut est maintenu par les d√©veloppeurs d`Anaconda`. \nCependant, pour en assurer la stabilit√©, ce canal a une forte inertie. \nLa `conda-forge` a √©merg√© pour offrir plus de flexibilit√© aux d√©veloppeurs\nde _package_ qui peuvent ainsi mettre √† disposition des versions plus\nr√©centes de leurs packages, comme sur  [PyPI](https://pypi.org/).\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\n```{.bash filename=\"terminal\" env=\"dev\"}\nconda install scikit-learn\n```\n\n```{.python}\npip install scikit-learn\nCollecting scikit-learn\n  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/5b/be/208f17ce87a5e55094b0e8ffd55b06919ab9b56e7e4ce2a64cd9095ec5d2/scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading scikit_learn-1.4.0-1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nCollecting numpy<2.0,>=1.19.5 (from scikit-learn)\n  Obtaining dependency information for numpy<2.0,>=1.19.5 from https://files.pythonhosted.org/packages/5a/62/007b63f916aca1d27f5fede933fda3315d931\n...\n```\n\nLes d√©pendances n√©cessaires (par exemple `Numpy` sont automatiquement install√©es).\nL'environnement s'enrichit donc:\n\n```{.bash filename=\"terminal\" env=\"dev\"}\npip list\n```\n\n```{.python}\nPackage       Version\n------------- -------\njoblib        1.3.2\nnumpy         1.26.3\npip           23.2.1\nscikit-learn  1.4.0\nscipy         1.12.0\nsetuptools    65.5.0\nthreadpoolctl 3.2.0\n```\n\n\n## `conda`\n\n\n```{.bash filename=\"terminal\" env=\"dev\"}\nconda install scikit-learn\n```\n\n<details>\n<summary>\nVoir la sortie\n</summary>\n\n```{.python}\nChannels:\n - conda-forge\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /opt/mamba/envs/dev\n\n  added / updated specs:\n    - scikit-learn\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    joblib-1.3.2               |     pyhd8ed1ab_0         216 KB  conda-forge\n    libblas-3.9.0              |21_linux64_openblas          14 KB  conda-forge\n    libcblas-3.9.0             |21_linux64_openblas          14 KB  conda-forge\n    libgfortran-ng-13.2.0      |       h69a702a_3          23 KB  conda-forge\n    libgfortran5-13.2.0        |       ha4646dd_3         1.4 MB  conda-forge\n    liblapack-3.9.0            |21_linux64_openblas          14 KB  conda-forge\n    libopenblas-0.3.26         |pthreads_h413a1c8_0         5.3 MB  conda-forge\n    libstdcxx-ng-13.2.0        |       h7e041cc_3         3.7 MB  conda-forge\n    numpy-1.26.3               |   py39h474f0d3_0         6.6 MB  conda-forge\n    python_abi-3.9             |           4_cp39           6 KB  conda-forge\n    scikit-learn-1.4.0         |   py39ha22ef79_0         8.7 MB  conda-forge\n    scipy-1.12.0               |   py39h474f0d3_2        15.6 MB  conda-forge\n    threadpoolctl-3.2.0        |     pyha21a80b_0          20 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:        41.6 MB\n\nThe following NEW packages will be INSTALLED:\n\n  joblib             conda-forge/noarch::joblib-1.3.2-pyhd8ed1ab_0 \n  libblas            conda-forge/linux-64::libblas-3.9.0-21_linux64_openblas \n  libcblas           conda-forge/linux-64::libcblas-3.9.0-21_linux64_openblas \n  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-13.2.0-h69a702a_3 \n  libgfortran5       conda-forge/linux-64::libgfortran5-13.2.0-ha4646dd_3 \n  liblapack          conda-forge/linux-64::liblapack-3.9.0-21_linux64_openblas \n  libopenblas        conda-forge/linux-64::libopenblas-0.3.26-pthreads_h413a1c8_0 \n  libstdcxx-ng       conda-forge/linux-64::libstdcxx-ng-13.2.0-h7e041cc_3 \n  numpy              conda-forge/linux-64::numpy-1.26.3-py39h474f0d3_0 \n  python_abi         conda-forge/linux-64::python_abi-3.9-4_cp39 \n  scikit-learn       conda-forge/linux-64::scikit-learn-1.4.0-py39ha22ef79_0 \n  scipy              conda-forge/linux-64::scipy-1.12.0-py39h474f0d3_2 \n  threadpoolctl      conda-forge/noarch::threadpoolctl-3.2.0-pyha21a80b_0 \n\n\n\nDownloading and Extracting Packages:\n                                                                                                                                                  \nPreparing transaction: done                                                                                                                       \nVerifying transaction: done                                                                                                                       \nExecuting transaction: done \n```\n</details>\n\nL√† encore, `conda` nous demande d'installer d'autres packages, qui sont des d√©pendances de `scikit-learn`. Par exemple, la librairie de calcul scientifique `NumPy`.\n\n\n```python\n(dev) $ conda list\n```\n\n```\n# packages in environment at /opt/mamba/envs/dev:\n#\n# Name                    Version                   Build  Channel\n_libgcc_mutex             0.1                 conda_forge    conda-forge\n_openmp_mutex             4.5                       2_gnu    conda-forge\nca-certificates           2023.11.17           hbcca054_0    conda-forge\njoblib                    1.3.2              pyhd8ed1ab_0    conda-forge\nld_impl_linux-64          2.40                 h41732ed_0    conda-forge\nlibblas                   3.9.0           21_linux64_openblas    conda-forge\nlibcblas                  3.9.0           21_linux64_openblas    conda-forge\nlibffi                    3.4.2                h7f98852_5    conda-forge\nlibgcc-ng                 13.2.0               h807b86a_3    conda-forge\nlibgfortran-ng            13.2.0               h69a702a_3    conda-forge\nlibgfortran5              13.2.0               ha4646dd_3    conda-forge\nlibgomp                   13.2.0               h807b86a_3    conda-forge\nliblapack                 3.9.0           21_linux64_openblas    conda-forge\nlibopenblas               0.3.26          pthreads_h413a1c8_0    conda-forge\nlibsqlite                 3.44.2               h2797004_0    conda-forge\nlibstdcxx-ng              13.2.0               h7e041cc_3    conda-forge\nlibzlib                   1.2.13               hd590300_5    conda-forge\nncurses                   6.4                  h59595ed_2    conda-forge\nnumpy                     1.26.3           py39h474f0d3_0    conda-forge\nopenssl                   3.2.0                hd590300_1    conda-forge\npip                       23.3.2             pyhd8ed1ab_0    conda-forge\npython                    3.9.7           hf930737_3_cpython    conda-forge\npython_abi                3.9                      4_cp39    conda-forge\nreadline                  8.2                  h8228510_1    conda-forge\nscikit-learn              1.4.0            py39ha22ef79_0    conda-forge\nscipy                     1.12.0           py39h474f0d3_2    conda-forge\nsetuptools                69.0.3             pyhd8ed1ab_0    conda-forge\nsqlite                    3.44.2               h2c6b66d_0    conda-forge\nthreadpoolctl             3.2.0              pyha21a80b_0    conda-forge\ntk                        8.6.13          noxft_h4845f30_101    conda-forge\ntzdata                    2023d                h0c530f3_0    conda-forge\nwheel                     0.42.0             pyhd8ed1ab_0    conda-forge\nxz                        5.2.6                h166bdaf_0    conda-forge\nzlib                      1.2.13               hd590300_5    conda-forge\n```\n\n:::\n\n\n\n### Exporter les sp√©cifications de l'environnement\n\nD√©velopper √† partir d'un environnement vierge est une bonne pratique de reproductibilit√© :\nen partant d'une base minimale, on s'assure que seuls les packages effectivement n√©cessaires\nau bon fonctionnement de notre application ont √©t√© install√©s au fur et √† mesure du projet. \n\nCela rend √©galement notre projet plus ais√© √† rendre portable. \nOn peut exporter les sp√©cifications de l'environnement\ndans un fichier sp√©cial qui peut permettre de cr√©er un nouvel environnement similaire\n√† celui ayant servi initialement.\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\n```{.bash filename=\"terminal\" env=\"dev\"}\npip freeze > requirements.txt\n```\n\n<details>\n<summary>\nVoir le fichier `requirements.txt` g√©n√©r√©\n</summary>\n\n```{.python filename=\"requirements.txt\"}\njoblib==1.3.2\nnumpy==1.26.3\nscikit-learn==1.4.0\nscipy==1.12.0\nthreadpoolctl==3.2.0\n```\n\n</details>\n\n## `conda`\n\n```{.bash filename=\"terminal\" env=\"dev\"}\nconda env export > environment.yml\n```\n\n<details>\n<summary>\nVoir le fichier `environment.yml` g√©n√©r√©\n</summary>\n\n```{.python filename=\"environment.yml\"}\nname: dev\nchannels:\n  - conda-forge\ndependencies:\n  - _libgcc_mutex=0.1=conda_forge\n  - _openmp_mutex=4.5=2_gnu\n  - ca-certificates=2023.11.17=hbcca054_0\n  - joblib=1.3.2=pyhd8ed1ab_0\n  - ld_impl_linux-64=2.40=h41732ed_0\n  - libblas=3.9.0=21_linux64_openblas\n  - libcblas=3.9.0=21_linux64_openblas\n  - libffi=3.4.2=h7f98852_5\n  - libgcc-ng=13.2.0=h807b86a_3\n  - libgfortran-ng=13.2.0=h69a702a_3\n  - libgfortran5=13.2.0=ha4646dd_3\n  - libgomp=13.2.0=h807b86a_3\n  - liblapack=3.9.0=21_linux64_openblas\n  - libopenblas=0.3.26=pthreads_h413a1c8_0\n  - libsqlite=3.44.2=h2797004_0\n  - libstdcxx-ng=13.2.0=h7e041cc_3\n  - libzlib=1.2.13=hd590300_5\n  - ncurses=6.4=h59595ed_2\n  - numpy=1.26.3=py39h474f0d3_0\n  - openssl=3.2.0=hd590300_1\n  - pip=23.3.2=pyhd8ed1ab_0\n  - python=3.9.7=hf930737_3_cpython\n  - python_abi=3.9=4_cp39\n  - readline=8.2=h8228510_1\n  - scikit-learn=1.4.0=py39ha22ef79_0\n  - scipy=1.12.0=py39h474f0d3_2\n  - setuptools=69.0.3=pyhd8ed1ab_0\n  - sqlite=3.44.2=h2c6b66d_0\n  - threadpoolctl=3.2.0=pyha21a80b_0\n  - tk=8.6.13=noxft_h4845f30_101\n  - tzdata=2023d=h0c530f3_0\n  - wheel=0.42.0=pyhd8ed1ab_0\n  - xz=5.2.6=h166bdaf_0\n  - zlib=1.2.13=hd590300_5\nprefix: /opt/mamba/envs/dev\n```\n\n</details>\n\n\n:::\n\nCe fichier est mis par convention √† la racine du d√©p√¥t `Git` du projet.\nAinsi, les personnes souhaitant tester l'application peuvent recr√©er le m√™me environnement Conda que celui qui a servi au d√©veloppement via la commande suivante.\n\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv`\n\nOn refait la d√©marche pr√©c√©dente de cr√©ation d'un \nenvironnement vierge puis un `pip install -r requirements.txt`\n\n```{.bash filename=\"terminal\"}\npython -m venv newenv\nsource newenv/bin/activate\n```\n\n```{.bash filename=\"terminal\" env=\"newenv\"}\npip install -r requirements.txt\n```\n\n\n\n## `conda` \n\nCela se fait en une seule commande:\n\n```{.bash filename=\"terminal\"}\n$ conda env create -f environment.yml\n```\n\n:::\n\n### Changer d'environnement\n\n\n::: {.panel-tabset group=\"language\"}\n\n## `venv` \n\nPour changer d'environnement virtuel, il suffit d'en activer un autre.\n\n```{.bash filename=\"terminal\" no-prefix=\"true\"}\n(myenv) $ deactivate\n$ source anotherenv/bin/activate\n(anotherenv) $ which python\n/chemin/vers/anotherenv/bin/python\n```\n\nPour quitter l'environnement virtuel actif, on utilise simplement la commande `deactivate` :\n\n```{.bash filename=\"terminal\" no-prefix=\"true\"}\n(anotherenv) $ deactivate\n$ \n```\n\n\n## `conda` \n\nPour changer d'environnement, il suffit d'en activer un autre.\n\n```{.bash filename=\"terminal\" no-prefix=\"true\"}\n(dev) $ conda activate base\n(base) $ which python\n/opt/mamba/bin/python\n```\n\nPour sortir de tout environnement conda, on utilise la commande `conda deactivate` :\n\n```{.bash filename=\"terminal\" no-prefix=\"true\"}\n(base) $ conda deactivate\n$ \n```\n\n:::\n\n\n### Aide-m√©moire\n\n| `venv` | `conda` | Principe |\n|------|----------|----------|\n| `python -m venv <env_name>` | `conda create -n <env_name> python=<python_version>` | Cr√©ation d'un environnement nomm√© `<env_name>` dont la version de Python est `<python_version>` |\n|  | `conda info --envs` | Lister les environnements |\n| `source <env_name>/bin/activate` | `conda activate <env_name>` | Utiliser l'environnement `<env_name>` pour la session du terminal |\n| `pip list` | `conda list` | Lister les _packages_ dans l'environnement actif |\n| `pip install <pkg>` | `conda install <pkg>` | Installer le _package_ `<pkg>` dans l'environnement actif |\n| `pip freeze > requirements.txt` | `conda env export > environment.yml` | Exporter les sp√©cifications de l‚Äôenvironnement dans un fichier `requirements.txt` |\n\n\n## Limites\n\nD√©velopper dans des environnements virtuels est une bonne pratique, car cela accro√Æt la portabilit√© d'une application. N√©anmoins, il y a plusieurs limites √† leur utilisation :\n\n- les librairies syst√®me n√©cessaires √† l'installation des packages ne sont pas g√©r√©es ;\n- les environnements virtuels ne permettent pas toujours de g√©rer des projets faisant intervenir diff√©rents langages de programmation ;\n- devoir installer `conda`, `Python`, et les packages n√©cessaires √† chaque changement d'environnement peut √™tre assez long et p√©nible en pratique ;\n- dans un environnement de production, g√©rer des environnements virtuels diff√©rents pour chaque projet peut s'av√©rer rapidement complexe pour les administrateurs syst√®me.\n\nLa technologie des conteneurs permet de r√©pondre √† ces diff√©rents probl√®mes.\n\n# Les conteneurs üêã\n\n![Image trouv√©e sur [reddit](https://www.reddit.com/r/ProgrammerHumor/comments/cw58z7/it_works_on_my_machine/)\n](https://external-preview.redd.it/aR6WdUcsrEgld5xUlglgKX_0sC_NlryCPTXIHk5qdu8.jpg?auto=webp&s=5fe64dd318eec71711d87805d43def2765dd83cd){fig-align=\"center\"}\n\n\n## Introduction\n\nAvec les environnements virtuels,\nl'id√©e √©tait de permettre √† chaque utilisateur potentiel de notre projet d'installer sur son environnement d'ex√©cution les packages n√©cessaires √† la bonne ex√©cution du projet.\n\nN√©anmoins, comme on l'a vu, cette approche ne garantit pas une reproductibilit√© parfaite et a l'inconv√©nient de demander beaucoup de gestion manuelle.\n\nChangeons de perspective : _au lieu de distribuer une recette permettant √† l'utilisateur de recr√©er l'environnement n√©cessaire sur sa machine, ne pourrait-on pas directement distribuer √† l'utilisateur une machine contenant l'environnement pr√©-configur√© ?_\n\nBien entendu, on ve pas configurer et envoyer des ordinateurs portables √† tous les utilisateurs potentiels d'un projet.\nOn va donc essayer de livrer une version virtuelle\nde notre ordinateur. Il existe deux approches principales pour cela:\n\n- Les __machines virtuelles__. Cette approche n'est pas nouvelle.  Elle consiste √† recr√©er, sur un serveur, un environnement informatique complet (mat√©riel et syst√®me d'exploitation) qui r√©plique le comportement d'un v√©ritable ordinateur. \n- Les __conteneurs__, une solution plus l√©g√®re pour empaqueter un environnement informatique afin de r√©pliquer le comportement d'une machine r√©elle. \n\n## Fonctionnement\n\nLes machines virtuelles ont l'inconv√©nient d'√™tre assez lourdes, et complexes √† r√©pliquer et distribuer. Pour pallier ces diff√©rentes limites, les conteneurs se sont impos√©s au cours de la derni√®re d√©cennie. Toutes les infrastructures _cloud_ modernes ont progressivement abandonn√© les machines virtuelles pour privil√©gier des conteneurs pour les raisons que nous allons √©voquer ult√©rieurement. \n\nComme les machines virtuelles, les conteneurs permettent d'empaqueter compl√®tement l'environnement (librairies syst√®mes, application, configuration) qui permet de faire tourner l'application.\nMais √† l'inverse d'une machine virtuelle, le conteneur n'inclut pas de syst√®me d'exploitation propre, il utilise celui de la machine h√¥te qui l'ex√©cute.\nCela signifie que si on d√©sire reproduire le comportement d'une machine Windows, il n'est pas n√©cessaire d'avoir un gros serveur avec Windows. Il est tout √† fait possible d'avoir un serveur Linux, ce qui est la norme, et de r√©pliquer le comportement d'une machine Windows √† l'int√©rieur. A l'inverse, cela peut permettre de tester des configurations Linux ou Mac sur un ordinateur Windows. C'est le r√¥le du logiciel de conteneurisation qui fera la traduction entre les instructions voulues par le _software_ et le syst√®me d'exploitation du _hardware_. \n\nLa technologie des conteneurs permet ainsi de garantir une tr√®s forte reproductibilit√© tout en restant suffisamment l√©g√®re pour permettre une distribution et un d√©ploiement simple aux utilisateurs. En effet, l'adh√©rence forte entre un syst√®me d'exploitation et un logiciel dans l'approche des machines virtuelles rend plus complexe la mont√©e en charge d'un serveur. Si plus d'utilisateurs commencent √† utiliser l'application, il est n√©cessaire de s'assurer que des serveurs correspondant aux besoins de l'application (syst√®me d'exploitation, configurations techniques, etc.) soient disponibles. Avec les conteneurs, la mont√©e en charge est plus simple puisque les restrictions mat√©rielles sont moins fortes: ajouter un serveur Linux avec les logiciels ad√©quats peut √™tre suffisant. \n\n![Diff√©rences entre l'approche conteneurs (gauche) et l'approche machines virtuelles (droite) (Source : [docker.com](https://www.docker.com/resources/what-container/)\n)](/docker-vm.png)\n\nDu point de vue de l'utilisateur, la diff√©rence n'est pas toujours perceptible pour des besoins standards. \nL'utilisateur acc√©dera √† son application par une application d√©di√©e (un navigateur, un logiciel sp√©cialis√©...) et les calculs issus des op√©rations effectu√©es seront d√©port√©s sur les serveurs o√π est h√©berg√©e cette application. N√©anmoins, pour l'organisation qui g√®re cette application, les conteneurs offriront plus de libert√© et de flexibilit√© comme nous l'avons √©voqu√©. \n\n\n## `Docker` {{< fa brands docker >}}, l'impl√©mentation standard\n\nComme nous l'avons √©voqu√©, le logiciel de conteneurisation fait office de couche tampon entre les applications et le syst√®me d'exploitation du serveur. \n\nComme pour les environnements virtuels, il existe diff√©rentes impl√©mentations de la technologie des conteneurs. En pratique, l'impl√©mentation offerte par `Docker` est devenue largement pr√©dominante, au point qu'il est devenu courant d'utiliser de mani√®re interchangeable les termes _\"conteneuriser\"_ et _\"Dockeriser\"_ une application. C'est donc cette impl√©mentation que nous allons √©tudier et utiliser dans ce cours.\n\n### Installation et environnements bacs √† sable\n\n`Docker` {{< fa brands docker >}} est un logiciel qui peut s'installer sur diff√©rents syst√®me d'exploitation. \nLes instructions sont d√©taill√©es dans la [documentation officielle](https://docs.docker.com/get-docker/).\nIl est n√©cessaire d'avoir des droits administrateurs sur son poste pour pouvoir faire cette installation. \n\n::: {.callout-warning collapse=\"true\"}\n## Besoins en espace disque\n\nIl est √©galement recommand√© d'avoir de l'espace disque libre car certaines images (concept sur lequel nous reviendrons), une fois d√©compress√©es et construites, peuvent √™tre lourdes selon la richesse des librairies install√©es dessus. Elles peuvent rapidement prendre quelques Gigas d'espace disque. \n\nCeci est n√©anmoins √† comparer √† l'espace disque monstrueux que peut prendre un syst√®me d'exploitation complet (autour de 15GB pour Ubuntu ou Mac OS, 20GB par exemple pour Windows...). La distribution Linux la plus minimaliste ([Alpine](https://hub.docker.com/_/alpine/tags)) ne fait que 3Mo compress√©e et 5Mo une fois d√©compress√©e. \n:::\n\nIl existe √©galement des environnements en ligne gratuits pouvant servir de bacs √† sable s'il n'est pas possible pour vous d'installer `Docker`.  \n_[Play with Docker](https://labs.play-with-docker.com)_ permet de tester en ligne `Docker` comme on pourrait le faire sur une installation personnelle. N√©anmoins, ces services sont limit√©s: la taille maximale des images d√©compress√©es est limit√©e √† 2Go, les services connaissent des coupures en cas d'utilisation massive...\n\nComme nous le verrons ult√©rieurement, l'utilisation de `Docker` en interactif est pratique pour apprendre et exp√©rimenter. N√©anmoins, en pratique, on utilise principalement `Docker` par le biais de l'int√©gration continue via `Github Actions` ou `Gitlab CI`. \n\n### Principes\n\n![Source : [k21academy.com](https://k21academy.com/docker-kubernetes/docker-and-kubernetes/)](https://ensae-reproductibilite.github.io/slides/img/docker-workflow.png)\n\nUn conteneur Docker est mis √† disposition sous la forme d'une **image**, c'est √† dire d'un fichier binaire qui contient l'environnement n√©cessaire √† l'ex√©cution de l'application. Celui-ci est mis √† disposition de tous sous une forme compress√©e sur un d√©p√¥t d'images publiques (le plus connu est `Dockerhub`). \n\nAvant de mettre √† disposition une image, il est n√©cessaire de la construire (*build*). \nPour cela on utilise un `Dockerfile`, un fichier texte qui contient la recette ‚Äî sous forme de commandes Linux ‚Äî de construction de l'environnement. \n\nUne fois l'image construite, il est possible de faire deux actions:\n\n- La lancer (*run*) en local. Cela permet de tester l'application, √©ventuellement de la corriger en cas de mauvais fonctionnement. Le lancement de l'application permet de faire tourner l'image dans un environnement isol√© qu'on appelle le conteneur (*container*), une instance vivante de l'image en quelques sortes[^assimilation]. \n- La mettre √† disposition sur un d√©p√¥t public pour permettre √† d'autres (ou √† soi-m√™me) de la tester.\nL'image va √™tre upload√©e (*push*) sur un d√©p√¥t (*registry*), public ou priv√©, depuis lequel les utilisateurs vont pouvoir t√©l√©charger l'image (*pull*). \n\n[^assimilation]: Par abus de langage, on m√©lange souvent les termes _\"image\"_ et _\"conteneur\"_. En pratique ces deux concepts sont tr√®s proches. \nLe second correspond √† la version vivante du premier.  \n\n::: {.callout-note collapse=\"true\"}\n## Mettre √† disposition son image `Docker`\n\nLe r√©pertoire d'images publiques le plus connu est [`DockerHub`](https://hub.docker.com/). Il s'agit d'un r√©pertoire o√π n'importe qui peut proposer une image `Docker`, associ√©e ou non √† un projet disponible sur `Github` ou `Gitlab`. Il est possible de mettre √† disposition de mani√®re manuelle des images mais, comme nous le montrerons dans le chapitre sur la [mise en production](/chapters/deployment.html), il est beaucoup plus pratique d'utiliser des fonctionalit√©s d'interaction automatique entre `DockerHub` et un d√©p√¥t `GitHub`.\n:::\n\n\n# `Docker` en pratique: un exemple\n\n[L'application fil rouge](/chapters/application.qmd)\npr√©sente des exemples similaires sur notre cas d'usage\nqu'est une application visant √† rendre public les r√©sultats de notre mod√®le de _machine learning_. \n\n\n## Application\n\nAfin de pr√©senter l'utilisation de `Docker` en pratique, nous allons pr√©senter les diff√©rentes √©tapes permettant de _\"dockeriser\"_ une application web minimaliste construite avec le _framework_ `Python` [`Flask`](https://flask.palletsprojects.com/en/2.1.x/)[^3].\n\n[^3]: [`Flask`](https://flask.palletsprojects.com/en/2.1.x/) est un \n_framework_ permettant de d√©ployer, de mani√®re l√©g√®re,\ndes applications reposant sur \n`Python`.\n\nLa structure de notre projet est la suivante.\n\n```\n‚îú‚îÄ‚îÄ myflaskapp\n‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile\n‚îÇ   ‚îú‚îÄ‚îÄ hello-world.py\n‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt\n```\n\n\nLe script `hello-world.py` contient le code d'une application minimaliste, qui affiche simplement _\"Hello, World!\"_ sur une page web. Nous verrons\ndans l'[application fil rouge](/chapters/application.qmd) comment construire une application interactive plus compl√®te.  \n\n```{.python filename=\"hello-world.py\"}\nfrom flask import Flask\n\napp = Flask(__name__)\n\n\n@app.route(\"/\")\ndef hello_world():\n    return \"<p>Hello, World!</p>\"\n```\n\nPour faire tourner l'application, il nous faut donc √† la fois `Python` et le package `Flask`.\nIl est donc n√©cessaire de contr√¥ler l'environnement virtuel autour de `Python` ce qui va impliquer:\n\n- Installer `Python` ;\n- Installer les _packages_ n√©cessaires √† l'ex√©cution de notre code. En l'occurrence, on n'a besoin que de `Flask`.\n\nSi la version de `Python` utilis√©e par notre application nous importe peu, il est plus simple d'adopter un environnement virtuel `venv` que `conda`. Nous allons donc proposer d'utiliser ceci ce qui tombe bien car nous avons d√©j√† notre `requirements.txt` qui\nprend la forme suivante:\n\n```{.python filename=\"requirements.txt\"}\nFlask==2.1.1\n```\n\nCes installations en deux temps (`Python` et packages n√©cessaires)  doivent √™tre sp√©cifi√©es dans le `Dockerfile` (cf. [section suivante](#dockerfile)). \n\n## Le `Dockerfile` {#dockerfile}\n\nPour faire un plat, il faut une recette. Pour faire\nune image image `Docker`, il faut un `Dockerfile`. \n\nCe fichier texte contient une s√©rie de commandes qui permettent de construire l'image. Ces fichiers peuvent √™tre plus ou moins complexes selon l'application que l'on cherche √† conteneuriser, mais leur structure est assez normalis√©e. \n\nL'id√©e est de partir d'une couche de base (une distribution Linux minimaliste) et y ajouter des couches en fonction des besoins de notre application. \n\nPour illustrer cela, analysons ligne √† ligne le `Dockerfile` n√©cessaire pour construire une image `Docker` de notre application `Flask.`\n\n::: {#efdfd9e0 .cell filename='Dockerfile' execution_count=1}\n``` {.python .cell-code}\nFROM ubuntu:20.04 #<1>\n\nRUN apt-get update -y && \\ \n    apt-get install -y python3-pip python3-dev #<2>\n    \nWORKDIR /app #<3>\n\nCOPY requirements.txt /app/requirements.txt #<4>\nRUN pip install -r requirements.txt #<4>\n\nCOPY . /app #<4>\n\nENV FLASK_APP=\"hello-world.py\" #<5>\nEXPOSE 5000 #<6>\n\nCMD [\"flask\", \"run\", \"--host=0.0.0.0\"] #<7>\n```\n:::\n\n\n1. `FROM` : sp√©cifie l'image de base. Une image `Docker` h√©rite toujours d'une image de base. Ici, on choisit l'image `Ubuntu` version `20.04`, tout va donc se passer comme si l'on d√©veloppait sur une machine virtuelle vierge ayant pour syst√®me d'exploitation `Ubuntu 20.04` {{< fa brands linux >}} ;\n2. `RUN` : lance une commande Linux. Ici, on met d'abord √† jour la liste des packages t√©l√©chargeables via `apt`, puis on installe `Python` {{< fa brands python >}} ainsi que des librairies syst√®me n√©cessaires au bon fonctionnement de notre application ;\n3. `WORKDIR` : sp√©cifie le r√©pertoire de travail de l'image. Ainsi, toutes les commandes suivantes seront ex√©cut√©es depuis ce r√©pertoire. C'est l'√©quivalent `Docker` de la commande `cd` (voir [Linux 101](/chapters/linux-101.qmd)) ;\n4. `COPY` : copie un fichier local sur l'image `Docker`. Cela est li√© √† la mani√®re dont fonctionne `Docker`. Pour ne pas polluer l'image de fichiers non n√©cessaires (qui affecteront de mani√®re incidente sa configuration et le poids de celle-ci), par d√©faut, votre image ne contient pas de fichiers de votre projet. Si certains sont n√©cessaires pour construire l'image, il faut explicitement le dire √† `Docker`. \nIci, on copie d'abord le fichier `requirements.txt` du projet, qui sp√©cifie les d√©pendances `Python` de notre application, puis on les installe avec une commande `RUN`. La seconde instruction `COPY` copie le r√©pertoire du projet sur l'image ;\n5. `ENV` : cr√©e une variable d'environnement qui sera accessible √† l'application dans le conteneur. Ici, on d√©finit une variable d'environnement attendue par `Flask`, qui sp√©cifie le nom du script permettant de lancer l'application ;\n6. `EXPOSE` : informe `Docker` que le conteneur \"√©coute\" sur le port 5000, qui est le port par d√©faut utilis√© par le serveur web de `Flask`. Ceci est li√© √† la nature du fonctionnement de `Flask` qui lance un _localhost_ sur un port donn√©, en l'occurrence le port 5000. ;\n7. `CMD` : sp√©cifie la commande que doit ex√©cuter le conteneur lors de son lancement. Il s'agit d'une liste, qui contient les diff√©rentes parties de la commande sous forme de cha√Ænes de caract√®res. Ici, on lance la commande `flask run` qui sait automatiquement quelle application lancer du fait de la commande `ENV` sp√©cifi√©e pr√©c√©demment. On ajoute l'option `--host=0.0.0.0` pour que ce soit l'application d√©ploy√©e sur le _localhost_ (notre application `Flask`) qui soit mis √† disposition de l'utilisateur final. \n\n::: {.callout-tip collapse=\"true\"}\n## Choisir l'image de base\n\nDans l'id√©al, on essaie de partir d'une couche la plus petite possible\npour limiter la taille de l'image finalement obtenue. Il n'est en effet\npas n√©cessaire d'utiliser une image disposant de {{< fa brands r-project >}} si on n'utilise que\ndu {{< fa brands python >}}.\n\nEn g√©n√©ral, les diff√©rents langages proposent des images de petite taille dans lequel un interpr√©teur est d√©j√† install√© et proprement configur√©. Dans cette application, on aurait par exemple pu utiliser l'image [`python:3.9-slim-buster`](https://hub.docker.com/layers/python/library/python/3.9-slim-buster/images/sha256-e07b35c0c81c21995a43cefd64730ac0e57a5164cc440b6a5c94c118cfacd0ca?context=explore).\n:::\n\n\nAvec la premi√®re commande `RUN` du `Dockerfile`, nous installons `Python` mais aussi des librairies syst√®me n√©cessaires au bon fonctionnement de l'application. Mais comment les avons-nous trouv√©es ?\n\nPar essai et erreur. Lors de l'√©tape de [build](#build) que l'on verra juste apr√®s, le moteur `Docker` va essayer de construire l'image selon les sp√©cifications du `Dockerfile`, comme s'il partait d'un ordinateur vide contenant simplement `Ubuntu 20.04`. Si des librairies manquent, le processus de *build* devrait renvoyer une erreur, qui s'affichera dans les *logs* de l'application, affich√©s par d√©faut dans la console. Quand on a de la chance, les _logs_ d√©crivent explicitement les librairies syst√®me manquantes. Mais souvent, les messages d'erreur ne sont pas tr√®s explicites, et il faut alors les copier dans un moteur de recherche bien connu pour trouver la r√©ponse, souvent sur [StackOverflow](https://stackoverflow.com/).\n\nIl est recommand√©, avant d'essayer de cr√©er une image `Docker`, de passer par l'√©tape interm√©diaire dans la d√©marche de reproductibilit√© qu'est la cr√©ation d'un script shell (`.sh`). Cette approche graduelle est illustr√©e dans [l'application fil rouge](/chapters/application.qmd). \n\n\n::: {.callout-note collapse=\"true\"}\n## L'instruction `COPY`\nLa recette pr√©sente dans le `Dockerfile` peut n√©cessiter l'utilisation de\nfichiers appartenant au dossier de travail. Pour que `Docker` les trouve\ndans son contexte, il est n√©cessaire d'introduire une\ncommande `COPY`. C'est un petit peu comme pour la cuisine: pour utiliser\nun produit dans une recette, il faut le sortir du frigo (fichier local)\net le mettre sur la table. \n:::\n\n\nNous n'avons ici vu que les commandes `Docker` les plus fr√©quentes, il en existe beaucoup d'autres en pratique. N'h√©sitez pas √† consulter la [documentation officielle](https://docs.docker.com/engine/reference/builder/) pour comprendre leur utilisation.\n\n\n\n## Construction d'une image Docker {#build}\n\nPour construire une image √† partir d'un `Dockerfile`, il suffit d'utiliser la commande `docker build` depuis la ligne de commande[^windows]. Il faut ensuite sp√©cifier deux √©l√©ments importants :\n\n- le __*build context*__. Il faut indiquer √† `Docker` le chemin de notre projet, qui doit contenir le `Dockerfile`. En pratique, il est plus simple de se mettre dans le dossier du projet via la commande `cd`, puis de passer `.` comme *build context* pour indiquer √† `Docker` de *build* \"d'ici\" ;\n- le __*tag*__, c'est √† dire le nom de l'image. Tant que l'on utilise `Docker` en local, le *tag* importe peu. On verra par la suite que la structure du *tag* a de l'importance lorsque l'on souhaite [exporter](#imp-docker) ou [importer](#exp-docker) une image `Docker` √† partir d'un d√©p√¥t distant.\n\n[^windows]: Si vous √™tes sur Windows, les lignes de commande disponibles par d√©faut (`cmd` ou `Powershell`) sont peu pratiques. Il est recommand√© d'utiliser la ligne de commande de `Git Bash` (une √©mulation minimaliste d'une ligne de commande `Linux`) qui vous permettra de faire des op√©rations en ligne de commande.  \n\nRegardons ce qui se passe en pratique lorsque l'on essaie de construire notre image. Le tag de celle-ci est `myflaskapp`:\n\n```{.bash filename=\"terminal\"}\ndocker build -t myflaskapp .\n```\n\n```{.python}\nSending build context to Docker daemon     47MB\nStep 1/8 : FROM ubuntu:20.04\n ---> 825d55fb6340\nStep 2/8 : RUN apt-get update && apt-get install -y python3-pip python3-dev\n ---> Running in 92b42d579cfa\n...\ndone.\nRemoving intermediate container 92b42d579cfa\n ---> 8826d53e3c01\nStep 3/8 : WORKDIR /app\n ---> Running in 153b32893c23\nRemoving intermediate container 153b32893c23\n ---> 7b4d22021986\nStep 4/8 : COPY requirements.txt /app/requirements.txt\n...\nSuccessfully built 125bd8da70ff\nSuccessfully tagged myflaskapp:latest\n```\n\n\n\nLe moteur `Docker` essaie de construire notre image s√©quentiellement √† partir des commandes sp√©cifi√©es dans le `Dockerfile`. S'il rencontre une erreur, la proc√©dure s'arr√™te, et il faut alors trouver la source du probl√®me dans les *logs* et adapter le `Dockerfile` en cons√©quence. \n\nSi tout se passe bien, `Docker` nous indique que le *build* a r√©ussi et l'image est pr√™te √† √™tre utilis√©e. On peut v√©rifier que l'image est bien disponible √† l'aide de la commande `docker images`.\n\n```{.bash filename=\"terminal\"}\ndocker images\n```\n\n```{.python}\nREPOSITORY                               TAG       IMAGE ID       CREATED          SIZE\nmyflaskapp                               latest    57d2f410a631   2 hours ago      433MB\n```\n\nInt√©ressons nous un peu plus en d√©tail aux *logs* de l'√©tape de *build* üëÜÔ∏è. \n\nEntre les √©tapes, `Docker` affiche des suites de lettres et de chiffres un peu √©sot√©riques, et nous parle de conteneurs interm√©diaires. En fait, il faut voir une image `Docker` comme un empilement de couches (*layers*), qui sont elles-m√™mes des images `Docker`. Quand on h√©rite d'une image avec l'instruction `FROM`, on sp√©cifie donc √† `Docker` la couche initiale, sur laquelle il va construire le reste de notre environnement. A chaque √©tape sa nouvelle couche, et √† chaque couche son *hash*, un identifiant unique fait de lettres et de chiffres.\n\nCela peut ressembler √† des d√©tails techniques, mais c'est en fait extr√™mement utile en pratique car cela permet √† `Docker` de faire du *caching*. Lorsqu'on d√©veloppe un `Dockerfile`, il est fr√©quent de devoir modifier ce dernier de nombreuses fois avant de trouver la bonne recette, et on aimerait bien ne pas avoir √† *rebuild* l'environnement complet √† chaque fois. `Docker` g√®re cela tr√®s bien : il *cache* chacune des couches interm√©diaires[^cacheCI]. \n\nPar exemple, si l'on modifie la 5√®me commande du `Dockerfile`, `Docker` va utiliser le cache pour ne pas avoir √† recalculer les √©tapes pr√©c√©dentes, qui n'ont pas chang√©. Cela s'appelle l'_\"invalidation du cache\"_ :\nd√®s lors qu'une √©tape du `Dockerfile` est modifi√©e, `Docker` va recalculer toutes les √©tapes suivantes, mais seulement celles-ci. Cons√©quence directe de cette observation : il faut toujours ordonner les √©tapes d'un `Dockerfile` de sorte √† ce qui est le plus susceptible d'√™tre souvent modifi√© soit √† la fin du fichier, et inversement.\n\n[^cacheCI]: Le _cache_ est tr√®s pratique pour une construction exp√©rimentale en local. Malheureusement, lorsqu'on passe par des services d'int√©gration continue, l'utilisation du _cache_ est moins √©vidente car chaque `run` se fait sur une machine ind√©pendante de la pr√©c√©dente. \n\nPour illustrer cela, regardons ce qui se passe si l'on modifie le nom du script qui lance l'application, et donc la valeur de la variable d'environnement `FLASK_APP` dans le `Dockerfile`.\n\n```{.bash filename=\"terminal\"}\ndocker build . -t myflaskapp\n```\n\n::: {#010a5330 .cell execution_count=2}\n``` {.python .cell-code}\nSending build context to Docker daemon  4.096kB\nStep 1/10 : FROM ubuntu:20.04\n ---> 825d55fb6340\nStep 2/10 : ENV DEBIAN_FRONTEND=noninteractive\n ---> Using cache\n ---> ea1c7c083ac9\nStep 3/10 : RUN apt-get update -y &&     apt-get install -y python3-pip python3-dev\n ---> Using cache\n ---> 078b8ac0e1cb\nStep 4/10 : WORKDIR /app\n ---> Using cache\n ---> cd19632825b3\nStep 5/10 : COPY requirements.txt /app/requirements.txt\n ---> Using cache\n ---> 271cd1686899\nStep 6/10 : RUN pip install -r requirements.txt\n ---> Using cache\n ---> 3ea406fdf383\nStep 7/10 : COPY . /app\n ---> 3ce5bd3a9572\nStep 8/10 : ENV FLASK_APP=\"new.py\"\n ---> Running in b378d16bb605\nRemoving intermediate container b378d16bb605\n ---> e1f50490287b\nStep 9/10 : EXPOSE 5000\n ---> Running in ab53c461d3de\nRemoving intermediate container ab53c461d3de\n ---> 0b86eca40a80\nStep 10/10 : CMD [\"flask\", \"run\", \"--host=0.0.0.0\"]\n ---> Running in 340eec151a51\nRemoving intermediate container 340eec151a51\n ---> 16d7a5b8db28\nSuccessfully built 16d7a5b8db28\nSuccessfully tagged myflaskapp:latest\n```\n:::\n\n\nL'√©tape de *build* a pris quelques secondes au lieu de plusieurs minutes, et les *logs* montrent bien l'utilisation du cache faite par `Docker` : les √©tapes pr√©c√©dant le changement r√©utilisent les couches cach√©es, mais celle d'apr√®s sont recalcul√©es.\n\n## Ex√©cuter (_run_) une image `Docker` {#execution}\n\nL'√©tape de *build* a permis de cr√©er une *image* `Docker`. Une image doit √™tre vue comme un *template* : elle permet d'ex√©cuter l'application sur n'importe quel environnement d'ex√©cution sur lequel un moteur `Docker` est install√©. \n\nEn l'√©tat, on a donc juste *construit*, mais rien *lanc√©* : notre application ne tourne pas encore. Pour cela, il faut cr√©er un *conteneur*, i.e. une instance vivante de l'image qui permet d'acc√©der √† l'application. Cela se fait via la commande `docker run`.\n\n```{.bash filename=\"terminal\" no-prefix=true}\n$ docker run -d -p 8000:5000 myflaskapp:latest\n6a2ab0d82d051a3829b182ede7b9152f7b692117d63fa013e7dfe6232f1b9e81\n```\n\nD√©taillons la syntaxe de cette commande :\n\n- `docker run tag` : lance l'image dont on fournit le *tag*. Le *tag* est de la forme `repository/projet:version`. Ici, il n'y a pas de *repository* puisque tout est fait en local ;\n- `-d` : \"d√©tache\" le conteneur du terminal qui le lance ;\n- `-p` : effectue un *mapping* entre un port de la machine qui ex√©cute le conteneur, et le conteneur lui-m√™me. Notre conteneur √©coute sur le port 5000, et l'on veut que notre application soit expos√©e sur le port 8000 de notre machine.\n\nLorsque l'on ex√©cute `docker run`, `Docker` nous r√©pond simplement un *hash* qui identifie le conteneur que l'on a lanc√©. On peut v√©rifier qu'il tourne bien avec la commande `docker ps`, qui renvoie toutes les informations associ√©es au conteneur.\n\n```{.bash filename=\"terminal\"}\ndocker ps\n```\n\n```{.python}\nCONTAINER ID   IMAGE        COMMAND                  CREATED         STATUS         PORTS                                   NAMES\n6a2ab0d82d05   myflaskapp   \"flask run --host=0.‚Ä¶\"   7 seconds ago   Up 6 seconds   0.0.0.0:8000->5000/tcp, :::8000->5000/tcp   vigorous_kalam\n```\n\nLes conteneurs peuvent √™tre utilis√©s pour r√©aliser des t√¢ches tr√®s diff√©rentes. Grossi√®rement, on peut distinguer deux situations :\n\n- le conteneur effectue une t√¢che \"one-shot\", c'est √† dire une op√©ration qui a vocation √† s'effectuer en un certain temps, suite √† quoi le conteneur peut s'arr√™ter ;\n- le conteneur ex√©cute une application. Dans ce cas, on souhaite que le conteneur reste en vie aussi longtemps que l'on souhaite utiliser l'application en question.\n\nDans notre cas d'application, on se situe dans la seconde configuration puisque l'on veut ex√©cuter une application web. Lorsque l'application tourne, elle expose sur le *localhost*, accessible depuis un navigateur web ‚Äî en l'occurence, √† l'adresse [localhost:5000/](localhost:5000/). Les calculs sont effectu√©s sur un serveur local, et le navigateur sert d'interface avec l'utilisateur ‚Äî comme lorsque vous utilisez un _notebook_ `Jupyter` par exemple. \n\nFinalement, on a pu d√©velopper et ex√©cuter une application compl√®te sur notre environnement local, sans avoir eu √† installer quoi que ce soit sur notre machine personnelle, √† part `Docker.`\n\n## Exporter une image `Docker` {#exp-docker}\n\nJusqu'√† maintenant, toutes les commandes `Docker` que nous avons ex√©cut√©es se sont pass√©es en local. Ce mode de fonctionnement peut √™tre int√©ressant pour la phase de d√©veloppement et d'exp√©rimentation. Mais comme on l'a vu, un des gros avantages de `Docker` est la facilit√© de redistribution des images construites, qui peuvent ensuite √™tre utilis√©es par de nombreux utilisateurs pour faire tourner notre application. Pour cela, il nous faut _uploader_ notre image sur un d√©p√¥t distant, √† partir duquel les utilisateurs pourront la t√©l√©charger.\n\nPlusieurs possibilit√©s existent selon le contexte de travail : une entreprise peut avoir un d√©p√¥t interne par exemple. Si le projet est _open source_, on peut utiliser le [DockerHub](https://hub.docker.com/). \n\nLe *workflow* pour uploader une image est le suivant :\n\n- cr√©er un compte sur `DockerHub` ;\n- cr√©er un projet (public) sur `DockerHub`, qui va h√©berger les images `Docker` du projet ;\n- sur un terminal, utiliser `docker login` pour s'authentifier au `DockerHub` ;\n- on va modifier le *tag* que l'on fournit lors du *build* pour sp√©cifier le chemin attendu. Dans notre cas : `docker build -t compte/projet:version .` ;\n- uploader l'image avec `docker push compte/projet:version`\n\n```{.bash filename=\"terminal\"}\ndocker push avouacr/myflaskapp:1.0.0\n```\n\n```{.python}\nThe push refers to repository [docker.io/avouacr/myflaskapp]\n71db96687fe6: Pushed \n624877ac887b: Pushed \nea4ab6b86e70: Pushed \nb5120a5bc48d: Pushed \n5fa484a3c9d8: Pushed \nc5ec52c98b31: Pushed \n1.0.0: digest: sha256:b75fe53fd1990c3092ec41ab0966a9fbbb762f3047957d99327cc16e27c68cc9 size: 1574\n```\n\n## Importer une image `Docker` {#imp-docker}\n\nEn supposant que le d√©p√¥t utilis√© pour uploader l'image est public, la proc√©dure que doit suivre un utilisateur pour la t√©l√©charger se r√©sume √† utiliser la commande `docker pull compte/projet:version`\n\n```{.bash filename=\"terminal\"}\ndocker pull avouacr/myflaskapp:1.0.0\n```\n\n```{.python}\n1.0.0: Pulling from avouacr/myflaskapp\ne0b25ef51634: Pull complete \nc0445e4b247e: Pull complete \n48ba4e71d1c2: Pull complete \nffd728caa80a: Pull complete \n906a95f00510: Pull complete \nd7d49b6e17ab: Pull complete \nDigest: sha256:b75fe53fd1990c3092ec41ab0966a9fbbb762f3047957d99327cc16e27c68cc9\nStatus: Downloaded newer image for avouacr/myflaskapp:1.0.0\ndocker.io/avouacr/myflaskapp:1.0.0\n```\n\n`Docker` t√©l√©charge et extrait chacune des couches qui constituent l'image (ce qui peut parfois √™tre long). L'utilisateur peut alors cr√©er un conteneur √† partir de l'image, en utilisant `docker run` comme illustr√© pr√©c√©demment.\n\n## Aide-m√©moire\n\nVoici une premi√®re aide-m√©moire sur les principales commandes √† int√©grer dans \nun `Dockerfile`:\n\n| Commande | Principe |\n|----------|----------|\n| `FROM <image>:<tag>` | Utiliser comme point de d√©part l'image `<image>` ayant le tag `<tag>` |\n| `RUN <instructions>` | Utiliser la suite d'instructions `<instructions>` dans un terminal `Linux`. Pour passer plusieurs commandes dans un `RUN`, utiliser `&&`. Cette suite de commande peut avoir plusieurs lignes, dans ce cas, mettre `\\` en fin de ligne |\n| `COPY <source> <dest>` | R√©cup√©rer le fichier pr√©sent dans le syst√®me de fichier local √† l'emplacement `<source>` pour que les instructions ult√©rieures puissent le trouver √† l'emplacement `<source>`   |\n| `ADD <source> <dest>` | Globalement, m√™me r√¥le que `COPY` |\n| `ENV MY_NAME=\"John Doe\"` | Cr√©ation d'une variable d'environnement (qui devient disponible sous l'alias `$MY_NAME`)   |\n| `WORKDIR <path>` | D√©finir le _working directory_ du conteuneur Docker dans le dossier `<path>`  |\n| `USER <username>` | Cr√©ation d'un utilisateur non _root_ nomm√© `<username>`  |\n| `EXPOSE <PORT_ID>` | Lorsqu'elle tournera, l'application sera disponible depuis le port `<PORT_ID>`\n| `CMD [\"executable\",\"param1\",\"param2\"]` | Au lancement de l'instance Docker la commande `executable` (par exemple `python3`) sera lanc√©e avec les param√®tres additionnels fournis  |\n\nUne seconde aide-m√©moire pour les principales commandes `Linux` est disponible ci-dessous:\n\n| Commande | Principe |\n|----------|----------|\n| `docker build . -t <tag>` | Construire l'image `Docker` √† partir des fichiers dans le r√©pertoire courant (`.`) en l'identifiant avec le tag `<tag>`  |\n| `docker run -it <tag>` | Lancer l'instance docker identifi√©e par `<tag>`  |\n| `docker images` | Lister les images disponibles sur la machine et quelques unes de leurs propri√©t√©s (tags, volume, etc.) |\n| `docker system prune` | Faire un peu de m√©nage dans ses images `Docker` (bien r√©fl√©chir avant de faire tourner cette commande) |\n\n",
    "supporting": [
      "portability_files"
    ],
    "filters": [],
    "includes": {}
  }
}