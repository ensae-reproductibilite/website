{
  "hash": "a129fd069fab68144083b880909809b2",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Application\"\nimage: images/rocket.png\ndescription: |\n  Une application fil rouge pour illustrer l'int√©r√™t d'appliquer graduellement les bonnes pratiques dans une optique de mise en production d'une application de data science.\norder: 7\nhref: chapters/application.html\n---\n\n<details>\n<summary>\nD√©rouler les _slides_ ci-dessous ou [cliquer ici](https://ensae-reproductibilite.github.io/slides/#/title-slide)\npour afficher les slides en plein √©cran.\n</summary>\n\n\n<div class=\"sourceCode\" id=\"cb1\"><pre class=\"sourceCode yaml code-with-copy\"><code class=\"sourceCode yaml\"></code><button title=\"Copy to Clipboard\" class=\"code-copy-button\"><i class=\"bi\"></i></button></pre><iframe class=\"sourceCode yaml code-with-copy\" src=\"https://ensae-reproductibilite.github.io/slides/#/title-slide\"></iframe></div>\n\n</details>\n\nL'objectif de cette mise en application est d'**illustrer les diff√©rentes √©tapes qui s√©parent la phase de d√©veloppement d'un projet de celle de la mise en production**. Elle permettra de mettre en pratique les diff√©rents concepts pr√©sent√©s tout au long du cours.\n\nCelle-ci est un tutoriel pas √† pas pour avoir un projet reproductible et disponible sous plusieurs livrables. \nToutes les √©tapes ne sont pas indispensables √† tous les projets de _data science_. \n\nNous nous pla√ßons dans une situation initiale correspondant √† la fin de la phase de d√©veloppement d'un projet de data science.\nOn a un _notebook_ un peu monolithique, qui r√©alise les √©tapes classiques d'un *pipeline* de *machine learning* :\n\n- Import de donn√©es ;\n- Statistiques descriptives et visualisations ;\n- *Feature engineering* ;\n- Entra√Ænement d'un mod√®le ;\n- Evaluation du mod√®le.\n\n**L'objectif est d'am√©liorer le projet de mani√®re incr√©mentale jusqu'√† pouvoir le mettre en production, en le valorisant sous une forme adapt√©e.** \n\n\n<details>\n<summary>\nIllustration de notre point de d√©part\n</summary>\n![](/workflow1.png)\n</details>\n\n<details>\n<summary>\nIllustration de l'horizon vers lequel on se dirige\n</summary>\n![](/workflow2.png)\n</details>\n\n::: {.callout-important}\nIl est important de bien lire les consignes et d'y aller progressivement.\nCertaines √©tapes peuvent √™tre rapides, d'autres plus fastidieuses ;\ncertaines √™tre assez guid√©es, d'autres vous laisser plus de libert√©.\nSi vous n'effectuez pas une √©tape, vous risquez de ne pas pouvoir passer √†\nl'√©tape suivante qui en d√©pend.\n\nBien que l'exercice soit applicable sur toute configuration bien faite, nous \nrecommandons de privil√©gier l'utilisation du [SSP Cloud](https://datalab.sspcloud.fr/home), o√π tous les \noutils n√©cessaires sont pr√©-install√©s et pr√©-configur√©s. Le service `VSCode`\nne sera en effet que le point d'entr√©e pour l'utilisation d'outils plus exigeants\nsur le plan de l'infrastructure: _Argo_, _MLFLow_, etc.\n:::\n\n\n# Partie 0 : initialisation du projet\n\n::: {.callout-tip}\n## Application pr√©liminaire: forker le d√©p√¥t d'exemple\n\nLes premi√®res √©tapes consistent √† mettre en place son environnement de travail sur `Github`:\n\n- G√©n√©rer un jeton d'acc√®s (*token*) sur `GitHub` afin de permettre l'authentification en ligne de commande √† votre compte.\nLa proc√©dure est d√©crite [ici](https://docs.sspcloud.fr/onyxia-guide/controle-de-version#creer-un-jeton-dacces-token). \n__Vous ne voyez ce jeton qu'une fois, ne fermez pas la page de suite__. \n\n- Mettez de c√¥t√© ce jeton en l'enregistrant dans un gestionnaire de mot de passe ou dans \nl'espace _[\"Mon compte\"](https://datalab.sspcloud.fr/account/third-party-integration)_\ndu `SSP Cloud`. \n\n- Forker le d√©p√¥t `Github` : [https://github.com/ensae-reproductibilite/application-correction](https://github.com/ensae-reproductibilite/application-correction) en faisant attention √† deux choses:\n    + Renommer le d√©p√¥t en `ensae-reproductibilite-application-correction.git` ;\n    + D√©cocher la case _\"Copy the `main` branch only\"_ afin de copier √©galement les _tags_ `Git` qui nous permettront de faire les _checkpoint_\n\n\n<details>\n\n<summary>\nCe que vous devriez voir sur la page de cr√©ation du _fork_\n</summary>\n\n![](/fork-example.png)\n\n</details>\n\nIl est maintenant possible de ce lancer dans la cr√©ation de l'environnement de travail:\n\n- Ouvrir un service `VSCode` sur le [SSP Cloud](https://datalab.sspcloud.fr/home). Vous pouvez aller\ndans la page `My Services` et cliquer sur `New service`. Sinon, vous\npouvez initialiser la cr√©ation du service en cliquant directement [ici](https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=false). __Modifier les options suivantes__:\n    + Dans l'onglet `Kubernetes`, s√©lectionner le r√¥le `Admin` ;\n    + Dans l'onglet `Networking`, cliquer sur \"Enable a custom service port\" et laisser la valeur par d√©faut 5000 pour le num√©ro du port\n\n- Cl√¥ner __votre__ d√©p√¥t `Github` en utilisant le\nterminal depuis `Visual Studio` (`Terminal > New Terminal`) et\nen passant directement le token dans l'URL selon cette structure:\n\n```{.bash filename=\"terminal\"}\ngit clone https://<TOKEN>@github.com/<USERNAME>/ensae-reproductibilite-application-correction.git\n```\n\no√π `<TOKEN>` et `<USERNAME>` sont √† remplacer, respectivement, \npar le jeton que vous avez g√©n√©r√© pr√©c√©demment et votre nom d'utilisateur.\n\n- Se placer avec le terminal dans le dossier en question : \n\n```{.bash filename=\"terminal\"}\ncd ensae-reproductibilite-application-correction\n```\n\n- Se placer sur une branche de travail en faisant:\n\n```{.bash filename=\"terminal\"}\ngit checkout -b dev\n```\n\n:::\n\n\n# Partie 1 : qualit√© du script\n\nCette premi√®re partie vise √† **rendre le projet conforme aux bonnes pratiques** pr√©sent√©es dans le cours.\n\nElle fait intervenir les notions suivantes : \n\n- Utilisation du **terminal** (voir [Linux 101](/chapters/linux-101.html)) ;\n- **Qualit√© du code** (voir [Qualit√© du code](/chapters/code-quality.html)) ;\n- **Architecture de projets** (voir [Architecture des projets](/chapters/projects-architecture.html)) ;\n- **Contr√¥le de version** avec `Git` (voir [Rappels `Git`](/chapters/git.qmd)) ;\n- **Travail collaboratif** avec `Git` et `GitHub` (voir [Rappels `Git`](/chapters/git.qmd)).\n\nNous allons partir de ce _Notebook_ `Jupyter`,\nque vous pouvez pr√©visualiser voire tester\nen cliquant sur l'un des liens suivants:\n\n_to do bouton onyxia_\n<a href=\"https://github.com/ensae-reproductibilite/application-correction/blob/main/titanic.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n\nLe plan de la partie est le suivant :\n\n1. S'assurer que le script fonctionne ;\n2. Nettoyer le code des scories formelles avec un _linter_ et un _formatter_ ;\n3. Param√©trisation du script ;\n4. Utilisation de fonctions.\n\n\n## √âtape 1 : s'assurer que le script s'ex√©cute correctement\n\nOn va partir du fichier `notebook.py` qui reprend le contenu \ndu _notebook_[^jupytext] mais dans un script classique.\nLe travail de nettoyage en sera facilit√©. \n\n[^jupytext]: L'export dans un script `.py` a √©t√© fait\n        directement depuis `VSCode`. Comme\n        cela n'est pas vraiment l'objet du cours, nous passons cette √©tape et fournissons\n        directement le script expurg√© du texte interm√©diaire. Mais n'oubliez\n        pas que cette d√©marche, fr√©quente quand on a d√©marr√© sur un _notebook_ et\n        qu'on d√©sire consolider en faisant la transition vers des \n        scripts, n√©cessite d'√™tre attentif pour ne pas risquer de faire une erreur. \n\nLa premi√®re √©tape est simple, mais souvent oubli√©e : **v√©rifier que le code fonctionne correctement**. \nPour cela, nous recommandons de faire un aller-retour entre le script ouvert dans `VSCode`\net un terminal pour le lancer. \n\n\n::: {.callout-tip}\n## Application 1: corriger les erreurs\n\n- Ouvrir dans `VSCode` le script `titanic.py` ;\n- Ex√©cuter le script en ligne de commande (`python titanic.py`)[^interactivite] pour d√©tecter les erreurs ;\n- Corriger les deux erreurs qui emp√™chent la bonne ex√©cution ;\n- V√©rifier le fonctionnement du script en utilisant la ligne de commande:\n\n```{.bash filename=\"terminal\"}\npython titanic.py\n```\n\nLe code devrait afficher des sorties.\n\n<details>\n<summary>\nAide sur les erreurs rencontr√©es\n</summary>\n\nLa premi√®re erreur rencontr√©e est une alerte `FileNotFoundError`,\nla seconde est li√©e √† un _package_. \n\n</details>\n\n\nIl est maintenant temps de *commit* les changements effectu√©s avec `Git`[^2] :\n\n\n```{.bash filename=\"terminal\"}\ngit add titanic.py\ngit commit -m \"Corrige l'erreur qui emp√™chait l'ex√©cution\"\ngit push\n```\n\n<!---- \nTemps estim√©: 3mn\n------>\n\n:::\n\n[^interactivite]: Il est √©galement possible avec `VSCode` d'ex√©cuter le script ligne √† ligne\nde mani√®re interactive ligne √† ligne (<kbd>MAJ</kbd>+<kbd>ENTER</kbd>). N√©anmoins, cela n√©cessite\nde s'assurer que le _working directory_ de votre console interactive est le bon. Celle-ci se\nlance selon les param√®tres pr√©configur√©s de `VSCode` et les votres ne sont peut-√™tre pas les\nm√™mes que les notres. Vous pouvez changer le _working directory_ dans le script\nen utilisant le _package_ `os` mais peut-√™tre allez vous d√©couvrir ult√©rieurement qu'il\ny a de meilleures pratiques...\n[^2]: Essayez de *commit* vos changements √† chaque √©tape de l'exercice, c'est une bonne habitude √† prendre.\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli1\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n## √âtape 2: utiliser un _linter_ puis un _formatter_\n\nOn va maintenant am√©liorer la qualit√© de notre code en appliquant les standards communautaires.\nPour cela, on va utiliser le *linter* classique [`PyLint`](https://pylint.readthedocs.io/en/latest/)\net le _formatter_ [`Black`](https://github.com/psf/black).\n\n::: {.callout-important}\n[`PyLint`](https://pylint.readthedocs.io/en/latest/) et [`Black`](https://black.readthedocs.io/en/stable/)\nsont des _packages_ `Python` qui \ns'utilisent principalement en ligne de commande.\n\nSi vous avez une erreur qui sugg√®re\nque votre terminal ne connait pas [`PyLint`](https://pylint.readthedocs.io/en/latest/)\nou [`Black`](https://black.readthedocs.io/en/stable/),\nn'oubliez pas d'ex√©cuter la commande `pip install pylint` ou `pip install black`.\n:::\n\n\nLe _linter_ renvoie alors une s√©rie d'irr√©gularit√©s,\nen pr√©cisant √† chaque fois la ligne de l'erreur et le message d'erreur associ√© (ex : mauvaise identation).\nIl renvoie finalement une note sur 10,\nqui estime la qualit√© du code √† l'aune des standards communautaires √©voqu√©s\ndans la partie [Qualit√© du code](/chapters/code-quality.html).\n\n::: {.callout-tip}\n## Application 2: rendre lisible le script\n\n- Diagnostiquer et √©valuer la qualit√© de `titanic.py` avec [`PyLint`](https://pylint.readthedocs.io/en/latest/). Regarder la note obtenue.\n- Utiliser `black titanic.py --diff --color` pour observer les changements de forme que va induire l'utilisation du _formatter_ [`Black`](https://black.readthedocs.io/en/stable/). Cette √©tape n'applique pas les modifications, elle ne fait que vous les montrer.\n- Appliquer le _formatter_ [`Black`](https://black.readthedocs.io/en/stable/)\n- R√©utiliser [`PyLint`](https://pylint.readthedocs.io/en/latest/) pour diagnostiquer l'am√©lioration de la qualit√© du script et le travail qui reste √† faire. \n- Comme la majorit√© du travail restant est √† consacrer aux imports:\n    - Mettre tous les _imports_ ensemble en d√©but de script\n    - Retirer les _imports_ redondants en s'aidant des diagnostics de votre √©diteur\n    - R√©ordonner les _imports_ si [`PyLint`](https://pylint.readthedocs.io/en/latest/) vous indique de le faire\n    - Corriger les derni√®res fautes formelles sugg√©r√©es par [`PyLint`](https://pylint.readthedocs.io/en/latest/)\n- D√©limiter des parties dans votre code pour rendre sa structure plus lisible \n\n<!-----\nTemps test Julien: 22mn\n------>\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli2\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\nLe code est maintenant lisible, il obtient √† ce stade une note formelle proche de 10.\nMais il n'est pas encore totalement intelligible ou fiable.\nIl y a notamment \nbeaucoup de redondance de code auxquelles nous allons nous attaquer par la suite. \nN√©anmoins, avant cela, occupons-nous de mieux g√©rer certains param√®tres du script: \njetons d'API et chemin des fichiers.\n\n\n## √âtape 3: gestion des param√®tres\n\nL'ex√©cution du code et les r√©sultats obtenus\nd√©pendent de certains param√®tres d√©finis dans le code. L'√©tude de r√©sultats\nalternatifs, en jouant sur \ndes variantes des (hyper)param√®tres, est √† ce stade compliqu√©e\ncar il est n√©cessaire de parcourir le code pour trouver\nces param√®tres. De plus, certains param√®tres personnels\ncomme des jetons\nd'API ou des mots de passe n'ont pas vocation √† \n√™tre pr√©sents dans le code. \n\nIl est plus judicieux de consid√©rer ces param√®tres comme des\nvariables d'entr√©e du script. Cela peut √™tre fait de deux\nmani√®res:\n\n1. Avec des __arguments optionnels__ appel√©s depuis la ligne de commande _(Application 3a)_.\nCela peut √™tre pratique pour mettre en oeuvre des tests automatis√©s mais\nn'est pas forc√©ment pertinent pour toutes les variables. Nous allons montrer\ncet usage avec le nombre d'arbres de notre _random forest_ ;\n2. En utilisant un __fichier de configuration__ dont les valeurs sont import√©es dans\nle script principal _(Application 3b)_. \n\n\n<details>\n<summary>\nUn exemple de d√©finition d'un argument pour l'utilisation en ligne de commande\n</summary>\n\n```{.python filename=\"prenom.py\"}\nimport argparse\nparser = argparse.ArgumentParser(description=\"Qui √™tes-vous?\")\nparser.add_argument(\n    \"--prenom\", type=str, default=\"Toto\", help=\"Un pr√©nom √† afficher\"\n)\nargs = parser.parse_args()\nprint(args.prenom)\n```\n\nExemples d'utilisations en ligne de commande\n\n```{.bash filename=\"terminal\"}\npython prenom.py\npython prenom.py --prenom \"Zinedine\"\n```\n\n</details>\n\n::: {.callout-tip}\n## Application 3a: Param√©trisation du script\n\n1. En s'inspirant de l'exemple ci-dessus üëÜÔ∏è,\ncr√©er une variable `n_trees` qui peut √©ventuellement √™tre param√©tr√©e en ligne de commande\net dont la valeur par d√©faut est 20 ;\n2. Tester cette param√©trisation en ligne de commande avec la valeur par d√©faut\npuis 2, 10 et 50 arbres.\n:::\n\nL'exercice suivant permet de mettre en application le fait de param√©triser\nun script en utilisant des variables d√©finies dans un fichier YAML. \n\n\n::: {.callout-tip}\n## Application 3b: La configuration dans un fichier YAML\n\nNous allons mettre 4 param√®tres dans notre YAML. Celui-ci prendra la forme suivante:\n\n```{.yaml filename=\"config.yaml\"}\njeton_api: ####\ntrain_path: ####\ntest_path: ####\ntest_fraction: ####\n```\n\nAvec `####` des valeurs √† remplacer.\n\n1. Cr√©er √† la racine du projet un fichier `config.yaml` √† partir du\nmod√®le üëÜÔ∏è ;\n2. Rep√©rer les valeurs dans le code associ√©es et compl√©ter.\n\nMaintenant, nous allons exploiter ce fichier:\n\n3. Pour √©viter d'avoir √† le faire plus tard,\ncr√©er une fonction `import_yaml_config` qui prend en argument le\nchemin d'un fichier `YAML`\net renvoie le contenu de celui-ci en _output_. Vous pouvez suivre\nle conseil du chapitre sur la [Qualit√© du code](/chapters/code-quality.html)\nen adoptant le _type hinting_ ;\n\n<details>\n<summary>Indice si vous ne trouvez pas comment lire un fichier `YAML`</summary>\n\nSi le fichier s'appelle `toto.yaml`, vous pouvez l'importer de cette mani√®re:\n\n::: {#61d83db6 .cell execution_count=1}\n``` {.python .cell-code}\nwith open(\"toto.yaml\", \"r\", encoding=\"utf-8\") as stream:\n    dict_config = yaml.safe_load(stream)\n```\n:::\n\n\n</details>\n\n4. Dans la fonction `import_yaml_config`,\ncr√©er une condition logique pour tenir compte du fait que le YAML de configuration\npeut ne pas exister[^fileexist] ;\n\n<details>\n<summary>Indice si vous ne savez comment conditionner la cr√©ation de la configuration √† l'existence du fichier</summary>\n\nVoici la ligne qui peut vous aider. L'id√©al\nest d'ins√©rer ceci dans `import_yaml_config`:\n\n::: {#d39567b1 .cell execution_count=2}\n``` {.python .cell-code}\nCONFIG_PATH = 'config.yaml'\nconfig = {}\nif os.path.exists(CONFIG_PATH):\n    # lecture du fichier\n```\n:::\n\n\n</details>\n\n\n5. Utiliser le canevas de code suivant pour cr√©er les variables ad√©quates\n\n::: {#8f05f0bd .cell execution_count=3}\n``` {.python .cell-code}\nAPI_TOKEN = config.get(\"jeton_api\")\nTRAIN_PATH = config.get(\"train_path\", \"train.csv\")\nTEST_PATH = config.get(\"test_path\", \"test.csv\")\nTEST_FRACTION = config.get(\"test_fraction\", .1)\n```\n:::\n\n\net remplacer dans le code ;\n\n5. Tester en ligne de commande que l'ex√©cution du fichier est toujours\nsans erreur et sinon corriger ;\n6. Refaire un diagnostic avec [`PyLint`](https://pylint.readthedocs.io/en/latest/)\net corriger les √©ventuels messages ;\n7. Cr√©er un fichier `.gitignore` (cf. [Chapitre `Git`](/chapters/git.qmd)). Ajouter dans ce fichier `config.yaml`\ncar il ne faut pas committer ce fichier. Au passage ajouter `__pycache__/` au `.gitignore`[^pycache], cela\n√©vitera d'avoir √† le faire ult√©rieurement ;\n9. Cr√©er un fichier `README.md` o√π vous indiquez qu'il faut cr√©er un fichier `config.yaml` pour\npouvoir utiliser l'API. \n\n[^fileexist]: Ici, le jeton d'API n'est pas indispensable pour que le code\n    fonctionne. Afin d'√©viter une erreur non n√©cessaire\n    lorsqu'on automatisera le processus, on peut\n    cr√©er une condition qui v√©rifie la pr√©sence ou non de ce fichier.\n    Le script reste donc reproductible m√™me pour un utilisateur n'ayant pas le fichier\n    `secrets.yaml`. \n\n[^pycache]: Il est normal d'avoir des dossiers `__pycache__` qui tra√Ænent en local : ils se cr√©ent automatiquement √† l'ex√©cution d'un script en `Python`. N√©anmoins, il ne faut pas associer ces fichiers √† `Git`, voil√† pourquoi on les ajoute au `.gitignore`.\n\n\n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli3\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n## √âtape 4 : Privil√©gier la programmation fonctionnelle\n\nNous allons **mettre en fonctions les parties importantes de l'analyse**. \nCeci facilitera l'√©tape ult√©rieure de modularisation de notre projet. \n\nCet exercice √©tant chronophage, il n'est __pas obligatoire de le r√©aliser en entier__. L'important est de\ncomprendre la d√©marche et d'adopter fr√©quemment une approche fonctionnelle[^POO]. Pour obtenir \nune chaine enti√®rement fonctionnalis√©e, vous pouvez reprendre le _checkpoint_.\n\n[^POO]: Nous proposons ici d'adopter le principe de la __programmation fonctionnelle__. Pour encore fiabiliser\nun processus, il serait possible d'adopter le paradigme de la __programmation orient√©e objet (POO)__. Celle-ci est\nplus rebutante et demande plus de temps au d√©veloppeur. L'arbitrage co√ªt-avantage est n√©gatif pour notre\nexemple, nous proposons donc de nous en passer. N√©anmoins, pour une mise en production r√©elle d'un mod√®le,\nil est recommand√© de l'adopter. C'est d'ailleurs obligatoire avec des [_pipelines_ `scikit`](https://pythonds.linogaliana.fr/pipeline-scikit/). \n\n::: {.callout-tip}\n## Application 4: adoption des standards de programmation fonctionnelle \n\n- Cr√©er une fonction qui importe les donn√©es d'entra√Ænement (`train.csv`) et de test (`test.csv`) et renvoie des `DataFrames` `Pandas` ;\n- En fonction du temps disponible, cr√©er plusieurs fonctions pour r√©aliser les √©tapes de *feature engineering*:\n    + La cr√©ation de la variable _\"Title\"_ peut √™tre automatis√©e en vertu du principe _\"do not repeat yourself\"_[^notepandas].\n    + Regrouper ensemble les `fillna` et essayer de cr√©er une fonction g√©n√©ralisant l'op√©ration. \n    + Les _label encoders_ peuvent √™tre transform√©s en deux fonctions: une premi√®re pour encoder une colonne puis une seconde qui utilise\n    la premi√®re de mani√®re r√©p√©t√©e pour encoder plusieurs colonnes. _Remarquez les erreurs de copier-coller que cela corrige_\n    + Finaliser les derni√®res transformations avec des fonctions\n- Cr√©er une fonction qui r√©alise le *split train/test* de validation en fonction d'un param√®tre repr√©sentant la proportion de l'√©chantillon de test.\n- Cr√©er une fonction qui entra√Æne et √©value un classifieur `RandomForest`, et qui prend en param√®tre le nombre d'arbres (`n_estimators`). La fonction doit imprimer √† la fin la performance obtenue et la matrice de confusion.\n- D√©placer toutes les fonctions ensemble, en d√©but de script.\n:::\n\n[^notepandas]: Au passage vous pouvez noter que mauvaises pratiques discutables,\n    peuvent\n    √™tre corrig√©es, notamment l'utilisation excessive de `apply` l√† o√π\n    il serait possible d'utiliser des m√©thodes embarqu√©es par `Pandas`.\n    Cela est plut√¥t de l'ordre du bon style de programmation que de la\n    qualit√© formelle du script. Ce n'est donc pas obligatoire mais c'est mieux. \n\n\n::: {.callout-important}\nLe fait d'appliquer des fonctions a d√©j√† am√©lior√© la fiabilit√© du processus\nen r√©duisant le nombre d'erreurs de copier-coller. N√©anmoins, pour vraiment\nfiabiliser le processus, il faudrait utiliser un _pipeline_ de transformations\nde donn√©es. \n\nCeci n'est pas encore au programme du cours mais le sera dans une prochaine \nversion. \n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli4\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\nCela ne se remarque pas encore vraiment car nous avons de nombreuses d√©finitions de fonctions\nmais notre chaine de production est beaucoup plus\nconcise (le script fait environ 300 lignes dont 250 de d√©finitions de fonctions g√©n√©riques).\nCette auto-discipline facilitera grandement\nles √©tapes ult√©rieures. Cela aurait √©t√© n√©anmoins beaucoup moins co√ªteux en temps d'adopter\nces bons gestes de mani√®re plus pr√©coce. \n\n\n# Partie 2 : adoption d'une structure modulaire {#partie2}\n\nDans la partie pr√©c√©dente,\non a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues tout au long du cours.\nCe faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'un\npossible partage du code : celui-ci est lisible et intelligible. \nLe code est proprement versionn√© sur un\nd√©p√¥t `GitHub`.\nCependant, le projet est encore perfectible: il est encore difficile de rentrer\ndedans si on ne sait pas exactement ce qu'on recherche. L'objectif de cette partie\nest d'isoler les diff√©rentes √©tapes de notre _pipeline_. \nOutre le gain de clart√© pour notre projet, nous √©conomiserons beaucoup de peines\npour la mise en production ult√©rieure de notre mod√®le. \n\n<details>\n<summary>\nIllustration de l'√©tat actuel du projet \n</summary>\n![](/schema_post_appli4.png)\n</details>\n\nDans cette partie nous allons continuer les am√©liorations\nincr√©mentales de notre projet avec les √©tapes suivantes:\n\n1. Modularisation du code `Python` pour s√©parer les diff√©rentes\n√©tapes de notre _pipeline_ ; \n2. Adopter une structure standardis√©e pour notre projet afin\nd'autodocumenter l'organisation de celui-ci ; \n3. Documenter les _packages_ indispensables √† l'ex√©cution du code ;\n4. Stocker les donn√©es dans un environnement ad√©quat\nafin de continuer la d√©marche de s√©parer conceptuellement les donn√©es du code en de la configuration.\n\n\n## √âtape 1 : modularisation\n\nNous allons profiter de la modularisation pour adopter une structure\napplicative pour notre code. Celui-ci n'√©tant en effet plus lanc√©\nque la ligne de commande, on peut consid√©rer qu'on construit\nune application g√©n√©rique o√π un script principal (`main.py`)\nencapsule des √©l√©ments issus d'autres scripts. \n\n::: {.callout-tip}\n## Application 5: modularisation\n\n- D√©placer les fonctions dans une s√©rie de fichiers d√©di√©s:\n    +  `import_data.py`: fonctions d'import de donn√©es \n    +  `build_features.py`: fonctions regroupant les √©tapes de _feature engineering_ \n    +  `train_evaluate.py`: fonctions d'entrainement et d'√©valuation du mod√®le\n- Sp√©cifier les d√©pendances (i.e. les packages √† importer)\ndans les modules pour que ceux-ci puissent s'ex√©cuter ind√©pendamment ;\n- Renommer `titanic.py` en `main.py` pour suivre la convention de nommage des projets `Python` ;\n- Importer les fonctions n√©cessaires √† partir des modules.\n- V√©rifier que tout fonctionne bien en ex√©cutant le _script_ `main` √† partir de la ligne de commande :\n\n```{.bash filename=\"terminal\"}\n$ python main.py\n```\n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli5\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n## √âtape 2 : adopter une architecture standardis√©e de projet\n\nOn dispose maintenant d'une application `Python` fonctionnelle. \nN√©anmoins, le projet est certes plus fiable mais sa structuration\nlaisse √† d√©sirer et il serait difficile de rentrer √† nouveau\ndans le projet dans quelques temps. \n\n<details>\n<summary>Etat actuel du projet üôà</summary>\n\n```\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ train.csv\n‚îú‚îÄ‚îÄ test.csv\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ config.yaml\n‚îú‚îÄ‚îÄ import_data.py\n‚îú‚îÄ‚îÄ build_features.py\n‚îú‚îÄ‚îÄ train_evaluate.py\n‚îú‚îÄ‚îÄ titanic.ipynb\n‚îî‚îÄ‚îÄ main.py\n```\n\n</details>\n\nComme cela est expliqu√© dans la\npartie [Structure des projets](/chapters/projects-architecture.html),\non va adopter une structure certes arbitraire mais qui va \nfaciliter l'autodocumentation de notre projet. De plus, une telle structure va faciliter des √©volutions optionnelles\ncomme la _packagisation_ du projet. Passer d'une structure modulaire\nbien faite √† un _package_ est quasi-imm√©diat en `Python`. \n\nOn va donc modifier l'architecture de notre projet pour la rendre plus standardis√©e.\nPour cela, on va s'inspirer des structures\n[`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/)\nqui g√©n√®rent des _templates_ de projet. En l'occurrence\nnotre source d'inspiration sera le [_template datascience_](https://drivendata.github.io/cookiecutter-data-science/)\nissu d'un effort communautaire.\n\n::: {.callout-note}\nL'id√©e de [`cookiecutter`](https://cookiecutter.readthedocs.io/en/stable/) est de proposer des _templates_ que l'on utilise pour __initialiser__ un projet, afin de b√¢tir √† l'avance une structure √©volutive. La syntaxe √† utiliser dans ce cas est la suivante : \n\n```{.bash filename=\"terminal\"}\npip install cookiecutter\ncookiecutter https://github.com/drivendata/cookiecutter-data-science\n```\n\nIci, on a d√©j√† un projet, on va donc faire les choses dans l'autre sens : on va s'inspirer de la structure propos√©e afin de r√©organiser celle de notre projet selon les standards communautaires.\n:::\n\nEn s'inspirant du _cookiecutter data science_\non va adopter la structure suivante:\n\n<details>\n<summary>\nStructure recommand√©e\n</summary>\n\n```\nensae-reproductibilite-application\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ data\n‚îÇ   ‚îî‚îÄ‚îÄ raw\n‚îÇ       ‚îú‚îÄ‚îÄ test.csv\n‚îÇ       ‚îî‚îÄ‚îÄ train.csv\n‚îú‚îÄ‚îÄ configuration\n‚îÇ   ‚îî‚îÄ‚îÄ config.yaml\n‚îú‚îÄ‚îÄ notebooks\n‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ data\n    ‚îÇ   ‚îî‚îÄ‚îÄ import_data.py\n    ‚îú‚îÄ‚îÄ features\n    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py\n    ‚îî‚îÄ‚îÄ models\n        ‚îî‚îÄ‚îÄ train_evaluate.py\n```\n\n</details>\n\n::: {.callout-tip}\n\n## Application 6: adopter une structure lisible\n\n- _(optionnel)_ Analyser et comprendre la [structure de projet](https://drivendata.github.io/cookiecutter-data-science/#directory-structure) propos√©e par le template ;\n- Modifier l'arborescence du projet selon le mod√®le ;\n- Mettre √† jour l'import des d√©pendances, le fichier de configuration et `main.py` avec les nouveaux chemins ;\n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli6\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n\n:::\n\n\n\n\n## √âtape 3: indiquer l'environnement minimal de reproductibilit√©\n\nLe script `main.py` n√©cessite un certain nombre de packages pour\n√™tre fonctionnel. Chez vous les packages n√©cessaires sont\nbien s√ªr install√©s mais √™tes-vous assur√© que c'est le cas \nchez la personne qui testera votre code ? \n\nAfin de favoriser la portabilit√© du projet,\nil est d'usage de _\"fixer l'environnement\"_,\nc'est-√†-dire d'indiquer dans un fichier toutes les d√©pendances utilis√©es ainsi que leurs version.\nNous proposons de cr√©er un fichier `requirements.txt` minimal, sur lequel nous reviendrons\ndans la partie consacr√©e aux environnements reproductibles. \n\nLe fichier `requirements.txt` est conventionnellement localis√© √† la racine du projet.\nIci on ne va pas fixer les versions, on raffinera ce fichier ult√©rieurement.\n\n::: {.callout-tip}\n\n## Application 7: cr√©ation du `requirements.txt`\n\n- Cr√©er un fichier `requirements.txt` avec la liste des packages n√©cessaires\n- Ajouter une indication dans `README.md` sur l'installation des _packages_ gr√¢ce au fichier `requirements.txt` \n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli7\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n## √âtape 4 : stocker les donn√©es de mani√®re externe {#stockageS3}\n\n::: {.callout-warning collapse=\"true\"}\n## Pour en savoir plus sur le syst√®me de stockage `S3`\n\nPour mettre en oeuvre cette √©tape, il peut √™tre utile de\ncomprendre un peu comme fonctionne le SSP Cloud.\nVous devrez suivre la [documentation du SSP Cloud](https://inseefrlab.github.io/docs.sspcloud.fr/docs/fr/storage.html) pour la r√©aliser. Une aide-m√©moire est √©galement disponible dans le cours\nde 2e ann√©e de l'ENSAE [Python pour la _data science_](https://linogaliana-teaching.netlify.app/reads3/#).\n:::\n\n\nLe chapitre sur la [structure des projets](/chapters/projects-architecture.qmd)\nd√©veloppe l'id√©e qu'il est recommand√© de converger vers un mod√®le\no√π environnements d'ex√©cution, de stockage du code et des donn√©es sont conceptuellement\ns√©par√©s. Ce haut niveau d'exigence est un gain de temps important \nlors de la mise en production car au cours de cette derni√®re, le projet\nest amen√© √† √™tre ex√©cut√© sur une infrastructure informatique d√©di√©e\nqu'il est bon d'anticiper. \n\nA l'heure actuelle, les donn√©es sont stock√©es dans le d√©p√¥t. C'est une\nmauvaise pratique. En premier lieu, `Git` n'est techniquement\npas bien adapt√© au stockage de donn√©es. Ici ce n'est pas tr√®s grave\ncar il ne s'agit pas de donn√©es volumineuses et ces derni√®res ne sont\npas modifi√©es au cours de notre chaine de traitement. \nLa raison principale\nest que les donn√©es trait√©es par les _data scientists_ \nsont g√©n√©ralement soumises √† des clauses de\nconfidentialit√©s ([RGPD](https://www.cnil.fr/fr/rgpd-de-quoi-parle-t-on), [secret statistique](https://www.insee.fr/fr/information/1300624)...). Mettre ces donn√©es sous contr√¥le de version\nc'est prendre le risque de les divulguer √† un public non habilit√©. \nIl est donc recommand√© de privil√©gier des outils techniques adapt√©s au\nstockage de donn√©es.\n\nL'id√©al, dans notre cas, est d'utiliser une solution de stockage externe. \nOn va utiliser pour cela `MinIO`, la solution de stockage de type `S3` offerte par le SSP Cloud. \nCela nous permettra de supprimer les donn√©es de `Github` tout en maintenant la reproductibilit√© \nde notre projet [^history].\n\n[^history]: Attention, les donn√©es ont √©t√© _committ√©es_ au moins une fois. Les supprimer\ndu d√©p√¥t ne les efface pas de l'historique. Si cette erreur arrive, le mieux est de supprimer\nle d√©p√¥t en ligne, cr√©er un nouvel historique `Git` et partir de celui-ci pour des publications\nult√©rieures sur `Github`. N√©anmoins l'id√©al serait de ne pas s'exposer √† cela. C'est justement\nl'objet des bonnes pratiques de ce cours: un `.gitignore` bien construit et une s√©paration des\nenvironnements de stockage du code et\ndes donn√©es seront bien plus efficaces pour vous √©viter ces probl√®mes que tout les conseils de \nvigilance que vous pourrez trouver ailleurs. \n\n::: {.callout-tip}\n\n## Application 8: utilisation d'un syst√®me de stockage distant\n\nA partir de la ligne de commande,\nutiliser l'utilitaire [MinIO](https://min.io/docs/minio/linux/reference/minio-mc.html)\npour copier les donn√©es `data/raw/train.csv` et `data/raw/test.csv` vers votre\nbucket personnel, respectivement dans les dossiers `ensae-reproductibilite/data/raw/train.csv`\net `ensae-reproductibilite/data/raw/test.csv`. \n\n<details>\n<summary>Indice</summary>\n\nStructure √† adopter:\n\n```{.bash filename=\"terminal\"}\nmc cp data/raw/train.csv s3/<BUCKET_PERSONNEL>/ensae-reproductibilite/data/raw/train.csv\nmc cp data/raw/test.csv s3/<BUCKET_PERSONNEL>/ensae-reproductibilite/data/raw/test.csv\n```\n\nen modifiant l'emplacement de votre bucket personnel\n</details>\n\nPour se simplifier la vie, on va utiliser des URL de t√©l√©chargement des fichiers\n(comme si ceux-ci √©taient sur n'importe quel espace de stockage) plut√¥t que d'utiliser\nune librairie `S3` compatible comme `boto3` ou `s3fs`.\nPar d√©faut, le contenu de votre _bucket_ est priv√©, seul vous y avez acc√®s. N√©anmoins,\nvous pouvez rendre accessible √† tous en lecture le contenu de votre _bucket_ en\nfaisant lui donnant des droits anonymes. \nPour cela, en ligne de\ncommande, faire:\n\n```{.bash filename=\"terminal\"}\nmc anonymous set download s3/<BUCKET_PERSONNEL>/ensae-reproductibilite/data/raw/\n```\n\nen modifiant `<BUCKET_PERSONNEL>`. Les URL de t√©l√©chargement seront de la forme \n`https://minio.lab.sspcloud.fr/<BUCKET_PERSONNEL>/ensae-reproductibilite/data/raw/test.csv`\net `https://minio.lab.sspcloud.fr/<BUCKET_PERSONNEL>/ensae-reproductibilite/data/raw/train.csv`\n\n- Modifier `configuration/config.yaml` pour utiliser directement les URL dans l'import ;\n- Modifier les valeurs par d√©faut dans votre code ; \n- Supprimer les fichiers `.csv` du dossier `data` de votre projet, on n'en a plus besoin vu qu'on les importe de l'ext√©rieur ;\n- V√©rifier le bon fonctionnement de votre application.\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli8\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n# Partie 2bis: packagisation de son projet (optionnel)\n\nCette s√©rie d'actions n'est pas forc√©ment pertinente pour tous\nles projets. Elle fait un peu la transition entre la modularit√©\net la portabilit√©. \n\n## √âtape 1 : proposer des tests unitaires (optionnel)\n\nNotre code comporte un certain nombre de fonctions g√©n√©riques.\nOn peut vouloir tester leur usage sur des donn√©es standardis√©es,\ndiff√©rentes de celles du Titanic.\n\nM√™me si la notion de tests unitaires\nprend plus de sens dans un _package_, nous pouvons proposer\ndans le projet des exemples d'utilisation de la fonction, ceci peut √™tre p√©dagogique. \n\nNous allons utiliser [`unittest`](https://docs.python.org/3/library/unittest.html)\npour effectuer des tests unitaires. Cette approche n√©cessite quelques notions\nde programmation orient√©e objet ou une bonne discussion avec `ChatGPT`.\n\n::: {.callout-tip}\n\n## Application 9: test unitaire _(optionnel)_\n\nDans le dossier `tests/`, cr√©er un fichier `test_create_variable_title.py`.\n\nEn s'inspirant de l'[exemple de base](https://docs.python.org/3/library/unittest.html#basic-example),\ncr√©er une classe `TestCreateVariableTitle` qui effectue les op√©rations suivantes:\n\n- Cr√©ation d'une fonction `test_create_variable_title_default_variable_name` qui permet \nde comparer les objets suivants:\n\n    + Cr√©ation d'un `DataFrame` de test :  \n\n    ```python\n    df = pd.DataFrame({\n                'Name': ['Braund, Mr. Owen Harris', 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)',\n                        'Heikkinen, Miss. Laina', 'Futrelle, Mrs. Jacques Heath (Lily May Peel)',\n                        'Allen, Mr. William Henry', 'Moran, Mr. James',\n                        'McCarthy, Mr. Timothy J', 'Palsson, Master. Gosta Leonard',\n                        'Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)',\n                        'Nasser, Mrs. Nicholas (Adele Achem)'],\n                'Age': [22, 38, 26, 35, 35, 27, 54, 2, 27, 14],\n                'Survived': [0, 1, 1, 1, 0, 0, 0, 0, 1, 1]\n            })\n    ```\n\n    + Utilisation de la fonction `create_variable_title` sur ce `DataFrame`\n    + Comparaison au `DataFrame` attendu:\n\n    ```python\n    expected_result = pd.DataFrame({\n                'Title': ['Mr.', 'Mrs.', 'Miss.', 'Mrs.', 'Mr.', 'Mr.', 'Mr.', 'Master.', 'Mrs.', 'Mrs.'],\n                'Age': [22, 38, 26, 35, 35, 27, 54, 2, 27, 14],\n                'Survived': [0, 1, 1, 1, 0, 0, 0, 0, 1, 1]\n            })\n    ```\n\n- Effectuer le test unitaire en ligne de commande avec `unittest` (`python -m unittest tests/test_create_variable_title.py`). Corriger le test unitaire en cas d'erreur. \n- Si le temps le permet, proposer des variantes pour tenir compte de param√®tres (comme la variable `variable_name`)\nou d'exceptions (comme la gestion du cas _\"Dona\"_).\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli9\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n\n:::\n\n\n\n\n::: {.callout-note}\n\nLorsqu'on effectue des tests unitaires, on cherche g√©n√©ralement\n√† tester le plus de lignes possibles de son code. On parle de\n__taux de couverture__ (_coverage rate_) pour d√©signer\nla statistique mesurant cela. \n\nCela peut s'effectuer de la mani√®re suivante avec le package\n[`coverage`](https://coverage.readthedocs.io/en/7.2.2/):\n\n```{.bash filename=\"terminal\"}\ncoverage run -m unittest tests/test_create_variable_title.py\ncoverage report -m\n```\n\n```{.python}\nName                                  Stmts   Miss  Cover   Missing\n-------------------------------------------------------------------\nsrc/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113\ntests/test_create_variable_title.py      21      1    95%   54\n-------------------------------------------------------------------\nTOTAL                                    55     22    60%\n```\n\nLe taux de couverture est souvent mis en avant par les gros\nprojets comme indicateur de leur qualit√©. Il existe d'ailleurs\ndes badges `Github` d√©di√©s. \n:::\n\n\n\n\n## √âtape 2 : transformer son projet en package (optionnel)\n\nNotre projet est modulaire, ce qui le rend assez simple √† transformer\nen _package_, en s'inspirant de la structure du `cookiecutter` adapt√©, issu\nde [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).\n\nOn va cr√©er un _package_ nomm√© `titanicml` qui encapsule\ntout notre code et qui sera appel√©\npar notre script `main.py`. La structure attendue\nest la suivante:\n\n<details>\n<summary>Structure vis√©e</summary>\n\n```\nensae-reproductibilite-application\n‚îú‚îÄ‚îÄ docs                                    ‚îê \n‚îÇ   ‚îú‚îÄ‚îÄ main.py                             ‚îÇ \n‚îÇ   ‚îî‚îÄ‚îÄ notebooks                           ‚îÇ Package documentation and examples\n‚îÇ       ‚îî‚îÄ‚îÄ titanic.ipynb                   ‚îÇ \n‚îú‚îÄ‚îÄ configuration                           ‚îê Configuration (pas √† partager avec Git)\n‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                         ‚îò \n‚îú‚îÄ‚îÄ README.md                                \n‚îú‚îÄ‚îÄ pyproject.toml                          ‚îê \n‚îú‚îÄ‚îÄ requirements.txt                        ‚îÇ\n‚îú‚îÄ‚îÄ titanicml                               ‚îÇ                \n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                         ‚îÇ Package source code, metadata\n‚îÇ   ‚îú‚îÄ‚îÄ data                                ‚îÇ and build instructions \n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                  ‚îÇ  \n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py   ‚îÇ   \n‚îÇ   ‚îú‚îÄ‚îÄ features                            ‚îÇ\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py               ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ models                              ‚îÇ\n‚îÇ       ‚îî‚îÄ‚îÄ train_evaluate.py               ‚îò\n‚îî‚îÄ‚îÄ tests                                   ‚îê\n    ‚îî‚îÄ‚îÄ test_create_variable_title.py       ‚îò Package tests\n```\n</details>\n\n<details>\n<summary>Rappel: structure actuelle</summary>\n\n```\nensae-reproductibilite-application\n‚îú‚îÄ‚îÄ notebooks                                 \n‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb                  \n‚îú‚îÄ‚îÄ configuration                                 \n‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                  \n‚îú‚îÄ‚îÄ main.py                              \n‚îú‚îÄ‚îÄ README.md                 \n‚îú‚îÄ‚îÄ requirements.txt                      \n‚îî‚îÄ‚îÄ src \n    ‚îú‚îÄ‚îÄ data                                \n    ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                    \n    ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py      \n    ‚îú‚îÄ‚îÄ features                           \n    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py      \n    ‚îî‚îÄ‚îÄ models                          \n        ‚îî‚îÄ‚îÄ train_evaluate.py              \n```\n</details>\n\nIl existe plusieurs \n_frameworks_ pour\nconstruire un _package_. Nous\nallons privil√©gier [`Poetry`](https://python-poetry.org/)\n√† [`Setuptools`](https://pypi.org/project/setuptools/). \n\n\n::: {.callout-note}\n\nPour cr√©er la structure minimale d'un _package_, le plus simple est\nd'utiliser le `cookiecutter` adapt√©,\nissu de [cet ouvrage](https://py-pkgs.org/03-how-to-package-a-python#package-structure).\n\nComme on a d√©j√† une structure tr√®s modulaire, on va plut√¥t recr√©er cette\nstructure dans notre projet d√©j√† existant. En fait, il ne manque qu'un fichier essentiel, \nle principal distinguant un projet classique d'un package : `pyproject.toml`.\n\n```{.bash filename=\"terminal\"}\ncookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git\n```\n\n<details>\n<summary>D√©rouler pour voir les choix possibles</summary>\n```{.python}\nauthor_name [Monty Python]: Daffy Duck\npackage_name [mypkg]: titanicml\npackage_short_description []: Impressive Titanic survival analysis\npackage_version [0.1.0]: \npython_version [3.9]: \nSelect open_source_license:\n1 - MIT\n2 - Apache License 2.0\n3 - GNU General Public License v3.0\n4 - Creative Commons Attribution 4.0\n5 - BSD 3-Clause\n6 - Proprietary\n7 - None\nChoose from 1, 2, 3, 4, 5, 6 [1]: \nSelect include_github_actions:\n1 - no\n2 - ci\n3 - ci+cd\nChoose from 1, 2, 3 [1]:\n```\n</details>\n\n:::\n\n::: {.callout-tip}\n\n## Application 10: packagisation _(optionnel)_\n\n- Renommer le dossier `titanicml` pour respecter la nouvelle\narborescence ;\n- Cr√©er un fichier `pyproject.toml` sur cette base ;\n\n::: {#5dae9aa5 .cell filename='pyproject.toml' execution_count=4}\n``` {.python .cell-code code-summary=\"pyproject.toml\"}\n[tool.poetry]\nname = \"titanicml\"\nversion = \"0.0.1\"\ndescription = \"Awesome Machine Learning project\"\nauthors = [\"Daffy Duck <daffy.duck@fauxmail.fr>\", \"Mickey Mouse\"]\nlicense = \"MIT\"\nreadme = \"README.md\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n[tool.pytest.ini_options]\nlog_cli = true\nlog_cli_level = \"WARNING\"\nlog_cli_format = \"%(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)\"\nlog_cli_date_format = \"%Y-%m-%d %H:%M:%S\"\n```\n:::\n\n\n- Cr√©er le dossier `docs` et mettre les fichiers indiqu√©s dedans\n- Dans `titanicml/`, cr√©er un fichier `__init__.py`[^init]\n\n::: {#c1a330fa .cell filename='__init__.py' execution_count=5}\n``` {.python .cell-code code-summary=\"__init__.py\"}\nfrom .import_data import (\n    import_data, import_yaml_config\n)\nfrom .build_features import (\n    create_variable_title,\n    fill_na_titanic,\n    label_encoder_titanic,\n    check_has_cabin,\n    ticket_length\n)\nfrom .train_evaluate import random_forest_titanic\n\n__all__ = [\n    \"import_data\", \"import_yaml_config\",\n    \"create_variable_title\",\n    \"fill_na_titanic\",\n    \"label_encoder_titanic\",\n    \"check_has_cabin\",\n    \"ticket_length\",\n    \"random_forest_titanic\"\n]\n```\n:::\n\n\n- Installer le package en local avec `pip install -e .`\n- Modifier le contenu de `docs/main.py` pour importer les fonctions de notre _package_ `titanicml` et tester en \nligne de commande notre fichier `main.py`\n:::\n\n[^init]: Le fichier `__init__.py` indique √† `Python` que le dossier\nest un _package_. Il permet de proposer certaines configurations\nlors de l'import du _package_. Il permet √©galement de contr√¥ler\nles objets export√©s (c'est-√†-dire mis √† disposition de l'utilisateur)\npar le _package_ par rapport aux objets internes au _package_. \nEn le laissant vide, nous allons utiliser ce fichier \npour importer l'ensemble des fonctions de nos sous-modules. \nCe n'est pas la meilleure pratique mais un contr√¥le plus fin des\nobjets export√©s demanderait un investissement qui ne vaut, ici, pas\nle co√ªt. \n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli10\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n\n:::\n\n\n\n# Partie 3 : construction d'un projet portable et reproductible {#partie3}\n\nDans la partie pr√©c√©dente,\non a appliqu√© de mani√®re incr√©mentale de nombreuses bonnes pratiques vues\ndans les chapitres [Qualit√© du code](/chapters/code-quality.html)\net [Structure des projets](/chapters/projects-architecture.html)\ntout au long du cours.\n\nCe faisant, on s'est d√©j√† consid√©rablement rapproch√©s d'une\npossible mise en production : le code est lisible,\nla structure du projet est normalis√©e et √©volutive,\net le code est proprement versionn√© sur un\nd√©p√¥t `GitHub` {{< fa brands github >}}.\n\n\n<details>\n<summary>\nIllustration de l'√©tat actuel du projet \n</summary>\n![](/schema_post_appli8.png)\n</details>\n\n\n\nA pr√©sent, nous avons une version du projet qui est largement partageable.\nDu moins en th√©orie, car la pratique est souvent plus compliqu√©e :\nil y a fort √† parier que si vous essayez d'ex√©cuter votre projet sur un autre environnement (typiquement, votre ordinateur personnel),\nles choses ne se passent pas du tout comme attendu. Cela signifie qu'**en l'√©tat, le projet n'est pas portable : il n'est pas possible, sans modifications co√ªteuses, de l'ex√©cuter dans un environnement diff√©rent de celui dans lequel il a √©t√© d√©velopp√©**.\n\nDans cette trois√®me partie de notre travail vers la mise en production,\nnous allons voir \ncomment **normaliser l'environnement d'ex√©cution afin de produire un projet portable**.\nAutrement dit, nous n'allons plus nous contenter de modularit√© mais allons rechercher\nla portabilit√©.\nOn sera alors tout proche de pouvoir mettre le projet en production.\n\nOn progressera dans l'√©chelle de la reproductibilit√© \nde la mani√®re suivante: \n\n1. [**Environnements virtuels**](#anaconda) ;\n2. Cr√©er un [script shell](#shell) qui permet, depuis un environnement minimal, de construire l'application de A √† Z ;\n3. [**Images et conteneurs `Docker`**](#docker).\n\n\nNous allons repartir de l'application 8, c'est-√†-dire d'un projet\nmodulaire mais qui n'est pas, √† strictement parler, un _package_\n(objet des applications optionnelles suivantes 9 et 10). \n\nPour se replacer dans l'√©tat du projet √† ce niveau,\nil est possible d'utiliser le _tag_ _ad hoc_.\n\n```{.bash filename=\"terminal\"}\ngit checkout appli8\n```\n\n\n## √âtape 1 : un environnement pour rendre le projet portable {#anaconda}\n\nPour qu'un projet soit portable, il doit remplir deux conditions:\n\n- Ne pas n√©cessiter de d√©pendance\nqui ne soient pas renseign√©es quelque part ;\n- Ne pas proposer des d√©pendances inutiles, qui ne\nsont pas utilis√©es dans le cadre du projet. \n\nLe prochain exercice vise √† mettre ceci en oeuvre.\nComme expliqu√© dans le [chapitre portabilit√©](/chapters/portability.qmd),\nle choix du gestionnaire d'environnement est laiss√©\nlibre. Il est recommand√© de privil√©gier `venv` si vous d√©couvrez\nla probl√©matique de la portabilit√©. \n\n::: {.panel-tabset group=\"language\"}\n\n## Environnement virtuel `venv`\n\nL'approche la plus l√©g√®re est l'environnement virtuel. \nNous avons en fait implicitement d√©j√† commenc√© √† aller vers\ncette direction\nen cr√©ant un fichier `requirements.txt`. \n\n:::: {.callout-tip}\n\n## Application 11a: environnement virtuel `venv` \n\n1. Ex√©cuter `pip freeze` en ligne de commande et observer la (tr√®s) longue\nliste de package\n2. Cr√©er l'environnement virtuel `titanic` en s'inspirant de [la documentation officielle](https://packaging.python.org/en/latest/guides/installing-using-pip-and-virtual-environments/)[^pythonversion] ou du [chapitre d√©di√©](/chapters/portability.qmd)\n3. Utiliser `ls` pour observer et comprendre le contenu du dossier `titanic/bin` install√©\n4. Activer l'environnement et v√©rifier l'installation de `Python` maintenant utilis√©e par votre machine \n<!---source titanic/bin/activate && which python---->\n5. V√©rifier directement depuis la ligne de commande que `Python` ex√©cute bien une commande[^option] avec:\n\n```{.bash filename=\"terminal\"}\npython -c \"print('Hello')\"\n```\n\n6. Faire la m√™me chose mais avec `import pandas as pd`\n7. Installer les _packages_ √† partir du `requirements.txt`. Tester √† nouveau `import pandas as pd` pour comprendre la diff√©rence. \n8. Ex√©cuter `pip freeze` et comprendre la diff√©rence avec la situation pr√©c√©dente.\n9. V√©rifier que le script `main.py` fonctionne bien. Sinon ajouter les _packages_ manquants dans le `requirements.txt` et reprendre de mani√®re it√©rative √† partir de la question 7.\n10. Ajouter le dossier `titanic/` au `.gitignore` pour ne pas ajouter ce dossier √† `Git`.\n\n\n<details>\n<summary>Aide pour la question 4</summary>\n\nApr√®s l'activation, vous pouvez v√©rifier quel `python` \nest utilis√© de cette mani√®re\n\n```{.bash filename=\"terminal\" env=\"titanic\"}\nwhich python\n```\n\n</details>\n\n::::\n\n[^pythonversion]: Si vous d√©sirez aussi contr√¥ler la version de `Python`, ce qui peut √™tre important\ndans une perspective de portabilit√©, vous pouvez ajouter une option, par exemple `-p python3.10`. N√©anmoins\nnous n'allons pas nous embarasser de cette nuance pour la suite car nous pourrons contr√¥ler\nla version de `Python` plus finement par le biais de `Docker`.\n[^option]: L'option `-c` pass√©e apr√®s la commande `python` permet d'indiquer √† `Python` que la commande\nne se trouve pas dans un fichier mais sera dans le texte qu'on va directement lui fournir. \n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli11a\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n## Environnement `conda`\n\nLes environnements `conda` sont plus lourds √† mettre en oeuvre que les \nenvironnements virtuels mais peuvent permettre un contr√¥le\nplus formel des d√©pendances. \n\n:::: {.callout-tip}\n\n## Application 11b: environnement `conda` \n\n1. Ex√©cuter `conda env export` en ligne de commande et observer la (tr√®s) longue\nliste de package\n2. Cr√©er un environnement `titanic`\navec [`conda create`](https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html#creating-an-environment-with-commands)\n4. Activer l'environnement et v√©rifier l'installation de `Python` maintenant utilis√©e par votre machine \n<!---conda activate titanic && which python---->\n5. V√©rifier directement depuis la ligne de commande que `Python` ex√©cute bien une commande[^option] avec:\n\n```{.bash filename=\"terminal\"}\npython -c \"print('Hello')\"\n```\n\n6. Faire la m√™me chose mais avec `import pandas as pd`\n7. Installer les _packages_ qu'on avait list√© dans le `requirements.txt` pr√©c√©demment. Ne pas faire un `pip install -r requirements.txt` afin de privil√©gier `conda install`\n8. Ex√©cuter √† nouveau `conda env export` et comprendre la diff√©rence avec la situation pr√©c√©dente[^splitscreen].\n9. V√©rifier que le script `main.py` fonctionne bien. Sinon installer les _packages_ manquants\net reprndre de mani√®re it√©rative\n√† partir de la question 7.\n10. Quand `main.py` fonctionne, faire `conda env export > environment.yml` pour figer l'environnement de travail.\n\n::::\n\n[^splitscreen]: Pour comparer les deux listes, vous pouvez utiliser la fonctionnalit√© de _split_ \ndu terminal sur `VSCode` pour comparer les outputs de `conda env export` en les mettant \nen face √† face. \n\n:::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli11b\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n::::\n\n\n\n:::\n\n\n## √âtape 2: construire l'environnement de notre application via un script `shell` {#shell}\n\nLes environnements virtuels permettent de mieux sp√©cifier les d√©pendances de notre projet, mais ne permettent pas de garantir une portabilit√© optimale. Pour cela, il faut recourir √† la technologie des conteneurs. L'id√©e est de construire une machine, en partant d'une base quasi-vierge, qui permette de construire √©tape par √©tape l'environnement n√©cessaire au bon fonctionnement de notre projet. C'est le principe des conteneurs `Docker` {{< fa brands docker >}}.\n\nLeur m√©thode de construction √©tant un peu difficile √† prendre en main au d√©but, nous allons passer par une √©tape interm√©diaire afin de bien comprendre le processus de production. \n\n- Nous allons d'abord cr√©er un script `shell`, c'est √† dire une suite de commandes `Linux` permettant de construire l'environnement √† partir d'une machine vierge ;\n- Nous transformerons celui-ci en `Dockerfile` dans un deuxi√®me temps. C'est l'objet de l'√©tape suivante. \n\n::: {.panel-tabset group=\"language\"}\n\n## Environnement virtuel `venv`\n\n:::: {.callout-tip}\n\n## Application 12a : cr√©er un fichier d'installation de A √† Z\n\n1. Cr√©er un service `ubuntu` sur le SSP Cloud\n2. Ouvrir un terminal\n3. Cloner le d√©p√¥t \n4. Se placer dans le dossier du projet avec `cd`\n5. Se placer au niveau du checkpoint 11a avec `git checkout appli11a`\n6. Via l'explorateur de fichiers, cr√©er le fichier `install.sh` √† la racine du projet avec le contenu suivant:\n\n<details>\n<summary>Script √† cr√©er sous le nom `install.sh` </summary>\n```{.bash filename=\"install.sh\" no-prefix=true}\n#!/bin/bash\n\n# Install Python\napt-get -y update\napt-get install -y python3-pip python3-venv\n\n# Create empty virtual environment\npython3 -m venv titanic\nsource titanic/bin/activate\n\n# Install project dependencies\npip install -r requirements.txt\n```\n</details>\n\n6. Changer les permissions sur le script pour le rendre ex√©cutable\n\n```{.bash filename=\"terminal\"}\nchmod +x install.sh\n```\n\n7. Ex√©cuter le script depuis la ligne de commande avec des droits de super-utilisateur (n√©cessaires pour installer des *packages* via `apt`)\n\n```{.bash filename=\"terminal\"}\nsudo ./install.sh\n```\n\n8. V√©rifier que le script `main.py` fonctionne correctement dans l'environnement virtuel cr√©√© \n\n```{.bash filename=\"terminal\"}\nsource titanic/bin/activate\npython3 main.py\n```\n\n::::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli12a\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n## Environnement `conda`\n\n:::: {.callout-tip}\n\n## Application 12b : cr√©er un fichier d'installation de A √† Z\n\n1. Cr√©er un service `ubuntu` sur le SSP Cloud\n2. Ouvrir un terminal\n3. Cloner le d√©p√¥t \n4. Se placer dans le dossier du projet avec `cd`\n5. Se placer au niveau du checkpoint 11b avec `git checkout appli11b`\n6. Via l'explorateur de fichiers, cr√©er le fichier `install.sh` √† la racine du projet avec le contenu suivant:\n\n<details>\n<summary>Script √† cr√©er sous le nom `install.sh` </summary>\n```{.bash filename=\"install.sh\" no-prefix=true}\napt-get -y update && apt-get -y install wget\n\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \\\n    bash Miniconda3-latest-Linux-x86_64.sh -b -p /miniconda && \\\n    rm -f Miniconda3-latest-Linux-x86_64.sh\n\nPATH=\"/miniconda/bin:${PATH}\"\n\n# Create environment\nconda create -n titanic pandas PyYAML scikit-learn -c conda-forge\nconda activate titanic\n\nPATH=\"/miniconda/envs/titanic/bin:${PATH}\"\n\npython main.py\n```\n</details>\n\n6. Changer les permissions sur le script pour le rendre ex√©cutable\n\n```{.bash filename=\"terminal\"}\nchmod +x install.sh\n```\n\n7. Ex√©cuter le script depuis la ligne de commande avec des droits de super-utilisateur (n√©cessaires pour installer des *packages* via `apt`)\n\n```{.bash filename=\"terminal\"}\nsudo ./install.sh\n```\n\n8. V√©rifier que le script `main.py` fonctionne correctement dans l'environnement virtuel cr√©√© \n\n```{.bash filename=\"terminal\"}\nconda activate titanic\npython3 main.py\n```\n\n::::\n\n:::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli12b\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n::::\n\n\n\n:::\n\n\n## √âtape 3: conteneuriser l'application avec `Docker` {#docker}\n\n\n::: {.callout-note}\nCette application n√©cessite l'acc√®s √† une version interactive de `Docker`.\nIl n'y a pas beaucoup d'instances en ligne disponibles.\n\nNous proposons deux solutions:\n\n- [Installer `Docker`](https://docs.docker.com/get-docker/) sur sa machine ;\n- Se rendre sur l'environnement bac √† sable _[Play with Docker](https://labs.play-with-docker.com)_\n\nSinon, elle peut √™tre r√©alis√©e en essai-erreur par le biais des services d'int√©gration continue de `Github` {{< fa brands github >}} ou `Gitlab` {{< fa brands gitlab >}}. N√©anmoins, nous pr√©senterons l'utilisation de ces services plus tard, dans la prochaine partie. \n:::\n\nMaintenant qu'on sait que ce script pr√©paratoire fonctionne, on va le transformer en `Dockerfile` pour anticiper la mise en production.  Comme la syntaxe `Docker` est l√©g√®rement diff√©rente de la syntaxe `Linux` classique (voir le [chapitre portabilit√©](/chapters/portability.qmd)), il va √™tre n√©cessaire de changer quelques instructions mais ceci sera tr√®s l√©ger.\n\nOn va tester le `Dockerfile` dans un environnement bac √† sable pour ensuite\npouvoir plus facilement automatiser la construction de l'image\n`Docker`.\n\n::: {.callout-tip}\n\n## Application 13: cr√©ation de l'image `Docker` \n\nSe placer dans un environnement avec `Docker`, par\nexemple _[Play with Docker](https://labs.play-with-docker.com)_\n\n#### Cr√©ation du `Dockerfile`\n\n- Dans le terminal `Linux`, cloner votre d√©p√¥t `Github` \n- Repartir de la derni√®re version √† disposition. Par exemple, si vous avez privil√©gi√© \nl'environnement virtuel `venv`, ce sera:\n\n```{.bash filename=\"terminal\"}\ngit checkout appli12a\n```\n\n- Cr√©er via la ligne de commande un fichier texte vierge nomm√© `Dockerfile` (la majuscule au d√©but du mot est importante)\n\n<details><summary>Commande pour cr√©er un `Dockerfile` vierge depuis la ligne de commande</summary>\n```{.bash filename=\"terminal\"}\ntouch Dockerfile\n```\n</details>\n\n- Ouvrir ce fichier via un √©diteur de texte et copier le contenu suivant dedans:\n\n<details><summary>Premier `Dockerfile`</summary>\n\n```{.bash filename=\"terminal\" no-prefix=true}\nFROM ubuntu:22.04\n\nWORKDIR ${HOME}/titanic\n\n# Install Python\nRUN apt-get -y update && \\\n    apt-get install -y python3-pip\n\n# Install project dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCMD [\"python3\", \"main.py\"]\n```\n</details>\n\n#### Construire (_build_) l'image\n\n- Utiliser `docker build` pour cr√©er une image avec le tag `my-python-app`\n\n```{.bash filename=\"terminal\"}\ndocker build . -t my-python-app\n```\n\n- V√©rifier les images dont vous disposez. Vous devriez avoir un r√©sultat proche de celui-ci :\n\n```{.bash filename=\"terminal\"}\ndocker images\n```\n\n```{.python}\nREPOSITORY      TAG       IMAGE ID       CREATED              SIZE\nmy-python-app   latest    188957e16594   About a minute ago   879MB\n```\n\n#### Tester l'image: d√©couverte du cache\n\nL'√©tape de `build` a fonctionn√©: une image a √©t√© construite.\n\nMais fait-elle effectivement ce que l'on attend d'elle ?\n\nPour le savoir, il faut passer √† l'√©tape suivante, l'√©tape de `run`.\n\n```{.bash filename=\"terminal\"}\ndocker run -it my-python-app\n```\n\n```{.python}\npython3: can't open file '/~/titanic/main.py': [Errno 2] No such file or directory\n```\n\nLe message d'erreur est clair : `Docker` ne sait pas o√π trouver le fichier `main.py`. D'ailleurs, il ne connait pas non plus les autres fichiers de notre application qui sont n√©cessaires pour faire tourner le code, par exemple le dossier `src`.\n\n- Avant l'√©tape `CMD`, copier les fichiers n√©cessaires sur l'image afin que l'application dispose de tous les √©l√©ments n√©cessaires pour √™tre en mesure de fonctionner.\n\n<details>\n<summary>Nouveau `Dockerfile` </summary>\n```{.bash filename=\"terminal\" no-prefix=true}\nFROM ubuntu:22.04\n\nWORKDIR ${HOME}/titanic\n\n# Install Python\nRUN apt-get -y update && \\\n    apt-get install -y python3-pip\n\n# Install project dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY main.py .\nCOPY src ./src\nCMD [\"python3\", \"main.py\"]\n```\n</details>\n\n- Refaire tourner l'√©tape de `build`\n\n- Refaire tourner l'√©tape de `run`. A ce stade, la matrice de confusion doit fonctionner üéâ.\nVous avez cr√©√© votre premi√®re application reproductible !\n\n:::\n\n::: {.callout-note}\n\nIci, le _cache_ permet d'√©conomiser beaucoup de temps. Par besoin de \nrefaire tourner toutes les √©tapes, `Docker` agit de mani√®re intelligente\nen faisant tourner uniquement les √©tapes qui ont chang√©.\n\n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli13\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n# Partie 4 : automatisation avec l'int√©gration continue\n\n\nImaginez que vous √™tes au restaurant\net qu'on ne vous serve pas le plat mais seulement la recette\net que, de plus, on vous demande de pr√©parer le plat\nchez vous avec les ingr√©dients dans votre frigo.\nVous seriez quelque peu d√©√ßu. En revanche, si vous avez go√ªt√©\nau plat, que vous √™tes un r√©el cordon bleu\net qu'on vous donne la recette pour refaire ce plat ult√©rieurement,\npeut-√™tre\nque vous appr√©ciriez plus. \n\nCette analogie illustre l'enjeu de d√©finir\nle public cible et ses attentes afin de fournir un livrable adapt√©. \nUne image `Docker` est un livrable qui n'est pas forc√©ment int√©ressant\npour tous les publics. Certains pr√©f√©reront avoir un plat bien pr√©par√©\nqu'une recette ; certains appr√©cieront avoir une image `Docker` mais\nd'autres ne seront pas en mesure de construire celle-ci ou ne sauront\npas la faire fonctionner. Une image `Docker` est plus souvent un \nmoyen pour faciliter la mise en service d'une production qu'une fin en soi. \n\nNous allons donc proposer\nplusieurs types de livrables plus classiques par la suite. Ceux-ci\ncorrespondront mieux aux attendus des publics utilisateurs de services\nconstruits √† partir de techniques de _data science_. `Docker` est n√©anmoins\nun passage oblig√© car l'ensemble des types de livrables que nous allons\nexplorer reposent sur la standardisation permise par les conteneurs. \n\nCette approche nous permettra de quitter le domaine de l'artisanat pour\ns'approcher d'une industrialisation de la mise √† disposition \nde notre projet. Ceci va notamment nous amener √† mettre en oeuvre\nl'approche pragmatique du `DevOps` qui consiste √† int√©grer d√®s la phase de\nd√©veloppement d'un projet les contraintes li√©es √† sa mise √† disposition\nau public cible (cette approche est d√©taill√©e plus\namplement dans le chapitre sur la [mise en production](/chapters/deployment.qmd)). \n\nL'automatisation et la mise √† disposition automatis√©e de nos productions\nsera faite progressivement, au cours des prochaines parties. Tous les \nprojets n'ont pas vocation √† aller aussi loin dans ce domaine. \nL'opportunit√© doit √™tre compar√©e aux co√ªts humains et financiers\nde leur mise en oeuvre et de leur cycle de vie. \nAvant de faire une production en s√©rie de nos mod√®les,\nnous allons d√©j√† commencer\npar automatiser quelques tests de conformit√© de notre code. \nOn va ici utiliser l'int√©gration continue pour deux objectifs distincts:\n\n- la mise √† disposition de l'image `Docker` ;\n- la mise en place de tests automatis√©s de la qualit√© du code\nsur le mod√®le de notre `linter` pr√©c√©dent.\n\nNous allons utiliser `Github Actions` pour cela. Il s'agit de serveurs\nstandardis√©s mis √† disposition gratuitement par `Github` {{<fa brands github >}}.\n`Gitlab` {{<fa brands gitlab >}}, l'autre principal acteur du domaine,\npropose des services similaires. L'impl√©mentation est l√©g√®rement diff√©rente\nmais les principes sont identiques. \n\n\n::: {.callout-caution collapse=\"true\"}\n## Si vous prenez ce projet fil rouge en cours de route\n\n```{.bash filename=\"terminal\"}\ngit checkout appli13\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n## √âtape 1: mise en place de tests automatis√©s\n\nAvant d'essayer de mettre en oeuvre la cr√©ation de notre image\n`Docker` de mani√®re automatis√©e, nous allons pr√©senter la logique\nde l'int√©gration continue en testant de mani√®re automatis√©e\nnotre script `main.py`.\n\nPour cela, nous allons partir de la structure propos√©e dans l'[action officielle](https://github.com/actions/setup-python). \nLa documentation associ√©e est [ici](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python).\nDes √©l√©ments succincts de pr√©sentation de la logique d√©clarative des actions `Github` \nsont disponibles dans le chapitre sur la [mise en production](/chapters/deployment.qmd). N√©anmoins, la meilleure\n√©cole pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d'observer\nles actions `Github` mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !\n\n\n::: {.callout-tip}\n\n## Application 14: premier script d'int√©gration continue\n\nA partir de l'exemple pr√©sent\ndans la [documentation officielle](https://docs.github.com/en/actions/automating-builds-and-tests/building-and-testing-python#using-a-specific-python-version)\nde `Github` {{< fa brands github >}}, on a d√©j√† une base de d√©part qui peut √™tre modifi√©e. \nLes questions suivantes permettront d'automatiser les tests et le diagnostic qualit√© de\nnotre code[^failure]\n\n[^failure]: Il est tout √† fait normal de ne pas parvenir √† cr√©er une action fonctionnelle\ndu premier coup. N'h√©sitez pas √† _pusher_ votre code apr√®s chaque question pour v√©rifier\nque vous parvenez bien √† r√©aliser chaque √©tape. Sinon vous risquez de devoir corriger\nbout par bout un fichier plus cons√©quent. \n\n1. Cr√©er un fichier `.github/workflows/test.yaml` avec le contenu de l'exemple de la documentation\n3. Avec l'aide de la documentation, introduire une √©tape d'installation des d√©pendances. \nUtiliser le fichier `requirements.txt` pour installer les d√©pendances. \n4. Utiliser `pylint` pour v√©rifier la qualit√© du code. Ajouter l'argument `--fail-under=6` pour\nrenvoyer une erreur en cas de note trop basse[^hook]\n5. Utiliser une √©tape appelant notre application en ligne de commande (`python main.py`)\npour tester que la matrice de confusion s'affiche bien.\n6. Aller voir votre test automatiser dans l'onglet `Actions` de votre d√©p√¥t sur `Github`\n\n[^hook]: Il existe une approche alternative pour faire des tests\n    r√©guliers: les _hooks_ `Git`.\n    Il s'agit de r√®gles qui doivent √™tre satisfaites pour que le \n    fichier puisse √™tre committ√©. Cela assure que chaque `commit` remplisse\n    des crit√®res de qualit√© afin d'√©viter le probl√®me de la procrastination.\n    \n    La [documentation de pylint](https://pylint.pycqa.org/en/latest/user_guide/pre-commit-integration.html) offre des explications suppl√©mentaires. \n    Ici, nous allons adopter une approche moins ambitieuse en demandant √† notre\n    action de faire ce travail d'√©valuation de la qualit√© de notre code\n\n\n\n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli14\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n \nMaintenant, nous pouvons observer que l'onglet `Actions`\ns'est enrichi. Chaque `commit` va entra√Æner une s√©ries d'actions automatis√©es.\n\nSi l'une des √©tapes √©choue, ou si la note de notre projet est mauvaise, nous aurons\nune croix rouge (et nous recevrons un mail). On pourra ainsi d√©tecter,\nen d√©veloppant son projet, les moments o√π on d√©grade la qualit√© du script \nafin de la r√©tablir imm√©diatemment. \n\n\n\n## √âtape 2: Automatisation de la livraison de l'image `Docker`\n\nMaintenant, nous allons automatiser la mise √† disposition de notre image\nsur `DockerHub` (le lieu de partage des images `Docker`). Cela facilitera sa r√©utilisation mais aussi des\nvalorisations ult√©rieures.\n\nL√† encore, nous allons utiliser une s√©rie d'actions pr√©-configur√©es.\n\nPour que `Github` puisse s'authentifier aupr√®s de `DockerHub`, il va \nfalloir d'abord interfacer les deux plateformes. Pour cela, nous allons utiliser\nun jeton (_token_) `DockerHub` que nous allons mettre dans un espace\ns√©curis√© associ√© √† votre d√©p√¥t `Github`.\n\n\n::: {.callout-tip}\n## Application 15a: configuration\n\n- Se rendre sur\nhttps://hub.docker.com/ et cr√©er un compte. Il est recommand√©\nd'associer ce compte √† votre compte `Github`. \n- Cr√©er un d√©p√¥t public `application-correction`\n- Aller dans les [param√®tres de votre compte](https://hub.docker.com/settings/general)\net cliquer, √† gauche, sur `Security`\n- Cr√©er un jeton personnel d'acc√®s, ne fermez pas l'onglet en question,\nvous ne pouvez voir sa valeur qu'une fois. \n- Dans le d√©p√¥t `Github` de votre projet, cliquer sur l'onglet `Settings` et cliquer,\n√† gauche, sur `Secrets and variables` puis\ndans le menu d√©roulant en dessous sur `Actions`. Sur la page qui s'affiche, aller\ndans la section `Repository secrets`\n- Cr√©er un jeton `DOCKERHUB_TOKEN` √† partir du jeton que vous aviez cr√©√© sur `Dockerhub`. Valider\n- Cr√©er un deuxi√®me secret nomm√© `DOCKERHUB_USERNAME` ayant comme valeur le nom d'utilisateur\nque vous avez cr√©√© sur `Dockerhub`\n\n<details>\n<summary>\nEtape optionnelle suppl√©mentaire si on met en production un site web\n</summary>\n\n- Dans le d√©p√¥t `Github` de votre projet, cliquer sur l'onglet `Settings` et cliquer,\n√† gauche, sur `Actions`. Donner les droits d'√©criture √† vos actions sur le d√©p√¥t\ndu projet (ce sera n√©cessaire pour `Github Pages`)\n\n![](/permissions.png)\n\n</details>\n\n:::\n\n\n\n\nA ce stade, nous avons donn√© les moyens √† `Github` de s'authentifier avec\nnotre identit√© sur `Dockerhub`. Il nous reste √† mettre en oeuvre l'action\nen s'inspirant de la [documentation officielle](https://github.com/docker/build-push-action/#usage).\nOn ne va modifier que trois √©l√©ments dans ce fichier. Effectuer les \nactions suivantes:\n\n\n::: {.callout-tip}\n\n## Application 15b: automatisation de l'image `Docker`\n\n- En s'inspirant de ce [_template_](https://github.com/marketplace/actions/build-and-push-docker-images), cr√©er le fichier `.github/workflows/prod.yml` qui va *build* et *push* l'image sur le `DockerHub`. Il va √™tre n√©cessaire de changer l√©g√®rement ce mod√®le :\n    + Retirer la condition restrictive sur les _commits_ pour lesquels sont lanc√©s cette automatisation. Pour cela, remplacer le contenu de `on` de sorte √† avoir `on: [push]`\n    + Changer le tag √† la fin pour mettre `username/application-correction:latest`\no√π `username` est le nom d'utilisateur sur `DockerHub`;\n    + Optionnel: changer le nom de l'action\n\n- Faire un `commit` et un `push` de ces fichiers\n\nComme on est fier de notre travail, on va afficher √ßa avec un badge sur le \n`README` _(partie optionnelle)_. \n\n- Se rendre dans l'onglet `Actions` et cliquer sur une des actions list√©es. \n- En haut √† droite, cliquer sur `...`\n- S√©lectionner `Create status badge`\n- R√©cup√©rer le code `Markdown` propos√©\n- Copier dans votre `README.md` le code _markdown_ propos√©\n\n<details>\n<summary>\nCr√©er le badge\n</summary>\n![](/create-badge.png)\n</details>\n\n:::\n\nMaintenant, il nous reste √† tester notre application dans l'espace bac √† sable\nou en local, si `Docker` est install√©.\n\n\n::: {.callout-tip}\n\n## Application 15b (partie optionnelle): Tester l'application\n\n- Se rendre sur l'environnement bac √† sable _[Play with Docker](https://labs.play-with-docker.com)_\nou dans votre environnement `Docker` de pr√©dilection.\n- R√©cup√©rer et lancer l'image :\n\n```yaml\ndocker run -it username/application-correction:latest\n```\n\nüéâ La matrice de confusion doit s'afficher ! Vous avez grandement\nfacilit√© la r√©utilisation de votre image. \n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli15\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\n\n\n\n# Partie 5: exp√©rimenter en local des valorisations puis automatiser leur production\n\n\nNous avons automatis√© les √©tapes interm√©diaires de notre projet. \nN√©anmoins nous n'avons pas encore r√©fl√©chi √† la valorisation\n√† mettre en oeuvre pour notre projet. On va supposer que notre\nprojet s'adresse √† des _data scientists_ mais aussi √† une audience\nmoins technique. Pour ces premiers, nous pourrions nous contenter\nde valorisations techniques, comme des API, \nmais pour ces derniers il est\nconseill√© de privil√©gier des formats plus _user friendly_. \n\n::: {.callout-caution collapse=\"true\"}\n## Si vous prenez ce projet fil rouge en cours de route\n\n```{.bash filename=\"terminal\"}\ngit checkout appli15\n```\n\n![](/checkpoint.jpg){width=80% fig-align=\"center\"}\n\n:::\n\n\nAfin de faire le parall√®le avec les parcours possibles pour l'√©valuation,\nnous allons proposer trois valorisations[^valorisation]:\n\n- Une API facilitant la r√©utilisation du mod√®le en \"production\" ;\n- Un site web statique exploitant cette API pour exposer les pr√©dictions\n√† une audience moins technique. Pour illustrer\nles enjeux sp√©cifiques aux applications r√©actives mises en oeuvre\navec `Streamlit`, nous proposerons aussi cette valorisation m√™me si, dans\nnotre cas, elle n'apportera pas plus que le site statique. \n\n[^valorisation]: Vous n'√™tes pas oblig√©s pour l'√©valuation de mettre en oeuvre\nles jalons de plusieurs parcours. N√©anmoins, vous d√©couvrirez que \nchaque nouveau pas en avant est moins co√ªteux que le\npr√©c√©dent si vous avez mis en oeuvre les r√©flexes des bonnes\npratiques.  \n\n::: {.callout-warning collapse=\"true\"}\n## Site statique vs application r√©active\n\nLa solution que nous allons proposer \npour les sites statiques, `Quarto` associ√©\n√† `Github Pages`, peut √™tre utilis√©e dans le cadre des parcours \n_\"rapport reproductible\"_ ou _\"dashboard / application interactive\"_. \n\nPour ce dernier\nparcours, d'autres approches techniques sont n√©anmoins possibles,\ncomme `Streamlit`. Celles-ci sont plus exigeantes sur le plan technique\npuisqu'elles n√©cessitent de mettre en production sur des serveurs\nconteuneuris√©s (comme la mise en production de l'API)\nl√† o√π le site statique ne n√©cessite qu'un serveur web, mis √† disposition\ngratuitement par `Github`. \n\n\nLa distinction principale entre ces deux approches est qu'elles\ns'appuient sur des serveurs diff√©rents. Un site statique repose\nsur un serveur web l√† o√π `Streamlit` s'appuie sur \nserveur classique en _backend_. La diff√©rence principale\nentre ces deux types de serveurs\nr√©side principalement dans leur fonction et leur utilisation:\n\n- Un __serveur web__ est sp√©cifiquement con√ßu pour stocker, traiter et livrer des pages web aux clients. Cela inclut des fichiers HTML, CSS, JavaScript, images, etc. Les serveurs web √©coutent les requ√™tes HTTP/HTTPS provenant des navigateurs des utilisateurs et y r√©pondent en envoyant les donn√©es demand√©es.\n- Un **serveur _backend_** classique est con√ßu pour effectuer des op√©rations en r√©ponse √† un _front_, en l'occurrence une page web. \nDans le contexte d'une application `Streamlit`, il s'agit d'un serveur avec l'environnement `Python` _ad hoc_ pour\nex√©cuter le code n√©cessaire √† r√©pondre √† toute action d'un utilisateur de l'appliacation. \n\n:::\n\n\n## √âtape pr√©liminaire: cr√©ation d'un _pipeline_ `scikit`\n\nLa mise en\nproduction n√©cessite d'√™tre exigeant sur la mise en oeuvre op√©rationnelle\nde notre _pipeline_. Nous avons n√©anmoins un _pipeline_ un peu bancal\ncar il requiert d'√™tre vigilant dans la mani√®re d'encha√Æner les\n√©tapes de _preprocessing_, d'entra√Ænement et d'√©valuation.\n\nQuand on utilise `scikit`, la bonne pratique est d'utiliser\nles [_pipelines_](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html)\nqui s√©curisent les √©tapes de _feature engineering_ n√©cessaires avant la mise en oeuvre d'un mod√®le, qu'il\nque\nce soit pour l'entra√Ænement ou pour appliquer les m√™mes op√©rations avec les m√™mes param√®tres sur \nsur un nouveau jeu de donn√©es avant de faire un _predict_. \n\nOn va donc devoir refactoriser notre application pour utiliser un _pipeline_ `scikit`. \nLes raisons sont expliqu√©es plus en d√©tail [ici](https://scikit-learn.org/stable/common_pitfalls.html).\nCela aura\n√©galement l'avantage de rendre les √©tapes de notre _pipeline_ plus lisibles lorsqu'on passera √†\nl'√©tape d'industrialisation avec `MLFLow`. \n\n\n::: {.callout-tip}\n\n## Application 16 _(optionnelle)_: Un _pipeline_ de _machine learning_\n\nCette application est __optionnelle__ car elle rel√®ve plut√¥t d'un cours\nde _machine learning_ que de cet enseignement. \nLes instructions sont donc minimales pour laisser de la marge de manoeuvre.\n\n- Simplifier le code de `split_train_test_titanic` pour\nrenvoyer deux `DataFrames`: `train` et `test` au lieu\ndes 4 _arrays_ `Numpy` comme jusqu'√† pr√©sent\n\n- Cr√©er une fonction `build_pipeline` dans `src/models/train_evaluate.py`\nqui :\n    + Reprend les arguments de `random_forest_titanic`\n    + Effectue le _preprocessing_ suivant pour les variables num√©riques (√† d√©finir):\nune imputation √† la valeur m√©diane, un `MinMaxScaler` ensuite\n    + Effectue le _preprocessing_ suivant pour les variables cat√©gorielles (√† d√©finir):\nune imputation √† la valeur la plus fr√©quente, un _one hot encoding_ ensuite\n    + D√©finit une _random forest_ avec le nombre d'arbre donn√© en argument de la fonction\n\n- Modifier `main.py` pour que ce soit √† ce niveau\nqu'a lieu le d√©coupage en train/test, l'entrainement\net l'√©valuation\ndu mod√®le (qui est donc √† exfiltrer de `src/models/train_evaluate.py`)\n\n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli16\n```\n\n:::\n\n## √âtape 2: d√©velopper une API en local\n\n::: {.callout-tip}\n\n## Application 17: Mise √† disposition sous forme d'API locale\n\n- Cr√©er un nouveau service `SSPCloud` en param√©trant dans l'onglet\n`Networking` le port 5000 ;\n- Cloner le d√©p√¥t et se placer au niveau de l'application pr√©c√©dente (`git checkout appli16`)\n- Installer `fastAPI` et `uvicorn` puis les ajouter au `requirements.txt`\n- Renommer le fichier `main.py` en `train.py` et ins√©rer le contenu suivant dedans :\n\n<details>\n<summary>\nFichier `train.py`\n</summary>\nR√©cup√©rer le contenu sur [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/appli17/train.py)\n</details>\n\n- Cr√©er le fichier `api.py` permettant d'initialiser l'API:\n\n<details>\n<summary>\nFichier `api.py`\n</summary>\nR√©cup√©rer le contenu sur [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/appli17/api.py)\n</details>\n\n- Ex√©cuter `train.py` pour stocker en local le mod√®le entra√Æn√©\n- Ajouter `model.joblib` au `.gitignore`\n- D√©ployer en local l'API avec la commande\n\n```{.bash filename=\"terminal\"}\nuvicorn api:app --reload --host \"0.0.0.0\" --port 5000\n```\n\n- A partir du `README` du service, se rendre sur l'URL de d√©ploiement, \najouter `/docs/` √† celui-ci et observer la documentation de l'API \n- Se servir de la documentation pour tester les requ√™tes `/predict`\n- R√©cup√©rer l'URL d'une des requ√™tes propos√©es. La tester dans le navigateur\net depuis `Python` avec `requests` (`requests.get(url).json()`)\n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli17\n```\n\n:::\n\n## √âtape 3: d√©ployer l'API\n\nA ce stade, nous avons d√©ploy√© l'API seulement localement, dans le cadre d'un service. Ce mode de d√©ploiement est tr√®s pratique pour la phase de d√©veloppement, afin de s'assurer que l'API fonctionne comme attendu. A pr√©sent, il est temps de passer √† l'√©tape de d√©ploiement, qui permettra √† notre API d'√™tre accessible via une URL sur le web, et donc aux utilisateurs potentiels de la requ√™ter. Pour se faire, on va utiliser les possibilit√©s offertes par `Kubernetes`, sur lequel est bas√© le [SSP Cloud](https://datalab.sspcloud.fr).\n\n::: {.callout-tip}\n\n## Application 18: Dockeriser l'API\n\n- Modifier le `Dockerfile` pour tenir compte des changements dans les noms de fichier effecut√©s dans l'application pr√©c√©dente\n\n- Cr√©er un script `run.sh` √† la racine du projet qui lance le script `train.py` puis d√©ploie localement l'API \n\n<details>\n<summary>Fichier `run.sh`</summary>\n\n```{.bash filename=\"terminal\"}\n#/bin/bash\n\npython3 train.py\nuvicorn api:app --reload --host \"0.0.0.0\" --port 5000\n```\n</details>\n\n- Donner au script `run.sh` des permissions d'ex√©cution : `chmod +x run.sh`\n\n- Changer l'instruction `CMD` du `Dockerfile` pour ex√©cuter le script `run.sh` au lancement du conteneur\n\n- *Commit* et *push* les changements\n\n- Une fois le CI termin√©, r√©cup√©rer la nouvelle image dans l'environnement de test et v√©rifier que l'API se d√©ploie correctement\n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli18\n```\n:::\n\n::: {.callout-tip}\n\n## Application 19: D√©ployer l'API\n\n- Cr√©er un dossier `deployment` √† la racine du projet qui va contenir les fichiers de configuration n√©cessaires pour d√©ployer sur un cluster `Kubernetes`\n\n- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#creating-a-deployment), y ajouter un premier fichier `deployment.yaml` qui va sp√©cifier la configuration du *Pod* √† lancer sur le cluster\n\n<details>\n<summary>Fichier `deployment/deployment.yaml`</summary>\n\n```yaml\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titanic-deployment\n  labels:\n    app: titanic\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: titanic\n  template:\n    metadata:\n      labels:\n        app: titanic\n    spec:\n      containers:\n      - name: titanic\n        image: linogaliana/application-correction:latest\n        ports:\n        - containerPort: 5000\n```\n</details>\n\n- En vous inspirant de la [documentation](https://kubernetes.io/fr/docs/concepts/services-networking/service/#d%C3%A9finition-d-un-service), y ajouter un second fichier `service.yaml` qui va cr√©er une ressource `Service` permettant de donner une identit√© fixe au `Pod` pr√©c√©demment cr√©√© au sein du cluster\n\n<details>\n<summary>Fichier `deployment/service.yaml`</summary>\n\n```yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: titanic-service\nspec:\n  selector:\n    app: titanic\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 5000\n```\n</details>\n\n- En vous inspirant de la [documentation](https://kubernetes.io/docs/concepts/services-networking/ingress/#the-ingress-resource), y ajouter un troisi√®me fichier `ingress.yaml` qui va cr√©er une ressource `Ingress` permettant d'exposer le service via une URL en dehors du cluster\n\n<details>\n<summary>Fichier `deployment/ingress.yaml`</summary>\n\n```yaml\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: titanic-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/rewrite-target: /\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - titanic.kub.sspcloud.fr\n  rules:\n  - host: titanic.kub.sspcloud.fr\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: titanic-service\n            port:\n              number: 80\n```\n</details>\n\n- Appliquer ces fichiers de configuration sur le cluster : `kubectl apply -f deployement/`\n\n- Si tout a correctement fonctionn√©, vous devriez pouvoir acc√©der √† l'API √† l'URL sp√©cifi√©e dans le fichier `deployment/ingress.yaml`\n\n:::\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli19\n```\n\n:::\n\n\n# Partie 6: un workflow complet de MLOps\n\nCe sera l'an prochain, d√©sol√© !\n\n# Partie 7: livrer un site web de mani√®re automatis√©e\n\nOn va proposer un nouveau livrable pour parler √† un public plus large.\nPour cela, on va d√©ployer un site web statique qui permet de visualiser\nrapidement les r√©sultats du mod√®le.\n\nOn propose de cr√©er un site web qui permet de comprendre, avec l'appui\ndes [valeurs de Shapley](https://christophm.github.io/interpretable-ml-book/shapley.html),\nles facteurs qui auraient pu nous mettre la puce\n√† l'oreille sur les destins de Jake et de Rose. \n\nPour faire ce site web,\non va utiliser `Quarto` et d√©ployer sur `Github Pages`.\nDes √©tapes pr√©liminaires sont r√©alis√©es en `Python` \npuis l'affichage interactif \nsera contr√¥l√© par du `JavaScript` gr√¢ce\n√† des [blocs `Observable`](https://quarto.org/docs/interactive/ojs/). \n\n\n::: {.callout-tip}\n\n## Application 19: D√©ploiement automatis√© d'un site web\n\nDans un premier temps, on va cr√©er un projet `Quarto`\nau sein de notre d√©p√¥t: \n\n- Installer `Quarto` dans votre environnement local (s'il n'est pas d√©j√† disponible) ;\n- Dans le projet, utiliser la commande `quarto create-project` pour initialiser le projet `Quarto` ;\n- Supprimer le fichier automatiquement g√©n√©r√© avec l'extension `.qmd` ;\n- R√©cup√©rer le contenu du mod√®le de fichier `Quarto Markdown` [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/index.qmd). Celui-ci permet de g√©n√©rer la page d'accueil de notre site. Enregistrer dans un fichier nomm√© `index.qmd`\n\nOn teste ensuite la compilation en local du fichier:\n\n- Modifier le fichier `train.py` √† partir de [cette page](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/train.py) pour √™tre en mesure de compiler le fichier \n- Ex√©cuter le fichier `train.py`\n- En ligne de commande, faire `quarto preview` (ajouter les arguments `--port 5000 --host 0.0.0.0` si vous passez par le `SSPCloud`)\n- Observer le site web g√©n√©r√© en local\n\nEnfin, on va construire et d√©ployer automatiquement ce site web gr√¢ce au\ncombo `Github Actions` et `Github Pages`:\n\n- Cr√©er une branche `gh-pages` √† partir du contenu de [cette page](https://quarto.org/docs/publishing/github-pages.html)\n- Cr√©er un fichier `.github/workflows/website.yaml` avec le contenu de [ce fichier](https://raw.githubusercontent.com/ensae-reproductibilite/application-correction/tree/appli19/.github/workflows/publish.yaml)\n\n:::\n\n::: {.callout-note}\n\nOn doit dans cette application modifier le fichier `train.py`\npour enregistrer en local une duplication du mod√®le\nde _machine learning_ et de l'ensemble d'entra√Ænement\ncar pour ces deux √©l√©ments\non n'est pas all√© au bout de la d√©marche MLOps\nd'enregistrement dans un _model registry_ et un\n_feature store_.\n\nDans la prochaine version de ce cours, qui\nint√®grera `MLFlow`, on aura une d√©marche plus \npropre car on utilisera bien le mod√®le de production\net le jeu d'entrainement associ√©. \n:::\n\n\n::: {.callout-caution collapse=\"true\"}\n## Checkpoint\n\n```{.bash filename=\"terminal\"}\ngit checkout appli20\n```\n\n:::\n\n",
    "supporting": [
      "application_files/figure-html"
    ],
    "filters": [],
    "includes": {}
  }
}