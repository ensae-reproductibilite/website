[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Mise en production",
    "section": "",
    "text": "Un parcours de formation construit par Romain Avouac et Lino Galiana pour le cursus d‚Äôing√©nieurs de la donn√©e de l‚ÄôENSAE.\nLes slides associ√©es au cours sont disponibles √† cette adresse et les codes sources sont sur Github ."
  },
  {
    "objectID": "index.html#cours-de-mise-en-production-de-projets-data-science",
    "href": "index.html#cours-de-mise-en-production-de-projets-data-science",
    "title": "Mise en production",
    "section": "",
    "text": "Un parcours de formation construit par Romain Avouac et Lino Galiana pour le cursus d‚Äôing√©nieurs de la donn√©e de l‚ÄôENSAE.\nLes slides associ√©es au cours sont disponibles √† cette adresse et les codes sources sont sur Github ."
  },
  {
    "objectID": "chapters/application.html",
    "href": "chapters/application.html",
    "title": "Application",
    "section": "",
    "text": "D√©rouler les slides ci-dessous ou cliquer ici pour afficher les slides en plein √©cran."
  },
  {
    "objectID": "chapters/application.html#objectif",
    "href": "chapters/application.html#objectif",
    "title": "Application",
    "section": "Objectif",
    "text": "Objectif\nL‚Äôobjectif est d‚Äôam√©liorer le projet de mani√®re incr√©mentale jusqu‚Äô√† pouvoir le mettre en production, en le valorisant sous une forme adapt√©e et en adoptant une m√©thode de travail fluidifiant les √©volutions futures.\nLa Figure¬†1 montre que notre point de d√©part initial, √† savoir un notebook, m√©lange tout. Ceci rend tr√®s complexe la mise √† jour de notre mod√®le ou l‚Äôexploitation de notre mod√®le sur de nouvelles donn√©es, ce qui est pourtant la raison d‚Äô√™tre du machine learning qui est pens√© pour l‚Äôextrapolation. Si on vous demande de valoriser votre mod√®le sur de nouvelles donn√©es, vous risquez de devoir refaire tourner tout votre notebook, avec le risque de ne pas retrouver les m√™mes r√©sultats que dans la version pr√©c√©dente.\nLa Figure¬†2 illustre l‚Äôhorizon auquel nous aboutirons √† la fin de cette application. Nous d√©synchronisons les √©tapes d‚Äôentra√Ænement et de pr√©diction, en identifiant mieux les pr√©-requis de chacune et en adoptant des briques technologiques adapt√©es √† celles-ci. Les noms pr√©sents sur cette figure sont encore obscurs, c‚Äôest normal, mais ils vous deviendrons familiers si vous adoptez une infrastructure et une m√©thode de travail √† l‚Äô√©tat de l‚Äôart.\n\n\n\n\n\n\nFigure¬†1: Illustration de notre point de d√©part\n\n\n\n\n\n\n\n\n\nFigure¬†2: Illustration de l‚Äôhorizon vers lequel on se dirige\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIl est important de bien lire les consignes et d‚Äôy aller progressivement. Certaines √©tapes peuvent √™tre rapides, d‚Äôautres plus fastidieuses ; certaines √™tre assez guid√©es, d‚Äôautres vous laisser plus de libert√©. Si vous n‚Äôeffectuez pas une √©tape, vous risquez de ne pas pouvoir passer √† l‚Äô√©tape suivante qui en d√©pend.\nBien que l‚Äôexercice soit applicable sur toute configuration bien faite, nous recommandons de privil√©gier l‚Äôutilisation du SSP Cloud, o√π tous les outils n√©cessaires sont pr√©-install√©s et pr√©-configur√©s. Le service VSCode ne sera en effet que le point d‚Äôentr√©e pour l‚Äôutilisation d‚Äôoutils plus exigeants sur le plan de l‚Äôinfrastructure: Argo, MLFLow, etc."
  },
  {
    "objectID": "chapters/application.html#ce-que-cette-application-ne-couvre-pas-pour-le-moment",
    "href": "chapters/application.html#ce-que-cette-application-ne-couvre-pas-pour-le-moment",
    "title": "Application",
    "section": "Ce que cette application ne couvre pas (pour le moment)",
    "text": "Ce que cette application ne couvre pas (pour le moment)\nA l‚Äôheure actuelle, cette application se concentre sur la mise en oeuvre fiable de l‚Äôentra√Ænement de mod√®les de machine learning. Comme vous pouvez le voir, quand on part d‚Äôaussi loin qu‚Äôun projet monolithique dans un notebook, c‚Äôest un travail cons√©quent d‚Äôen arriver √† un pipeline pens√© pour la production. Cette application vise √† vous sensibiliser au fait qu‚Äôavoir la Figure¬†2 en t√™te et adopter une organisation de travail et faire des choix techniques ad√©quats, vous fera √©conomiser des dizaines voire centaines d‚Äôheures lorsque votre mod√®le aura vocation √† passer en production.\nA l‚Äôheure actuelle, cette application ne se concentre que sur une partie du cycle de vie d‚Äôun projet data ; il y a d√©j√† fort √† faire. Nous nous concentrons sur l‚Äôentra√Ænement et la mise √† disposition d‚Äôun mod√®le √† des fins op√©rationnelles. C‚Äôest la premi√®re partie du cycle de vie d‚Äôun mod√®le. Dans une approche MLOps, il faut √©galement penser la maintenance de ce mod√®le et les enjeux que repr√©sentent l‚Äôarriv√©e continue de nouvelles donn√©es, ou le besoin d‚Äôen collecter de nouvelles √† travers des annotations, sur la qualit√© pr√©dictive d‚Äôun mod√®le. Toute entreprise qui ne pense pas cet apr√®s est vou√©e √† se faire doubler par un nouveau venu. Une prochaine version de cette application permettra certainement d‚Äôillustrer certains des enjeux aff√©rants √† la vie en production d‚Äôun mod√®le (supervision, annotations‚Ä¶) sur notre cas d‚Äôusage.\nIl convient aussi de noter que nous ne faisons que parcourir la surface des sujets que nous √©voquons. Ce cours, d√©j√† dense, deviendrait indigeste si nous devions pr√©senter chaque outil dans le d√©tail. Nous laissons donc les curieux approfondir chacun des outils que nous pr√©sentons pour d√©couvrir comment en tirer le maximum (et si vous avez l‚Äôimpression que nous oublions des √©l√©ments cruciaux, les issues et pull requests  sont bienvenues)."
  },
  {
    "objectID": "chapters/application.html#comment-g√©rer-les-checkpoints",
    "href": "chapters/application.html#comment-g√©rer-les-checkpoints",
    "title": "Application",
    "section": "Comment g√©rer les checkpoints ?",
    "text": "Comment g√©rer les checkpoints ?\nPour simplifier la reprise en cours de ce fil rouge, nous proposons un syst√®me de checkpoints qui s‚Äôappuient sur des tags Git. Ces tags figent le projet tel qu‚Äôil est √† l‚Äôissue d‚Äôun exercice donn√©.\nSi vous faites √©voluer votre projet de mani√®re exp√©rimentale mais d√©sirez tout de m√™me utiliser √† un moment ces checkpoints, il va falloir faire quelques acrobaties Git. Pour cela, nous mettons √† disposition un script qui permet de sauvegarder votre avanc√©e dans un tag donn√© (au cas o√π, √† un moment, vous vouliez revenir dessus) et √©craser la branche main avec le tag en question. Par exemple, si vous d√©sirez reprendre apr√®s l‚Äôexercice 9, vous devrez faire tourner le code dans cette boite :\n  \n    \n      \n        \n      \n      \n        Checkpoint d'exemple      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli92\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli9\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nCelui-ci sauvegarde votre avanc√©e dans un tag nomm√© dev_before_appli9, le pousse sur votre d√©p√¥t Github  puis force votre branche √† adopter l‚Äô√©tat du tag appli9."
  },
  {
    "objectID": "chapters/application.html#√©tape-1-sassurer-que-le-script-sex√©cute-correctement",
    "href": "chapters/application.html#√©tape-1-sassurer-que-le-script-sex√©cute-correctement",
    "title": "Application",
    "section": "√âtape 1 : s‚Äôassurer que le script s‚Äôex√©cute correctement",
    "text": "√âtape 1 : s‚Äôassurer que le script s‚Äôex√©cute correctement\nOn va partir du fichier notebook.py qui reprend le contenu du notebook2 mais dans un script classique. Le travail de nettoyage en sera facilit√©.\nLa premi√®re √©tape est simple, mais souvent oubli√©e : v√©rifier que le code fonctionne correctement. Pour cela, nous recommandons de faire un aller-retour entre le script ouvert dans VSCode et un terminal pour le lancer.\n\n\n\n\n\n\nApplication 1: corriger les erreurs\n\n\n\n\nOuvrir dans VSCode le script titanic.py ;\nEx√©cuter le script en ligne de commande (python titanic.py)3 pour d√©tecter les erreurs ;\nCorriger les deux erreurs qui emp√™chent la bonne ex√©cution ;\nV√©rifier le fonctionnement du script en utilisant la ligne de commande:\n\n\n\nterminal\n\npython titanic.py\n\nLe code devrait afficher des sorties.\n\n\nAide sur les erreurs rencontr√©es\n\nLa premi√®re erreur rencontr√©e est une alerte FileNotFoundError, la seconde est li√©e √† un package.\n\nIl est maintenant temps de commit les changements effectu√©s avec Git4 :\n\n\nterminal\n\ngit add titanic.py\ngit commit -m \"Corrige l'erreur qui emp√™chait l'ex√©cution\"\ngit push\n\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli1      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli12\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli1\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-2-utiliser-un-linter-puis-un-formatter",
    "href": "chapters/application.html#√©tape-2-utiliser-un-linter-puis-un-formatter",
    "title": "Application",
    "section": "√âtape 2: utiliser un linter puis un formatter",
    "text": "√âtape 2: utiliser un linter puis un formatter\nOn va maintenant am√©liorer la qualit√© de notre code en appliquant les standards communautaires. Pour cela, on va utiliser le linter classique PyLint et le formatter Black. Si vous d√©sirez un outil deux en un, il est possible d‚Äôutiliser Ruff en compl√©ment ou substitut.\nCe nettoyage automatique du code permettra, au passage, de restructurer notre script de mani√®re plus naturelle.\n\n\n\n\n\n\nImportant\n\n\n\nPyLint, Black et Ruff sont des packages Python qui s‚Äôutilisent principalement en ligne de commande.\nSi vous avez une erreur qui sugg√®re que votre terminal ne connait pas PyLint, Black, ou Ruff, n‚Äôoubliez pas d‚Äôex√©cuter la commande pip install pylint, pip install black ou pip install ruff.\n\n\nLe linter PyLint renvoie alors une s√©rie d‚Äôirr√©gularit√©s, en pr√©cisant √† chaque fois la ligne de l‚Äôerreur et le message d‚Äôerreur associ√© (ex : mauvaise identation). Il renvoie finalement une note sur 10, qui estime la qualit√© du code √† l‚Äôaune des standards communautaires √©voqu√©s dans la partie Qualit√© du code.\n\n\n\n\n\n\nApplication 2: rendre lisible le script\n\n\n\n\nDiagnostiquer et √©valuer la qualit√© de titanic.py avec PyLint. Regarder la note obtenue.\nUtiliser black titanic.py --diff --color pour observer les changements de forme que va induire l‚Äôutilisation du formatter Black. Cette √©tape n‚Äôapplique pas les modifications, elle ne fait que vous les montrer.\nAppliquer le formatter Black\nR√©utiliser PyLint pour diagnostiquer l‚Äôam√©lioration de la qualit√© du script et le travail qui reste √† faire.\nComme la majorit√© du travail restant est √† consacrer aux imports:\n\nMettre tous les imports ensemble en d√©but de script\nRetirer les imports redondants en s‚Äôaidant des diagnostics de votre √©diteur\nR√©ordonner les imports si PyLint vous indique de le faire\nCorriger les derni√®res fautes formelles sugg√©r√©es par PyLint\n\nD√©limiter des parties dans votre code pour rendre sa structure plus lisible. Si des parties vous semblent √™tre dans le d√©sordre, vous pouvez r√©ordonner le script (mais n‚Äôoubliez pas de le tester)\n\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli2      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli22\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli2\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nLe code est maintenant lisible, il obtient √† ce stade une note formelle proche de 10. Mais il n‚Äôest pas encore totalement intelligible ou fiable. Il y a notamment quelques redondances de code auxquelles nous allons nous attaquer par la suite. N√©anmoins, avant cela, occupons-nous de mieux g√©rer certains param√®tres du script: jetons d‚ÄôAPI et chemin des fichiers."
  },
  {
    "objectID": "chapters/application.html#√©tape-3-gestion-des-param√®tres",
    "href": "chapters/application.html#√©tape-3-gestion-des-param√®tres",
    "title": "Application",
    "section": "√âtape 3: gestion des param√®tres",
    "text": "√âtape 3: gestion des param√®tres\n  \n    \n      \n        \n      \n      \n        Reprendre √† partir d'ici      \n      \n    \n    \n      \n\n        Si vous n'avez plus de VSCode actif avec la configuration propos√©e dans l'application pr√©liminaire, vous pouvez repartir de ce service:    \n      \n    \n    Et ensuite, apr√®s avoir cl√¥n√© le d√©p√¥t\n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli22\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli2\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nL‚Äôex√©cution du code et les r√©sultats obtenus d√©pendent de certains param√®tres d√©finis dans le code. L‚Äô√©tude de r√©sultats alternatifs, en jouant sur des variantes des (hyper)param√®tres, est √† ce stade compliqu√©e car il est n√©cessaire de parcourir le code pour trouver ces param√®tres. De plus, certains param√®tres personnels comme des jetons d‚ÄôAPI ou des mots de passe n‚Äôont pas vocation √† √™tre pr√©sents dans le code.\nIl est plus judicieux de consid√©rer ces param√®tres comme des variables d‚Äôentr√©e du script. Cela peut √™tre fait de deux mani√®res:\n\nAvec des arguments optionnels appel√©s depuis la ligne de commande (Application 3a). Cela peut √™tre pratique pour mettre en oeuvre des tests automatis√©s mais n‚Äôest pas forc√©ment pertinent pour toutes les variables. Nous allons montrer cet usage avec le nombre d‚Äôarbres de notre random forest ;\nEn utilisant un fichier de configuration dont les valeurs sont import√©es dans le script principal (Application 3b).\n\n\n\nUn exemple de d√©finition d‚Äôun argument pour l‚Äôutilisation en ligne de commande\n\n\n\nprenom.py\n\nimport argparse\nparser = argparse.ArgumentParser(description=\"Qui √™tes-vous?\")\nparser.add_argument(\n    \"--prenom\", type=str, default=\"Toto\", help=\"Un pr√©nom √† afficher\"\n)\nargs = parser.parse_args()\nprint(args.prenom)\n\nExemples d‚Äôutilisations en ligne de commande\n\n\nterminal\n\npython prenom.py\npython prenom.py --prenom \"Zinedine\"\n\n\n\n\n\n\n\n\nApplication 3a: Param√©trisation du script\n\n\n\n\nEn s‚Äôinspirant de l‚Äôexemple ci-dessus üëÜÔ∏è, cr√©er une variable n_trees qui peut √©ventuellement √™tre param√©tr√©e en ligne de commande et dont la valeur par d√©faut est 20 ;\nTester cette param√©trisation en ligne de commande avec la valeur par d√©faut puis 2, 10 et 50 arbres.\n\n\n\nL‚Äôexercice suivant permet de mettre en application le fait de param√©triser un script en utilisant des variables d√©finies dans un fichier YAML.\n\n\n\n\n\n\nApplication 3b: La configuration dans un fichier d√©di√©\n\n\n\n\nInstaller le package python-dotenv que nous allons utiliser pour charger notre jeton d‚ÄôAPI √† partir d‚Äôune variable d‚Äôenvironnement.\nA partir de l‚Äôexemple de la documentation, utiliser la fonction load_dotenv pour charger dans Python nos variables d‚Äôenvironnement √† partir d‚Äôun fichier (vous pouvez le cr√©er mais ne pas le remplir encore avec les valeurs voulues, ce sera fait ensuite)\nCr√©er la variable et v√©rifier la sortie de Python en faisant tourner titanic.py en ligne de commande\n\n\n\ntitanic.py\n\njeton_api = os.environ.get(\"JETON_API\", \"\")\n\nif jeton_api.startswith(\"$\"):\n    print(\"API token has been configured properly\")\nelse:\n    print(\"API token has not been configured\")\n\n\nMaintenant introduire la valeur voulue pour le jeton d‚ÄôAPI dans le fichier d‚Äôenvironnement lu par dotenv\nS‚Äôil n‚Äôexiste pas d√©j√†, cr√©er un fichier .gitignore (cf.¬†Chapitre Git). Ajouter dans ce fichier .env car il ne faut pas committer ce fichier. Au passage ajouter __pycache__/ au .gitignore5, cela √©vitera d‚Äôavoir √† le faire ult√©rieurement ;\nCr√©er un fichier README.md o√π vous indiquez qu‚Äôil faut cr√©er un fichier .env pour pouvoir utiliser l‚ÄôAPI.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli3      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli32\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli3\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-4-privil√©gier-la-programmation-fonctionnelle",
    "href": "chapters/application.html#√©tape-4-privil√©gier-la-programmation-fonctionnelle",
    "title": "Application",
    "section": "√âtape 4 : Privil√©gier la programmation fonctionnelle",
    "text": "√âtape 4 : Privil√©gier la programmation fonctionnelle\nNous allons mettre en fonctions les parties importantes de l‚Äôanalyse. Ceci facilitera l‚Äô√©tape ult√©rieure de modularisation de notre projet. Comme cela est √©voqu√© dans les √©l√©ments magistraux de ce cours, l‚Äôutilisation de fonctions va rendre notre code plus concis, plus tra√ßable, mieux document√©.\nCet exercice √©tant chronophage, il n‚Äôest pas obligatoire de le r√©aliser en entier. L‚Äôimportant est de comprendre la d√©marche et d‚Äôadopter fr√©quemment une approche fonctionnelle6. Pour obtenir une chaine enti√®rement fonctionnalis√©e, vous pouvez reprendre le checkpoint.\nPour commencer, cet exercice fait un petit pas de c√¥t√© pour faire comprendre la mani√®re dont les pipelines scikit sont un outil au service des bonnes pratiques.\n\n\n\n\n\n\nApplication 4 (optionnelle): pourquoi utiliser un pipeline Scikit ?\n\n\n\n\nLe pipeline Scikit d‚Äôestimation et d‚Äô√©valuation vous a √©t√© donn√© tel quel. Regardez, ci-dessous, le code √©quivalent sans utiliser de pipeline Scikit:\n\n\n\nLe code √©quivalent sans pipeline\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\n\nimport pandas as pd\nimport numpy as np\n\n# D√©finition des variables\nnumeric_features = [\"Age\", \"Fare\"]\ncategorical_features = [\"Embarked\", \"Sex\"]\n\n# PREPROCESSING ----------------------------\n\n# Handling missing values for numerical features\nnum_imputer = SimpleImputer(strategy=\"median\")\nX_train[numeric_features] = num_imputer.fit_transform(X_train[numeric_features])\nX_test[numeric_features] = num_imputer.transform(X_test[numeric_features])\n\n# Scaling numerical features\nscaler = MinMaxScaler()\nX_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\nX_test[numeric_features] = scaler.transform(X_test[numeric_features])\n\n# Handling missing values for categorical features\ncat_imputer = SimpleImputer(strategy=\"most_frequent\")\nX_train[categorical_features] = cat_imputer.fit_transform(X_train[categorical_features])\nX_test[categorical_features] = cat_imputer.transform(X_test[categorical_features])\n\n# One-hot encoding categorical features\nencoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nX_train_encoded = encoder.fit_transform(X_train[categorical_features])\nX_test_encoded = encoder.transform(X_test[categorical_features])\n\n# Convert encoded features into a DataFrame\nX_train_encoded = pd.DataFrame(X_train_encoded, columns=encoder.get_feature_names_out(categorical_features), index=X_train.index)\nX_test_encoded = pd.DataFrame(X_test_encoded, columns=encoder.get_feature_names_out(categorical_features), index=X_test.index)\n\n# Drop original categorical columns and concatenate encoded ones\nX_train = X_train.drop(columns=categorical_features).join(X_train_encoded)\nX_test = X_test.drop(columns=categorical_features).join(X_test_encoded)\n\n# MODEL TRAINING ----------------------------\n\n# Defining the model\nmodel = RandomForestClassifier(n_estimators=n_trees)\n\n# Fitting the model\nmodel.fit(X_train, y_train)\n\n# EVALUATION ----------------------------\n\n# Scoring\nrdmf_score = model.score(X_test, y_test)\nprint(f\"{rdmf_score:.1%} de bonnes r√©ponses sur les donn√©es de test pour validation\")\n\n# Confusion matrix\nprint(20 * \"-\")\nprint(\"matrice de confusion\")\nprint(confusion_matrix(y_test, model.predict(X_test)))\n\n\nVoyez-vous l‚Äôint√©r√™t de l‚Äôapproche par pipeline en termes de lisibilit√©, √©volutivit√© et fiabilit√© ?\nCr√©er un notebook qui servira de brouillon. Y introduire le code suivant:\n\n\n\nLe code √† copier-coller dans un notebook\n\nimport pandas as pd\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\ntrain = pd.read_csv(\"train.csv\")\ntest = pd.read_csv(\"test.csv\")\nX_train, y_train = train.drop(\"Survived\", axis=\"columns\"), train[\"Survived\"]\nX_test, y_test = test.drop(\"Survived\", axis=\"columns\"), train[\"Survived\"]\n\nMAX_DEPTH = None\nMAX_FEATURES = \"sqrt\"\nn_trees=20\n\nnumeric_features = [\"Age\", \"Fare\"]\ncategorical_features = [\"Embarked\", \"Sex\"]\n\n# Variables num√©riques\nnumeric_transformer = Pipeline(\n    steps=[\n        (\"imputer\", SimpleImputer(strategy=\"median\")),\n        (\"scaler\", MinMaxScaler()),\n    ]\n)\n\n# Variables cat√©gorielles\ncategorical_transformer = Pipeline(\n    steps=[\n        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n        (\"onehot\", OneHotEncoder()),\n    ]\n)\n\n# Preprocessing\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"Preprocessing numerical\", numeric_transformer, numeric_features),\n        (\n            \"Preprocessing categorical\",\n            categorical_transformer,\n            categorical_features,\n        ),\n    ]\n)\n\n# Pipeline\npipe = Pipeline(\n    [\n        (\"preprocessor\", preprocessor),\n        (\"classifier\", RandomForestClassifier(\n            n_estimators=n_trees,\n            max_depth=MAX_DEPTH,\n            max_features=MAX_FEATURES\n        )),\n    ]\n)\n\npipe.fit(X_train, y_train)\n\n\nAfficher ce pipeline dans une cellule de votre notebook. Cela vous aide-t-il mieux √† comprendre les diff√©rentes √©tapes du pipeline de mod√©lisation ?\nComment pouvez-vous acc√©der aux √©tapes de preprocessing ?\n\n\n\nComment pouvez-vous faire pour appliquer le pipeline de preprocessing des variables num√©riques (et uniquement celui-ci) √† ce DataFrame ?\n\n\n\nLe DataFrame √† cr√©er pour appliquer un bout de notre pipeline\n\nimport numpy as np\n\nnew_data = {\n    \"Age\": [22, np.nan, 35, 28, np.nan],\n    \"Fare\": [7.25, 8.05, np.nan, 13.00, 15.50]\n}\n\nnew_data = pd.DataFrame(new_data)\n\n\n\nNormalement ce code ne devrait pas prendre plus d‚Äôune demie-douzaine de lignes. Sans pipeline le code √©quivalent, beaucoup plus verbeux et moins fiable, ressemble √† celui-ci\n\n\n\nLe code √©quivalent, sans pipeline\n\nimport pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\n\n# D√©finition des nouvelles donn√©es\nnew_data = pd.DataFrame({\n    \"Age\": [25, np.nan, 40, 33, np.nan],\n    \"Fare\": [10.50, 7.85, np.nan, 22.00, 12.75]\n})\n\n# D√©finition des transformations (m√™me que dans le pipeline)\nnum_imputer = SimpleImputer(strategy=\"median\")\nscaler = MinMaxScaler()\n\n# Apprentissage des transformations sur X_train (assumant que vous l'avez d√©j√†)\nX_train_numeric = X_train[[\"Age\", \"Fare\"]]  # Supposons que X_train existe\nnum_imputer.fit(X_train_numeric)\nscaler.fit(num_imputer.transform(X_train_numeric))\n\n# Transformation des nouvelles donn√©es\nnew_data_imputed = num_imputer.transform(new_data)\nnew_data_scaled = scaler.transform(new_data_imputed)\n\n# Cr√©ation du DataFrame final\nnew_data_preprocessed = pd.DataFrame(\n    new_data_scaled,\n    columns=[\"Age_scaled\", \"Fare_scaled\"]  # G√©n√©rer des noms de colonnes adapt√©s\n)\n\n# Affichage du DataFrame\nprint(new_data_preprocessed)\n\n\nImaginons que vous ayez d√©j√† des donn√©es pr√©process√©es:\n\n\n\nCr√©er des donn√©es pr√©process√©es\n\nimport numpy as np\nimport pandas as pd\n\nnew_data = pd.DataFrame({\n    \"Age\": [25, np.nan, 40, 33, np.nan],\n    \"Fare\": [10.50, 7.85, np.nan, 22.00, 12.75],\n    \"Embarked\": [\"S\", \"C\", np.nan, \"Q\", \"S\"],\n    \"Sex\": [\"male\", \"female\", \"male\", np.nan, \"female\"]\n})\nnew_y = np.random.randint(0, 2, size=len(new_data))\n\npreprocessed_data = pd.DataFrame(\n    pipe[:-1].transform(new_data),\n    columns = preprocessor_numeric.get_feature_names_out()\n)\npreprocessed_data\n\n\nD√©terminer le score en pr√©diction sur ces donn√©es\n\n\n\n\nMaintenant, revenons √† notre chaine de production et appliquons des fonctions pour la rendre plus lisible, plus fiable et plus modulaire.\n\n\n\n\n\n\nApplication 4: adoption des standards de programmation fonctionnelle\n\n\n\nCette application peut √™tre chronophage, vous pouvez aller plus ou moins loin dans la fonctionalisation de votre script en fonction du temps dont vous disposez.\n\nCr√©er une fonction qui int√®gre les diff√©rentes √©tapes du pipeline (preprocessing et d√©finition du mod√®le). Cette fonction prend en param√®tre le nombre d‚Äôarbres (argument obligatoire) et des arguments optionnels suppl√©mentaires (les colonnes sur lesquelles s‚Äôappliquent les diff√©rentes √©tapes du pipeline, max_depth et max_features).\nCr√©er une fonction d‚Äô√©valuation renvoyant le score obtenu et la matrice de confusion, √† l‚Äôissue d‚Äôune estimation (mais cette estimation est faite en amont de la fonction, pas au sein de celle-ci)\nD√©placer toutes les fonctions ensemble, en d√©but de script. Si besoin, ajouter des param√®tres √† votre fichier d‚Äôenvironnement pour cr√©er de nouvelles variables comme les chemins des donn√©es.\nEn profiter pour supprimer le code zombie qu‚Äôon a gard√© jusqu‚Äô√† pr√©sent mais qui ne correspond pas vraiment √† des op√©rations utiles √† notre chaine de production\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli4      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli42\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli4\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nCela ne se remarque pas encore vraiment car nous avons de nombreuses d√©finitions de fonctions mais notre chaine de production est beaucoup plus concise (le script fait environ 150 lignes dont une centaine issues de d√©finitions de fonctions g√©n√©riques). Cette auto-discipline facilitera grandement les √©tapes ult√©rieures. Cela aurait √©t√© n√©anmoins beaucoup moins co√ªteux en temps d‚Äôadopter ces bons gestes de mani√®re plus pr√©coce."
  },
  {
    "objectID": "chapters/application.html#√©tape-1-modularisation",
    "href": "chapters/application.html#√©tape-1-modularisation",
    "title": "Application",
    "section": "√âtape 1 : modularisation",
    "text": "√âtape 1 : modularisation\nNous allons profiter de la modularisation pour adopter une structure applicative pour notre code. Celui-ci n‚Äô√©tant en effet plus lanc√© que depuis la ligne de commande, on peut consid√©rer qu‚Äôon construit une application g√©n√©rique o√π un script principal (main.py) encapsule des √©l√©ments issus d‚Äôautres scripts Python.\n\n\n\n\n\n\nApplication 5: modularisation\n\n\n\n\nD√©placer les fonctions dans une s√©rie de fichiers d√©di√©s:\n\nbuild_pipeline.py: script avec la d√©finition du pipeline\ntrain_evaluate.py: script avec les fonctions d‚Äô√©valuation du projet\n\nSp√©cifier les d√©pendances (i.e.¬†les packages √† importer) dans les modules pour que ceux-ci puissent s‚Äôex√©cuter ind√©pendamment ;\nRenommer titanic.py en main.py pour suivre la convention de nommage des projets Python ;\nImporter les fonctions n√©cessaires √† partir des modules.\nV√©rifier que tout fonctionne bien en ex√©cutant le script main √† partir de la ligne de commande :\n\n\n\nterminal\n\npython main.py\n\n\nOptionnel: profitez en pour mettre un petit coup de formatter √† votre projet, si vous ne l‚Äôavez pas fait r√©guli√®rement.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli5      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli52\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli5\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-2-adopter-une-architecture-standardis√©e-de-projet",
    "href": "chapters/application.html#√©tape-2-adopter-une-architecture-standardis√©e-de-projet",
    "title": "Application",
    "section": "√âtape 2 : adopter une architecture standardis√©e de projet",
    "text": "√âtape 2 : adopter une architecture standardis√©e de projet\nOn dispose maintenant d‚Äôune application Python fonctionnelle. N√©anmoins, le projet est certes plus fiable mais sa structuration laisse √† d√©sirer et il serait difficile de rentrer √† nouveau dans le projet dans quelques temps.\n\n\nEtat actuel du projet üôà\n\n‚îú‚îÄ‚îÄ .gitignore\n‚îú‚îÄ‚îÄ .env\n‚îú‚îÄ‚îÄ data.csv\n‚îú‚îÄ‚îÄ train.csv\n‚îú‚îÄ‚îÄ test.csv\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ build_pipeline.py\n‚îú‚îÄ‚îÄ train_evaluate.py\n‚îú‚îÄ‚îÄ titanic.ipynb\n‚îî‚îÄ‚îÄ main.py\n\nComme cela est expliqu√© dans la partie Structure des projets, on va adopter une structure certes arbitraire mais qui va faciliter l‚Äôautodocumentation de notre projet. De plus, une telle structure va faciliter des √©volutions optionnelles comme la packagisation du projet. Passer d‚Äôune structure modulaire bien faite √† un package est quasi-imm√©diat en Python.\nOn va donc modifier l‚Äôarchitecture de notre projet pour la rendre plus standardis√©e. Pour cela, on va s‚Äôinspirer des structures cookiecutter qui g√©n√®rent des templates de projet. En l‚Äôoccurrence notre source d‚Äôinspiration sera le template datascience issu d‚Äôun effort communautaire.\n\n\n\n\n\n\nNote\n\n\n\nL‚Äôid√©e de cookiecutter est de proposer des templates que l‚Äôon utilise pour initialiser un projet, afin de b√¢tir √† l‚Äôavance une structure √©volutive. La syntaxe √† utiliser dans ce cas est la suivante :\n\n\nterminal\n\npip install cookiecutter\ncookiecutter https://github.com/drivendata/cookiecutter-data-science\n\nIci, on a d√©j√† un projet, on va donc faire les choses dans l‚Äôautre sens : on va s‚Äôinspirer de la structure propos√©e afin de r√©organiser celle de notre projet selon les standards communautaires.\n\n\nEn s‚Äôinspirant du cookiecutter data science on va adopter la structure suivante:\n\n\nStructure recommand√©e\n\napplication\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ .env\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ data\n‚îÇ   ‚îú‚îÄ‚îÄ raw\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ data.csv\n‚îÇ   ‚îî‚îÄ‚îÄ derived\n‚îÇ       ‚îú‚îÄ‚îÄ test.csv\n‚îÇ       ‚îî‚îÄ‚îÄ train.csv\n‚îú‚îÄ‚îÄ notebooks\n‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ pipeline\n    ‚îÇ   ‚îî‚îÄ‚îÄ build_pipeline.py\n    ‚îî‚îÄ‚îÄ models\n        ‚îî‚îÄ‚îÄ train_evaluate.py\n\n\n\n\n\n\n\nApplication 6: adopter une structure lisible\n\n\n\n\n(optionnel) Analyser et comprendre la structure de projet propos√©e par le template ;\nModifier l‚Äôarborescence du projet selon le mod√®le ;\nMettre √† jour l‚Äôimport des d√©pendances, le fichier de configuration et main.py avec les nouveaux chemins ;\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli6      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli62\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli6\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-3-mieux-tracer-notre-chaine-de-production",
    "href": "chapters/application.html#√©tape-3-mieux-tracer-notre-chaine-de-production",
    "title": "Application",
    "section": "√âtape 3: mieux tracer notre chaine de production",
    "text": "√âtape 3: mieux tracer notre chaine de production\n\nIndiquer l‚Äôenvironnement minimal de reproductibilit√©\nLe script main.py n√©cessite un certain nombre de packages pour √™tre fonctionnel. Chez vous les packages n√©cessaires sont bien s√ªr install√©s mais √™tes-vous assur√© que c‚Äôest le cas chez la personne qui testera votre code ?\nAfin de favoriser la portabilit√© du projet, il est d‚Äôusage de ‚Äúfixer l‚Äôenvironnement‚Äù, c‚Äôest-√†-dire d‚Äôindiquer dans un fichier toutes les d√©pendances utilis√©es ainsi que leurs version. Nous proposons de cr√©er un fichier requirements.txt minimal, sur lequel nous reviendrons dans la partie consacr√©e aux environnements reproductibles.\nLe fichier requirements.txt est conventionnellement localis√© √† la racine du projet. Ici on ne va pas fixer les versions, on raffinera ce fichier ult√©rieurement.\n\n\n\n\n\n\nApplication 7a: cr√©ation du requirements.txt\n\n\n\n\nCr√©er un fichier requirements.txt avec la liste des packages n√©cessaires\nAjouter une indication dans README.md sur l‚Äôinstallation des packages gr√¢ce au fichier requirements.txt\n\n\n\n\n\nTracer notre cha√Æne\nQuand votre projet passera en production, vous aurez un acc√®s limit√© √† celui-ci. Il est donc important de faire remonter, par le biais du logging des informations critiques sur votre projet qui vous permettront de savoir o√π il en est (si vous avez acc√®s √† la console o√π il tourne) ou l√† o√π il s‚Äôest arr√™t√©.\nL‚Äôutilisation de print montre rapidement ses limites pour cela. Les informations enregistr√©es ne persistent pas apr√®s la session et sont quelques peu rudimentaires.\nPour faire du logging, la librairie consacr√©e depuis longtemps en Python est‚Ä¶ logging. Il existe aussi une librairie nomm√©e loguru qui est un peu plus simple √† configurer (l‚Äôinstanciation du logger est plus ais√©e) et plus agr√©able gr√¢ce √† ses messages en couleurs qui permettent de visuellement trier les informations.\n\nL‚Äôexercice suivant peut √™tre fait avec les deux librairies, cela ne change pas grand chose. Les prochaines applications repartiront de la version utilisant la librairie standard logging.\n\n\n\n\n\n\nApplication 7b: remont√©e de messages par logging\n\n\n\n\nVersion utilisant loggingVersion utilisant loguru\n\n\n\nAller sur la documentation de la librairie ici et sur ce tutoriel pour trouver des sources d‚Äôinspiration sur la configuration et l‚Äôutilisation de logging.\nPour afficher les messages dans la console et dans un fichier de log, s‚Äôinspirer de cette r√©ponse sur stack overflow.\nTester en ligne de commande votre code et observer le fichier de log\n\n\n\n\nInstaller loguru et l‚Äôajouter au requirements.txt\nEn s‚Äôaidant du README du projet sur Github, remplacer nos print par diff√©rents types de messages (info, success, etc.).\nTester l‚Äôex√©cution du script en ligne de commande et observer vos sorties\nMettre √† jour le logger pour enregistrer dans un fichier de log. Ajouter celui-ci au .gitignore puis tester en ligne de commande votre script. Ouvrir le fichier en question, refaites tourner le script et regardez son √©volutoin.\nIl est possible avec loguru de capturer les erreurs des fonctions gr√¢ce au syst√®me de cache d√©crit ici. Introduire une erreur dans une des fonctions (par exemple dans create_pipeline) avec un code du type raise ValueError(\"Probl√®me ici\")\n\n\n\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli7      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli72\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli7\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#stockageS3",
    "href": "chapters/application.html#stockageS3",
    "title": "Application",
    "section": "√âtape 4 : stocker les donn√©es de mani√®re externe",
    "text": "√âtape 4 : stocker les donn√©es de mani√®re externe\nPour cette partie, il faut avoir un service VSCode dont les jetons d‚Äôauthentification √† S3 sont valides. Pour cela, si vous √™tes sur le SSPCloud, le plus simple est de recr√©er un nouveau service avec le bouton suivant\n\net remplir l‚Äôonglet Git comme √ßa votre VSCode sera pr√© √† l‚Äôemploi (cf.¬†application 0).\nUne fois que vous avez un VSCode fonctionnel, il est possible de reprendre cette application fil rouge depuis le checkpoint pr√©c√©dent.\n  \n    \n      \n        \n      \n      \n        Reprendre √† partir d'ici      \n      \n    \n    \n      \n\n        Si vous n'avez plus de VSCode actif avec la configuration propos√©e dans l'application pr√©liminaire, vous pouvez repartir de ce service:    \n      \n    \n    Et ensuite, apr√®s avoir cl√¥n√© le d√©p√¥t\n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli72\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli7\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nEnfin, il vous suffira d‚Äôouvrir un terminal et faire pip install -r requirements.txt && python main.py pour pouvoir d√©marrer l‚Äôapplication.\nL‚Äô√©tape pr√©c√©dente nous a permis d‚Äôisoler la configuration. Nous avons conceptuellement isol√© les donn√©es du code lors des applications pr√©c√©dentes. Cependant, nous n‚Äôavons pas √©t√© au bout du chemin car le stockage des donn√©es reste conjoint √† celui du code. Nous allons maintenant dissocier ces deux √©l√©ments.\n\n\n\n\n\n\nPour en savoir plus sur le syst√®me de stockage S3\n\n\n\n\n\nPour mettre en oeuvre cette √©tape, il peut √™tre utile de comprendre un peu comme fonctionne le SSP Cloud. Vous devrez suivre la documentation du SSP Cloud pour la r√©aliser. Une aide-m√©moire est √©galement disponible dans le cours de 2e ann√©e de l‚ÄôENSAE Python pour la data science.\n\n\n\n\n\n\n\n\n\nPour en savoir plus sur le format Parquet\n\n\n\n\n\nL‚Äôobjectif de cette application est de montrer comment utiliser le format Parquet dans une cha√Æne production ; un objectif somme toute modeste.\nSi vous voulez aller plus loin dans la d√©couverte du format Parquet, vous pouvez consulter cette ressource R tr√®s similaire √† ce cours (oui elle est faite par les m√™mes auteurs‚Ä¶) et essayer de faire les exercices avec votre librairie Python de pr√©dilection (PyArrow ou DuckDB)\n\n\n\n\n\n\n\n\n\nEt si vous utilisez une infrastructure cloud qui n‚Äôest pas le SSPCloud ? (une id√©e saugrenue mais sait-on jamais)\n\n\n\n\n\nLes exemples √† venir peuvent tr√®s bien √™tre r√©pliqu√©s sur n‚Äôimporte quel cloud provider qui propose une solution de type S3, qu‚Äôil s‚Äôagisse d‚Äôun cloud provider priv√© (AWS, GCP, Azure, etc.) ou d‚Äôune r√©instanciation ad hoc du projet Onyxia, le logiciel derri√®re le SSPCloud.\nPour un syst√®me de stockage S3, il suffit de changer les param√®tres de connexion de s3fs (endpoint, region, etc.). Pour les stockages sur GCP, les codes sont presque √©quivalents, il suffit de remplacer la librairie s3fs par gcfs; ces deux librairies sont en fait des briques d‚Äôun standard plus g√©n√©ral de gestion de syst√®mes de fichiers en Python ffspec.\n\n\n\nLe chapitre sur la structure des projets d√©veloppe l‚Äôid√©e qu‚Äôil est recommand√© de converger vers un mod√®le o√π environnements d‚Äôex√©cution, de stockage du code et des donn√©es sont conceptuellement s√©par√©s. Ce haut niveau d‚Äôexigence est un gain de temps important lors de la mise en production car au cours de cette derni√®re, le projet est amen√© √† √™tre ex√©cut√© sur une infrastructure informatique d√©di√©e qu‚Äôil est bon d‚Äôanticiper. Sch√©matiquement, nous visons la structure de projet suivante:\n\nA l‚Äôheure actuelle, les donn√©es sont stock√©es dans le d√©p√¥t. C‚Äôest une mauvaise pratique. En premier lieu, Git n‚Äôest techniquement pas bien adapt√© au stockage de donn√©es. Ici ce n‚Äôest pas tr√®s grave car il ne s‚Äôagit pas de donn√©es volumineuses et ces derni√®res ne sont pas modifi√©es au cours de notre chaine de traitement.\nLa raison principale est que les donn√©es trait√©es par les data scientists sont g√©n√©ralement soumises √† des clauses de confidentialit√©s (RGPD, secret statistique‚Ä¶). Mettre ces donn√©es sous contr√¥le de version c‚Äôest prendre le risque de les divulguer √† un public non habilit√©. Il est donc recommand√© de privil√©gier des outils techniques adapt√©s au stockage de donn√©es.\nL‚Äôid√©al, dans notre cas, est d‚Äôutiliser une solution de stockage externe. On va utiliser pour cela MinIO, la solution de stockage de type S3 offerte par le SSP Cloud. Cela nous permettra de supprimer les donn√©es de Github tout en maintenant la reproductibilit√© de notre projet 7.\nPlus concr√®tement, nous allons adopter le pipeline suivant pour notre projet:\n\nLe sc√©nario type est que nous avons une source brute, re√ßue sous forme de CSV, dont on ne peut changer le format. Il aurait √©t√© id√©al d‚Äôavoir un format plus adapt√© au traitement de donn√©es pour ce fichier mais ce n‚Äô√©tait pas de notre ressort. Notre chaine va aller chercher ce fichier, travailler dessus jusqu‚Äô√† valoriser celui-ci sous la forme de notre matrice de confusion. Si on imagine que notre chaine prend un certain temps, il n‚Äôest pas inutile d‚Äô√©crire des donn√©es interm√©diaires. Pour faire cela, puisque nous avons la main, autant choisir un format adapt√©, √† savoir le format Parquet.\nCette application va se d√©rouler en trois temps:\n\nUpload de notre source brute (CSV) sur S3\nIllustration de l‚Äôusage des librairies cloud native pour lire celle-ci\nPartage public de cette donn√©e pour la rendre accessible de mani√®re plus simple √† nos futures applications.\n\n\n\n\n\n\n\nApplication 8a: ajout de donn√©es sur le syst√®me de stockage S3\n\n\n\nPour commencer, √† partir de la ligne de commande, utiliser l‚Äôutilitaire MinIO pour copier les donn√©es data/raw/data.csv vers votre bucket personnel. Les donn√©es interm√©diaires peuvent √™tre laiss√©es en local mais doivent √™tre ajout√©es au .gitignore.\n\n\nIndice\n\nStructure √† adopter:\n\n\nterminal\n\nBUCKET_PERSONNEL=\"nom_utilisateur_sspcloud\"\nmc cp data/raw/data.csv s3/${BUCKET_PERSONNEL}/ensae-reproductibilite/data/raw/data.csv\n\nen modifiant la variable BUCKET_PERSONNEL, l‚Äôemplacement de votre bucket personnel\n\nPour se simplifier la vie, dans les prochaines applications, on va utiliser des URL de t√©l√©chargement des fichiers (comme si ceux-ci √©taient sur n‚Äôimporte quel espace de stockage) plut√¥t que d‚Äôutiliser une librairie S3 compatible comme boto3 ou s3fs.\nN√©anmoins, il est utile de les utiliser une fois pour comprendre la logique. Pour aller plus loin sur ces librairies, vous pouvez consulter cette page du cours de 2A de Python pour la data science.\nPour commencer, on va lister les fichiers se trouvant dans un bucket. En ligne de commande, sur notre poste local, on ferait ls (cf.¬†Linux 101). Cela ne va pas beaucoup diff√©rer avec les librairies cloud native:\n\nAvec s3fsAvec mc\n\n\nDans un notebook, copier-coller ce code, le modifier et ex√©cuter:\nimport s3fs\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\n1MY_BUCKET = \"mon_nom_utilisateur_sspcloud\"\n2CHEMIN = \"ensae-reproductibilite/data/raw\"\nfs.ls(f\"s3://{MY_BUCKET}/{CHEMIN}\")\n\n1\n\nChanger avec le bucket\n\n2\n\nChanger en fonction du chemin voulu\n\n\n\n\nDans un terminal, copier-coller ligne √† ligne ce code, le modifier et ex√©cuter:\nimport s3fs\n\n1MY_BUCKET=\"mon_nom_utilisateur_sspcloud\"\n2CHEMIN = \"ensae-reproductibilite/data/raw\"\nmc ls s3/${MY_BUCKET}/${CHEMIN}\n\n1\n\nChanger avec le bucket\n\n2\n\nChanger en fonction du chemin voulu\n\n\n\n\n\n\n\nOn va maintenant lire directement une donn√©e stock√©e sur S3. Pour illustrer le fait que cela change peu notre code d‚Äô√™tre sur un syst√®me cloud avec les librairies adapt√©es, on va lire directement un fichier CSV stock√© sur le SSPCloud, sans passer par un fichier en local8.\n\n\n\n\n\n\nApplication 8b: importer une donn√©e depuis un syst√®me de stockage S3\n\n\n\nPour illustrer la coh√©rence avec un syst√®me de fichier local, voici trois solutions pour lire le fichier que vous venez de mettre sur S3. Attention, il faut avoir des jetons de connexion √† S3 √† jour. Si vous avez cette erreur\n\nA client error (InvalidAccessKeyId) occurred when calling the ListBuckets operation: The AWS Access Key Id you provided does not exist in our records.\n\nc‚Äôest que vos identifiants de connexion ne sont plus √† jour (pour des raisons de s√©curit√©, ils sont r√©guli√®rement renouvel√©s). Dans ce cas, recr√©ez un service VSCode avec le bouton propos√© plus haut.\nDans un notebook, copier-coller et mettre √† jour ces deux variables qui seront utilis√©es dans diff√©rents exemples:\n1MY_BUCKET = \"mon_nom_utilisateur_sspcloud\"\n2CHEMIN_FICHIER = \"ensae-reproductibilite/data/raw/data.csv\"\n\n1\n\nChanger avec le bucket\n\n2\n\nChanger en fonction du chemin voulu\n\n\n\nAvec Pandas et s3fsAvec Pyarrow et s3fsAvec DuckDB\n\n\nimport s3fs\nimport pandas as pd\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\nwith fs.open(f\"s3://{MY_BUCKET}/{CHEMIN_FICHIER}\") as f:\n    df = pd.read_csv(f)\n\ndf\n\n\nimport s3fs\nfrom pyarrow import csv\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\nwith fs.open(f\"s3://{MY_BUCKET}/{CHEMIN_FICHIER}\") as f:\n    df = csv.read_csv(f)\n\ndf\n\n\nimport os\nimport duckdb\n\ncon = duckdb.connect(database=\":memory:\")\n\ncon.execute(\n    f\"\"\"\nCREATE SECRET secret (\n    TYPE S3,\n    KEY_ID '{os.environ[\"AWS_ACCESS_KEY_ID\"]}',\n    SECRET '{os.environ[\"AWS_SECRET_ACCESS_KEY\"]}',\n    ENDPOINT 'minio.lab.sspcloud.fr',\n    SESSION_TOKEN '{os.environ[\"AWS_SESSION_TOKEN\"]}',\n    REGION 'us-east-1',\n    URL_STYLE 'path',\n    SCOPE 's3://{MY_BUCKET}/'\n);\n\"\"\"\n)\n\nquery_definition = f\"SELECT * FROM read_csv('s3://{MY_BUCKET}/{CHEMIN_FICHIER}')\"\ndf = con.sql(query_definition)\n\ndf\n\n\n\nPour illustrer le fonctionnement encore plus simple de S3 avec les fichiers Parquet, on propose de copier un Parquet mis √† disposition dans un bucket collectiv vers votre bucket personnel:\n1BUCKET_PERSONNEL=\"nom_utilisateur_sspcloud\"\n\n2curl -o rp.parquet \"https://minio.lab.sspcloud.fr/projet-formation/bonnes-pratiques/data/REGION=11/part-0.parquet\"\n\nmc cp rp.parquet s3/${BUCKET_PERSONNEL}/ensae-reproductibilite/data/example/rp.parquet\n\nrm rp.parquet\n\n1\n\nRemplacer par le nom de votre bucket.\n\n2\n\nT√©l√©charger le fichier Parquet mis √† dispositoin\n\n\nPour lire ceux-ci, tester les exemples de code suivants:\n1MY_BUCKET = \"mon_nom_utilisateur_sspcloud\"\nCHEMIN_FICHIER = \"ensae-reproductibilite/data/example/rp.parquet\"\n\n1\n\nRemplacer ici par la valeur appropri√©e\n\n\n\nAvec Pandas et s3fsAvec Pyarrow et s3fsAvec DuckDB\n\n\nimport s3fs\nimport pandas as pd\n\nfs = s3fs.S3FileSystem(client_kwargs={\"endpoint_url\": \"https://minio.lab.sspcloud.fr\"})\n\ndf = pd.read_parquet(f\"s3://{MY_BUCKET}/{CHEMIN_FICHIER}\", filesystem=fs)\n\ndf\n\n\nimport pyarrow as pa\nimport pyarrow.parquet as pq\n\ns3 = pa.fs.S3FileSystem(endpoint_override =\"https://minio.lab.sspcloud.fr\")\n\ndf = pq.read_table(f\"{MY_BUCKET}/{CHEMIN_FICHIER}\", filesystem=s3)\n\ndf\n\n\nimport os\nimport duckdb\n\ncon = duckdb.connect(database=\":memory:\")\n\ncon.execute(\n    f\"\"\"\nCREATE SECRET secret (\n    TYPE S3,\n    KEY_ID '{os.environ[\"AWS_ACCESS_KEY_ID\"]}',\n    SECRET '{os.environ[\"AWS_SECRET_ACCESS_KEY\"]}',\n    ENDPOINT 'minio.lab.sspcloud.fr',\n    SESSION_TOKEN '{os.environ[\"AWS_SESSION_TOKEN\"]}',\n    REGION 'us-east-1',\n    URL_STYLE 'path',\n    SCOPE 's3://{MY_BUCKET}/'\n);\n\"\"\"\n)\n\nquery_definition = f\"SELECT * FROM read_parquet('s3://{MY_BUCKET}/{CHEMIN_FICHIER}')\"\ndf = con.sql(query_definition)\n\ndf\n\n\n\nPour aller plus loin sur le format Parquet, notamment d√©couvrir comment importer des donn√©es partitionn√©es, vous pouvez traduire en Python les exemples issus de la formation aux bonnes pratiques avec R de l‚ÄôInsee.\n\n\n\n\n\n\n\n\nApplication 8c: privil√©gier le format Parquet dans notre cha√Æne\n\n\n\nDans main.py, remplacer le format csv initialement pr√©vu par un format parquet:\ndata_train_path = os.environ.get(\"train_path\", \"data/derived/train.parquet\")\ndata_test_path = os.environ.get(\"test_path\", \"data/derived/test.parquet\")\nEt modifier l‚Äô√©criture des donn√©es pour utiliser to_parquet plut√¥t que to_csv pour √©crire les fichiers interm√©diaires:\n\n\nmain.py\n\npd.concat([X_train, y_train], axis = 1).to_parquet(data_train_path)\npd.concat([X_test, y_test], axis = 1).to_parquet(data_test_path)\n\n\n\n\n\n\n\n\n\nApplication 8d: partage de donn√©es sur le syst√®me de stockage S3\n\n\n\nPar d√©faut, le contenu de votre bucket est priv√©, seul vous y avez acc√®s. Pour pouvoir lire votre donn√©e, vos applications externes devront utiliser des jetons vous identifiant. Ici, comme nous utilisons une donn√©e publique, vous pouvez rendre accessible celle-ci √† tous en lecture. Dans le jargon S3, cela signifie donner un acc√®s anonyme √† votre donn√©e.\nLe mod√®le de commande √† utiliser dans le terminal est le suivant:\n\n\nterminal\n\n1BUCKET_PERSONNEL=\"nom_utilisateur_sspcloud\"\n\nmc anonymous set download s3/${BUCKET_PERSONNEL}/ensae-reproductibilite/data/raw/\n\n\n1\n\nRemplacer par le nom de votre bucket.\n\n\nLes URL de t√©l√©chargement seront de la forme https://minio.lab.sspcloud.fr/&lt;BUCKET_PERSONNEL&gt;/ensae-reproductibilite/data/raw/data.csv\n\nRemplacer la d√©finition de data_path pour utiliser, par d√©faut, directement l‚ÄôURL dans l‚Äôimport. Modifier, si cela est pertinent, aussi votre fichier .env.\n\n1URL_RAW = \"\"\ndata_path = os.environ.get(\"data_path\", URL_RAW)\n\n1\n\nModifier avec URL_RAW un lien de la forme \"https://minio.lab.sspcloud.fr/${BUCKET_PERSONNEL}/ensae-reproductibilite/data/raw/data.csv\" (ne laissez pas ${BUCKET_PERSONNEL}, remplacez par la vraie valeur!).\n\n\n\nAjouter le dossier data/ au .gitignore ainsi que les fichiers *.parquet\nSupprimer le dossier data de votre projet et faites git rm --cached -r data\nV√©rifier le bon fonctionnement de votre application.\n\n\n\nMaintenant qu‚Äôon a arrang√© la structure de notre projet, c‚Äôest l‚Äôoccasion de supprimer le code qui n‚Äôest plus n√©cessaire au bon fonctionnement de notre projet (cela r√©duit la charge de maintenance9).\nPour vous aider, vous pouvez utiliser vulture de mani√®re it√©rative pour vous assister dans le nettoyage de votre code.\n\n\nterminal\n\npip install vulture\nvulture .\n\n\n\nExemple de sortie\n\n\n\nterminal\n\nvulture .\n\nsrc/data/import_data.py:3: unused function 'split_and_count' (60% confidence)\nsrc/pipeline/build_pipeline.py:12: unused function 'split_train_test' (60% confidence)\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli8      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli82\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli8\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-1-proposer-des-tests-unitaires-optionnel",
    "href": "chapters/application.html#√©tape-1-proposer-des-tests-unitaires-optionnel",
    "title": "Application",
    "section": "√âtape 1 : proposer des tests unitaires (optionnel)",
    "text": "√âtape 1 : proposer des tests unitaires (optionnel)\nNotre code comporte un certain nombre de fonctions g√©n√©riques. On peut vouloir tester leur usage sur des donn√©es standardis√©es, diff√©rentes de celles du Titanic.\nM√™me si la notion de tests unitaires prend plus de sens dans un package, nous pouvons proposer dans le projet des exemples d‚Äôutilisation de la fonction, ceci peut √™tre p√©dagogique.\nNous allons utiliser unittest pour effectuer des tests unitaires. Cette approche n√©cessite quelques notions de programmation orient√©e objet ou une bonne discussion avec ChatGPT.\n\n\n\n\n\n\nApplication 9: test unitaire (optionnel)\n\n\n\nDans le dossier tests/, cr√©er avec l‚Äôaide de ChatGPT ou de Copilot un test pour la fonction split_and_count.\n\nEffectuer le test unitaire en ligne de commande avec unittest (python -m unittest tests/test_split.py). Corriger le test unitaire en cas d‚Äôerreur.\nSi le temps le permet, proposer des variantes ou d‚Äôautres tests.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli9      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli92\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli9\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \n\n\n\n\n\n\nNote\n\n\n\nLorsqu‚Äôon effectue des tests unitaires, on cherche g√©n√©ralement √† tester le plus de lignes possibles de son code. On parle de taux de couverture (coverage rate) pour d√©signer la statistique mesurant cela.\nCela peut s‚Äôeffectuer de la mani√®re suivante avec le package coverage:\n\n\nterminal\n\ncoverage run -m unittest tests/test_create_variable_title.py\ncoverage report -m\n\nName                                  Stmts   Miss  Cover   Missing\n-------------------------------------------------------------------\nsrc/features/build_features.py           34     21    38%   35-36, 48-58, 71-74, 85-89, 99-101, 111-113\ntests/test_create_variable_title.py      21      1    95%   54\n-------------------------------------------------------------------\nTOTAL                                    55     22    60%\nLe taux de couverture est souvent mis en avant par les gros projets comme indicateur de leur qualit√©. Il existe d‚Äôailleurs des badges Github d√©di√©s."
  },
  {
    "objectID": "chapters/application.html#√©tape-2-transformer-son-projet-en-package-optionnel",
    "href": "chapters/application.html#√©tape-2-transformer-son-projet-en-package-optionnel",
    "title": "Application",
    "section": "√âtape 2 : transformer son projet en package (optionnel)",
    "text": "√âtape 2 : transformer son projet en package (optionnel)\nNotre projet est modulaire, ce qui le rend assez simple √† transformer en package, en s‚Äôinspirant de la structure du cookiecutter adapt√©, issu de cet ouvrage.\nOn va cr√©er un package nomm√© titanicml qui encapsule tout notre code et qui sera appel√© par notre script main.py. La structure attendue est la suivante:\n\n\nStructure vis√©e\n\nensae-reproductibilite-application\n‚îú‚îÄ‚îÄ docs                                    ‚îê\n‚îÇ   ‚îú‚îÄ‚îÄ main.py                             ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ notebooks                           ‚îÇ Package documentation and examples\n‚îÇ       ‚îî‚îÄ‚îÄ titanic.ipynb                   ‚îÇ\n‚îú‚îÄ‚îÄ configuration                           ‚îê Configuration (pas √† partager avec Git)\n‚îÇ   ‚îî‚îÄ‚îÄ config.yaml                         ‚îò\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ pyproject.toml                          ‚îê\n‚îú‚îÄ‚îÄ requirements.txt                        ‚îÇ\n‚îú‚îÄ‚îÄ titanicml                               ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                         ‚îÇ Package source code, metadata\n‚îÇ   ‚îú‚îÄ‚îÄ data                                ‚îÇ and build instructions\n‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py                  ‚îÇ\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py   ‚îÇ\n‚îÇ   ‚îú‚îÄ‚îÄ features                            ‚îÇ\n‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py               ‚îÇ\n‚îÇ   ‚îî‚îÄ‚îÄ models                              ‚îÇ\n‚îÇ       ‚îî‚îÄ‚îÄ train_evaluate.py               ‚îò\n‚îî‚îÄ‚îÄ tests                                   ‚îê\n    ‚îî‚îÄ‚îÄ test_create_variable_title.py       ‚îò Package tests\n\n\n\nRappel: structure actuelle\n\nensae-reproductibilite-application\n‚îú‚îÄ‚îÄ notebooks\n‚îÇ   ‚îî‚îÄ‚îÄ titanic.ipynb\n‚îú‚îÄ‚îÄ configuration\n‚îÇ   ‚îî‚îÄ‚îÄ config.yaml\n‚îú‚îÄ‚îÄ main.py\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ requirements.txt\n‚îî‚îÄ‚îÄ src\n    ‚îú‚îÄ‚îÄ data\n    ‚îÇ   ‚îú‚îÄ‚îÄ import_data.py\n    ‚îÇ   ‚îî‚îÄ‚îÄ test_create_variable_title.py\n    ‚îú‚îÄ‚îÄ features\n    ‚îÇ   ‚îî‚îÄ‚îÄ build_features.py\n    ‚îî‚îÄ‚îÄ models\n        ‚îî‚îÄ‚îÄ train_evaluate.py\n\nIl existe plusieurs frameworks pour construire un package. Nous allons privil√©gier Poetry √† Setuptools.\n\n\n\n\n\n\nNote\n\n\n\nPour cr√©er la structure minimale d‚Äôun package, le plus simple est d‚Äôutiliser le cookiecutter adapt√©, issu de cet ouvrage.\nComme on a d√©j√† une structure tr√®s modulaire, on va plut√¥t recr√©er cette structure dans notre projet d√©j√† existant. En fait, il ne manque qu‚Äôun fichier essentiel, le principal distinguant un projet classique d‚Äôun package : pyproject.toml.\n\n\nterminal\n\ncookiecutter https://github.com/py-pkgs/py-pkgs-cookiecutter.git\n\n\n\nD√©rouler pour voir les choix possibles\n\nauthor_name [Monty Python]: Daffy Duck\npackage_name [mypkg]: titanicml\npackage_short_description []: Impressive Titanic survival analysis\npackage_version [0.1.0]:\npython_version [3.9]:\nSelect open_source_license:\n1 - MIT\n2 - Apache License 2.0\n3 - GNU General Public License v3.0\n4 - Creative Commons Attribution 4.0\n5 - BSD 3-Clause\n6 - Proprietary\n7 - None\nChoose from 1, 2, 3, 4, 5, 6 [1]:\nSelect include_github_actions:\n1 - no\n2 - ci\n3 - ci+cd\nChoose from 1, 2, 3 [1]:\n\n\n\n\n\n\n\n\n\nApplication 10: packagisation (optionnel)\n\n\n\n\nRenommer le dossier titanicml pour respecter la nouvelle arborescence ;\nCr√©er un fichier pyproject.toml sur cette base ;\n\n#| code-summary: \"pyproject.toml\"\n#| filename: \"pyproject.toml\"\n[tool.poetry]\nname = \"titanicml\"\nversion = \"0.0.1\"\ndescription = \"Awesome Machine Learning project\"\nauthors = [\"Daffy Duck &lt;daffy.duck@fauxmail.fr&gt;\", \"Mickey Mouse\"]\nlicense = \"MIT\"\nreadme = \"README.md\"\n\n[build-system]\nrequires = [\"poetry-core\"]\nbuild-backend = \"poetry.core.masonry.api\"\n\n[tool.pytest.ini_options]\nlog_cli = true\nlog_cli_level = \"WARNING\"\nlog_cli_format = \"%(asctime)s [%(levelname)8s] %(message)s (%(filename)s:%(lineno)s)\"\nlog_cli_date_format = \"%Y-%m-%d %H:%M:%S\"\n\nCr√©er le dossier docs et mettre les fichiers indiqu√©s dedans\nDans titanicml/, cr√©er un fichier __init__.py10\n\n#| code-summary: \"__init__.py\"\n#| filename: \"__init__.py\"\nfrom .data.import_data import (\n    split_and_count\n)\nfrom .pipeline.build_pipeline import (\n    split_train_test,\n    create_pipeline\n)\nfrom .models.train_evaluate import (\n    evaluate_model\n)\n__all__ = [\n    \"split_and_count\",\n    \"split_train_test\",\n    \"create_pipeline\",\n    \"evaluate_model\"\n]\n\nInstaller le package en local avec pip install -e .\nModifier le contenu de docs/main.py pour importer les fonctions de notre package titanicml et tester en ligne de commande notre fichier main.py\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli10      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli102\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli10\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#anaconda",
    "href": "chapters/application.html#anaconda",
    "title": "Application",
    "section": "√âtape 1 : un environnement pour rendre le projet portable",
    "text": "√âtape 1 : un environnement pour rendre le projet portable\nPour qu‚Äôun projet soit portable, il doit remplir deux conditions:\n\nNe pas n√©cessiter de d√©pendance qui ne soient pas renseign√©es quelque part ;\nNe pas proposer des d√©pendances inutiles, qui ne sont pas utilis√©es dans le cadre du projet.\n\nLe prochain exercice vise √† mettre ceci en oeuvre. Comme expliqu√© dans le chapitre portabilit√©, le choix du gestionnaire d‚Äôenvironnement est laiss√© libre. Il est recommand√© de privil√©gier venv si vous d√©couvrez la probl√©matique de la portabilit√©.\n\nEnvironnement virtuel venvEnvironnement condaEnvironnement virtuel via uv\n\n\nL‚Äôapproche la plus l√©g√®re est l‚Äôenvironnement virtuel. Nous avons en fait implicitement d√©j√† commenc√© √† aller vers cette direction en cr√©ant un fichier requirements.txt.\n\n\n\n\n\n\nApplication 11a: environnement virtuel venv\n\n\n\n\nEx√©cuter pip freeze en ligne de commande et observer la (tr√®s) longue liste de package\nCr√©er l‚Äôenvironnement virtuel titanic en s‚Äôinspirant de la documentation officielle11 ou du chapitre d√©di√©\nUtiliser ls pour observer et comprendre le contenu du dossier titanic/bin install√©\nLe SSPCloud, par d√©faut, fonctionne sur un environnement conda. Le d√©sactiver en faisant conda deactivate.\nActiver l‚Äôenvironnement et v√©rifier l‚Äôinstallation de Python maintenant utilis√©e par votre machine \nV√©rifier directement depuis la ligne de commande que Python ex√©cute bien une commande12 avec:\n\n\n\nterminal\n\npython -c \"print('Hello')\"\n\n\nFaire la m√™me chose mais avec import pandas as pd\nInstaller les packages √† partir du requirements.txt. Tester √† nouveau import pandas as pd pour comprendre la diff√©rence.\nEx√©cuter pip freeze et comprendre la diff√©rence avec la situation pr√©c√©dente.\nV√©rifier que le script main.py fonctionne bien. Sinon ajouter les packages manquants dans le requirements.txt et reprendre de mani√®re it√©rative √† partir de la question 7.\nAjouter le dossier titanic/ au .gitignore pour ne pas ajouter ce dossier √† Git.\n\n\n\nAide pour la question 4\n\nApr√®s l‚Äôactivation, vous pouvez v√©rifier quel python est utilis√© de cette mani√®re\n\n\nterminal\n\nwhich python\n\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli11a      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli11a2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli11a\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \n\n\nLes environnements conda sont plus lourds √† mettre en oeuvre que les environnements virtuels mais peuvent permettre un contr√¥le plus formel des d√©pendances.\n\n\n\n\n\n\nApplication 11b: environnement conda\n\n\n\n\nEx√©cuter conda env export en ligne de commande et observer la (tr√®s) longue liste de package\nCr√©er un environnement titanic avec conda create\nActiver l‚Äôenvironnement et v√©rifier l‚Äôinstallation de Python maintenant utilis√©e par votre machine \nV√©rifier directement depuis la ligne de commande que Python ex√©cute bien une commande13 avec:\n\n\n\nterminal\n\npython -c \"print('Hello')\"\n\n\nFaire la m√™me chose mais avec import pandas as pd\nInstaller les packages qu‚Äôon avait list√© dans le requirements.txt pr√©c√©demment. Ne pas faire un pip install -r requirements.txt afin de privil√©gier conda install\nEx√©cuter √† nouveau conda env export et comprendre la diff√©rence avec la situation pr√©c√©dente14.\nV√©rifier que le script main.py fonctionne bien. Sinon installer les packages manquants et reprndre de mani√®re it√©rative √† partir de la question 7.\nQuand main.py fonctionne, faire conda env export &gt; environment.yml pour figer l‚Äôenvironnement de travail.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli11b      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli11b2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli11b\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \n\n\nuv est le new kid in the game pour g√©rer les environnements virtuels avec Python.\n\n\n\n\n\n\nApplication 11c: environnement virtuel venv (via uv)\n\n\n\n\nApr√®s avoir install√© uv, ex√©cuter uv init . et supprimer le fichier hello.py g√©n√©r√©. Ouvrir le pyproject.toml et observer sa structure.\nEx√©cuter uv pip freeze en ligne de commande et observer la (tr√®s) longue liste de package\nCr√©er un environnement virtuel titanic par le biais d‚Äôuv (documentation) sous le nom titanic\nUtiliser ls pour observer et comprendre le contenu du dossier titanic/bin install√©\nActiver l‚Äôenvironnement et v√©rifier l‚Äôinstallation de Python maintenant utilis√©e par votre machine \nV√©rifier directement depuis la ligne de commande que Python ex√©cute bien une commande15 avec:\n\n\n\nterminal\n\npython -c \"print('Hello')\"\n\n\nFaire la m√™me chose mais avec import pandas as pd. Maintenant, essayer uv run main.py en ligne de commande: comprenez-vous ce qu‚Äôil se passe ?\nInstaller de mani√®re it√©rative les packages √† partir d‚Äôuv add (documentation) et en testant avec uv run main.py: avez-vous remarqu√© la vitesse √† laquelle cela a √©t√© quand vous avez fait uv add pandas ?\nObserver votre pyproject.toml. Regarder le lockfile uv.lock. G√©n√©rer automatiquement le requirements.txt en faisant pip compile et regarder celui-ci.\nAjouter le dossier titanic/ au .gitignore pour ne pas ajouter ce dossier √† Git.\n\n\n\nAide pour la question 5\n\nApr√®s l‚Äôactivation, vous pouvez v√©rifier quel python est utilis√© de cette mani√®re\n\n\nterminal\n\nwhich python\n\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli11c      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli11c2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli11c\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#shell",
    "href": "chapters/application.html#shell",
    "title": "Application",
    "section": "√âtape 2: construire l‚Äôenvironnement de notre application via un script shell",
    "text": "√âtape 2: construire l‚Äôenvironnement de notre application via un script shell\nLes environnements virtuels permettent de mieux sp√©cifier les d√©pendances de notre projet, mais ne permettent pas de garantir une portabilit√© optimale. Pour cela, il faut recourir √† la technologie des conteneurs. L‚Äôid√©e est de construire une machine, en partant d‚Äôune base quasi-vierge, qui permette de construire √©tape par √©tape l‚Äôenvironnement n√©cessaire au bon fonctionnement de notre projet. C‚Äôest le principe des conteneurs Docker .\nLeur m√©thode de construction √©tant un peu difficile √† prendre en main au d√©but, nous allons passer par une √©tape interm√©diaire afin de bien comprendre le processus de production.\n\nNous allons d‚Äôabord cr√©er un script shell, c‚Äôest √† dire une suite de commandes Linux permettant de construire l‚Äôenvironnement √† partir d‚Äôune machine vierge ;\nNous transformerons celui-ci en Dockerfile dans un deuxi√®me temps. C‚Äôest l‚Äôobjet de l‚Äô√©tape suivante.\n\n\nEnvironnement virtuel venvEnvironnement conda\n\n\n\n\n\n\n\n\nApplication 12a : cr√©er un fichier d‚Äôinstallation de A √† Z\n\n\n\n\nCr√©er un service ubuntu sur le SSP Cloud\nOuvrir un terminal\nCloner le d√©p√¥t\nSe placer dans le dossier du projet avec cd\nSe placer au niveau du checkpoint 11a avec git checkout appli11a\nVia l‚Äôexplorateur de fichiers, cr√©er le fichier install.sh √† la racine du projet avec le contenu suivant:\n\n\n\nScript √† cr√©er sous le nom install.sh\n\n\n\ninstall.sh\n\n#!/bin/bash\n\n# Install Python\napt-get -y update\napt-get install -y python3-pip python3-venv\n\n# Create empty virtual environment\npython3 -m venv titanic\nsource titanic/bin/activate\n\n# Install project dependencies\npip install -r requirements.txt\n\n\n\nChanger les permissions sur le script pour le rendre ex√©cutable\n\n\n\nterminal\n\nchmod +x install.sh\n\n\nEx√©cuter le script depuis la ligne de commande avec des droits de super-utilisateur (n√©cessaires pour installer des packages via apt)\n\n\n\nterminal\n\nsudo ./install.sh\n\n\nV√©rifier que le script main.py fonctionne correctement dans l‚Äôenvironnement virtuel cr√©√©\n\n\n\nterminal\n\nsource titanic/bin/activate\npython3 main.py\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli12a      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli12a2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli12a\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \n\n\n\n\n\n\n\n\nApplication 12b : cr√©er un fichier d‚Äôinstallation de A √† Z\n\n\n\n\nCr√©er un service ubuntu sur le SSP Cloud\nOuvrir un terminal\nCloner le d√©p√¥t\nSe placer dans le dossier du projet avec cd\nSe placer au niveau du checkpoint 11b avec git checkout appli11b\nVia l‚Äôexplorateur de fichiers, cr√©er le fichier install.sh √† la racine du projet avec le contenu suivant:\n\n\n\nScript √† cr√©er sous le nom install.sh\n\n\n\ninstall.sh\n\napt-get -y update && apt-get -y install wget\n\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \\\n    bash Miniconda3-latest-Linux-x86_64.sh -b -p /miniconda && \\\n    rm -f Miniconda3-latest-Linux-x86_64.sh\n\nPATH=\"/miniconda/bin:${PATH}\"\n\n# Create environment\nconda create -n titanic pandas PyYAML scikit-learn -c conda-forge\nconda activate titanic\n\nPATH=\"/miniconda/envs/titanic/bin:${PATH}\"\n\npython main.py\n\n\n\nChanger les permissions sur le script pour le rendre ex√©cutable\n\n\n\nterminal\n\nchmod +x install.sh\n\n\nEx√©cuter le script depuis la ligne de commande avec des droits de super-utilisateur (n√©cessaires pour installer des packages via apt)\n\n\n\nterminal\n\nsudo ./install.sh\n\n\nV√©rifier que le script main.py fonctionne correctement dans l‚Äôenvironnement virtuel cr√©√©\n\n\n\nterminal\n\nconda activate titanic\npython3 main.py\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli12b      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli12b2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli12b\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#docker",
    "href": "chapters/application.html#docker",
    "title": "Application",
    "section": "√âtape 3: conteneuriser l‚Äôapplication avec Docker",
    "text": "√âtape 3: conteneuriser l‚Äôapplication avec Docker\n\n\n\n\n\n\nNote\n\n\n\nCette application n√©cessite l‚Äôacc√®s √† une version interactive de Docker. Il n‚Äôy a pas beaucoup d‚Äôinstances en ligne disponibles.\nNous proposons deux solutions:\n\nInstaller Docker sur sa machine ;\nSe rendre sur l‚Äôenvironnement bac √† sable Play with Docker\n\nSinon, elle peut √™tre r√©alis√©e en essai-erreur par le biais des services d‚Äôint√©gration continue de Github  ou Gitlab . N√©anmoins, nous pr√©senterons l‚Äôutilisation de ces services plus tard, dans la prochaine partie.\n\n\nMaintenant qu‚Äôon sait que ce script pr√©paratoire fonctionne, on va le transformer en Dockerfile pour anticiper la mise en production. Comme la syntaxe Docker est l√©g√®rement diff√©rente de la syntaxe Linux classique (voir le chapitre portabilit√©), il va √™tre n√©cessaire de changer quelques instructions mais ceci sera tr√®s l√©ger.\nOn va tester le Dockerfile dans un environnement bac √† sable pour ensuite pouvoir plus facilement automatiser la construction de l‚Äôimage Docker.\n\n\n\n\n\n\nApplication 13: cr√©ation de l‚Äôimage Docker\n\n\n\nSe placer dans un environnement avec Docker, par exemple Play with Docker\n\nCr√©ation du Dockerfile\n\nDans le terminal Linux, cloner votre d√©p√¥t Github\nRepartir de la derni√®re version √† disposition. Par exemple, si vous avez privil√©gi√© l‚Äôenvironnement virtuel venv, ce sera:\n\n\n\nterminal\n\n1git stash\ngit checkout appli12a\n\n\n1\n\nPour annuler les modifications depuis le dernier commit\n\n\n\nCr√©er via la ligne de commande un fichier texte vierge nomm√© Dockerfile (la majuscule au d√©but du mot est importante)\n\n\n\nCommande pour cr√©er un Dockerfile vierge depuis la ligne de commande\n\n\n\nterminal\n\ntouch Dockerfile\n\n\n\nOuvrir ce fichier via un √©diteur de texte et copier le contenu suivant dedans:\n\n\n\nPremier Dockerfile\n\n\n\nterminal\n\nFROM ubuntu:22.04\n\n# Install Python\nRUN apt-get -y update && \\\n    apt-get install -y python3-pip\n\n# Install project dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCMD [\"python3\", \"main.py\"]\n\n\n\n\nConstruire (build) l‚Äôimage\n\nUtiliser docker build pour cr√©er une image avec le tag my-python-app\n\n\n\nterminal\n\ndocker build . -t my-python-app\n\n\nV√©rifier les images dont vous disposez. Vous devriez avoir un r√©sultat proche de celui-ci :\n\n\n\nterminal\n\ndocker images\n\nREPOSITORY      TAG       IMAGE ID       CREATED              SIZE\nmy-python-app   latest    188957e16594   About a minute ago   879MB\n\n\nTester l‚Äôimage: d√©couverte du cache\nL‚Äô√©tape de build a fonctionn√©: une image a √©t√© construite.\nMais fait-elle effectivement ce que l‚Äôon attend d‚Äôelle ?\nPour le savoir, il faut passer √† l‚Äô√©tape suivante, l‚Äô√©tape de run.\n\n\nterminal\n\ndocker run -it my-python-app\n\npython3: can't open file '/~/titanic/main.py': [Errno 2] No such file or directory\nLe message d‚Äôerreur est clair : Docker ne sait pas o√π trouver le fichier main.py. D‚Äôailleurs, il ne connait pas non plus les autres fichiers de notre application qui sont n√©cessaires pour faire tourner le code, par exemple le dossier src.\n\nAvant l‚Äô√©tape CMD, copier les fichiers n√©cessaires sur l‚Äôimage afin que l‚Äôapplication dispose de tous les √©l√©ments n√©cessaires pour √™tre en mesure de fonctionner.\n\n\n\nNouveau Dockerfile\n\n\n\nterminal\n\nFROM ubuntu:22.04\n\n# Install Python\nRUN apt-get -y update && \\\n    apt-get install -y python3-pip\n\n# Install project dependencies\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY main.py .\nCOPY src ./src\nCMD [\"python3\", \"main.py\"]\n\n\n\nRefaire tourner l‚Äô√©tape de build\nRefaire tourner l‚Äô√©tape de run. A ce stade, la matrice de confusion doit fonctionner üéâ. Vous avez cr√©√© votre premi√®re application reproductible !\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIci, le cache permet d‚Äô√©conomiser beaucoup de temps. Par besoin de refaire tourner toutes les √©tapes, Docker agit de mani√®re intelligente en faisant tourner uniquement les √©tapes qui ont chang√©.\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli13      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli132\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli13\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-1-mise-en-place-de-tests-automatis√©s",
    "href": "chapters/application.html#√©tape-1-mise-en-place-de-tests-automatis√©s",
    "title": "Application",
    "section": "√âtape 1: mise en place de tests automatis√©s",
    "text": "√âtape 1: mise en place de tests automatis√©s\nAvant d‚Äôessayer de mettre en oeuvre la cr√©ation de notre image Docker de mani√®re automatis√©e, nous allons pr√©senter la logique de l‚Äôint√©gration continue en testant de mani√®re automatis√©e notre script main.py.\nPour cela, nous allons partir de la structure propos√©e dans l‚Äôaction officielle. La documentation associ√©e est ici. Des √©l√©ments succincts de pr√©sentation de la logique d√©clarative des actions Github sont disponibles dans le chapitre sur la mise en production. N√©anmoins, la meilleure √©cole pour comprendre le fonctionnement de celles-ci est de parcourir la documentation du service et d‚Äôobserver les actions Github mises en oeuvre par vos projets favoris, celles-ci seront fort instructives !\n\n\n\n\n\n\nApplication 14: premier script d‚Äôint√©gration continue\n\n\n\nA partir de l‚Äôexemple pr√©sent dans la documentation officielle de Github , on a d√©j√† une base de d√©part qui peut √™tre modifi√©e. Les questions suivantes permettront d‚Äôautomatiser les tests et le diagnostic qualit√© de notre code16\n\nCr√©er un fichier .github/workflows/test.yaml avec le contenu de l‚Äôexemple de la documentation\nAvec l‚Äôaide de la documentation, introduire une √©tape d‚Äôinstallation des d√©pendances. Utiliser le fichier requirements.txt pour installer les d√©pendances.\nUtiliser pylint pour v√©rifier la qualit√© du code. Ajouter l‚Äôargument --fail-under=6 pour renvoyer une erreur en cas de note trop basse17\nUtiliser une √©tape appelant notre application en ligne de commande (python main.py) pour tester que la matrice de confusion s‚Äôaffiche bien.\nCr√©er un secret stockant une valeur du JETON_API. Ne le faites pas commencer par un ‚Äú$‚Äù comme √ßa vous pourrez regarder la log ult√©rieurement\nAller voir votre test automatis√© dans l‚Äôonglet Actions de votre d√©p√¥t sur Github\n(optionnel): Cr√©er un artefact √† partir du fichier de log que vous cr√©ez dans main.py\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli14      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli142\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli14\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nMaintenant, nous pouvons observer que l‚Äôonglet Actions s‚Äôest enrichi. Chaque commit va entra√Æner une s√©rie d‚Äôactions automatis√©es.\nSi l‚Äôune des √©tapes √©choue, ou si la note de notre projet est mauvaise, nous aurons une croix rouge (et nous recevrons un mail). On pourra ainsi d√©tecter, en d√©veloppant son projet, les moments o√π on d√©grade la qualit√© du script afin de la r√©tablir imm√©diatemment."
  },
  {
    "objectID": "chapters/application.html#√©tape-2-automatisation-de-la-livraison-de-limage-docker",
    "href": "chapters/application.html#√©tape-2-automatisation-de-la-livraison-de-limage-docker",
    "title": "Application",
    "section": "√âtape 2: Automatisation de la livraison de l‚Äôimage Docker",
    "text": "√âtape 2: Automatisation de la livraison de l‚Äôimage Docker\nMaintenant, nous allons automatiser la mise √† disposition de notre image sur DockerHub (le lieu de partage des images Docker). Cela facilitera sa r√©utilisation mais aussi des valorisations ult√©rieures.\nL√† encore, nous allons utiliser une s√©rie d‚Äôactions pr√©-configur√©es.\nPour que Github puisse s‚Äôauthentifier aupr√®s de DockerHub, il va falloir d‚Äôabord interfacer les deux plateformes. Pour cela, nous allons utiliser un jeton (token) DockerHub que nous allons mettre dans un espace s√©curis√© associ√© √† votre d√©p√¥t Github.\n\n\n\n\n\n\nApplication 15a: configuration\n\n\n\n\nSe rendre sur https://hub.docker.com/ et cr√©er un compte. Il est recommand√© d‚Äôassocier ce compte √† votre compte Github.\nCr√©er un d√©p√¥t public application\nAller dans les param√®tres de votre compte et cliquer, √† gauche, sur Security\nCr√©er un jeton personnel d‚Äôacc√®s, ne fermez pas l‚Äôonglet en question, vous ne pouvez voir sa valeur qu‚Äôune fois.\nDans le d√©p√¥t Github de votre projet, cliquer sur l‚Äôonglet Settings et cliquer, √† gauche, sur Secrets and variables puis dans le menu d√©roulant en dessous sur Actions. Sur la page qui s‚Äôaffiche, aller dans la section Repository secrets\nCr√©er un jeton DOCKERHUB_TOKEN √† partir du jeton que vous aviez cr√©√© sur Dockerhub. Valider\nCr√©er un deuxi√®me secret nomm√© DOCKERHUB_USERNAME ayant comme valeur le nom d‚Äôutilisateur que vous avez cr√©√© sur Dockerhub\n\n\n\nEtape optionnelle suppl√©mentaire si on met en production un site web\n\n\nDans le d√©p√¥t Github de votre projet, cliquer sur l‚Äôonglet Settings et cliquer, √† gauche, sur Actions. Donner les droits d‚Äô√©criture √† vos actions sur le d√©p√¥t du projet (ce sera n√©cessaire pour Github Pages)\n\n\n\n\n\nA ce stade, nous avons donn√© les moyens √† Github de s‚Äôauthentifier avec notre identit√© sur Dockerhub. Il nous reste √† mettre en oeuvre l‚Äôaction en s‚Äôinspirant de la documentation officielle. On ne va modifier que trois √©l√©ments dans ce fichier. Effectuer les actions suivantes:\n\n\n\n\n\n\nApplication 15b: automatisation de l‚Äôimage Docker\n\n\n\n\nEn s‚Äôinspirant de ce template, cr√©er le fichier .github/workflows/prod.yml qui va build et push l‚Äôimage sur le DockerHub. Il va √™tre n√©cessaire de changer l√©g√®rement ce mod√®le :\n\nRetirer la condition restrictive sur les commits pour lesquels sont lanc√©s cette automatisation. Pour cela, remplacer le contenu de on de sorte √† avoir\n\non:\n  push:\n    branches:\n      - main\n      - dev\n\nChanger le tag √† la fin pour mettre username/application:latest o√π username est le nom d‚Äôutilisateur sur DockerHub;\nOptionnel: changer le nom de l‚Äôaction\n\nFaire un commit et un push de ces fichiers\n\nComme on est fier de notre travail, on va afficher √ßa avec un badge sur le README (partie optionnelle).\n\nSe rendre dans l‚Äôonglet Actions et cliquer sur une des actions list√©es.\nEn haut √† droite, cliquer sur ...\nS√©lectionner Create status badge\nR√©cup√©rer le code Markdown propos√©\nCopier dans votre README.md le code markdown propos√©\n\n\n\nCr√©er le badge\n\n\n\n\n\nMaintenant, il nous reste √† tester notre application dans l‚Äôespace bac √† sable ou en local, si Docker est install√©.\n\n\n\n\n\n\nApplication 15b (partie optionnelle): Tester l‚Äôapplication\n\n\n\n\nSe rendre sur l‚Äôenvironnement bac √† sable Play with Docker ou dans votre environnement Docker de pr√©dilection.\nR√©cup√©rer et lancer l‚Äôimage :\n\n\n\nterminal\n\ndocker run -it username/application:latest\n\nüéâ La matrice de confusion doit s‚Äôafficher ! Vous avez grandement facilit√© la r√©utilisation de votre image.\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli15      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli152\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli15\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-1-d√©velopper-une-api-en-local",
    "href": "chapters/application.html#√©tape-1-d√©velopper-une-api-en-local",
    "title": "Application",
    "section": "√âtape 1: d√©velopper une API en local",
    "text": "√âtape 1: d√©velopper une API en local\nLe premier livrable devenu classique dans un projet impliquant du machine learning est la mise √† disposition d‚Äôun mod√®le par le biais d‚Äôune API (voir chapitre sur la mise en production). Le framework FastAPI va permettre de rapidement transformer notre application Python en une API fonctionnelle.\n\n\n\n\n\n\nApplication 16: Mise √† disposition sous forme d‚ÄôAPI locale\n\n\n\n\nInstaller fastAPI et uvicorn puis les ajouter au requirements.txt\nRenommer le fichier main.py en train.py.\nDans ce script, ajouter une sauvegarde du mod√®le apr√®s l‚Äôavoir entra√Æn√©, sous le format joblib.\nFaire tourner\n\n\n\nterminal\n\npython train.py\n\npour enregistrer en local votre mod√®le de production.\n\nModifier les appels √† main.py dans votre Dockerfile et vos actions Github sous peine d‚Äôessuyer des √©checs lors de vos actions Github apr√®s le prochain push.\nAjouter model.joblib au .gitignore car Git n‚Äôest pas fait pour ce type de fichiers.\n\nNous allons maintenant passer au d√©veloppement de l‚ÄôAPI. Comme d√©couvrir FastAPI n‚Äôest pas l‚Äôobjet de cet enseignement, nous donnons directement le mod√®le pour cr√©er l‚ÄôAPI. Si vous d√©sirez tester de vous-m√™mes, vous pouvez cr√©er votre fichier sans vous r√©f√©rer √† l‚Äôexemple.\n\nCr√©er le fichier app/api.py permettant d‚Äôinitialiser l‚ÄôAPI:\n\n\n\nFichier app/api.py\n\n\n\napp/api.py\n\n\"\"\"A simple API to expose our trained RandomForest model for Tutanic survival.\"\"\"\nfrom fastapi import FastAPI\nfrom joblib import load\n\nimport pandas as pd\n\nmodel = load('model.joblib')\n\napp = FastAPI(\n    title=\"Pr√©diction de survie sur le Titanic\",\n    description=\n    \"Application de pr√©diction de survie sur le Titanic üö¢ &lt;br&gt;Une version par API pour faciliter la r√©utilisation du mod√®le üöÄ\" +\\\n        \"&lt;br&gt;&lt;br&gt;&lt;img src=\\\"https://media.vogue.fr/photos/5faac06d39c5194ff9752ec9/1:1/w_2404,h_2404,c_limit/076_CHL_126884.jpg\\\" width=\\\"200\\\"&gt;\"\n    )\n\n\n@app.get(\"/\", tags=[\"Welcome\"])\ndef show_welcome_page():\n    \"\"\"\n    Show welcome page with model name and version.\n    \"\"\"\n\n    return {\n        \"Message\": \"API de pr√©diction de survie sur le Titanic\",\n        \"Model_name\": 'Titanic ML',\n        \"Model_version\": \"0.1\",\n    }\n\n\n@app.get(\"/predict\", tags=[\"Predict\"])\nasync def predict(\n    sex: str = \"female\",\n    age: float = 29.0,\n    fare: float = 16.5,\n    embarked: str = \"S\"\n) -&gt; str:\n    \"\"\"\n    \"\"\"\n\n    df = pd.DataFrame(\n        {\n            \"Sex\": [sex],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embarked],\n        }\n    )\n\n    prediction = \"Survived üéâ\" if int(model.predict(df)) == 1 else \"Dead ‚ö∞Ô∏è\"\n\n    return prediction\n\n\n\nD√©ployer l‚ÄôAPI en local avec la commande suivante.\n\n\n\nterminal\n\nuvicorn app.api:app\n\n\nObserver l‚Äôoutput dans la console. Notre API est d√©sormais d√©ploy√©e en local, plus pr√©cis√©ment sur le localhost, un serveur web local d√©ploy√© √† l‚Äôadresse http://127.0.0.1. L‚ÄôAPI est d√©ploy√©e sur le port par d√©faut utilis√© par uvicorn, soit le port 8000.\nSans fermer le terminal pr√©c√©dent, ouvrir un nouveau terminal. Tester le bon d√©ploiement de l‚ÄôAPI en requ√™tant son endpoint. Pour cela, on envoie une simple requ√™te GET sur le endpoint via l‚Äôutilitaire curl.\n\n\n\nterminal\n\ncurl \"http://127.0.0.1:8000\"\n\n\nSi tout s‚Äôest bien pass√©, on devrait avoir r√©cup√©r√© une r√©ponse (au format JSON) affichant le message d‚Äôaccueil de notre API. Dans ce cas, on va pouvoir requ√™ter notre mod√®le via l‚ÄôAPI.\nEn vous inspirant du code qui d√©finit le endpoint /predict dans le code de l‚ÄôAPI (app/api.py), effectuer sur le m√™me mod√®le que la requ√™te pr√©c√©dente une requ√™te qui calcule la survie d‚Äôune femme de 32 ans qui aurait pay√© son billet 16 dollars et aurait embarqu√© au port S.\n\n\n\nSolution\n\n\n\nterminal\n\ncurl \"http://127.0.0.1:8000/predict?sex=female&age=32&fare=16&embarked=S\"\n\n\n\nToujours sans fermer le terminal qui d√©ploie l‚ÄôAPI, ouvrir une session Python et tester une requ√™te avec des param√®tres diff√©rents, avec la librairie requests :\n\n\n\nSolution\n\nimport requests\n\nURL = \"http://127.0.0.1:8000/predict?sex=male&age=25&fare=80&embarked=S\"\nrequests.get(URL).json()\n\n\nUne fois que l‚ÄôAPI a √©t√© test√©e, vous pouvez fermer l‚Äôapplication en effectuant CTRL+C depuis le terminal o√π elle est lanc√©e.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli16      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli162\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli16\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#√©tape-2-d√©ployer-lapi-de-mani√®re-manuelle",
    "href": "chapters/application.html#√©tape-2-d√©ployer-lapi-de-mani√®re-manuelle",
    "title": "Application",
    "section": "√âtape 2: d√©ployer l‚ÄôAPI de mani√®re manuelle",
    "text": "√âtape 2: d√©ployer l‚ÄôAPI de mani√®re manuelle\nA ce stade, nous avons d√©ploy√© l‚ÄôAPI seulement localement, dans le cadre d‚Äôun terminal qui tourne en arri√®re-plan. C‚Äôest une mise en production manuelle, pas franchement p√©renne. Ce mode de d√©ploiement est tr√®s pratique pour la phase de d√©veloppement, afin de s‚Äôassurer que l‚ÄôAPI fonctionne comme attendue. Pour p√©renniser la mise en production, on va √©liminer l‚Äôaspect artisanal de celle-ci.\nIl est temps de passer √† l‚Äô√©tape de d√©ploiement, qui permettra √† notre API d‚Äô√™tre accessible, √† tout moment, via une URL sur le web et d‚Äôavoir un serveur, en arri√®re plan, qui effectuera les op√©rations pour r√©pondre √† une requ√™te. Pour se faire, on va utiliser les possibilit√©s offertes par Kubernetes, technologie sur laquelle est bas√©e l‚Äôinfrastructure SSP Cloud.\n\n\n\n\n\n\nEt si vous n‚Äôutilisez pas le SSPCloud ? (une id√©e saugrenue mais sait-on jamais)\n\n\n\n\n\nLes exemples √† venir peuvent tr√®s bien √™tre r√©pliqu√©s sur n‚Äôimporte quel cloud provider qui propose une solution d‚Äôordonnancement type Kubernetes. Il existe √©galement des fournisseurs de services d√©di√©s, g√©n√©ralement associ√©s √† une impl√©mentation, par exemple pour Streamlit. Ces services sont pratiques si on n‚Äôa pas le choix mais il faut garder √† l‚Äôesprit qu‚Äôils peuvent constituer un mur de la production car vous ne contr√¥lez pas l‚Äôenvironnement en question, qui peut se distinguer de votre environnement de d√©veloppement.\nEt si jamais vous voulez avoir un SSPCloud dans votre entreprise c‚Äôest possible: le logiciel Onyxia sur lequel repose cette infrastructure est open source et est, d√©j√†, r√©impl√©ment√© par de nombreux acteurs. Pour b√©n√©ficier d‚Äôun accompagnement dans la cr√©ation d‚Äôune telle infrastructure, rdv sur le Slack du projet Onyxia:\n\n\n\n\n\n\n\n\n\n\nApplication 17: Dockeriser l‚ÄôAPI (int√©gration continue)\n\n\n\n\nCr√©er un script app/run.sh √† la racine du projet qui lance le script train.py puis d√©ploie localement l‚ÄôAPI. Attention, quand on se place dans le monde des conteneurs et plus g√©n√©ralement des infrastructures cloud, on ne va plus d√©ployer sur le localhost mais sur ‚Äúl‚Äôensemble des interfaces r√©seaux‚Äù. Lorsqu‚Äôon d√©ploie une application web dans un conteneur, on va donc toujours devoir sp√©cifier un host valant 0.0.0.0 (et non plus localhost ou, de mani√®re √©quivalente, http://127.0.0.1).\n\n\n\nFichier run.sh\n\n\n\napi/run.sh\n\n#/bin/bash\n\npython3 train.py\nuvicorn app.api:app --host \"0.0.0.0\"\n\n\n\nDonner au script api/run.sh des permissions d‚Äôex√©cution : chmod +x api/run.sh\nAjouter COPY app ./app pour avoir les fichiers n√©cessaires au lancement dans l‚ÄôAPI dans l‚Äôimage\nModifier COPY train.py . pour tenir compte du nouveau nom du fichier\nChanger l‚Äôinstruction CMD du Dockerfile pour ex√©cuter le script api/run.sh au lancement du conteneur (CMD [\"bash\", \"-c\", \"./app/run.sh\"])\nCommit et push les changements\nUne fois le CI termin√©, v√©rifier que le nouveau tag latest a √©t√© push√© sur le DockerHub. R√©cup√©rer la nouvelle image dans votre environnement de test de Docker et v√©rifier que l‚ÄôAPI se d√©ploie correctement.\n\n\n\nTester l‚Äôimage sur le SSP Cloud\n\nLancer dans un terminal la commande suivante pour pull l‚Äôapplication depuis le DockerHub et la d√©ployer en local :\n\n\nterminal\n\nkubectl run -it api-ml --image=votre_compte_docker_hub/application:latest\n\n\n\nSi tout se passe correctement, vous devriez observer dans la console un output similaire au d√©ploiement en local de la partie pr√©c√©dente. Cette fois, l‚Äôapplication est d√©ploy√©e √† l‚Äôadresse http://0.0.0.0:8000. On ne peut n√©anmoins pas directement l‚Äôexploiter √† ce stade : si le conteneur de l‚ÄôAPI est d√©ploy√©, il manque un ensemble de ressources Kubernetes qui permettent de d√©ployer proprement l‚ÄôAPI √† tout utilisateur. C‚Äôest l‚Äôobjet de l‚Äôapplication suivante !\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli17      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli172\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli17\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nNous avons pr√©par√© la mise √† disposition de notre API mais √† l‚Äôheure actuelle elle n‚Äôest pas accessible de mani√®re ais√©e car il est n√©cessaire de lancer manuellement une image Docker pour pouvoir y acc√©der. Ce type de travail est la sp√©cialit√© de Kubernetes que nous allons utiliser pour g√©rer la mise √† disposition de notre API.\n\n\n\n\n\n\nApplication 18: Mettre √† disposition l‚ÄôAPI (d√©ploiement manuel)\n\n\n\nCette partie n√©cessite d‚Äôavoir √† disposition une infrastructure cloud.\n\nCr√©er un dossier deployment √† la racine du projet qui va contenir les fichiers de configuration n√©cessaires pour d√©ployer sur un cluster Kubernetes\nEn vous inspirant de la documentation, y ajouter un premier fichier deployment.yaml qui va sp√©cifier la configuration du Pod √† lancer sur le cluster\n\n\n\nFichier deployment/deployment.yaml\n\n#| filename: \"deployment/deployment.yaml\"\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titanic-deployment\n  labels:\n    app: titanic\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: titanic\n  template:\n    metadata:\n      labels:\n        app: titanic\n    spec:\n      containers:\n      - name: titanic\n        image: votre_compte_docker_hub/application:latest\n        ports:\n        - containerPort: 8000\n\n\nEn vous inspirant de la documentation, y ajouter un second fichier service.yaml qui va cr√©er une ressource Service permettant de donner une identit√© fixe au Pod pr√©c√©demment cr√©√© au sein du cluster\n\n\n\nFichier deployment/service.yaml\n\n\n\ndeployment/service.yaml\n\napiVersion: v1\nkind: Service\nmetadata:\n  name: titanic-service\nspec:\n  selector:\n    app: titanic\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 8000\n\n\n\nEn vous inspirant de la documentation, y ajouter un troisi√®me fichier ingress.yaml qui va cr√©er une ressource Ingress permettant d‚Äôexposer le service via une URL en dehors du cluster\n\n\n\nFichier deployment/ingress.yaml\n\n#| filename: \"deployment/ingress.yaml\"\napiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: titanic-ingress\nspec:\n  ingressClassName: nginx\n  tls:\n  - hosts:\n    - votre_nom_d_application.lab.sspcloud.fr\n  rules:\n  - host: votre_nom_d_application.lab.sspcloud.fr\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: titanic-service\n            port:\n              number: 80\n\nMettez l‚ÄôURL auquel vous voulez exposer votre service. Sur le mod√®le de titanic.lab.sspcloud.fr (mais ne tentez pas celui-l√†, il est d√©j√† pris üòÉ)\nMettre cette m√™me URL ici aussi\n\n\n\nAppliquer ces fichiers de configuration sur le cluster : kubectl apply -f deployment/\nV√©rifier le bon d√©ploiement de l‚Äôapplication (c‚Äôest √† dire du Pod qui encapsule le conteneur) √† l‚Äôaide de la commande kubectl get pods\nSi tout a correctement fonctionn√©, vous devriez pouvoir acc√©der depuis votre navigateur √† l‚ÄôAPI √† l‚ÄôURL sp√©cifi√©e dans le fichier deployment/ingress.yaml. Par exemple https://api-titanic-test.lab.sspcloud.fr/ si vous avez mis celui-ci plus t√¥t\nExplorer le swagger de votre API √† l‚Äôadresse https://api-titanic-test.lab.sspcloud.fr/docs. Il s‚Äôagit d‚Äôune page de documentation standard √† la plupart des APIs, bien utiles pour tester des requ√™tes de mani√®re interactive.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli18      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli182\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli18\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nOn peut remarquer quelques voies d‚Äôam√©lioration de notre approche qui seront ult√©rieurement trait√©es:\n\nL‚Äôentra√Ænement du mod√®le est r√©-effectu√© √† chaque lancement d‚Äôun nouveau conteneur. On relance donc autant de fois un entra√Ænement qu‚Äôon d√©ploie de conteneurs pour r√©pondre √† nos utilisateurs. Ce sera l‚Äôobjet de la partie MLOps de fiabiliser et optimiser cette partie du pipeline.\nil est n√©cessaire de (re)lancer manuellement kubectl apply -f deployment/ √† chaque changement de notre code. Autrement dit, lors de cette application, on a am√©lior√© la fiabilit√© du lancement de notre API mais un lancement manuel est encore indispensable. Comme dans le reste de ce cours, on va essayer d‚Äô√©viter un geste manuel pouvant √™tre source d‚Äôerreur en privil√©giant l‚Äôautomatisation et l‚Äôarchivage dans des scripts. C‚Äôest l‚Äôobjet de la prochaine √©tape."
  },
  {
    "objectID": "chapters/application.html#etape-3-automatiser-le-d√©ploiement-d√©ploiement-en-continu",
    "href": "chapters/application.html#etape-3-automatiser-le-d√©ploiement-d√©ploiement-en-continu",
    "title": "Application",
    "section": "Etape 3: automatiser le d√©ploiement (d√©ploiement en continu)",
    "text": "Etape 3: automatiser le d√©ploiement (d√©ploiement en continu)\n\n\n\n\n\n\nClarification sur la branche de travail, les tags et l‚Äôimage Docker utilis√©e\n\n\n\n\n\nA partir de maintenant, il est n√©cessaire de clarifier la branche principale sur laquelle nous travaillons. Toutes les prochaines applications supposeront que vous travaillez depuis la branche main. Si vous avez chang√© de branche, vous pouvez fusionner celle-ci √† main.\nSi vous avez utilis√© un tag pour sauter une ou plusieurs √©tapes, il va √™tre n√©cessaire de se placer sur une branche car vous √™tes en head detached. Si vous avez utilis√© les scripts automatis√©s de checkpoint, cette gymnastique a √©t√© faite pour vous.\nLes prochaines applications vont √©galement n√©cessiter d‚Äôutiliser une image Docker. Si vous avez suivi de mani√®re lin√©aire cette application, votre image Docker devrait exister depuis l‚Äôapplication 15 si vous avez push√© votre d√©p√¥t √† ce moment l√†.\nN√©anmoins, si vous n‚Äôavez pas fait cette application, vous pouvez utiliser le checkpoint de l‚Äôapplication 18 et faire un git push origin main --force (√† ne pas reproduire sur vos projets!) qui devrait d√©clencher les op√©rations c√¥t√© Github pour construire et livrer votre image Docker. Cela n√©cessite quelques op√©rations de votre c√¥t√©, notamment la cr√©ation d‚Äôun token Dockerhub √† renseigner en secret Github. Pour vous refra√Æchir la m√©moire sur le sujet, vous pouvez retourner consulter l‚Äôapplication 15.\n\n\n\nQu‚Äôest-ce qui peut d√©clencher une √©volution n√©cessitant de mettre √† jour l‚Äôensemble de notre processus de production ?\nRegardons √† nouveau notre pipeline:\n\nLes inputs de notre pipeline sont donc:\n\nLa configuration. Ici, on peut consid√©rer que notre .env de configuration, les secrets renseign√©s √† Github ou encore le requirements.txt rel√®vent de cette cat√©gorie ;\nLes donn√©es. Nos donn√©es sont statiques et n‚Äôont pas vocation √† √©voluer. Si c‚Äô√©tait le cas, il faudrait en tenir compte dans notre automatisation (Note¬†1). ;\nLe code. C‚Äôest l‚Äô√©l√©ment principal qui √©volue chez nous. Id√©alement, on veut automatiser le processus au maximum en faisant en sorte qu‚Äô√† chaque mise √† jour de notre code (un push sur Github), les √©tapes ult√©rieures (production de l‚Äôimage Docker, etc.) se lancent. N√©anmoins, on veut aussi √©viter qu‚Äôune erreur puisse donner lieu √† une mise en production non-fonctionnelle, on va donc maintenir une action manuelle minimale comme garde-fou.\n\n\n\n\n\n\n\nNote¬†1: Et le versionning des donn√©es ?\n\n\n\nIci, nous nous pla√ßons dans le cas simple o√π les donn√©es brutes re√ßues sont fig√©es. Ce qui peut changer est la mani√®re dont on constitue nos √©chantillons train/test. Il sera donc utile de logguer les donn√©es en question par le biais de MLFlow. Mais il n‚Äôest pas n√©cessaire de versionner les donn√©es brutes.\nSi celles-ci √©voluaient, il pourrait √™tre utile de versionner les donn√©es, √† la mani√®re dont on le fait pour le code. Git n‚Äôest pas l‚Äôoutil appropri√© pour cela. Parmi les outils populaires de versionning de donn√©es, bien int√©gr√©s avec S3, il y a, sur le SSPCloud, lakefs.\n\n\nPour automatiser au maximum la mise en production, on va utiliser un nouvel outil : ArgoCD. Ainsi, au lieu de devoir appliquer manuellement la commande kubectl apply √† chaque modification des fichiers de d√©ploiement (pr√©sents dans le dossier kubernetes/), c‚Äôest l‚Äôop√©rateur ArgoCD, d√©ploy√© sur le cluster, qui va d√©tecter les changements de configuration du d√©ploiement et les appliquer automatiquement.\nC‚Äôest l‚Äôapproche dite GitOps : le d√©p√¥t Git du d√©ploiement fait office de source de v√©rit√© unique de l‚Äô√©tat voulu de l‚Äôapplication, tout changement sur ce dernier doit donc se r√©percuter imm√©diatement sur le d√©ploiement effectif.\n\n\n\n\n\n\nApplication 19a: Automatiser la mise √† disposition de l‚ÄôAPI (d√©ploiement continu)\n\n\n\n\nLancer un service ArgoCD sur le SSPCloud depuis la page Mes services (catalogue Automation). Laisser les configurations par d√©faut.\nSur GitHub, cr√©er un d√©p√¥t application-deployment qui va servir de d√©p√¥t GitOps, c‚Äôest √† dire un d√©p√¥t qui sp√©cifie le param√©trage du d√©ploiement de votre application.\nAjouter un dossier deployment √† votre d√©p√¥t GitOps, dans lequel on mettra les trois fichiers de d√©ploiement qui permettent de d√©ployer notre application sur Kubernetes (deployment.yaml, service.yaml, ingress.yaml).\nA la racine de votre d√©p√¥t GitOps, cr√©ez un fichier application.yml avec le contenu suivant, en prenant bien soin de modifier les lignes annot√©es avec des informations pertinentes :\n\n\napplication.yaml\n\napiVersion: argoproj.io/v1alpha1\nkind: Application\nmetadata:\n  name: ensae-mlops\nspec:\n  project: default\n  source:\n1    repoURL: https://github.com/&lt;your_github_username&gt;/application-deployment.git\n2    targetRevision: main\n3    path: deployment\n  destination:\n    server: https://kubernetes.default.svc\n4    namespace: user-&lt;your_sspcloud_username&gt;\n  syncPolicy:\n    automated:\n      selfHeal: true\n\n\n1\n\nL‚ÄôURL de votre d√©p√¥t Github  faisant office de d√©p√¥t GitOps.\n\n2\n\nLa branche √† partir de laquelle vous d√©ployez.\n\n3\n\nLe nom du dossier contenant vos fichiers de d√©ploiement Kubernetes.\n\n4\n\nVotre namespace Kubernetes. Sur le SSPCloud, cela prend la forme user-${username}.\n\n\nPousser sur Github le d√©p√¥t GitOps.\nDans ArgoCD, cliquez sur New App puis Edit as a YAML. Copiez-collez le contenu de application.yml et cliquez sur Create.\nObservez dans l‚Äôinterface d‚ÄôArgoCD le d√©ploiement progressif des ressources n√©cessaires √† votre application sur le cluster. Joli non ?\nV√©rifiez que votre API est bien d√©ploy√©e en utilisant l‚ÄôURL d√©finie dans le fichier ingress.yml.\nSupprimer du code applicatif le dossier deployment puisque c‚Äôest maintenant votre d√©p√¥t de d√©ploiement qui le contr√¥le.\nIndiquer dans le README.md que le d√©ploiement de votre application (dont vous pouvez mettre l‚ÄôURL dans le README) est contr√¥l√© par un autre d√©p√¥t.\n\n\n\nSi cela a fonctionn√©, vous devriez maintenant voir votre application dans votre tableau de bord ArgoCD:\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli19a      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli19a2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli19a\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nA pr√©sent, nous avons tous les outils √† notre disposition pour construire un vrai pipeline de CI/CD, automatis√© de bout en bout. Il va nous suffire pour cela de mettre √† bout les composants :\n\ndans la partie 4 de l‚Äôapplication, nous avons construit un pipeline de CI : on a donc seulement √† faire un commit sur le d√©p√¥t de l‚Äôapplication pour lancer l‚Äô√©tape de build et de mise √† disposition de la nouvelle image sur le DockerHub ;\ndans l‚Äôapplication pr√©c√©dente, nous avons construit un pipeline de CD : ArgoCD suit en permanence l‚Äô√©tat du d√©p√¥t GitOps, tout commit sur ce dernier lancera donc automatiquement un red√©ploiement de l‚Äôapplication.\n\nIl y a donc un √©l√©ment qui fait la liaison entre ces deux pipelines et qui nous sert de garde-fou en cas d‚Äôerreur : la version de l‚Äôapplication.\n\n\n\n\n\n\nApplication 19b : Mettre √† jour la version en production\n\n\n\nJusqu‚Äô√† maintenant, on a utilis√© le tag latest pour d√©finir la version de notre application. En pratique, lorsqu‚Äôon passe de la phase de d√©veloppement √† celle de production, on a plut√¥t envie de versionner proprement les versions de l‚Äôapplication afin de savoir ce qui est d√©ploy√©. On va pour cela utiliser les tags avec Git, qui vont se propager au nommage de l‚Äôimage Docker.\n\nModifier le fichier de CI prod.yml pour assurer la propagation des tags.\n\n\n\nFichier .github/workflows/prod.yml\n\n\n\n.github/workflows/prod.yml\n\nname: Construction image Docker\n\non:\n  push:\n    branches:\n      - main\n      - dev\n    tags:\n      - 'v*.*.*'\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      -\n        name: Docker meta\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n1          images: linogaliana/application\n\n      -\n        name: Login to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      -\n        name: Build and push\n        uses: docker/build-push-action@v5\n        with:\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n\n\n1\n\nModifier ici !\n\n\n\n\nDans le d√©p√¥t de l‚Äôapplication, mettre √† jour le code dans app/main.py pour changer un √©l√©ment de l‚Äôinterface de votre documentation. Par exemple, mettre en gras un titre.\n\n\napp/main.py\n\napp = FastAPI(\n    title=\"D√©monstration du mod√®le de pr√©diction de survie sur le Titanic\",\n    description=\n    \"&lt;b&gt;Application de pr√©diction de survie sur le Titanic&lt;/b&gt; üö¢ &lt;br&gt;Une version par API pour faciliter la r√©utilisation du mod√®le üöÄ\" +\\\n        \"&lt;br&gt;&lt;br&gt;&lt;img src=\\\"https://media.vogue.fr/photos/5faac06d39c5194ff9752ec9/1:1/w_2404,h_2404,c_limit/076_CHL_126884.jpg\\\" width=\\\"200\\\"&gt;\"\n    )\n\nCommit et push les changements.\nTagger le commit effectu√© pr√©c√©demment et push le nouveau tag :\n\n\nterminal\n\ngit tag v0.0.1\ngit push --tags\n\nV√©rifier sur le d√©p√¥t GitHub de l‚Äôapplication que ce commit lance bien un pipeline de CI associ√© au tag v1.0.0. Une fois termin√©, v√©rifier sur le DockerHub que le tag v0.0.1 existe bien parmi les tags disponibles de l‚Äôimage.\n\nLa partie CI a correctement fonctionn√©. Int√©ressons-nous √† pr√©sent √† la partie CD.\n\nSur le d√©p√¥t GitOps, mettre √† jour la version de l‚Äôimage √† d√©ployer en production dans le fichier deployment/deployment.yaml\n\n\n\nFichier deployment/deployment.yaml\n\n\n\ndeployment/deployment.yaml\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: titanic-deployment\n  labels:\n    app: titanic\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      app: titanic\n  template:\n    metadata:\n      labels:\n        app: titanic\n    spec:\n      containers:\n      - name: titanic\n1        image: linogaliana/application:v0.0.1\n        ports:\n        - containerPort: 8000\n\n\n1\n\nRemplacer ici par le d√©p√¥t applicatif ad√©quat\n\n\n\n\nApr√®s avoir committ√© et push√©, observer dans ArgoCD le statut de votre application. Normalement, l‚Äôop√©rateur devrait avoir automatiquement identifi√© le changement, et mettre √† jour le d√©ploiement pour en tenir compte.\n\n\n\nV√©rifier que l‚ÄôAPI a bien √©t√© mise √† jour.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli19b      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli19b2\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli19b\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#etape-4-construire-un-site-web",
    "href": "chapters/application.html#etape-4-construire-un-site-web",
    "title": "Application",
    "section": "Etape 4: construire un site web",
    "text": "Etape 4: construire un site web\n\n\n\n\n\n\nSi vous prenez ce projet fil rouge en cours de route\n\n\n\n\n\n\n\nterminal\n\ngit checkout appli19\ngit checkout -b dev\ngit push origin dev\n\n\n\n\n\n\n\n\n\nOn va proposer un nouveau livrable pour parler √† un public plus large. Pour faire ce site web, on va utiliser Quarto et d√©ployer sur Github Pages.\n\n\n\n\n\n\nApplication 20: Cr√©ation d‚Äôun site web pour valoriser le projet\n\n\n\nquarto create project website mysite\n\nFaire remonter d‚Äôun niveau _quarto.yml\nSupprimer about.qmd, d√©placer index.qmd vers la racine de notre projet.\nRemplacer le contenu de index.qmd par celui-ci et retirer about.qmd des fichiers √† compiler.\nD√©placer styles.css √† la racine du projet\nMettre √† jour le .gitignore avec les instructions suivantes\n\n/.quarto/\n*.html\n*_files\n_site/\n\nEn ligne de commande, faire quarto preview\nObserver le site web g√©n√©r√© en local\n\nEnfin, on va construire et d√©ployer automatiquement ce site web gr√¢ce au combo Github Actions et Github Pages:\n\nCr√©er une branche gh-pages √† partir des lignes suivantes\n\n\n\nterminal\n\ngit checkout --orphan gh-pages\ngit reset --hard # make sure all changes are committed before running this!\ngit commit --allow-empty -m \"Initialising gh-pages branch\"\ngit push origin gh-pages\n\n\nRevenir √† votre branche principale (main normalement)\nCr√©er un fichier .github/workflows/website.yaml avec le contenu de ce fichier\nModifier le README pour indiquer l‚ÄôURL de votre site web et de votre API\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli20      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli202\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli20\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#revenir-sur-le-code-dentra√Ænement-du-mod√®le-pour-faire-de-la-validation-crois√©e",
    "href": "chapters/application.html#revenir-sur-le-code-dentra√Ænement-du-mod√®le-pour-faire-de-la-validation-crois√©e",
    "title": "Application",
    "section": "Revenir sur le code d‚Äôentra√Ænement du mod√®le pour faire de la validation crois√©e",
    "text": "Revenir sur le code d‚Äôentra√Ænement du mod√®le pour faire de la validation crois√©e\nPour pouvoir faire ceci, il va falloir changer un tout petit peu notre code applicatif dans sa phase d‚Äôentra√Ænement.\n\n\n\n\n\n\nApplication 21 (optionnelle): restructuration de la cha√Æne\n\n\n\n\nFaire les modifications suivantes pour restructurer notre pipeline afin de mieux distinguer les √©tapes d‚Äôestimation et d‚Äô√©valuation\n\n\n\nModification de train.py pour faire une grid search\n\n\n\ntrain.py\n\n\"\"\"\nPrediction de la survie d'un individu sur le Titanic\n\"\"\"\n\nimport os\nfrom dotenv import load_dotenv\nimport argparse\nfrom loguru import logger\nfrom joblib import dump\n\nimport pathlib\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\nfrom src.pipeline.build_pipeline import create_pipeline\nfrom src.models.train_evaluate import evaluate_model\n\n\n# ENVIRONMENT CONFIGURATION ---------------------------\n\nlogger.add(\"recording.log\", rotation=\"500 MB\")\nload_dotenv()\n\nparser = argparse.ArgumentParser(description=\"Param√®tres du random forest\")\nparser.add_argument(\n    \"--n_trees\", type=int, default=20, help=\"Nombre d'arbres\"\n)\nargs = parser.parse_args()\n\nURL_RAW = \"https://minio.lab.sspcloud.fr/lgaliana/ensae-reproductibilite/data/raw/data.csv\"\n\nn_trees = args.n_trees\njeton_api = os.environ.get(\"JETON_API\", \"\")\ndata_path = os.environ.get(\"data_path\", URL_RAW)\ndata_train_path = os.environ.get(\"train_path\", \"data/derived/train.parquet\")\ndata_test_path = os.environ.get(\"test_path\", \"data/derived/test.parquet\")\nMAX_DEPTH = None\nMAX_FEATURES = \"sqrt\"\n\nif jeton_api.startswith(\"$\"):\n    logger.info(\"API token has been configured properly\")\nelse:\n    logger.warning(\"API token has not been configured\")\n\n\n# IMPORT ET STRUCTURATION DONNEES --------------------------------\n\np = pathlib.Path(\"data/derived/\")\np.mkdir(parents=True, exist_ok=True)\n\nTrainingData = pd.read_csv(data_path)\n\ny = TrainingData[\"Survived\"]\nX = TrainingData.drop(\"Survived\", axis=\"columns\")\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.1\n)\npd.concat([X_train, y_train], axis = 1).to_parquet(data_train_path)\npd.concat([X_test, y_test], axis = 1).to_parquet(data_test_path)\n\n\n# PIPELINE ----------------------------\n\n\n# Create the pipeline\npipe = create_pipeline(\n    n_trees, max_depth=MAX_DEPTH, max_features=MAX_FEATURES\n)\n\nparam_grid = {\n    \"classifier__n_estimators\": [10, 20, 50],\n    \"classifier__max_leaf_nodes\": [5, 10, 50],\n}\n\npipe_cross_validation = GridSearchCV(\n    pipe,\n    param_grid=param_grid,\n    scoring=[\"accuracy\", \"precision\", \"recall\", \"f1\"],\n    refit=\"f1\",\n    cv=5,\n    n_jobs=5,\n    verbose=1,\n)\n\npipe_cross_validation.fit(X_train, y_train)\n\npipe = pipe_cross_validation.best_estimator_\n\n\n# ESTIMATION ET EVALUATION ----------------------\n\npipe.fit(X_train, y_train)\n\nwith open(\"model.joblib\", \"wb\") as f:\n    dump(pipe, f)\n\n# Evaluate the model\nscore, matrix = evaluate_model(pipe, X_test, y_test)\n\nlogger.success(f\"{score:.1%} de bonnes r√©ponses sur les donn√©es de test pour validation\")\nlogger.debug(20 * \"-\")\nlogger.info(\"Matrice de confusion\")\nlogger.debug(matrix)\n\n\n\nDans le code de l‚ÄôAPI (app/api.py), changer la version du mod√®le mis en oeuvre en ‚Äú0.2‚Äù (dans la fonction show_welcome_page)\nApr√®s avoir committ√© cette nouvelle version du code applicatif, tagguer ce d√©p√¥t avec le tag v0.0.2\nModifier deployment/deployment.yaml dans le code GitOps pour utiliser ce tag.\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli21      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli212\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli21\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#garder-une-trace-des-entra√Ænements-de-notre-mod√®le-gr√¢ce-au-register-de-mlflow",
    "href": "chapters/application.html#garder-une-trace-des-entra√Ænements-de-notre-mod√®le-gr√¢ce-au-register-de-mlflow",
    "title": "Application",
    "section": "Garder une trace des entra√Ænements de notre mod√®le gr√¢ce au register de MLFlow",
    "text": "Garder une trace des entra√Ænements de notre mod√®le gr√¢ce au register de MLFlow\n  \n    \n      \n        \n      \n      \n        Reprendre √† partir d'ici      \n      \n    \n    \n      \n\n        Si vous n'avez plus de VSCode actif avec la configuration propos√©e dans l'application pr√©liminaire, vous pouvez repartir de ce service:    \n      \n    \n    Et ensuite, apr√®s avoir cl√¥n√© le d√©p√¥t\n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli212\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli21\n          3\n          Nettoyer derri√®re nous"
  },
  {
    "objectID": "chapters/application.html#enregistrer-nos-premiers-entra√Ænements",
    "href": "chapters/application.html#enregistrer-nos-premiers-entra√Ænements",
    "title": "Application",
    "section": "Enregistrer nos premiers entra√Ænements",
    "text": "Enregistrer nos premiers entra√Ænements\n\n\n\n\n\n\nApplication 22 : archiver nos entra√Ænements avec MLFlow\n\n\n\n\nLancer MLFlow depuis l‚Äôonflet Mes services du SSPCloud. Attendre que le service soit bien lanc√©. Cela cr√©era un service dont l‚ÄôURL est de la forme https://user-{username}.user.lab.sspcloud.fr. Ce service MLFlow communiquera avec les VSCode que vous ouvrirez ult√©rieurement √† partir de cet URL ainsi qu‚Äôavec le syst√®me de stockage S318.\nRegarder la page Experiments. Elle ne contient que Default √† ce stade, c‚Äôest normal.\n\n\nUne fois le service MLFlow fonctionnel, lancer un nouveau VSCode pour b√©n√©ficier de la connexion automatique entre les services interactifs du SSPCloud et les services d‚Äôautomatisation comme MLFlow.\nCl√¥ner votre projet, vous situer sur la branche de travail.\nDans la section de passage des param√®tres de notre ligne de commande, introduire ce morceau de code:\n\nparser = argparse.ArgumentParser(description=\"Param√®tres du random forest\")\nparser.add_argument(\n    \"--n_trees\", type=int, default=20, help=\"Nombre d'arbres\"\n)\nparser.add_argument(\n    \"--experiment_name\", type=str, default=\"titanicml\", help=\"MLFlow experiment name\"\n)\nargs = parser.parse_args()\n\nA la fin du script train.py, ajouter le code suivant\n\n\n\nCode √† ajouter\n\n\n\nfin de train.py\n\n# LOGGING IN MLFLOW -----------------\n\nmlflow_server = os.getenv(\"MLFLOW_TRACKING_URI\")\n\nlogger.info(f\"Saving experiment in {mlflow_server}\")\n\nmlflow.set_tracking_uri(mlflow_server)\nmlflow.set_experiment(args.experiment_name)\n\n\ninput_data_mlflow = mlflow.data.from_pandas(\n    TrainingData, source=data_path, name=\"Raw dataset\"\n)\ntraining_data_mlflow = mlflow.data.from_pandas(\n    pd.concat([X_train, y_train], axis=1), source=data_path, name=\"Training data\"\n)\n\n\nwith mlflow.start_run():\n\n    # Log datasets\n    mlflow.log_input(input_data_mlflow, context=\"raw\")\n    mlflow.log_input(training_data_mlflow, context=\"raw\")\n\n    # Log parameters\n    mlflow.log_param(\"n_trees\", n_trees)\n    mlflow.log_param(\"max_depth\", MAX_DEPTH)\n    mlflow.log_param(\"max_features\", MAX_FEATURES)\n\n    # Log best hyperparameters from GridSearchCV\n    best_params = pipe_cross_validation.best_params_\n    for param, value in best_params.items():\n        mlflow.log_param(param, value)\n\n    # Log metrics\n    mlflow.log_metric(\"accuracy\", score)\n\n    # Log confusion matrix as an artifact\n    matrix_path = \"confusion_matrix.txt\"\n    with open(matrix_path, \"w\") as f:\n        f.write(str(matrix))\n    mlflow.log_artifact(matrix_path)\n\n    # Log model\n    mlflow.sklearn.log_model(pipe, \"model\")\n\n\n\nAjouter mlruns/* dans .gitignore\nTester train.py en ligne de commande\nObserver l‚Äô√©volution de la page Experiments. Cliquer sur un des run. Observer toutes les m√©tadonn√©es archiv√©es (hyperparam√®tres, m√©triques d‚Äô√©valuation, requirements.txt dont MLFlow a fait l‚Äôinf√©rence, etc.)\nObserver le code propos√© par MLFlow pour r√©cup√©rer le run en question. Tester celui-ci dans un notebook sur le fichier interm√©diaire de test au format Parquet\nEn ligne de commande, faites tourner pour une autre valeur de n_trees. Retourner √† la liste des runs en cliquant √† nouveau sur ‚Äútitanicml‚Äù dans les exp√©rimentations\nDans l‚Äôonglet Table, s√©lectionner plusieurs exp√©rimentations, cliquer sur Columns et ajouter la statistique d‚Äôaccuracy. Ajuster la taille des colonnes pour la voir et classer les mod√®les par score d√©croissants\nCliquer sur Compare apr√®s en avoir s√©lectionn√© plusieurs. Afficher un scatterplot des performances en fonction du nombre d‚Äôestimateurs. Conclure.\nAjouter mlflow au requirements.txt\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli22      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli222\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli22\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nCette appplication illustre l‚Äôun des premiers apports de MLFlow: on garde une trace de nos exp√©rimentations: le mod√®le est archiv√© avec les param√®tres et des m√©triques de performance. On peut donc retrouver de plusieurs mani√®res un mod√®le qui nous avait tap√© dans l‚Äôoeil.\nN√©anmoins, persistent un certain nombre de voies d‚Äôam√©lioration dans notre pipeline.\n\nOn entra√Æne le mod√®le en local, de mani√®re s√©quentielle, et en lan√ßant nous-m√™mes le script train.py.\nPis encore, √† l‚Äôheure actuelle, cette √©tape d‚Äôestimation n‚Äôest pas s√©par√©e de la mise √† disposition du mod√®le par le biais de notre API. On archive des mod√®les mais on les utilise pas ult√©rieurement.\n\nLes prochaines applications permettront d‚Äôam√©liorer ceci."
  },
  {
    "objectID": "chapters/application.html#consommation-dun-mod√®le-archiv√©-sur-mlflow",
    "href": "chapters/application.html#consommation-dun-mod√®le-archiv√©-sur-mlflow",
    "title": "Application",
    "section": "Consommation d‚Äôun mod√®le archiv√© sur MLFlow",
    "text": "Consommation d‚Äôun mod√®le archiv√© sur MLFlow\nA l‚Äôheure actuelle, notre pipeline est lin√©aire:\n\nCeci nous g√™ne pour faire √©voluer notre mod√®le: on ne dissocie pas ce qui rel√®ve de l‚Äôentra√Ænement du mod√®le de son utilisation. Un pipeline plus cyclique permettra de mieux dissocier l‚Äôexp√©rimentation de la production:\n\n\n\n\n\n\n\nApplication 23 : passer en production un mod√®le avec MLFlow\n\n\n\n\nSi vous avez entra√Æn√© plusieurs mod√®les avec des n_trees diff√©rents, utiliser l‚Äôinterface de MLFlow pour s√©lectionner le ‚Äúmeilleur‚Äù. Cliquer sur le mod√®le en question et faire l‚Äôaction ‚ÄúRegister Model‚Äù. L‚Äôenregistrer comme le mod√®le de ‚Äúproduction‚Äù\nRendez-vous sur l‚Äôonglet Models et observez cet entrep√¥t de mod√®les. Cliquez sur le mod√®le de production. Vous pourrez par ce biais suivre ses diff√©rentes versions.\nOuvrir un notebook temporaire et observer le r√©sultat.\n\n\n\nExemple de code √† tester\n\nimport mlflow\nimport pandas as pd\n\nmodel_name = \"production\"\nmodel_version = \"latest\"\n\n# Load the model from the Model Registry\nmodel_uri = f\"models:/{model_name}/{model_version}\"\nlogged_model = mlflow.sklearn.load_model(model_uri)\n\n# GENERATE PREDICTION DATA ---------------------\n\ndef create_data(\n    sex: str = \"female\",\n    age: float = 29.0,\n    fare: float = 16.5,\n    embarked: str = \"S\",\n) -&gt; str:\n    \"\"\"\n    \"\"\"\n\n    df = pd.DataFrame(\n        {\n            \"Sex\": [sex],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embarked],\n        }\n    )\n\n    return df\n\n\ndata = pd.concat(\n    [create_data(age=40), create_data(sex=\"male\")]\n)\n\n# PREDICTION ---------------------\n\nlogged_model.predict(pd.DataFrame(data))\n\n\nOn va adapter le code applicatif de notre API pour tenir compte de ce mod√®le de production.\n\n\n\nVoir le script app/api.py propos√©\n\n\"\"\"A simple API to expose our trained RandomForest model for Tutanic survival.\"\"\"\nfrom fastapi import FastAPI\nimport mlflow\n\nimport pandas as pd\n\n# Preload model -------------------\n\nmodel_name = \"production\"\nmodel_version = \"latest\"\n\n# Load the model from the Model Registry\nmodel_uri = f\"models:/{model_name}/{model_version}\"\nmodel = mlflow.sklearn.load_model(model_uri)\n\n# Define app -------------------------\n\n\napp = FastAPI(\n    title=\"Pr√©diction de survie sur le Titanic\",\n    description=\n    \"Application de pr√©diction de survie sur le Titanic üö¢ &lt;br&gt;Une version par API pour faciliter la r√©utilisation du mod√®le üöÄ\" +\\\n        \"&lt;br&gt;&lt;br&gt;&lt;img src=\\\"https://media.vogue.fr/photos/5faac06d39c5194ff9752ec9/1:1/w_2404,h_2404,c_limit/076_CHL_126884.jpg\\\" width=\\\"200\\\"&gt;\"\n    )\n\n\n@app.get(\"/\", tags=[\"Welcome\"])\ndef show_welcome_page():\n    \"\"\"\n    Show welcome page with model name and version.\n    \"\"\"\n\n    return {\n        \"Message\": \"API de pr√©diction de survie sur le Titanic\",\n        \"Model_name\": 'Titanic ML',\n        \"Model_version\": \"0.3\",\n    }\n\n\n@app.get(\"/predict\", tags=[\"Predict\"])\nasync def predict(\n    sex: str = \"female\",\n    age: float = 29.0,\n    fare: float = 16.5,\n    embarked: str = \"S\"\n) -&gt; str:\n    \"\"\"\n    \"\"\"\n\n    df = pd.DataFrame(\n        {\n            \"Sex\": [sex],\n            \"Age\": [age],\n            \"Fare\": [fare],\n            \"Embarked\": [embarked],\n        }\n    )\n\n    prediction = \"Survived üéâ\" if int(model.predict(df)) == 1 else \"Dead ‚ö∞Ô∏è\"\n\n    return prediction\n\nLes changements principaux de ce code sont:\n\non va chercher le mod√®le de production\non met √† jour la version de notre API pour signaler √† nos clients que celle-ci a √©volu√©\n\n\nOn va retirer l‚Äôentra√Ænement de la s√©quence d‚Äôop√©ration du api/run.sh. En supprimant la ligne relative √† l‚Äôentra√Ænement du mod√®le, vous devriez avoir\n\n#/bin/bash\nuvicorn app.api:app --host \"0.0.0.0\"\nMettons en production cette nouvelle version. Cela implique de faire les gestes suivants:\n\nCommit de ce changement dans main\nPublier un tag v0.0.3 pour le code applicatif\nMettre √† jour notre manifeste dans le d√©p√¥t GitOps.\n\nEn premier lieu, il faut changer la version de r√©f√©rence pour utiliser le tag v0.0.3.\nDe plus, il faut d√©clarer la variable d‚Äôenvironnement MLFLOW_TRACKING_URI qui indique √† Python l‚Äôentrep√¥t de mod√®les o√π aller chercher celui en production. La bonne pratique est de d√©finir ceci hors du code, dans un fichier de configuration donc, ce qui est l‚Äôobjet de notre manifeste deployment.yaml. On peut donc changer de cette mani√®re ce fichier:\n\n\n\n\nLe mod√®le deployment.yaml propos√©\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nname: titanic-deployment\nlabels:\n    app: titanic\nspec:\nreplicas: 1\nselector:\n    matchLabels:\n    app: titanic\ntemplate:\n    metadata:\n    labels:\n        app: titanic\n    spec:\n    containers:\n    - name: titanic\n1        image: linogaliana/application:v0.0.3\n        ports:\n        - containerPort: 8000\n        env:\n        - name: MLFLOW_TRACKING_URI\n2            value: https://user-${USERNAME}-mlflow.user.lab.sspcloud.fr\n        resources:\n        limits:\n            memory: \"2Gi\"\n            cpu: \"1000m\"\n\n1\n\nLe tag de notre code applicatif\n\n2\n\nLa variable d‚Äôenvironnement √† adapter en fonction de l‚Äôadresse du d√©p√¥t demod√®les utilis√©. Remplacer par votre URL MLFlow.\n\n\n\n\nPour s‚Äôassurer que l‚Äôapplication fonctionne bien, on peut aller voir les logs de la machine qui fait tourner notre code. Pour √ßa, faire kubectl get pods et, en supposant que votre service soit nomm√© titanic dans vos fichiers YAML de configuration, r√©cup√©rer le nom commen√ßant par titanic-deployment-* et faire kubectl logs titanic-deployment-*\n\n\n\n  \n    \n      \n        \n      \n      \n        Checkpoint post appli23      \n      \n    \n    \n      \n\n        \n        \n          \n            terminal\n          \n          \n            curl -sSL https://raw.githubusercontent.com/ensae-reproductibilite/website/refs/heads/main/chapters/applications/overwrite.sh -o update.sh && chmod +x update.sh\n./update.sh appli232\nrm -f update.sh\n          \n        \n        \n          1\n          R√©cup√©rer le script de checkpoint\n          2\n          Avancer √† l‚Äô√©tat √† l‚Äôissue de l‚Äôapplication appli23\n          3\n          Nettoyer derri√®re nous\n        \n\n        \n          \n            \n          \n        \n      \n    \n  \n  \nA ce stade, nous avons am√©lior√© la fiabilit√© de notre application car nous utilisons le meilleur mod√®le. N√©anmoins, nos entra√Ænements sont encore manuels. L√† encore il y a des gains possibles car cela para√Æt p√©nible √† la longue de devoir syst√©matiquement relancer des entra√Ænements manuellement pour tester des variations de tel ou tel param√®tre. Heureusement, nous allons pouvoir automatiser ceci √©galement."
  },
  {
    "objectID": "chapters/application.html#industrialiser-les-entra√Ænements-de-nos-mod√®les",
    "href": "chapters/application.html#industrialiser-les-entra√Ænements-de-nos-mod√®les",
    "title": "Application",
    "section": "Industrialiser les entra√Ænements de nos mod√®les",
    "text": "Industrialiser les entra√Ænements de nos mod√®les\nPour industrialiser nos entra√Ænements, nous allons cr√©er des processus parall√®les ind√©pendants pour chaque combinaison de nos hyperparam√®tres.\nCe travail nous am√®ne de l‚Äôapproche pipeline √† mi chemin entre data science et data engineering. Il existe plusieurs outils pour faire ceci, g√©n√©ralement issus de la sph√®re du data engineering. L‚Äôoutil le plus complet sur le SSPCloud, bien int√©gr√© √† l‚Äô√©cosyst√®me Kubernetes, est Argo Workflows19.\nChaque combinaison d‚Äôhyperparam√®tres sera un processus isol√© √† l‚Äôissue duquel sera loggu√© le r√©sultat dans MLFlow. Ces entra√Ænements auront lieu en parall√®le.\nNous allons construire, dans les deux prochaines applications, un pipeline simple prenant cette forme20:\n\n\n\n\n\n\n\n\n\n\n\n(a) Via Argo Workflows\n\n\n\n\n\n\n\n\n\n\n\n(b) Via Github Actions\n\n\n\n\n\n\n\nFigure¬†3: Pipeline d‚Äôentra√Ænement de nos mod√®les avec deux outils d‚Äôautomatisation diff√©rents\n\n\n\nL‚Äôoutil permettant une int√©gration native de notre pipeline dans l‚Äôinfrastructure cloud (SSPCloud) que nous avons utilis√©e jusqu‚Äô√† pr√©sent est Argo Workflows. N√©anmoins, pour illustrer la modularit√© de notre cha√Æne, permise par l‚Äôadoption de Docker, nous allons montrer que les serveurs d‚Äôint√©gration continue de Github peuvent tr√®s bien servir d‚Äôenvironnement d‚Äôex√©cution, sans rien perdre de ce que nous avons mis en oeuvre pr√©c√©demment (logging des mod√®les dans MLFlow, r√©cup√©ration de donn√©es depuis S3, etc.)\n\n\n\n\n\n\nApplication 24 : industrialisation des entra√Ænements avec Argo Workflow\n\n\n\nA l‚Äôheure actuelle, notre entra√Ænement ne d√©pend que d‚Äôun hyperparam√®tre fix√© √† partir de la ligne de commande: n_trees. Nous allons commencer par ajouter un argument √† notre chaine de production (code applicatif):\n\nDans train.py, dans la section relative au parsing de nos arguments, ajouter ce bout de code\n\nparser.add_argument(\n    \"--max_features\",\n    type=str, default=\"sqrt\",\n    choices=['sqrt', 'log2'],\n    help=\"Number of features to consider when looking for the best split\"\n)\net remplacer la d√©finition de MAX_FEATURES par l‚Äôargument fourni en ligne de commande:\nMAX_FEATURES = args.max_features\n\nFaire un commit, taguer cette version (v0.0.4) et pusher le tag\nMaintenant, dans le d√©p√¥t GitOps, cr√©er un fichier argo-workflow/manifest.yaml\n\n\n\nLe mod√®le propos√©\n\napiVersion: argoproj.io/v1alpha1\nkind: Workflow\nmetadata:\ngenerateName: titanic-training-workflow-\nnamespace: user-lgaliana\nspec:\nentrypoint: main\nserviceAccountName: workflow\narguments:\n    parameters:\n    # The MLflow tracking server is responsible to log the hyper-parameter and model metrics.\n    - name: mlflow-tracking-uri\n1        value: https://user-${USERNAME}-mlflow.user.lab.sspcloud.fr/\n    - name: mlflow-experiment-name\n2        value: titanicml\n    - name: model-training-conf-list\n        value: |\n        [\n            { \"n_trees\": 10, \"max_features\": \"log2\" },\n            { \"n_trees\": 20, \"max_features\": \"sqrt\" },\n            { \"n_trees\": 20, \"max_features\": \"log2\" },\n            { \"n_trees\": 50, \"max_features\": \"sqrt\" }\n        ]\ntemplates:\n    # Entrypoint DAG template\n    - name: main\n    dag:\n        tasks:\n        # Task 0: Start pipeline\n        - name: start-pipeline\n            template: start-pipeline-wt\n        # Task 1: Train model with given params\n        - name: train-model-with-params\n            dependencies: [ start-pipeline ]\n            template: run-model-training-wt\n            arguments:\n            parameters:\n                - name: max_features\n                value: \"{{item.max_features}}\"\n                - name: n_trees\n                value: \"{{item.n_trees}}\"\n            # Pass the inputs to the task using \"withParam\"\n            withParam: \"{{workflow.parameters.model-training-conf-list}}\"\n    # Now task container templates are defined\n    # Worker template for task 0 : start-pipeline\n    - name: start-pipeline-wt\n    inputs:\n    container:\n        image: busybox\n        command: [ sh, -c ]\n        args: [ \"echo Starting pipeline\" ]\n    # Worker template for task-1 : train model with params\n    - name: run-model-training-wt\n    inputs:\n        parameters:\n        - name: n_trees\n        - name: max_features\n    container:\n3        image: ****/application:v0.0.4\n        imagePullPolicy: Always\n        command: [sh, -c]\n        args: [\n        \"python3 train.py --n_trees={{inputs.parameters.n_trees}} --max_features={{inputs.parameters.max_features}}\"\n        ]\n        env:\n        - name: MLFLOW_TRACKING_URI\n            value: \"{{workflow.parameters.mlflow-tracking-uri}}\"\n        - name: MLFLOW_EXPERIMENT_NAME\n            value: \"{{workflow.parameters.mlflow-experiment-name}}\"\n        - name: AWS_DEFAULT_REGION\n            value: us-east-1\n        - name: AWS_S3_ENDPOINT\n            value: minio.lab.sspcloud.fr\n\n1\n\nChanger pour votre entrepot de mod√®le\n\n2\n\nLe nom de l‚Äôexp√©rimentation MLFLow dont nous allons avoir besoin (on propose de continuer sur titanicml)\n\n3\n\nChanger l‚Äôimage Docker  ici\n\n\n\n\nObserver l‚ÄôUI d‚ÄôArgo Workflow dans vos services ouverts du SSPCloud. Vous devriez retrouver Figure¬†3 (a) dans celle-ci.\n\n\n\nNous pouvons maintenant passer √† la version Github. Celle-ci est optionnelle car elle vient surtout d√©montrer l‚Äôint√©r√™t d‚Äôavoir une chaine modulaire et la dissociation que cela permet entre l‚Äôenvironnement d‚Äôex√©cution et les autres environnements n√©cessaires √† notre chaine (notamment le stockage code et le logging).\n\n\n\n\n\n\nApplication 25 (optionnelle) : Github Actions comme ordonnanceur\n\n\n\nPour que Github sache o√π aller chercher MLFlow et S3 et comment s‚Äôy identifier, il va falloir lui donner un certain de variables d‚Äôenvironnement. Il est hors de question de mettre celles-ci dans le code. Heureusement, Github propose la possibilit√© de renseigner des secrets: nous allons utiliser ceux-ci.\n\nAller dans les param√®tres de votre projet GitOps et dans la section Secrets and variables\nVous allez avoir besoin de cr√©er les secrets suivants:\n\nMLFLOW_TRACKING_PASSWORD\nAWS_ACCESS_KEY_ID\nAWS_SECRET_ACCESS_KEY\nAWS_SESSION_TOKEN\n\n\nLes valeurs √† renseigner sont √† r√©cup√©rer √† diff√©rents endroits:\n\nPour les secrets li√©s √† S3 (AWS_*), ceux-ci sont dans l‚Äôespace Mon compte du SSPCloud. Ils ont une dur√©e de validit√© limit√©e: si vous devez refaire tourner le code dans quelques jours, il faudra les mettre √† jour (ou passer par un compte de service comme indiqu√© pr√©c√©demment)\nLe mot de passe de MLFlow est dans le README de votre service, qui s‚Äôaffiche quand vous cliquez sur le bouton Ouvrir depuis la page Mes services\n\n\nReprendre ce mod√®le d‚Äôaction √† mettre dans votre d√©p√¥t GitOps (.github/workflows/train.yaml par exemple).\n\n\n\nMod√®le d‚Äôaction Github\n\nname: Titanic Model Training\n\non:\n  push:\n    branches:\n      - main\n  workflow_dispatch:\n\njobs:\n  start-pipeline:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Start Pipeline\n        run: echo \"Starting pipeline\"\n\n  train-model:\n    needs: start-pipeline\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        model-config:\n          - { n_trees: 10, max_features: \"log2\" }\n          - { n_trees: 20, max_features: \"sqrt\" }\n          - { n_trees: 20, max_features: \"log2\" }\n          - { n_trees: 50, max_features: \"sqrt\" }\n    container:\n1      image: ***/application:v0.0.4\n    env:\n      MLFLOW_TRACKING_URI: \"https://user-lgaliana-mlflow.user.lab.sspcloud.fr/\"\n      MLFLOW_EXPERIMENT_NAME: \"titanicml\"\n      MLFLOW_TRACKING_PASSWORD: \"${{ secrets.MLFLOW_TRACKING_PASSWORD }}\"\n      AWS_DEFAULT_REGION: \"us-east-1\"\n      AWS_S3_ENDPOINT: \"minio.lab.sspcloud.fr\"\n      AWS_ACCESS_KEY_ID: \"${{ secrets.AWS_ACCESS_KEY_ID }}\"\n      AWS_SECRET_ACCESS_KEY: \"${{ secrets.AWS_SECRET_ACCESS_KEY }}\"\n      AWS_SESSION_TOKEN: \"${{ secrets.AWS_SESSION_TOKEN }}\"\n\n    steps:\n      - name: Checkout Repository\n        uses: actions/checkout@v4\n        with:\n2            repository: 'ensae-reproductibilite/application'\n            ref: appli24\n\n      - name: Train Model\n        run: |\n          python3 train.py --n_trees=${{ matrix.model-config.n_trees }} --max_features=${{ matrix.model-config.max_features }}\n\n1\n\nMettre votre image ici. Si vous n‚Äôen avez pas, vous pouvez mettre linogaliana/application:v0.0.4\n\n2\n\nOn reprend le code applicatif de l‚Äôapplication pr√©c√©dente. Vous pouvez remplacer par votre d√©p√¥t et une r√©f√©rence adapt√©e si vous pr√©f√©rez\n\n\n\n\nPusher et observer l‚ÄôUI de Github depuis l‚Äôonglet Actions. Vous devriez retrouver Figure¬†3 (b) dans celle-ci."
  },
  {
    "objectID": "chapters/application.html#footnotes",
    "href": "chapters/application.html#footnotes",
    "title": "Application",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIl y a quelques diff√©rences entre le VSCode server mis √† disposition sur le SSPCloud et la version desktop sur laquelle s‚Äôappuient beaucoup de ressources. A quelques extensions pr√™ts (Data Wrangler, Copilot), les diff√©rences sont n√©anmoins minimes.‚Ü©Ô∏é\nL‚Äôexport dans un script .py a √©t√© fait directement depuis VSCode. Comme cela n‚Äôest pas vraiment l‚Äôobjet du cours, nous passons cette √©tape et fournissons directement le script expurg√© du texte interm√©diaire. Mais n‚Äôoubliez pas que cette d√©marche, fr√©quente quand on a d√©marr√© sur un notebook et qu‚Äôon d√©sire consolider en faisant la transition vers des scripts, n√©cessite d‚Äô√™tre attentif pour ne pas risquer de faire une erreur.‚Ü©Ô∏é\nIl est √©galement possible avec VSCode d‚Äôex√©cuter le script ligne √† ligne de mani√®re interactive ligne √† ligne (MAJ+ENTER). N√©anmoins, cela n√©cessite de s‚Äôassurer que le working directory de votre console interactive est le bon. Celle-ci se lance selon les param√®tres pr√©configur√©s de VSCode et les votres ne sont peut-√™tre pas les m√™mes que les notres. Vous pouvez changer le working directory dans le script en utilisant le package os mais peut-√™tre allez vous d√©couvrir ult√©rieurement qu‚Äôil y a de meilleures pratiques‚Ä¶‚Ü©Ô∏é\nEssayez de commit vos changements √† chaque √©tape de l‚Äôexercice, c‚Äôest une bonne habitude √† prendre.‚Ü©Ô∏é\nIl est normal d‚Äôavoir des dossiers __pycache__ qui tra√Ænent en local : ils se cr√©ent automatiquement √† l‚Äôex√©cution d‚Äôun script en Python. N√©anmoins, il ne faut pas associer ces fichiers √† Git, voil√† pourquoi on les ajoute au .gitignore.‚Ü©Ô∏é\nNous proposons ici d‚Äôadopter le principe de la programmation fonctionnelle. Pour encore fiabiliser un processus, il serait possible d‚Äôadopter le paradigme de la programmation orient√©e objet (POO). Celle-ci est plus rebutante et demande plus de temps au d√©veloppeur. L‚Äôarbitrage co√ªt-avantage est n√©gatif pour notre exemple, nous proposons donc de nous en passer. N√©anmoins, pour une mise en production r√©elle d‚Äôun mod√®le, il peut √™tre utle de l‚Äôadopter car certains frameworks, √† commencer par les pipelines scikit, exigeront certaines classes et m√©thodes si vous d√©sirez brancher des objets ad hoc √† ceux-ci.‚Ü©Ô∏é\nAttention, les donn√©es ont √©t√© committ√©es au moins une fois. Les supprimer du d√©p√¥t ne les efface pas de l‚Äôhistorique. Si cette erreur arrive, le mieux est de supprimer le d√©p√¥t en ligne, cr√©er un nouvel historique Git et partir de celui-ci pour des publications ult√©rieures sur Github. N√©anmoins l‚Äôid√©al serait de ne pas s‚Äôexposer √† cela. C‚Äôest justement l‚Äôobjet des bonnes pratiques de ce cours: un .gitignore bien construit et une s√©paration des environnements de stockage du code et des donn√©es seront bien plus efficaces pour vous √©viter ces probl√®mes que tout les conseils de vigilance que vous pourrez trouver ailleurs.‚Ü©Ô∏é\nAlors oui, c‚Äôest vrai, s3 se distingue d‚Äôun syst√®me de fichiers classiques comme on peut le lire dans certains posts √©nerv√©s sur la question (par exemple sur Reddit). Mais du point de vue de l‚Äôutilisateur Python plut√¥t que de l‚Äôarchitecte cloud, on va avoir assez peu de diff√©rence avec un syst√®me de fichier local. C‚Äôest pour le mieux, cela r√©duit la difficult√© √† rentrer dans cette technologie.‚Ü©Ô∏é\nLorsqu‚Äôon d√©veloppe du code qui finalement ne s‚Äôav√®re plus n√©cessaire, on a souvent un cas de conscience √† le supprimer et on pr√©f√®re le mettre de c√¥t√©. Au final, ce syndr√¥me de Diog√®ne est mauvais pour la p√©rennit√© du projet : on se retrouve √† devoir maintenir une base de code qui n‚Äôest, en pratique, pas utilis√©e. Ce n‚Äôest pas un probl√®me de supprimer un code ; si finalement celui-ci s‚Äôav√®re utile, on peut le retrouver gr√¢ce √† l‚Äôhistorique Git et les outils de recherche sur Github. Le package vulture est tr√®s pratique pour diagnostiquer les morceaux de code inutiles dans un projet.‚Ü©Ô∏é\nLe fichier __init__.py indique √† Python que le dossier est un package. Il permet de proposer certaines configurations lors de l‚Äôimport du package. Il permet √©galement de contr√¥ler les objets export√©s (c‚Äôest-√†-dire mis √† disposition de l‚Äôutilisateur) par le package par rapport aux objets internes au package. En le laissant vide, nous allons utiliser ce fichier pour importer l‚Äôensemble des fonctions de nos sous-modules. Ce n‚Äôest pas la meilleure pratique mais un contr√¥le plus fin des objets export√©s demanderait un investissement qui ne vaut, ici, pas le co√ªt.‚Ü©Ô∏é\nSi vous d√©sirez aussi contr√¥ler la version de Python, ce qui peut √™tre important dans une perspective de portabilit√©, vous pouvez ajouter une option, par exemple -p python3.10. N√©anmoins nous n‚Äôallons pas nous embarasser de cette nuance pour la suite car nous pourrons contr√¥ler la version de Python plus finement par le biais de Docker.‚Ü©Ô∏é\nL‚Äôoption -c pass√©e apr√®s la commande python permet d‚Äôindiquer √† Python que la commande ne se trouve pas dans un fichier mais sera dans le texte qu‚Äôon va directement lui fournir.‚Ü©Ô∏é\nL‚Äôoption -c pass√©e apr√®s la commande python permet d‚Äôindiquer √† Python que la commande ne se trouve pas dans un fichier mais sera dans le texte qu‚Äôon va directement lui fournir.‚Ü©Ô∏é\nPour comparer les deux listes, vous pouvez utiliser la fonctionnalit√© de split du terminal sur VSCode pour comparer les outputs de conda env export en les mettant en face √† face.‚Ü©Ô∏é\nL‚Äôoption -c pass√©e apr√®s la commande python permet d‚Äôindiquer √† Python que la commande ne se trouve pas dans un fichier mais sera dans le texte qu‚Äôon va directement lui fournir.‚Ü©Ô∏é\nIl est tout √† fait normal de ne pas parvenir √† cr√©er une action fonctionnelle du premier coup. N‚Äôh√©sitez pas √† pusher votre code apr√®s chaque question pour v√©rifier que vous parvenez bien √† r√©aliser chaque √©tape. Sinon vous risquez de devoir corriger bout par bout un fichier plus cons√©quent.‚Ü©Ô∏é\nIl existe une approche alternative pour faire des tests r√©guliers: les hooks Git. Il s‚Äôagit de r√®gles qui doivent √™tre satisfaites pour que le fichier puisse √™tre committ√©. Cela assure que chaque commit remplisse des crit√®res de qualit√© afin d‚Äô√©viter le probl√®me de la procrastination.\nLa documentation de pylint offre des explications suppl√©mentaires. Ici, nous allons adopter une approche moins ambitieuse en demandant √† notre action de faire ce travail d‚Äô√©valuation de la qualit√© de notre code‚Ü©Ô∏é\nPar cons√©quent, MLFLow b√©n√©ficie de l‚Äôinjection automatique des tokens pour pouvoir lire/√©crire sur S3. Ces jetons ont la m√™me dur√©e avant expiration que ceux de vos services interactifs VSCode. Il faut donc, par d√©faut, supprimer et rouvrir un service MLFLow r√©guli√®rement. La mani√®re d‚Äô√©viter cela est de cr√©er des service account sur https://minio-console.lab.sspcloud.fr/ et de les renseigner sur la page.‚Ü©Ô∏é\nIl existe d‚Äôautres outils d‚Äôordonnancement de pipelines tr√®s utilis√©s dans l‚Äôindustrie, notamment Airflow.\nCe dernier est plus utilis√©, en pratique, qu‚ÄôArgo Workflow mais, m√™me s‚Äôil est disponible sur le SSPCloud aussi, est moins pens√© autour de Kubernetes que l‚Äôest Argo.\nPour mieux comprendre la diff√©rence entre Argo et Airflow, la philosphie diff√©rente de ces deux outils et leurs avantages comparatifs, cette courte vid√©o est int√©ressante:\n\n‚Ü©Ô∏é\nIl serait bien s√ªr possible d‚Äôaller beaucoup plus loin dans la d√©finition du pipeline.\nPar exemple, il est possible, si le framework utilis√© pour la mod√©lisation n‚Äôint√®gre pas la notion de pipeline au niveau de Python de faire ceci au niveau d‚ÄôArgo. Cela donnerait un pipeline prenant cette forme:\n\nN√©anmoins, ici, nous utilisons Scikit qui permet d‚Äôint√©grer le preprocessing comme une √©tape de mod√©lisation. Nous n‚Äôavons donc pas d‚Äôint√©r√™t √† d√©finir ceci comme une t√¢che autonome, raison pour laquelle notre pipeline appara√Æt plus simple.‚Ü©Ô∏é"
  }
]